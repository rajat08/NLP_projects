{"id": "37235", "url": "https://en.wikipedia.org/wiki?curid=37235", "title": "Society", "text": "Society\n\nA society is a group of individuals involved in persistent social interaction, or a large social group sharing the same spatial or social territory, typically subject to the same political authority and dominant cultural expectations. Societies are characterized by patterns of relationships (social relations) between individuals who share a distinctive culture and institutions; a given society may be described as the sum total of such relationships among its constituent of members. In the social sciences, a larger society often exhibits stratification or dominance patterns in subgroups.\n\nSocieties construct patterns of behavior by deeming certain actions or speech as acceptable or unacceptable. These patterns of behavior within a given society are known as societal norms. Societies, and their norms, undergo gradual and perpetual changes.\n\nInsofar as it is collaborative, a society can enable its members to benefit in ways that would otherwise be difficult on an individual basis; both individual and social (common) benefits can thus be distinguished, or in many cases found to overlap. A society can also consist of like-minded people governed by their own norms and values within a dominant, larger society. This is sometimes referred to as a subculture, a term used extensively within criminology.\n\nMore broadly, and especially within structuralist thought, a society may be illustrated as an economic, social, industrial or cultural infrastructure, made up of, yet distinct from, a varied collection of individuals. In this regard society can mean the objective relationships people have with the material world and with other people, rather than \"other people\" beyond the individual and their familiar social environment.\n\nThe term \"society\" came from the Latin word \"\", which in turn was derived from the noun \"socius\" (\"comrade, friend, ally\"; adjectival form \"socialis\") used to describe a bond or interaction between parties that are friendly, or at least civil. Without an article, the term can refer to the entirety of humanity (also: \"society in general\", \"society at large\", etc.), although those who are unfriendly or uncivil to the remainder of society in this sense may be deemed to be \"antisocial\". However, the Scottish economist, Adam Smith taught instead that a society \"may subsist among different men, as among different merchants, from a sense of its utility without any mutual love or affection, if only they refrain from doing injury to each other.\"\n\nUsed in the sense of an association, a society is a body of individuals outlined by the bounds of functional interdependence, possibly comprising characteristics such as national or cultural identity, social solidarity, language, or hierarchical structure.\n\nSociety, in general, addresses the fact that an individual has rather limited means as an autonomous unit. The great apes have always been more (\"Bonobo\", \"Homo\", \"Pan\") or less (\"Gorilla\", \"Pongo\") social animals, so Robinson Crusoe-like situations are either fictions or unusual corner cases to the ubiquity of social context for humans, who fall between presocial and eusocial in the spectrum of animal ethology.\n\nCultural relativism as a widespread approach or ethic has largely replaced notions of \"primitive\", better/worse, or \"progress\" in relation to cultures (including their material culture/technology and social organization).\n\nAccording to anthropologist Maurice Godelier, one critical novelty in society, in contrast to humanity's closest biological relatives (chimpanzees and bonobos), is the parental role assumed by the males, which supposedly would be absent in our nearest relatives for whom paternity is not generally determinable.\n\nSocieties may also be structured politically. In order of increasing size and complexity, there are bands, tribes, chiefdoms, and state societies. These structures may have varying degrees of political power, depending on the cultural, geographical, and historical environments that these societies must contend with. Thus, a more isolated society with the same level of technology and culture as other societies is more likely to survive than one in close proximity to others that may encroach on their resources. A society that is unable to offer an effective response to other societies it competes with will usually be subsumed into the culture of the competing society.\n\nSociologist Peter L. Berger defines society as \"...a human product, and nothing but a human product, that yet continuously acts upon its producers.\" According to him, society was created by humans, but this creation turns back and creates or molds humans every day.\nSociologist Gerhard Lenski differentiates societies based on their level of technology, communication, and economy: (1) hunters and gatherers, (2) simple agricultural, (3) advanced agricultural, (4) industrial, and (5) special (e.g. fishing societies or maritime societies). This is similar to the system earlier developed by anthropologists Morton H. Fried, a conflict theorist, and Elman Service, an integration theorist, who have produced a system of classification for societies in all human cultures based on the evolution of social inequality and the role of the state. This system of classification contains four categories:\n\nIn addition to this there are:\n\nOver time, some cultures have progressed toward more complex forms of organization and control. This cultural evolution has a profound effect on patterns of community. Hunter-gatherer tribes settled around seasonal food stocks to become agrarian villages. Villages grew to become towns and cities. Cities turned into city-states and nation-states.\n\nMany societies distribute largess at the behest of some individual or some larger group of people. This type of generosity can be seen in all known cultures; typically, prestige accrues to the generous individual or group. Conversely, members of a society may also shun or scapegoat any members of the society who violate its norms. Mechanisms such as gift-giving, joking relationships and scapegoating, which may be seen in various types of human groupings, tend to be institutionalized within a society. Social evolution as a phenomenon carries with it certain elements that could be detrimental to the population it serves.\n\nSome societies bestow status on an individual or group of people when that individual or group performs an admired or desired action. This type of recognition is bestowed in the form of a name, title, manner of dress, or monetary reward. In many societies, adult male or female status is subject to a ritual or process of this type. Altruistic action in the interests of the larger group is seen in virtually all societies. The phenomena of community action, shunning, scapegoating, generosity, shared risk, and reward are common to many forms of society.\n\nSocieties are social groups that differ according to subsistence strategies, the ways that humans use technology to provide needs for themselves. Although humans have established many types of societies throughout history, anthropologists tend to classify different societies according to the degree to which different groups within a society have unequal access to advantages such as resources, prestige, or power. Virtually all societies have developed some degree of inequality among their people through the process of social stratification, the division of members of a society into levels with unequal wealth, prestige, or power. Sociologists place societies in three broad categories: pre-industrial, industrial, and postindustrial.\n\nIn a pre-industrial society, food production, which is carried out through the use of human and animal labor, is the main economic activity. These societies can be subdivided according to their level of technology and their method of producing food. These subdivisions are hunting and gathering, pastoral, horticultural, agricultural, and feudal.\n\nThe main form of food production in such societies is the daily collection of wild plants and the hunting of wild animals. Hunter-gatherers move around constantly in search of food. As a result, they do not build permanent villages or create a wide variety of artifacts, and usually only form small groups such as bands and tribes. However, some hunting and gathering societies in areas with abundant resources (such as people of tlingit) lived in larger groups and formed complex hierarchical social structures such as chiefdom. The need for mobility also limits the size of these societies. They generally consist of fewer than 60 people and rarely exceed 100. Statuses within the tribe are relatively equal, and decisions are reached through general agreement. The ties that bind the tribe are more complex than those of the bands. Leadership is personal—charismatic—and used for special purposes only in tribal society. There are no political offices containing real power, and a chief is merely a person of influence, a sort of adviser; therefore, tribal consolidations for collective action are not governmental. The family forms the main social unit, with most members being related by birth or marriage. This type of organization requires the family to carry out most social functions, including production and education.\n\nPastoralism is a slightly more efficient form of subsistence. Rather than searching for food on a daily basis, members of a pastoral society rely on domesticated herd animals to meet their food needs. Pastoralists live a nomadic life, moving their herds from one pasture to another. Because their food supply is far more reliable, pastoral societies can support larger populations. Since there are food surpluses, fewer people are needed to produce food. As a result, the division of labor (the specialization by individuals or groups in the performance of specific economic activities) becomes more complex. For example, some people become craftworkers, producing tools, weapons, and jewelry, among other items of value. The production of goods encourages trade. This trade helps to create inequality, as some families acquire more goods than others do. These families often gain power through their increased wealth. The passing on of property from one generation to another helps to centralize wealth and power. Over time emerge hereditary chieftainships, the typical form of government in pastoral societies.\n\nFruits and vegetables grown in garden plots that have been cleared from the jungle or forest provide the main source of food in a horticultural society. These societies have a level of technology and complexity similar to pastoral societies. Some horticultural groups use the slash-and-burn method to raise crops. The wild vegetation is cut and burned, and ashes are used as fertilizers. Horticulturists use human labor and simple tools to cultivate the land for one or more seasons. When the land becomes barren, horticulturists clear a new plot and leave the old plot to revert to its natural state. They may return to the original land several years later and begin the process again. By rotating their garden plots, horticulturists can stay in one area for a fairly long period of time. This allows them to build semipermanent or permanent villages. The size of a village's population depends on the amount of land available for farming; thus villages can range from as few as 30 people to as many as 2000.\n\nAs with pastoral societies, surplus food leads to a more complex division of labor. Specialized roles in horticultural societies include craftspeople, shamans (religious leaders), and traders. This role specialization allows people to create a wide variety of artifacts. As in pastoral societies, surplus food can lead to inequalities in wealth and power within horticultural political systems, developed because of the settled nature of horticultural life.\n\nAgrarian societies use agricultural technological advances to cultivate crops over a large area. Sociologists use the phrase agricultural revolution to refer to the technological changes that occurred as long as 8,500 years ago that led to cultivating crops and raising farm animals. Increases in food supplies then led to larger populations than in earlier communities. This meant a greater surplus, which resulted in towns that became centers of trade supporting various rulers, educators, craftspeople, merchants, and religious leaders who did not have to worry about locating nourishment.\n\nGreater degrees of social stratification appeared in agrarian societies. For example, women previously had higher social status because they shared labor more equally with men. In hunting and gathering societies, women even gathered more food than men. However, as food stores improved and women took on lesser roles in providing food for the family, they increasingly became subordinate to men. As villages and towns expanded into neighboring areas, conflicts with other communities inevitably occurred. Farmers provided warriors with food in exchange for protection against invasion by enemies. A system of rulers with high social status also appeared. This nobility organized warriors to protect the society from invasion. In this way, the nobility managed to extract goods from \"lesser\" members of society.\n\nFeudalism was a form of society based on ownership of land. Unlike today's farmers, vassals under feudalism were bound to cultivating their lord's land. In exchange for military protection, the lords exploited the peasants into providing food, crops, crafts, homage, and other services to the landowner. The estates of the realm system of feudalism was often multigenerational; the families of peasants may have cultivated their lord's land for generations.\n\nBetween the 15th and 16th centuries, a new economic system emerged that began to replace feudalism. Capitalism is marked by open competition in a free market, in which the means of production are privately owned. Europe's exploration of the Americas served as one impetus for the development of capitalism. The introduction of foreign metals, silks, and spices stimulated great commercial activity in European societies.\n\nIndustrial societies rely heavily on machines powered by fuels for the production of goods. This produced further dramatic increases in efficiency. The increased efficiency of production of the industrial revolution produced an even greater surplus than before. Now the surplus was not just agricultural goods, but also manufactured goods. This larger surplus caused all of the changes discussed earlier in the domestication revolution to become even more pronounced.\n\nOnce again, the population boomed. Increased productivity made more goods available to everyone. However, inequality became even greater than before. The breakup of agricultural-based feudal societies caused many people to leave the land and seek employment in cities. This created a great surplus of labor and gave capitalists plenty of laborers who could be hired for extremely low wages.\n\nPost-industrial societies are societies dominated by information, services, and high technology more than the production of goods. Advanced industrial societies are now seeing a shift toward an increase in service sectors over manufacturing and production. The United States is the first country to have over half of its work force employed in service industries. Service industries include government, research, education, health, sales, law, and banking.\n\nThe term \"society\" is currently used to cover both a number of political and scientific connotations as well as a variety of associations.\n\nThe development of the Western world has brought with it the emerging concepts of Western culture, politics, and ideas, often referred to simply as \"Western society\". Geographically, it covers at the very least the countries of Western Europe, North America, Australia, and New Zealand. It sometimes also includes Eastern Europe, South America, and Israel.\n\nThe cultures and lifestyles of all of these stem from Western Europe. They all enjoy relatively strong economies and stable governments, allow freedom of religion, have chosen democracy as a form of governance, favor capitalism and international trade, are heavily influenced by Judeo-Christian values, and have some form of political and military alliance or cooperation.\n\nAlthough the concept of information society has been under discussion since the 1930s, in the modern world it is almost always applied to the manner in which information technologies have impacted society and culture. It therefore covers the effects of computers and telecommunications on the home, the workplace, schools, government, and various communities and organizations, as well as the emergence of new social forms in cyberspace.\n\nOne of the European Union's areas of interest is the information society. Here policies are directed towards promoting an open and competitive digital economy, research into information and communication technologies, as well as their application to improve social inclusion, public services, and quality of life.\n\nThe International Telecommunications Union's World Summit on the Information Society in Geneva and Tunis (2003 and 2005) has led to a number of policy and application areas where action is envisaged.\n\nAs access to electronic information resources increased at the beginning of the 21st century, special attention was extended from the information society to the knowledge society. An analysis by the Irish government stated, \"The capacity to manipulate, store and transmit large quantities of information cheaply has increased at a staggering rate over recent years. The digitisation of information and the associated pervasiveness of the Internet are facilitating a new intensity in the application of knowledge to economic activity, to the extent that it has become the predominant factor in the creation of wealth. As much as 70 to 80 percent of economic growth is now said to be due to new and better knowledge.\"\n\nPeople of many nations united by common political and cultural traditions, beliefs, or values are sometimes also said to form a society (such as Judeo-Christian, Eastern, and Western). When used in this context, the term is employed as a means of contrasting two or more \"societies\" whose members represent alternative conflicting and competing worldviews.\n\nSome academic, professional, and scientific associations describe themselves as \"societies\" (for example, the American Mathematical Society, the American Society of Civil Engineers, or the Royal Society).\n\nIn some countries, e.g. the United States, France, and Latin America, the term \"society' is used in commerce to denote a partnership between investors or the start of a business. In the United Kingdom, partnerships are not called societies, but co-operatives or mutuals are often known as societies (such as friendly societies and building societies).\n\n\n\n"}
{"id": "5695", "url": "https://en.wikipedia.org/wiki?curid=5695", "title": "Community", "text": "Community\n\nA community is a social unit (a group of living things) with commonality such as norms, religion, values, customs, or identity. Communities may share a sense of place situated in a given geographical area (e.g. a country, village, town, or neighbourhood) or in virtual space through communication platforms. Durable relations that extend beyond immediate genealogical ties also define a sense of community, important to their identity, practice, and roles in social institutions such as family, home, work, government, society, or humanity at large. Although communities are usually small relative to personal social ties, \"community\" may also refer to large group affiliations such as national communities, international communities, and virtual communities.\n\nThe English-language word \"community\" derives from the Old French \"comuneté\", which comes from the Latin \"communitas\" \"community\", \"public spirit\" (from Latin \"communis\", \"shared in common word\").\n\nHuman communities may share intent, belief, resources, preferences, needs, and risks in common, affecting the identity of the participants and their degree of cohesiveness.\n\nArchaeological studies of social communities use the term \"community\" in two ways, paralleling usage in other areas. The first is an informal definition of community as a place where people used to live. In this sense it is synonymous with the concept of an ancient settlement - whether a hamlet, village, town, or city. The second meaning resembles the usage of the term in other social sciences: a community is a group of people living near one another who interact socially. Social interaction on a small scale can be difficult to identify with archaeological data. Most reconstructions of social communities by archaeologists rely on the principle that social interaction in the past was conditioned by physical distance. Therefore, a small village settlement likely constituted a social community, and spatial subdivisions of cities and other large settlements may have formed communities. Archaeologists typically use similarities in material culture—from house types to styles of pottery—to reconstruct communities in the past. This classification method relies on the assumption that people or households will share more similarities in the types and styles of their material goods with other members of a social community than they will with outsiders.\n\nIn ecology, a community is an assemblage of populations of different species, interacting with one another. Community ecology is the branch of ecology that studies interactions between and among species. It considers how such interactions, along with interactions between species and the abiotic environment, affect community structure and species richness, diversity and patterns of abundance. Species interact in three ways: competition, predation and mutualism. Competition typically results in a double negative—that is both species lose in the interaction. Predation is a win/lose situation with one species winning. Mutualism, on the other hand, involves both species cooperating in some way, with both winning. The two main types of communities are major which are self-sustaining and self-regulating (such as a forest or a lake) and minor communities which rely on other communities (like fungi decomposing a log) and are the building blocks of major communities.\n\nIn \"Gemeinschaft und Gesellschaft\" (1887), German sociologist Ferdinand Tönnies described two types of human association: \"Gemeinschaft\" (usually translated as \"community\") and \"Gesellschaft\" (\"society\" or \"association\"). Tönnies proposed the \"Gemeinschaft–Gesellschaft\" dichotomy as a way to think about social ties. No group is exclusively one or the other. \"Gemeinschaft\" stress personal social interactions, and the roles, values, and beliefs based on such interactions. \"Gesellschaft\" stress indirect interactions, impersonal roles, formal values, and beliefs based on such interactions.\n\nIn a seminal 1986 study, McMillan and Chavis identify four elements of \"sense of community\":\n\n\nA \"sense of community index\" (SCI) was developed by Chavis and colleagues, and revised and adapted by others. Although originally designed to assess sense of community in neighborhoods, the index has been adapted for use in schools, the workplace, and a variety of types of communities.\n\nStudies conducted by the APPA indicate that young adults who feel a sense of belonging in a community, particularly small communities, develop fewer psychiatric and depressive disorders than those who do not have the feeling of love and belonging.\n\nThe process of learning to adopt the behavior patterns of the community is called socialization. The most fertile time of socialization is usually the early stages of life, during which individuals develop the skills and knowledge and learn the roles necessary to function within their culture and social environment. For some psychologists, especially those in the psychodynamic tradition, the most important period of socialization is between the ages of one and ten. But socialization also includes adults moving into a significantly different environment, where they must learn a new set of behaviors.\n\nSocialization is influenced primarily by the family, through which children first learn community norms. Other important influences include schools, peer groups, people, mass media, the workplace, and government. The degree to which the norms of a particular society or community are adopted determines one's willingness to engage with others. The norms of tolerance, reciprocity, and trust are important \"habits of the heart,\" as de Tocqueville put it, in an individual's involvement in community.\n\nCommunity development is often linked with community work or community planning, and may involve stakeholders, foundations, governments, or contracted entities including non-government organisations (NGOs), universities or government agencies to progress the social well-being of local, regional and, sometimes, national communities. More grassroots efforts, called community building or community organizing, seek to empower individuals and groups of people by providing them with the skills they need to effect change in their own communities. These skills often assist in building political power through the formation of large social groups working for a common agenda. Community development practitioners must understand both how to work with individuals and how to affect communities' positions within the context of larger social institutions. Public administrators, in contrast, need to understand community development in the context of rural and urban development, housing and economic development, and community, organizational and business development.\n\nFormal accredited programs conducted by universities, as part of degree granting institutions, are often used to build a knowledge base to drive curricula in public administration, sociology and community studies. The General Social Survey from the National Opinion Research Center at the University of Chicago and the Saguaro Seminar at the John F. Kennedy School of Government at Harvard University are examples of national community development in the United States. The Maxwell School of Citizenship and Public Affairs at Syracuse University in New York State offers core courses in community and economic development, and in areas ranging from non-profit development to US budgeting (federal to local, community funds). In the United Kingdom, Oxford University has led in providing extensive research in the field through its \" Community Development Journal,\" used worldwide by sociologists and community development practitioners.\n\nAt the intersection between community \"development\" and community \"building\" are a number of programs and organizations with community development tools. One example of this is the program of the Asset Based Community Development Institute of Northwestern University. The institute makes available downloadable tools to assess community assets and make connections between non-profit groups and other organizations that can help in community building. The Institute focuses on helping communities develop by \"mobilizing neighborhood assets\" – building from the inside out rather than the outside in. In the disability field, community building was prevalent in the 1980s and 1990s with roots in John McKnight's approaches.\n\nIn \"The Different Drum: Community-Making and Peace\" (1987) Scott Peck argues that the almost accidental sense of community that exists at times of crisis can be consciously built. Peck believes that conscious community building is a process of deliberate design based on the knowledge and application of certain rules. He states that this process goes through four stages:\n\nIn 1991, Peck remarked that building a sense of community is easy but maintaining this sense of community is difficult in the modern world.\n\nThe three basic types of community organizing are grassroots organizing, coalition building, and \"institution-based community organizing,\" (also called \"broad-based community organizing,\" an example of which is faith-based community organizing, or Congregation-based Community Organizing).\n\nCommunity building can use a wide variety of practices, ranging from simple events (e.g., potlucks, small book clubs) to larger-scale efforts (e.g., mass festivals, construction projects that involve local participants rather than outside contractors).\n\nCommunity building that is geared toward citizen action is usually termed \"community organizing.\" In these cases, organized community groups seek accountability from elected officials and increased direct representation within decision-making bodies. Where good-faith negotiations fail, these constituency-led organizations seek to pressure the decision-makers through a variety of means, including picketing, boycotting, sit-ins, petitioning, and electoral politics. \n\nCommunity organizing can focus on more than just resolving specific issues. Organizing often means building a widely accessible power structure, often with the end goal of distributing power equally throughout the community. Community organizers generally seek to build groups that are open and democratic in governance. Such groups facilitate and encourage consensus decision-making with a focus on the general health of the community rather than a specific interest group.\n\nIf communities are developed based on something they share in common, whether location or values, then one challenge for developing communities is how to incorporate individuality and differences. Rebekah Nathan suggests in her book, \"My Freshman Year\", we are drawn to developing communities totally based on sameness, despite stated commitments to diversity, such as those found on university websites.\n\nSome communities have developed their own local exchange trading systems (LETS) and local currencies, such as the Ithaca Hours system, to encourage economic growth and an enhanced sense of community. Community currencies have recently proven valuable in meeting the needs of people living in various South American nations, particularly Argentina, that recently suffered as a result of the collapse of the Argentinian national currency.\n\nA number of ways to categorize types of community have been proposed. One such breakdown is as follows:\n\n\nThe usual categorizations of community relations have a number of problems: (1) they tend to give the impression that a particular community can be defined as just this kind or another; (2) they tend to conflate modern and customary community relations; (3) they tend to take sociological categories such as ethnicity or race as given, forgetting that different ethnically defined persons live in different kinds of communities —grounded, interest-based, diasporic, etc.\n\nIn response to these problems, Paul James and his colleagues have developed a taxonomy that maps community relations, and recognizes that actual communities can be characterized by different kinds of relations at the same time:\n\n\nIn these terms, communities can be nested and/or intersecting; one community can contain another—for example a location-based community may contain a number of ethnic communities. Both lists above can used in a cross-cutting matrix in relation to each other.\n\nIn general, virtual communities value knowledge and information as currency or social resource. What differentiates virtual communities from their physical counterparts is the extent and impact of \"weak ties,\" which are the relationships acquaintances or strangers form to acquire information through online networks. Relationships among members in a virtual community tend to focus on information exchange about specific topics. A survey conducted by Pew Internet and The American Life Project in 2001 found those involved in entertainment, professional, and sports virtual groups focused their activities on obtaining information. \n\nAn epidemic of bullying and harassment has arisen from the exchange of information between strangers, especially among teenagers, in virtual communities. Despite attempts to implement anti-bullying policies, Sheri Bauman, professor of counselling at the University of Arizona, claims the \"most effective strategies to prevent bullying\" may cost companies revenue.\n\n\n"}
{"id": "53132", "url": "https://en.wikipedia.org/wiki?curid=53132", "title": "Humanities", "text": "Humanities\n\nHumanities are academic disciplines that study aspects of human society and culture. In the Renaissance, the term contrasted with divinity and referred to what is now called classics, the main area of secular study in universities at the time. Today, the humanities are more frequently contrasted with natural, and sometimes social sciences, as well as professional training.\n\nThe humanities use methods that are primarily critical, or speculative, and have a significant historical element—as distinguished from the mainly empirical approaches of the natural sciences, yet, unlike the sciences, it has no central discipline.\nThe humanities include ancient and modern languages, literature, philosophy, history, human geography, law, politics, religion, and art.\n\nScholars in the humanities are \"humanity scholars\" or \"humanists\". The term \"humanist\" also describes the philosophical position of humanism, which some \"antihumanist\" scholars in the humanities reject. The Renaissance scholars and artists were also called humanists. Some secondary schools offer humanities classes usually consisting of literature, global studies and art.\n\nHuman disciplines like history, folkloristics, and cultural anthropology study subject matters that the manipulative experimental method does not apply to—and instead mainly use the comparative method and comparative research.\n\nAnthropology is the holistic \"science of humans\", a science of the totality of human existence. The discipline deals with the integration of different aspects of the social sciences, humanities and human biology. In the twentieth century, academic disciplines have often been institutionally divided into three broad domains. The natural \"sciences\" seek to derive general laws through reproducible and verifiable experiments. The \"humanities\" generally study local traditions, through their history, literature, music, and arts, with an emphasis on understanding particular individuals, events, or eras. The \"social sciences\" have generally attempted to develop scientific methods to understand social phenomena in a generalizable way, though usually with methods distinct from those of the natural sciences.\n\nThe anthropological social sciences often develop nuanced descriptions rather than the general laws derived in physics or chemistry, or they may explain individual cases through more general principles, as in many fields of psychology. Anthropology (like some fields of history) does not easily fit into one of these categories, and different branches of anthropology draw on one or more of these domains. Within the United States, anthropology is divided into four sub-fields: archaeology, physical or biological anthropology, anthropological linguistics, and cultural anthropology. It is an area that is offered at most undergraduate institutions. The word \"anthropos\" (άνθρωπος) is from the Greek for \"human being\" or \"person\". Eric Wolf described sociocultural anthropology as \"the most scientific of the humanities, and the most humanistic of the sciences\".\n\nThe goal of anthropology is to provide a holistic account of humans and human nature. This means that, though anthropologists generally specialize in only one sub-field, they always keep in mind the biological, linguistic, historic and cultural aspects of any problem. Since anthropology arose as a science in Western societies that were complex and industrial, a major trend within anthropology has been a methodological drive to study peoples in societies with more simple social organization, sometimes called \"primitive\" in anthropological literature, but without any connotation of \"inferior\". Today, anthropologists use terms such as \"less complex\" societies, or refer to specific modes of subsistence or production, such as \"pastoralist\" or \"forager\" or \"horticulturalist\", to discuss humans living in non-industrial, non-Western cultures, such people or folk (\"ethnos\") remaining of great interest within anthropology.\n\nThe quest for holism leads most anthropologists to study a people in detail, using biogenetic, archaeological, and linguistic data alongside direct observation of contemporary customs. In the 1990s and 2000s, calls for clarification of what constitutes a culture, of how an observer knows where his or her own culture ends and another begins, and other crucial topics in writing anthropology were heard. It is possible to view all human cultures as part of one large, evolving global culture. These dynamic relationships, between what can be observed on the ground, as opposed to what can be observed by compiling many local observations remain fundamental in any kind of anthropology, whether cultural, biological, linguistic or archaeological.\n\nArchaeology is the study of human activity through the recovery and analysis of material culture. The archaeological record consists of artifacts, architecture, biofacts or ecofacts, and cultural landscapes. Archaeology can be considered both a social science and a branch of the humanities. It has various goals, which range from understanding culture history to reconstructing past lifeways to documenting and explaining changes in human societies through time.\n\nArchaeology is thought of as a branch of anthropology in the United States, while in Europe, it is viewed as a discipline in its own right, or grouped under other related disciplines such as history.\n\nClassics, in the Western academic tradition, refers to the studies of the cultures of classical antiquity, namely Ancient Greek and Latin and the Ancient Greek and Roman cultures. Classical studies is considered one of the cornerstones of the humanities; however, its popularity declined during the 20th century. Nevertheless, the influence of classical ideas on many humanities disciplines, such as philosophy and literature, remains strong.\n\nHistory is systematically collected information about the past. When used as the name of a field of study, \"history\" refers to the study and interpretation of the record of humans, societies, institutions, and any topic that has changed over time.\n\nTraditionally, the study of history has been considered a part of the humanities. In modern academia, history is occasionally classified as a social science.\n\nWhile the scientific study of language is known as linguistics and is generally considered a social science, a natural science or a cognitive science, the study of languages is still central to the humanities. A good deal of twentieth-century and twenty-first-century philosophy has been devoted to the analysis of language and to the question of whether, as Wittgenstein claimed, many of our philosophical confusions derive from the vocabulary we use; literary theory has explored the rhetorical, associative, and ordering features of language; and historical linguists have studied the development of languages across time. Literature, covering a variety of uses of language including prose forms (such as the novel), poetry and drama, also lies at the heart of the modern humanities curriculum. College-level programs in a foreign language usually include study of important works of the literature in that language, as well as the language itself.\n\n In common parlance, law means a rule that (unlike a rule of ethics) is enforceable through institutions. The study of law crosses the boundaries between the social sciences and humanities, depending on one's view of research into its objectives and effects. Law is not always enforceable, especially in the international relations context. It has been defined as a \"system of rules\", as an \"interpretive concept\" to achieve justice, as an \"authority\" to mediate people's interests, and even as \"the command of a sovereign, backed by the threat of a sanction\". However one likes to think of law, it is a completely central social institution. Legal policy incorporates the practical manifestation of thinking from almost every social science and discipline of the humanities. Laws are politics, because politicians create them. Law is philosophy, because moral and ethical persuasions shape their ideas. Law tells many of history's stories, because statutes, case law and codifications build up over time. And law is economics, because any rule about contract, tort, property law, labour law, company law and many more can have long-lasting effects on how productivity is organised and the distribution of wealth. The noun \"law\" derives from the late Old English \"lagu\", meaning something laid down or fixed, and the adjective \"legal\" comes from the Latin word \"LEX\".\n\n Literature is a term that does not have a universally accepted definition, but which has variably included all written work; writing that possesses literary merit; and language that foregrounds literariness, as opposed to ordinary language. Etymologically the term derives from Latin \"literatura/litteratura\" \"writing formed with letters\", although some definitions include spoken or sung texts. Literature can be classified according to whether it is fiction or non-fiction, and whether it is poetry or prose; it can be further distinguished according to major forms such as the novel, short story or drama; and works are often categorised according to historical periods, or according to their adherence to certain aesthetic features or expectations (genre).\n\nPhilosophy—etymologically, the \"love of wisdom\"—is generally the study of problems concerning matters such as existence, knowledge, justification, truth, justice, right and wrong, beauty, validity, mind, and language. Philosophy is distinguished from other ways of addressing these issues by its critical, generally systematic approach and its reliance on reasoned argument, rather than experiments (experimental philosophy being an exception).\n\nPhilosophy used to be a very comprehensive term, including what have subsequently become separate disciplines, such as physics. (As Immanuel Kant noted, \"Ancient Greek philosophy was divided into three sciences: physics, ethics, and logic.\") Today, the main fields of philosophy are logic, ethics, metaphysics, and epistemology. Still, it continues to overlap with other disciplines. The field of semantics, for example, brings philosophy into contact with linguistics.\n\nSince the early twentieth century, philosophy in English-speaking universities has moved away from the humanities and closer to the formal sciences, becoming much more \"analytic.\" Analytic philosophy is marked by emphasis on the use of logic and formal methods of reasoning, conceptual analysis, and the use of symbolic and/or mathematical logic, as contrasted with the Continental style of philosophy. This method of inquiry is largely indebted to the work of philosophers such as Gottlob Frege, Bertrand Russell, G.E. Moore, Georg Wilhelm Friedrich Hegel and Ludwig Wittgenstein.\n\nNew philosophies and religions arose in both east and west, particularly around the 6th century BC. Over time, a great variety of religions developed around the world, with Hinduism, Jainism, and Buddhism in India, and Zoroastrianism in Persia being some of the earliest major faiths. In the east, three schools of thought were to dominate Chinese thinking until the modern day. These were Taoism, Legalism, and Confucianism. The Confucian tradition, which would attain predominance, looked not to the force of law, but to the power and example of tradition for political morality. In the west, the Greek philosophical tradition, represented by the works of Plato and Aristotle, was diffused throughout Europe and the Middle East by the conquests of Alexander of Macedon in the 4th century BC.\n\nAbrahamic religions are those religions deriving from a common ancient tradition and traced by their adherents to Abraham (circa 1900 BCE), a patriarch whose life is narrated in the Hebrew Bible/Old Testament, where he is described as a prophet (Genesis 20:7), and in the Quran, where he also appears as a prophet. This forms a large group of related largely monotheistic religions, generally held to include Judaism, Christianity, and Islam, and comprises over half of the world's religious adherents.\n\nThe performing arts differ from the visual arts in so far as the former uses the artist's own body, face, and presence as a medium, and the latter uses materials such as clay, metal, or paint, which can be molded or transformed to create some art object. Performing arts include acrobatics, busking, comedy, dance, film, magic, music, opera, juggling, marching arts, such as brass bands, and theatre.\n\nArtists who participate in these arts in front of an audience are called performers, including actors, comedians, dancers, musicians, and singers. Performing arts are also supported by workers in related fields, such as songwriting and stagecraft. Performers often adapt their appearance, such as with costumes and stage makeup, etc. There is also a specialized form of fine art in which the artists \"perform\" their work live to an audience. This is called Performance art. Most performance art also involves some form of plastic art, perhaps in the creation of props. Dance was often referred to as a \"plastic art\" during the Modern dance era.\n\nMusicology as an academic discipline can take a number of different paths, including historical musicology, ethnomusicology and music theory. Undergraduate music majors generally take courses in all of these areas, while graduate students focus on a particular path. In the liberal arts tradition, musicology is also used to broaden skills of non-musicians by teaching skills such as concentration and listening.\n\nTheatre (or theater) (Greek \"theatron\", \"θέατρον\") is the branch of the performing arts concerned with acting out stories in front of an audience using combinations of speech, gesture, music, dance, sound and spectacle — indeed any one or more elements of the other performing arts. In addition to the standard narrative dialogue style, theatre takes such forms as opera, ballet, mime, kabuki, classical Indian dance, Chinese opera, mummers' plays, and pantomime.\n\nDance (from Old French \"dancier\", perhaps from Frankish) generally refers to human movement either used as a form of expression or presented in a social, spiritual or performance setting. Dance is also used to describe methods of non-verbal communication (see body language) between humans or animals (bee dance, mating dance), and motion in inanimate objects (\"the leaves danced in the wind\"). Choreography is the art of creating dances, and the person who does this is called a choreographer.\n\nDefinitions of what constitutes dance are dependent on social, cultural, aesthetic, artistic, and moral constraints and range from functional movement (such as Folk dance) to codified, virtuoso techniques such as ballet.\n\nThe great traditions in art have a foundation in the art of one of the ancient civilizations, such as Ancient Japan, Greece and Rome, China, India, Greater Nepal, Mesopotamia and Mesoamerica.\n\nAncient Greek art saw a veneration of the human physical form and the development of equivalent skills to show musculature, poise, beauty and anatomically correct proportions. Ancient Roman art depicted gods as idealized humans, shown with characteristic distinguishing features (e.g., Zeus' thunderbolt).\n\nIn Byzantine and Gothic art of the Middle Ages, the dominance of the church insisted on the expression of biblical and not material truths. The Renaissance saw the return to valuation of the material world, and this shift is reflected in art forms, which show the corporeality of the human body, and the three-dimensional reality of landscape.\n\nEastern art has generally worked in a style akin to Western medieval art, namely a concentration on surface patterning and local colour (meaning the plain colour of an object, such as basic red for a red robe, rather than the modulations of that colour brought about by light, shade and reflection). A characteristic of this style is that the local colour is often defined by an outline (a contemporary equivalent is the cartoon). This is evident in, for example, the art of India, Tibet and Japan.\n\nReligious Islamic art forbids iconography, and expresses religious ideas through geometry instead. The physical and rational certainties depicted by the 19th-century Enlightenment were shattered not only by new discoveries of relativity by Einstein and of unseen psychology by Freud, but also by unprecedented technological development. Increasing global interaction during this time saw an equivalent influence of other cultures into Western art.\n\nDrawing is a means of making a picture, using any of a wide variety of tools and techniques. It generally involves making marks on a surface by applying pressure from a tool, or moving a tool across a surface. Common tools are graphite pencils, pen and ink, inked brushes, wax color pencils, crayons, charcoals, pastels, and markers. Digital tools that simulate the effects of these are also used. The main techniques used in drawing are: line drawing, hatching, crosshatching, random hatching, scribbling, stippling, and blending. A computer aided designer who excels in technical drawing is referred to as a \"draftsman\" or \"draughtsman\".\n\nPainting taken literally is the practice of applying pigment suspended in a carrier (or medium) and a binding agent (a glue) to a surface (support) such as paper, canvas or a wall. However, when used in an artistic sense it means the use of this activity in combination with drawing, composition and other aesthetic considerations in order to manifest the expressive and conceptual intention of the practitioner. Painting is also used to express spiritual motifs and ideas; sites of this kind of painting range from artwork depicting mythological figures on pottery to The Sistine Chapel to the human body itself.\n\nColour is highly subjective, but has observable psychological effects, although these can differ from one culture to the next. Black is associated with mourning in the West, but elsewhere white may be. Some painters, theoreticians, writers and scientists, including Goethe, Kandinsky, Isaac Newton, have written their own colour theories. Moreover, the use of language is only a generalization for a colour equivalent. The word \"red\", for example, can cover a wide range of variations on the pure red of the spectrum. There is not a formalized register of different colours in the way that there is agreement on different notes in music, such as C or C# in music, although the Pantone system is widely used in the printing and design industry for this purpose.\n\nModern artists have extended the practice of painting considerably to include, for example, collage. This began with cubism and is not painting in strict sense. Some modern painters incorporate different materials such as sand, cement, straw or wood for their texture. Examples of this are the works of Jean Dubuffet or Anselm Kiefer. Modern and contemporary art has moved away from the historic value of craft in favour of concept; this has led some to say that painting, as a serious art form, is dead, although this has not deterred the majority of artists from continuing to practise it either as whole or part of their work.\n\nThe word \"humanities\" is derived from the Renaissance Latin expression \"studia humanitatis\", or \"study of \"humanitas\"\" (a classical Latin word meaning—in addition to \"humanity\"—\"culture, refinement, education\" and, specifically, an \"education befitting a cultivated man\"). In its usage in the early 15th century, the \"studia humanitatis\" was a course of studies that consisted of grammar, poetry, rhetoric, history, and moral philosophy, primarily derived from the study of Latin and Greek classics. The word \"humanitas\" also gave rise to the Renaissance Italian neologism \"umanisti\", whence \"humanist\", \"Renaissance humanism\".\n\nIn the West, the study of the humanities can be traced to ancient Greece, as the basis of a broad education for citizens. During Roman times, the concept of the seven liberal arts evolved, involving grammar, rhetoric and logic (the trivium), along with arithmetic, geometry, astronomy and music (the quadrivium). These subjects formed the bulk of medieval education, with the emphasis being on the humanities as skills or \"ways of doing\".\n\nA major shift occurred with the Renaissance humanism of the fifteenth century, when the humanities began to be regarded as subjects to study rather than practice, with a corresponding shift away from traditional fields into areas such as literature and history. In the 20th century, this view was in turn challenged by the postmodernist movement, which sought to redefine the humanities in more egalitarian terms suitable for a democratic society since the Greek and Roman societies in which the humanities originated were not at all democratic. This was in keeping with the postmodernists' nuanced view of themselves as the culmination of history.\n\nFor many decades, there has been a growing public perception that a humanities education inadequately prepares graduates for employment. The common belief is that graduates from such programs face underemployment and incomes too low for a humanities education to be worth the investment.\n\nIn fact, humanities graduates find employment in a wide variety of management and professional occupations. In Britain, for example, over 11,000 humanities majors found employment in the following occupations:\nMany humanities graduates finish university with no career goals in mind. Consequently, many spend the first few years after graduation deciding what to do next, resulting in lower incomes at the start of their career; meanwhile, graduates from career-oriented programs experience more rapid entry into the labour market. However, usually within five years of graduation, humanities graduates find an occupation or career path that appeals to them.\n\nThere is empirical evidence that graduates from humanities programs earn less than graduates from other university programs. However, the empirical evidence also shows that humanities graduates still earn notably higher incomes than workers with no postsecondary education, and have job satisfaction levels comparable to their peers from other fields. Humanities graduates also earn more as their careers progress; ten years after graduation, the income difference between humanities graduates and graduates from other university programs is no longer statistically significant. Humanities graduates can earn even higher incomes if they obtain advanced or professional degrees.\n\nThe Humanities Indicators, unveiled in 2009 by the American Academy of Arts and Sciences, are the first comprehensive compilation of data about the humanities in the United States, providing scholars, policymakers and the public with detailed information on humanities education from primary to higher education, the humanities workforce, humanities funding and research, and public humanities activities. Modeled after the National Science Board's Science and Engineering Indicators, the Humanities Indicators are a source of reliable benchmarks to guide analysis of the state of the humanities in the United States.\n\nIf \"The STEM Crisis Is a Myth\", statements about a \"crisis\" in the humanities are also misleading and ignore data of the sort collected by the Humanities Indicators.\n\nThe 1980 United States Rockefeller Commission on the Humanities described the humanities in its report, \"The Humanities in American Life\":\nThrough the humanities we reflect on the fundamental question: What does it mean to be human? The humanities offer clues but never a complete answer. They reveal how people have tried to make moral, spiritual, and intellectual sense of a world where irrationality, despair, loneliness, and death are as conspicuous as birth, friendship, hope, and reason.\n\nIn 1950, a little over 1 percent of 22-year-olds in the United States had earned a humanities degrees (defined as a degree in English, language, history, philosophy); in 2010, this had doubled to about 2 and a half percent. In part, this is because there was an overall rise in the number of Americans who have any kind of college degree. (In 1940, 4.6 percent had a four-year degree; in 2016, 33.4 percent had one.) As a percentage of the type of degrees awarded, however, the humanities seem to be declining. Harvard University provides one example. In 1954, 36 percent of Harvard undergraduates majored in the humanities, but in 2012, only 20 percent took that course of study. Professor Benjamin Schmidt of Northeastern University has documented that between 1990 and 2008, degrees in English, history, foreign languages, and philosophy have decreased from 8 percent to just under 5 percent of all U.S. college degrees.\n\nThe Commission on the Humanities and Social Sciences 2013 report \"The Heart of the Matter\" supports the notion of a broad \"liberal arts education\", which includes study in disciplines from the natural sciences to the arts as well as the humanities.\n\nMany colleges provide such an education; some require it. The University of Chicago and Columbia University were among the first schools to require an extensive core curriculum in philosophy, literature, and the arts for all students. Other colleges with nationally recognized, mandatory programs in the liberal arts are Fordham University, St. John's College, Saint Anselm College and Providence College. Prominent proponents of liberal arts in the United States have included Mortimer J. Adler and E. D. Hirsch, Jr..\n\nResearchers in the humanities have developed numerous large- and small-scale digital corporation, such as digitized collections of historical texts, along with the digital tools and methods to analyze them. Their aim is both to uncover new knowledge about corpora and to visualize research data in new and revealing ways. Much of this activity occurs in a field called the digital humanities.\n\nPoliticians in the United States currently espouse a need for increased funding of the STEM fields, science, technology, engineering, mathematics. Federal funding represents a much smaller fraction of funding for humanities than other fields such as STEM or medicine. The result was a decline of quality in both college and pre-college education in the humanities field.\n\nFormer four-term Louisiana Governor, Edwin Edwards (D), has recently acknowledged the importance of the humanities. In a video address to the academic conference, \"Revolutions in Eighteenth-Century Sociability\", Edwards said\n\nThe contemporary debate in the field of critical university studies centers around the declining value of the humanities. As in America, there is a perceived decline in interest within higher education policy in research that is qualitative and does not produce marketable products. This threat can be seen in a variety of forms across Europe, but much critical attention has been given to the field of research assessment in particular. For example, the UK [Research Excellence Framework] has been subject to criticism due to its assessment criteria from across the humanities, and indeed, the social sciences. In particular, the notion of \"impact\" has generated significant debate.\n\nIn India, there are many institutions that offer undergraduate UG or bachelor's degree/diploma and postgraduate PG or master's degree/diploma as well as doctoral PhD and postdoctoral studies and research, in this academic discipline.\n\nSince the late 19th century, a central justification for the humanities has been that it aids and encourages self-reflection—a self-reflection that, in turn, helps develop personal consciousness or an active sense of civic duty.\n\nWilhelm Dilthey and Hans-Georg Gadamer centered the humanities' attempt to distinguish itself from the natural sciences in humankind's urge to understand its own experiences. This understanding, they claimed, ties like-minded people from similar cultural backgrounds together and provides a sense of cultural continuity with the philosophical past.\n\nScholars in the late 20th and early 21st centuries extended that \"narrative imagination\" to the ability to understand the records of lived experiences outside of one's own individual social and cultural context. Through that narrative imagination, it is claimed, humanities scholars and students develop a conscience more suited to the multicultural world we live in. That conscience might take the form of a passive one that allows more effective self-reflection or extend into active empathy that facilitates the dispensation of civic duties a responsible world citizen must engage in. There is disagreement, however, on the level of influence humanities study can have on an individual and whether or not the understanding produced in humanistic enterprise can guarantee an \"identifiable positive effect on people.\"\n\nThere are three major branches of knowledge: natural sciences, social sciences, and the humanities. Technology is the practical extension of the natural sciences, as politics is the extension of the social sciences. Similarly, the humanities have their own practical extension, sometimes called \"transformative humanities\" (transhumanities) or \"culturonics\" (Mikhail Epstein's term):\nTechnology, politics and culturonics are designed to transform what their respective disciplines study: nature, society, and culture. The field of transformative humanities includes various practicies and technologies, for example, language planning, the construction of new languages, like Esperanto, and invention of new artistic and literary genres and movements in the genre of manifesto, like Romanticism, Symbolism, or Surrealism. Humanistic invention in the sphere of culture, as a practice complementary to scholarship, is an important aspect of the humanities.\n\nThe divide between humanistic study and natural sciences informs arguments of meaning in humanities as well. What distinguishes the humanities from the natural sciences is not a certain subject matter, but rather the mode of approach to any question. Humanities focuses on understanding meaning, purpose, and goals and furthers the appreciation of singular historical and social phenomena—an interpretive method of finding \"truth\"—rather than explaining the causality of events or uncovering the truth of the natural world. Apart from its societal application, narrative imagination is an important tool in the (re)production of understood meaning in history, culture and literature.\n\nImagination, as part of the tool kit of artists or scholars, helps create meaning that invokes a response from an audience. Since a humanities scholar is always within the nexus of lived experiences, no \"absolute\" knowledge is theoretically possible; knowledge is instead a ceaseless procedure of inventing and reinventing the context a text is read in. Poststructuralism has problematized an approach to the humanistic study based on questions of meaning, intentionality, and authorship. In the wake of the death of the author proclaimed by Roland Barthes, various theoretical currents such as deconstruction and discourse analysis seek to expose the ideologies and rhetoric operative in producing both the purportedly meaningful objects and the hermeneutic subjects of humanistic study. This exposure has opened up the interpretive structures of the humanities to criticism that humanities scholarship is \"unscientific\" and therefore unfit for inclusion in modern university curricula because of the very nature of its changing contextual meaning.\n\nSome, like Stanley Fish, have claimed that the humanities can defend themselves best by refusing to make any claims of utility. (Fish may well be thinking primarily of literary study, rather than history and philosophy.) Any attempt to justify the humanities in terms of outside benefits such as social usefulness (say increased productivity) or in terms of ennobling effects on the individual (such as greater wisdom or diminished prejudice) is ungrounded, according to Fish, and simply places impossible demands on the relevant academic departments. Furthermore, critical thinking, while arguably a result of humanistic training, can be acquired in other contexts. And the humanities do not even provide any more the kind of social cachet (what sociologists sometimes call \"cultural capital\") that was helpful to succeed in Western society before the age of mass education following World War II.\n\nInstead, scholars like Fish suggest that the humanities offer a unique kind of pleasure, a pleasure based on the common pursuit of knowledge (even if it is only disciplinary knowledge). Such pleasure contrasts with the increasing privatization of leisure and instant gratification characteristic of Western culture; it thus meets Jürgen Habermas' requirements for the disregard of social status and rational problematization of previously unquestioned areas necessary for an endeavor which takes place in the bourgeois public sphere. In this argument, then, only the academic pursuit of pleasure can provide a link between the private and the public realm in modern Western consumer society and strengthen that public sphere that, according to many theorists, is the foundation for modern democracy.\n\nOthers, like Mark Bauerlein, argue that professors in the humanities have increasingly abandoned proven methods of epistemology (\"I care only about the quality of your arguments, not your conclusions.\") in favor of indoctrination (\"I care only about your conclusions, not the quality of your arguments.\"). The result is that professors and their students adhere rigidly to a limited set of viewpoints, and have little interest in, or understanding of, opposing viewpoints. Once they obtain this intellectual self-satisfaction, persistent lapses in learning, research, and evaluation are common.\n\nImplicit in many of these arguments supporting the humanities are the makings of arguments against public support of the humanities. Joseph Carroll asserts that we live in a changing world, a world where \"cultural capital\" is replaced with \"scientific literacy\", and in which the romantic notion of a Renaissance humanities scholar is obsolete. Such arguments appeal to judgments and anxieties about the essential uselessness of the humanities, especially in an age when it is seemingly vitally important for scholars of literature, history and the arts to engage in \"collaborative work with experimental scientists or even simply to make \"intelligent use of the findings from empirical science.\" \n\nDespite many humanities based arguments against the humanities some within the exact sciences have called for their return.In 2017, Science popularizer Bill Nye retracted previous claims about the supposed 'uselessness' of philosophy. As Bill Nye states, “People allude to Socrates and Plato and Aristotle all the time, and I think many of us who make those references don’t have a solid grounding,” he said. “It’s good to know the history of philosophy.” Scholars, such as biologist Scott F. Gilbert, make the claim that it is in fact the increasing predominance, leading to exclusivity, of scientific ways of thinking that need to be tempered by historical and social context. Gilbert worries that the commercialization that may be inherent in some ways of conceiving science (pursuit of funding, academic prestige etc.) need to be examined externally. Gilbert argues \"First of all, there is a very successful alternative to science as a commercialized march to “progress.” This is the approach taken by the liberal arts college, a model that takes pride in seeing science in context and in integrating science with the humanities and social sciences.\"\n\n\n"}
{"id": "5177", "url": "https://en.wikipedia.org/wiki?curid=5177", "title": "Communication", "text": "Communication\n\nCommunication (from Latin \"communicare\", meaning \"to share\") is the act of conveying meanings from one entity or group to another through the use of mutually understood signs, symbols, and semiotic rules.\n\nThe main steps inherent to all communication are:\n\nThe scientific study of communication can be divided into:\n\nThe channel of communication can be visual, auditory, tactile/haptic (e.g. Braille or other physical means), olfactory, electromagnetic, or biochemical.\n\nHuman communication is unique for its extensive use of abstract language. Development of civilization has been closely linked with progress in telecommunication.\n\nNonverbal communication describes the processes of conveying a type of information in a form of non-linguistic representations. Examples of nonverbal communication include haptic communication, chronemic communication, gestures, body language, facial expressions, eye contact etc. Nonverbal communication also relates to the intent of a message. Examples of intent are voluntary, intentional movements like shaking a hand or winking, as well as involuntary, such as sweating. Speech also contains nonverbal elements known as paralanguage, e.g. rhythm, intonation, tempo, and stress. It affects communication most at the subconscious level and establishes trust. Likewise, written texts include nonverbal elements such as handwriting style, the spatial arrangement of words and the use of emoticons to convey emotion.\n\nNonverbal communication demonstrates one of Paul Watzlawick's laws: you cannot not communicate. Once proximity has formed awareness, living creatures begin interpreting any signals received. Some of the functions of nonverbal communication in humans are to complement and illustrate, to reinforce and emphasize, to replace and substitute, to control and regulate, and to contradict the denotative message.\n\nNonverbal cues are heavily relied on to express communication and to interpret others' communication and can replace or substitute verbal messages. However, non-verbal communication is ambiguous. When verbal messages contradict non-verbal messages, observation of non-verbal behaviour is relied on to judge another's attitudes and feelings, rather than assuming the truth of the verbal message alone.\n\nThere are several reasons as to why non-verbal communication plays a vital role in communication:\n\n\"Non-verbal communication is omnipresent.\" They are included in every single communication act. To have total communication, all non-verbal channels such as the body, face, voice, appearance, touch, distance, timing, and other environmental forces must be engaged during face-to-face interaction. Written communication can also have non-verbal attributes. E-mails and web chats allow an individual's the option to change text font colours, stationary, emoticons, and capitalization in order to capture non-verbal cues into a verbal medium.\n\n\"Non-verbal behaviours are multifunctional.\" Many different non-verbal channels are engaged at the same time in communication acts and allow the chance for simultaneous messages to be sent and received.\n\n\"Non-verbal behaviours may form a universal language system.\" Smiling, crying, pointing, caressing, and glaring are non-verbal behaviours that are used and understood by people regardless of nationality. Such non-verbal signals allow the most basic form of communication when verbal communication is not effective due to language barriers.\n\nVerbal communication is the spoken or written conveyance of a message. Human language can be defined as a system of symbols (sometimes known as lexemes) and the grammars (rules) by which the symbols are manipulated. The word \"language\" also refers to common properties of languages. Language learning normally occurs most intensively during human childhood. Most of the large number of human languages use patterns of sound or gesture for symbols which enable communication with others around them. Languages tend to share certain properties, although there are exceptions. There is no defined line between a language and a dialect. Constructed languages such as Esperanto, programming languages, and various mathematical formalisms are not necessarily restricted to the properties shared by human languages.\n\nAs previously mentioned, language can be characterized as symbolic. Charles Ogden and I.A Richards developed The Triangle of Meaning model to explain the symbol (the relationship between a word), the referent (the thing it describes), and the meaning (the thought associated with the word and the thing).\n\nThe properties of language are governed by rules. Language follows phonological rules (sounds that appear in a language), syntactic rules (arrangement of words and punctuation in a sentence), semantic rules (the agreed upon meaning of words), and pragmatic rules (meaning derived upon context).\n\nThe meanings that are attached to words can be literal, or otherwise known as denotative; relating to the topic being discussed, or, the meanings take context and relationships into account, otherwise known as connotative; relating to the feelings, history, and power dynamics of the communicators.\n\nContrary to popular belief, signed languages of the world (e.g., American Sign Language) are considered to be verbal communication because their sign vocabulary, grammar, and other linguistic structures abide by all the necessary classifications as spoken languages. There are however, nonverbal elements to signed languages, such as the speed, intensity, and size of signs that are made. A signer might sign \"yes\" in response to a question, or they might sign a sarcastic-large slow yes to convey a different nonverbal meaning. The sign yes is the verbal message while the other movements add nonverbal meaning to the message.\n\nOver time the forms of and ideas about communication have evolved through the continuing progression of technology. Advances include communications psychology and media psychology, an emerging field of study.\n\nThe progression of written communication can be divided into three \"information communication revolutions\":\n\nCommunication is thus a process by which meaning is assigned and conveyed in an attempt to create shared understanding. Gregory Bateson called it \"the replication of tautologies in the universe. This process, which requires a vast repertoire of skills in interpersonal processing, listening, observing, speaking, questioning, analyzing, gestures, and evaluating enables collaboration and cooperation.\n\nBusiness communication is used for a wide variety of activities including, but not limited to: strategic communications planning, media relations, public relations (which can include social media, broadcast and written communications, and more), brand management, reputation management, speech-writing, customer-client relations, and internal/employee communications.\n\nCompanies with limited resources may choose to engage in only a few of these activities, while larger organizations may employ a full spectrum of communications. Since it is difficult to develop such a broad range of skills, communications professionals often specialize in one or two of these areas but usually have at least a working knowledge of most of them. By far, the most important qualifications communications professionals can possess are excellent writing ability, good 'people' skills, and the capacity to think critically and strategically.\n\nCommunication is one of the most relevant tools in political strategies, including persuasion and propaganda. In mass media research and online media research, the effort of the strategist is that of getting a precise decoding, avoiding \"message reactance\", that is, message refusal. The reaction to a message is referred also in terms of approach to a message, as follows:\nHolistic approaches are used by communication campaign leaders and communication strategists in order to examine all the options, \"actors\" and channels that can generate change in the semiotic landscape, that is, change in perceptions, change in credibility, change in the \"memetic background\", change in the image of movements, of candidates, players and managers as perceived by key influencers that can have a role in generating the desired \"end-state\".\n\nThe modern political communication field is highly influenced by the framework and practices of \"information operations\" doctrines that derive their nature from strategic and military studies. According to this view, what is really relevant is the concept of acting on the Information Environment. The information environment is the aggregate of individuals, organizations, and systems that collect, process, disseminate, or act on information. This environment consists of three interrelated dimensions, which continuously interact with individuals, organizations, and systems. These dimensions are known as physical, informational, and cognitive.\n\nFamily communication is the study of the communication perspective in a broadly defined family, with intimacy and trusting relationship. The main goal of family communication is to understand the interactions of family and the pattern of behaviors of family members in different circumstances. Open and honest communication creates an atmosphere that allows family members to express their differences as well as love and admiration for one another. It also helps to understand the feelings of one another.\n\nFamily communication study looks at topics such as family rules, family roles or family dialectics and how those factors could affect the communication between family members. Researchers develop theories to understand communication behaviors. Family communication study also digs deep into certain time periods of family life such as marriage, parenthood or divorce and how communication stands in those situations. It is important for family members to understand communication as a trusted way which leads to a well constructed family.\n\nIn simple terms, interpersonal communication is the communication between one person and another (or others). It is often referred to as face-to-face communication between two (or more) people. Both verbal and nonverbal communication, or body language, play a part in how one person understands another. In verbal interpersonal communication there are two types of messages being sent: a content message and a relational message. Content messages are messages about the topic at hand and relational messages are messages about the relationship itself. This means that relational messages come across in \"how\" one says something and it demonstrates a person's feelings, whether positive or negative, towards the individual they are talking to, indicating not only how they feel about the topic at hand, but also how they feel about their relationship with the other individual.\n\nThere are many different aspects of interpersonal communication including:\n\nBarriers to effective communication can retard or distort the message or intention of the message being conveyed. This may result in failure of the communication process or cause an effect that is undesirable. These include filtering, selective perception, information overload, emotions, language, silence, communication apprehension, gender differences and political correctness.\n\nThis also includes a lack of expressing \"knowledge-appropriate\" communication, which occurs when a person uses ambiguous or complex legal words, medical jargon, or descriptions of a situation or environment that is not understood by the recipient.\n\nCultural differences exist within countries (tribal/regional differences, dialects etc.), between religious groups and in organisations or at an organisational level – where companies, teams and units may have different expectations, norms and idiolects. Families and family groups may also experience the effect of cultural barriers to communication within and between different family members or groups. For example: words, colours and symbols have different meanings in different cultures. In most parts of the world, nodding your head means agreement, shaking your head means no, except in some parts of the world.\n\nCommunication to a great extent is influenced by culture and cultural variables. Understanding \"cultural aspects of communication\" refers to having knowledge of different cultures in order to communicate effectively with cross culture people. Cultural aspects of communication are of great relevance in today's world which is now a global village, thanks to globalisation. Cultural aspects of communication are the cultural differences which influences communication across borders. Impact of cultural differences on communication components are explained below:\n\n\nSo in order to have an effective communication across the world it is desirable to have a knowledge of cultural variables effecting communication.\n\nAccording to Michael Walsh and Ghil'ad Zuckermann, Western conversational interaction is typically \"dyadic\", between two particular people, where eye contact is important and the speaker controls the interaction; and \"contained\" in a relatively short, defined time frame. However, traditional Aboriginal conversational interaction is \"communal\", broadcast to many people, eye contact is not important, the listener controls the interaction; and \"continuous\", spread over a longer, indefinite time frame.\n\nEvery information exchange between living organisms — i.e. transmission of signals that involve a living sender and receiver can be considered a form of communication; and even primitive creatures such as corals are competent to communicate. Nonhuman communication also include cell signaling, cellular communication, and chemical transmissions between primitive organisms like bacteria and within the plant and fungal kingdoms.\n\nThe broad field of animal communication encompasses most of the issues in ethology. Animal communication can be defined as any behavior of one animal that affects the current or future behavior of another animal. The study of animal communication, called \"zoo semiotics\" (distinguishable from anthroposemiotics, the study of human communication) has played an important part in the development of ethology, sociobiology, and the study of animal cognition. Animal communication, and indeed the understanding of the animal world in general, is a rapidly growing field, and even in the 21st century so far, a great share of prior understanding related to diverse fields such as personal symbolic name use, animal emotions, animal culture and learning, and even sexual conduct, long thought to be well understood, has been revolutionized.\n\nCommunication is observed within the plant organism, i.e. within plant cells and between plant cells, between plants of the same or related species, and between plants and non-plant organisms, especially in the root zone. Plant roots communicate with rhizome bacteria, fungi, and insects within the soil. Recent research has shown that most of the microorganism plant communication processes are neuron-like. Plants also communicate via volatiles when exposed to herbivory attack behavior, thus warning neighboring plants. In parallel they produce other volatiles to attract parasites which attack these herbivores.\n\nFungi communicate to coordinate and organize their growth and development such as the formation of Marcelia and fruiting bodies. Fungi communicate with their own and related species as well as with non fungal organisms in a great variety of symbiotic interactions, especially with bacteria, unicellular eukaryote, plants and insects through biochemicals of biotic origin. The biochemicals trigger the fungal organism to react in a specific manner, while if the same chemical molecules are not part of biotic messages, they do not trigger the fungal organism to react. This implies that fungal organisms can differentiate between molecules taking part in biotic messages and similar molecules being irrelevant in the situation. So far five different primary signalling molecules are known to coordinate different behavioral patterns such as filamentation, mating, growth, and pathogenicity. Behavioral coordination and production of signaling substances is achieved through interpretation processes that enables the organism to differ between self or non-self, a biotic indicator, biotic message from similar, related, or non-related species, and even filter out \"noise\", i.e. similar molecules without biotic content.\n\nCommunication is not a tool used only by humans, plants and animals, but it is also used by microorganisms like bacteria. The process is called quorum sensing. Through quorum sensing, bacteria are able to sense the density of cells, and regulate gene expression accordingly. This can be seen in both gram positive and gram negative bacteria.\nThis was first observed by Fuqua \"et al.\" in marine microorganisms like \"V. harveyi\" and \"V. fischeri\".\n\nThe first major model for communication was introduced by Claude Shannon and Warren Weaver for Bell Laboratories in 1949 The original model was designed to mirror the functioning of radio and telephone technologies. Their initial model consisted of three primary parts: sender, channel, and receiver. The sender was the part of a telephone a person spoke into, the channel was the telephone itself, and the receiver was the part of the phone where one could hear the other person. Shannon and Weaver also recognized that often there is static that interferes with one listening to a telephone conversation, which they deemed noise.\n\nIn a simple model, often referred to as the transmission model or standard view of communication, information or content (e.g. a message in natural language) is sent in some form (as spoken language) from an emitter (\"emisor\" in the picture)/ sender/ encoder to a destination/ receiver/ decoder. This common conception of communication simply views communication as a means of sending and receiving information. The strengths of this model are simplicity, generality, and quantifiability. Claude Shannon and Warren Weaver structured this model based on the following elements:\n\nShannon and Weaver argued that there were three levels of problems for communication within this theory.\n\nDaniel Chandler critiques the transmission model by stating:\n\nIn 1960, David Berlo expanded on Shannon and Weaver's (1949) linear model of communication and created the SMCR Model of Communication. The Sender-Message-Channel-Receiver Model of communication separated the model into clear parts and has been expanded upon by other scholars.\n\nCommunication is usually described along a few major dimensions: Message (what type of things are communicated), source / emisor / sender / encoder (by whom), form (in which form), channel (through which medium), destination / receiver / target / decoder (to whom), and Receiver. Wilbur Schram (1954) also indicated that we should also examine the impact that a message has (both desired and undesired) on the target of the message. Between parties, communication includes acts that confer knowledge and experiences, give advice and commands, and ask questions. These acts may take many forms, in one of the various manners of communication. The form depends on the abilities of the group communicating. Together, communication content and form make messages that are sent towards a destination. The target can be oneself, another person or being, another entity (such as a corporation or group of beings).\n\nCommunication can be seen as processes of information transmission with three levels of semiotic rules:\n\nTherefore, communication is social interaction where at least two interacting agents share a common set of signs and a common set of semiotic rules. This commonly held rule in some sense ignores autocommunication, including intrapersonal communication via diaries or self-talk, both secondary phenomena that followed the primary acquisition of communicative competences within social interactions.\n\nIn light of these weaknesses, Barnlund (2008) proposed a transactional model of communication. The basic premise of the transactional model of communication is that individuals are simultaneously engaging in the sending and receiving of messages.\n\nIn a slightly more complex form a sender and a receiver are linked reciprocally. This second attitude of communication, referred to as the constitutive model or constructionist view, focuses on how an individual communicates as the determining factor of the way the message will be interpreted. Communication is viewed as a conduit; a passage in which information travels from one individual to another and this information becomes separate from the communication itself. A particular instance of communication is called a speech act. The sender's personal filters and the receiver's personal filters may vary depending upon different regional traditions, cultures, or gender; which may alter the intended meaning of message contents. In the presence of \"communication noise\" on the transmission channel (air, in this case), reception and decoding of content may be faulty, and thus the speech act may not achieve the desired effect. One problem with this encode-transmit-receive-decode model is that the processes of encoding and decoding imply that the sender and receiver each possess something that functions as a codebook, and that these two code books are, at the very least, similar if not identical. Although something like code books is implied by the model, they are nowhere represented in the model, which creates many conceptual difficulties.\n\nTheories of coregulation describe communication as a creative and dynamic continuous process, rather than a discrete exchange of information. Canadian media scholar Harold Innis had the theory that people use different types of media to communicate and which one they choose to use will offer different possibilities for the shape and durability of society. His famous example of this is using ancient Egypt and looking at the ways they built themselves out of media with very different properties stone and papyrus. Papyrus is what he called 'Space Binding'. it made possible the transmission of written orders across space, empires and enables the waging of distant military campaigns and colonial administration. The other is stone and 'Time Binding', through the construction of temples and the pyramids can sustain their authority generation to generation, through this media they can change and shape communication in their society.\n\nIn any communication model, noise is interference with the decoding of messages sent over the channel by an encoder. There are many examples of noise:\nTo face communication noise, redundancy and acknowledgement must often be used. Acknowledgements are messages from the addressee informing the originator that his/her communication has been received and is understood. Message repetition and feedback about message received are necessary in the presence of noise to reduce the probability of misunderstanding.\nThe act of disambiguation regards the attempt of reducing noise and wrong interpretations, when the semantic value or meaning of a sign can be subject to noise, or in presence of multiple meanings, which makes the sense-making difficult. Disambiguation attempts to decrease the likelihood of misunderstanding. This is also a fundamental skill in communication processes activated by counselors, psychotherapists, interpreters, and in coaching sessions based on colloquium. In Information Technology, the disambiguation process and the automatic disambiguation of meanings of words and sentences has also been an interest and concern since the earliest days of computer treatment of language.\n\nThe academic discipline that deals with processes of human communication is communication studies. The discipline encompasses a range of topics, from face-to-face conversation to mass media outlets such as television broadcasting. Communication studies also examines how messages are interpreted through the political, cultural, economic, semiotic, hermeneutic, and social dimensions of their contexts. Statistics, as a quantitative approach to communication science, has also been incorporated into research on communication science in order to help substantiate claims.\n\n"}
{"id": "18985062", "url": "https://en.wikipedia.org/wiki?curid=18985062", "title": "Information", "text": "Information\n\nInformation can be thought of as the resolution of uncertainty; it is that which answers the question of \"what an entity is\" and thus defines both its essence and nature of its characteristics. It is associated with data, as data represents values attributed to parameters, and information is data in context and with meaning attached. Information relates also to knowledge, as knowledge signifies understanding of an abstract or concrete concept. \n\nIn terms of communication, information is expressed either as the content of a message or through direct or indirect observation. That which is perceived can be construed as a message in its own right, and in that sense, information is always conveyed as the content of a message.\n\nInformation can be encoded into various forms for transmission and interpretation (for example, information may be encoded into a sequence of signs, or transmitted via a signal). It can also be encrypted for safe storage and communication.\n\nThe uncertainty of an event is measured by its probability of occurrence and is inversely proportional to that. The more uncertain an event, the more information is required to resolve uncertainty of that event. The bit is a typical unit of information, but other units such as the nat may be used. For example, the information encoded in one \"fair\" coin flip is log(2/1) = 1 bit, and in two fair coin flips is\nlog(4/1) = 2 bits.\n\nThe concept of \"information\" has different meanings in different contexts. Thus the concept becomes related to notions of constraint, communication, control, data, form, education, knowledge, meaning, understanding, mental stimuli, pattern, perception, representation, and entropy.\n\nThe English word apparently derives from the Latin stem (\"information-\") of the nominative (\"informatio\"): this noun derives from the verb \"informare\" (to inform) in the sense of \"to give form to the mind\", \"to discipline\", \"instruct\", \"teach\". \"Inform\" itself comes (via French \"informer\") from the Latin verb \"informare\", which means to give form, or to form an idea of. Furthermore, Latin itself already contained the word \"informatio\" meaning concept or idea, but the extent to which this may have influenced the development of the word \"information\" in English is not clear.\n\nThe ancient Greek word for \"form\" was (\"morphe\"; cf. morph) and also εἶδος (\"eidos\") \"kind, idea, shape, set\", the latter word was famously used in a technical philosophical sense by Plato (and later Aristotle) to denote the ideal identity or essence of something (see Theory of Forms). 'Eidos' can also be associated with thought, proposition, or even concept.\n\nThe ancient Greek word for \"information\" is , which transliterates (\"plērophoria\") from \nπλήρης (\"plērēs\") \"fully\" and φέρω (\"phorein\") frequentative of (\"pherein\") \"to carry through\". It literally means \"bears fully\" or \"conveys fully\". In modern Greek the word is still in daily use and has the same meaning as the word \"information\" in English. In addition to its primary meaning, the word as a symbol has deep roots in Aristotle's semiotic triangle. In this regard it can be interpreted to communicate information to the one decoding that specific type of sign. This is something that occurs frequently with the etymology of many words in ancient and modern Greek where there is a very strong denotative relationship between the signifier, e.g. the word symbol that conveys a specific encoded interpretation, and the signified, e.g. a concept whose meaning the interpreter attempts to decode.\n\nIn English, “information” is an uncountable mass noun.\n\nIn information theory, \"information\" is taken as an ordered sequence of symbols from an alphabet, say an input alphabet χ, and an output alphabet ϒ. Information processing consists of an input-output function that maps any input sequence from χ into an output sequence from ϒ. The mapping may be probabilistic or deterministic. It may have memory or be memoryless.\n\nOften information can be viewed as a type of input to an organism or system. Inputs are of two kinds; some inputs are important to the function of the organism (for example, food) or system (energy) by themselves. In his book \"Sensory Ecology\" Dusenbery called these causal inputs. Other inputs (information) are important only because they are associated with causal inputs and can be used to predict the occurrence of a causal input at a later time (and perhaps another place). Some information is important because of association with other information but eventually there must be a connection to a causal input. In practice, information is usually carried by weak stimuli that must be detected by specialized sensory systems and amplified by energy inputs before they can be functional to the organism or system. For example, light is mainly (but not only, e.g. plants can grow in the direction of the lightsource) a causal input to plants but for animals it only provides information. The colored light reflected from a flower is too weak to do much photosynthetic work but the visual system of the bee detects it and the bee's nervous system uses the information to guide the bee to the flower, where the bee often finds nectar or pollen, which are causal inputs, serving a nutritional function.\n\nThe cognitive scientist and applied mathematician Ronaldo Vigo argues that information is a concept that requires at least two related entities to make quantitative sense. These are, any dimensionally defined category of objects S, and any of its subsets R. R, in essence, is a representation of S, or, in other words, conveys representational (and hence, conceptual) information about S. Vigo then defines the amount of information that R conveys about S as the rate of change in the complexity of S whenever the objects in R are removed from S. Under \"Vigo information\", pattern, invariance, complexity, representation, and information—five fundamental constructs of universal science—are unified under a novel mathematical framework. Among other things, the framework aims to overcome the limitations of Shannon-Weaver information when attempting to characterize and measure subjective information.\n\nInformation is any type of pattern that influences the formation or transformation of other patterns. In this sense, there is no need for a conscious mind to perceive, much less appreciate, the pattern. Consider, for example, DNA. The sequence of nucleotides is a pattern that influences the formation and development of an organism without any need for a conscious mind. One might argue though that for a human to consciously define a pattern, for example a nucleotide, naturally involves conscious information processing.\n\nSystems theory at times seems to refer to information in this sense, assuming information does not necessarily involve any conscious mind, and patterns circulating (due to feedback) in the system can be called information. In other words, it can be said that information in this sense is something potentially perceived as representation, though not created or presented for that purpose. For example, Gregory Bateson defines \"information\" as a \"difference that makes a difference\".\n\nIf, however, the premise of \"influence\" implies that information has been perceived by a conscious mind and also interpreted by it, the specific context associated with this interpretation may cause the transformation of the information into knowledge. Complex definitions of both \"information\" and \"knowledge\" make such semantic and logical analysis difficult, but the condition of \"transformation\" is an important point in the study of information as it relates to knowledge, especially in the business discipline of knowledge management. In this practice, tools and processes are used to assist a knowledge worker in performing research and making decisions, including steps such as:\n\n\nStewart (2001) argues that transformation of information into knowledge is critical, lying at the core of value creation and competitive advantage for the modern enterprise.\n\nThe Danish Dictionary of Information Terms argues that information only provides an answer to a posed question. Whether the answer provides knowledge depends on the informed person. So a generalized definition of the concept should be: \"Information\" = An answer to a specific question\".\n\nWhen Marshall McLuhan speaks of media and their effects on human cultures, he refers to the structure of artifacts that in turn shape our behaviors and mindsets. Also, pheromones are often said to be \"information\" in this sense.\n\nInformation has a well-defined meaning in physics. In 2003 J. D. Bekenstein claimed that a growing trend in physics was to define the physical world as being made up of information itself (and thus information is defined in this way) (see Digital physics). Examples of this include the phenomenon of quantum entanglement, where particles can interact without reference to their separation or the speed of light. Material information itself cannot travel faster than light even if that information is transmitted indirectly. This could lead to all attempts at physically observing a particle with an \"entangled\" relationship to another being slowed down, even though the particles are not connected in any other way other than by the information they carry.\n\nThe mathematical universe hypothesis suggests a new paradigm, in which virtually everything, from particles and fields, through biological entities and consciousness, to the multiverse itself, could be described by mathematical patterns of information. By the same token, the cosmic void can be conceived of as the absence of material information in space (setting aside the virtual particles that pop in and out of existence due to quantum fluctuations, as well as the gravitational field and the dark energy). Nothingness can be understood then as that within which no matter, energy, space, time, or any other type of information could exist, which would be possible if symmetry and structure break within the manifold of the multiverse (i.e. the manifold would have tears or holes). Physical information exists beyond event horizons, since astronomical observations show that, due to the expansion of the universe, distant objects continue to pass the cosmological horizon, as seen from a present time, local observer point of view.\n\nAnother link is demonstrated by the Maxwell's demon thought experiment. In this experiment, a direct relationship between information and another physical property, entropy, is demonstrated. A consequence is that it is impossible to destroy information without increasing the entropy of a system; in practical terms this often means generating heat. Another more philosophical outcome is that information could be thought of as interchangeable with energy. Toyabe et al. experimentally showed in nature that information can be converted into work. Thus, in the study of logic gates, the theoretical lower bound of thermal energy released by an \"AND gate\" is higher than for the \"NOT gate\" (because information is destroyed in an \"AND gate\" and simply converted in a \"NOT gate\"). Physical information is of particular importance in the theory of quantum computers.\n\nIn thermodynamics, information is any kind of event that affects the state of a dynamic system that can interpret the information.\n\nThe information cycle (addressed as a whole or in its distinct components) is of great concern to information technology, information systems, as well as information science. These fields deal with those processes and techniques pertaining to information capture (through sensors) and generation (through computation, formulation or composition), processing (including encoding, encryption, compression, packaging), transmission (including all telecommunication methods), presentation (including visualization / display methods), storage (such as magnetic or optical, including holographic methods), etc. \n\nInformation visualization (shortened as InfoVis) depends on the computation and digital representation of data, and assists users in pattern recognition and anomaly detection.\nInformation security (shortened as InfoSec) is the ongoing process of exercising due diligence to protect information, and information systems, from unauthorized access, use, disclosure, destruction, modification, disruption or distribution, through algorithms and procedures focused on monitoring and detection, as well as incident response and repair. \n\nInformation analysis is the process of inspecting, transforming, and modelling information, by converting raw data into actionable knowledge, in support of the decision-making process.\n\nInformation quality (shortened as InfoQ) is the potential of a dataset to achieve a specific (scientific or practical) goal using a given empirical analysis method.\n\nInformation communication represents the convergence of informatics, telecommunication and audio-visual media & content.\n\nIt is estimated that the world's technological capacity to store information grew from 2.6 (optimally compressed) exabytes in 1986 – which is the informational equivalent to less than one 730-MB CD-ROM per person (539 MB per person) – to 295 (optimally compressed) exabytes in 2007. This is the informational equivalent of almost 61 CD-ROM per person in 2007.\n\nThe world’s combined technological capacity to receive information through one-way broadcast networks was the informational equivalent of 174 newspapers per person per day in 2007.\n\nThe world's combined effective capacity to exchange information through two-way telecommunication networks was the informational equivalent of 6 newspapers per person per day in 2007.\n\nAs of 2007, an estimated 90% of all new information is digital, mostly stored on hard drives.\n\nRecords are specialized forms of information. Essentially, records are information produced consciously or as by-products of business activities or transactions and retained because of their value. Primarily, their value is as evidence of the activities of the organization but they may also be retained for their informational value. Sound records management ensures that the integrity of records is preserved for as long as they are required.\n\nThe international standard on records management, ISO 15489, defines records as \"information created, received, and maintained as evidence and information by an organization or person, in pursuance of legal obligations or in the transaction of business\". The International Committee on Archives (ICA) Committee on electronic records defined a record as, \"recorded information produced or received in the initiation, conduct or completion of an institutional or individual activity and that comprises content, context and structure sufficient to provide evidence of the activity\".\n\nRecords may be maintained to retain corporate memory of the organization or to meet legal, fiscal or accountability requirements imposed on the organization. Willis expressed the view that sound management of business records and information delivered \"...six key requirements for good corporate governance...transparency; accountability; due process; compliance; meeting statutory and common law requirements; and security of personal and corporate information.\"\n\nMichael Buckland has classified \"information\" in terms of its uses: \"information as process\", \"information as knowledge\", and \"information as thing\".\n\nBeynon-Davies explains the multi-faceted concept of information in terms of signs and signal-sign systems. Signs themselves can be considered in terms of four inter-dependent levels, layers or branches of semiotics: pragmatics, semantics, syntax, and empirics. These four layers serve to connect the social world on the one hand with the physical or technical world on the other.\n\nPragmatics is concerned with the purpose of communication. Pragmatics links the issue of signs with the context within which signs are used. The focus of pragmatics is on the intentions of living agents underlying communicative behaviour. In other words, pragmatics link language to action.\n\nSemantics is concerned with the meaning of a message conveyed in a communicative act. Semantics considers the content of communication. Semantics is the study of the meaning of signs - the association between signs and behaviour. Semantics can be considered as the study of the link between symbols and their referents or concepts – particularly the way that signs relate to human behavior.\n\nSyntax is concerned with the formalism used to represent a message. Syntax as an area studies the form of communication in terms of the logic and grammar of sign systems. Syntax is devoted to the study of the form rather than the content of signs and sign-systems.\n\nNielsen (2008) discusses the relationship between semiotics and information in relation to dictionaries. He introduces the concept of lexicographic information costs and refers to the effort a user of a dictionary must make to first find, and then understand data so that they can generate information.\n\nCommunication normally exists within the context of some social situation. The social situation sets the context for the intentions conveyed (pragmatics) and the form of communication. In a communicative situation intentions are expressed through messages that comprise collections of inter-related signs taken from a language mutually understood by the agents involved in the communication. Mutual understanding implies that agents involved understand the chosen language in terms of its agreed syntax (syntactics) and semantics. The sender codes the message in the language and sends the message as signals along some communication channel (empirics). The chosen communication channel has inherent properties that determine outcomes such as the speed at which communication can take place, and over what distance.\n\n\n"}
{"id": "2118929", "url": "https://en.wikipedia.org/wiki?curid=2118929", "title": "Solidarity", "text": "Solidarity\n\nSolidarity is an awareness of shared interests, objectives, standards, and sympathies creating a psychological sense of unity of groups or classes. It refers to the ties in a society that bind people together as one. The term is generally employed in sociology and the other social sciences as well as in philosophy and bioethics. It is also a significant concept in Catholic social teaching; therefore it is a core concept in Christian democratic political ideology.\n\nWhat forms the basis of solidarity and how it's implemented varies between societies. In developing societies it may be mainly based on kinship and shared values while more developed societies accumulate various theories as to what contributes to a sense of solidarity, or rather, social cohesion.\n\nSolidarity is also one of six principles of the Charter of Fundamental Rights of the European Union and December 20 of each year is International Human Solidarity Day recognized as an international observance. Concepts of solidarity are mentioned in the Universal Declaration on Bioethics and Human Rights, but not defined clearly. As biotechnology and biomedical enhancement research and production increase, the need for distinct definition of solidarity within healthcare system frameworks is important.\n\nAccording to Émile Durkheim, the types of social solidarity correlate with types of society. Durkheim introduced the terms \"mechanical\" and \"organic solidarity\" as part of his theory of the development of societies in \"The Division of Labour in Society\" (1893). In a society exhibiting mechanical solidarity, its cohesion and integration comes from the homogeneity of individuals—people feel connected through similar work, educational and religious training, and lifestyle. Mechanical solidarity normally operates in \"traditional\" and small scale societies. In simpler societies (e.g., tribal), solidarity is usually based on kinship ties of familial networks. Organic solidarity comes from the interdependence that arises from specialization of work and the complementarities between people—a development which occurs in \"modern\" and \"industrial\" societies.\n\nAlthough individuals perform different tasks and often have different values and interest, the order and very solidarity of society depends on their reliance on each other to perform their specified tasks. \"Organic\" here is referring to the interdependence of the component parts, and thus social solidarity is maintained in more complex societies through the interdependence of its component parts (e.g., farmers produce the food to feed the factory workers who produce the tractors that allow the farmer to produce the food).\n\nA connection between the biological and the social was of principal importance for the idea of solidarity as expressed by the anarchist ideologist and former Prince Peter Kropotkin (1842–1921). In his most famous book, \"\" (1902), written partly in response to Huxleyan Social Darwinism, Kropotkin studied the use of cooperation as a survival mechanism in human societies at their various stages, as well as with animals. According to him, mutual aid, or cooperation, within a species has been an important factor in the evolution of social institutions. Solidarity is essential for mutual aid; supportive activity towards other people does not result from the expectation of reward, but rather from instinctive feelings of solidarity.\n\nIn his introduction to the book, Kropotkin wrote: \"The number and importance of mutual-aid institutions which were developed by the creative genius of the savage and half-savage masses, during the earliest clan-period of mankind and still more during the next village-community period, and the immense influence which these early institutions have exercised upon the subsequent development of mankind, down to the present times, induced me to extend my researches to the later, historical periods as well; especially, to study that most interesting period – the free medieval city republics, whose universality and influence upon our modern civilization have not yet been duly appreciated. And finally, I have tried to indicate in brief the immense importance which the mutual-support instincts, inherited by mankind from its extremely long evolution, play even now in our modern society, which is supposed to rest upon the principle \"every one for himself, and the State for all,\" but which it never has succeeded, nor will succeed in realizing\". Kropotkin advocated an alternative economic and social system, which would be coordinated through a horizontal network of voluntary associations with goods distributed in compliance with the physical needs of the individual, rather than according to labour.\n\nSolidarity is a re-emerging concept in contemporary philosophy within various sub-fields of law, ethics, and political philosophy. Early ancient philosophers such as Socrates and Aristotle discuss solidarity as a virtue ethics framework because in order to live a good life one must perform actions and behave in a way that is in solidarity with the community.\n\nOne notable approach in bioethics is to identify solidarity primarily as a three-tiered practice enacted at the interpersonal, communal, and contractual and legal levels. This approach is driven by the quest to differentiate between the diverse applications of the concept and to clarify its meaning, both historically and in terms of its potential as a fruitful concept for contemporary moral, social and political issues. The modern practice of bioethics is significantly influenced by Immanuel Kant's concept of the Categorical Imperative. Pastor and philosopher Fritz Jahr's article \"Bio-Ethics: A Review of the Ethical Relationships of Humans to Animals and Plants\" refines Kant's original Categorical Imperative discourse by including the notion of the Bioethical Imperative.\n\nBiomedical technology has also further introduced solidarity as the pivotal concept in bioethics. Scholars, such as Ori Levi, bring to attention the negative implications of biomedical enhancements. Another scholar, Dr. Meulen ter Ruud discusses the application of solidarity within healthcare systems.\n\nFritz Jahr describes that bioethics is ultimately made up of \"academic discipline, principle, and virtue\". This echoes back to the deep influence Socrates has on the normalization of bioethics and its practices. Jahr utilizes Kant's Categorical Imperative to demonstrate the obligatory, yet innately human practice of the Bioethical Imperative:\"This results in the guiding principle for our actions is the \"Bioethical Imperative\": Respect every living being in general as an end in itself, and treat it if possible, as such\"as it arises in the relationships not only between conscious human being, but also with plants and other animal species. Jahr fully believes that in order to truly practice bioethics, one must be in solidarity with all forms of life. If one only decides to be in solidarity in humans, then one should not behave virtuously in any manner.\n\nSolidarity is an integral element of Catholic social teaching. According to Pope Francis:\nThe Church's teaching on solidarity is explained in the Compendium of the Social Doctrine of the Church, and briefly summarised in the Catechism of the Catholic Church:\n\n\n"}
{"id": "489094", "url": "https://en.wikipedia.org/wiki?curid=489094", "title": "Area studies", "text": "Area studies\n\nArea studies (also regional studies) are interdisciplinary fields of research and scholarship pertaining to particular geographical, national/federal, or cultural regions. The term exists primarily as a general description for what are, in the practice of scholarship, many heterogeneous fields of research, encompassing both the social sciences and the humanities. Typical area study programs involve international relations, strategic studies, history, political science, political economy, cultural studies, languages, geography, literature, and other related disciplines. In contrast to cultural studies, area studies often include diaspora and emigration from the area.\n\nInterdisciplinary area studies became increasingly common in the United States of America and in Western scholarship after World War II. Before that war American universities had just a few faculty who taught or conducted research on the non-Western world. Foreign-area studies were virtually nonexistent. After the war, liberals and conservatives alike were concerned about the U.S. ability to respond effectively to perceived external threats from the Soviet Union and China in the context of the emerging Cold War, as well as to the fall-out from the Decolonization of Africa and Asia.\n\nIn this context, the Ford Foundation, the Rockefeller Foundation, and the Carnegie Corporation of New York convened a series of meetings producing a broad consensus that to address this knowledge deficit, the U.S. must invest in international studies. Therefore, the foundations of the field are strongly rooted in America. Participants argued that a large brain trust of internationally oriented political scientists and economists was an urgent national priority. There was a central tension, however, between those who felt strongly that, instead of applying Western models, social scientists should develop culturally and historically contextualized knowledge of various parts of the world by working closely with humanists, and those who thought social scientists should seek to develop overarching macrohistorial theories that could draw connections between patterns of change and development across different geographies. The former became area-studies advocates, the latter proponents of modernization theory.\n\nThe Ford Foundation would eventually become the dominant player in shaping the area-studies program in the United States.\n\nIn 1950 the foundation established the prestigious Foreign Area Fellowship Program (FAFP), the first large-scale national competition in support of area-studies training in the United States. From 1953 to 1966 it contributed $270 million to 34 universities for area and language studies. Also during this period, it poured millions of dollars into the committees run jointly by the Social Science Research Council and the American Council of Learned Societies for field-development workshops, conferences, and publication programs. Eventually, the SSRC-ACLS joint committees would take over the administration of FAFP.\n\nOther large and important programs followed Ford's. Most notably, the National Defense Education Act of 1957, renamed the Higher Education Act in 1965, allocated funding for some 125 university-based area-studies units known as National Resource Center programs at U.S. universities, as well as for Foreign Language and Area Studies fellowships for graduate students.\n\nMeanwhile, area studies were also developed in the Soviet Union.\n\nSince their inception, area studies have been subject to criticism—including by area specialists themselves. Many of them alleged that because area studies were connected to the Cold War agendas of the CIA, the FBI, and other intelligence and military agencies, participating in such programs was tantamount to serving as an agent of the state. Some argue that there is the notion that U.S concerns and research priorities will define the intellectual terrain of area studies. Others insisted, however, that once they were established on university campuses, area studies began to encompass a much broader and deeper intellectual agenda than the one foreseen by government agencies, thus not American centric.\n\nArguably, one of the greatest threats to the area studies project was the rise of rational choice theory in political science and economics. To mock one of the most outspoken rational choice theory critics, Japan scholar Chalmers Johnson asked: Why do you need to know Japanese or anything about Japan's history and culture if the methods of rational choice will explain why Japanese politicians and bureaucrats do the things they do?\n\nFollowing the demise of the Soviet Union, philanthropic foundations and scientific bureaucracies moved to attenuate their support for area studies, emphasizing instead interregional themes like \"development and democracy\". When the Social Science Research Council and the American Council of Learned Societies, which had long served as the national nexus for raising and administering funds for area studies, underwent their first major restructuring in thirty years, closing down their area committees, scholars interpreted this as a massive signal about the changing research environment.\n\nFields are defined differently from university to university, and from department to department, but common area-studies fields include:\nDue to an increasing interest in studying translocal, transregional, transnational and transcontinental phenomena, a Potsdam-based research network has recently coined the term \"TransArea Studies\" (POINTS – Potsdam International Network for TransArea Studies).\n\nOther interdisciplinary research fields such as women's studies (also known as gender studies), disability studies, and ethnic studies (including African American studies, Asian American studies, Latino/a studies, and Native American studies) are not part of area studies but are sometimes included in discussion along with it.\n\nArea studies is sometimes known as regional studies. The Regional Studies Association is an international association focusing on these interdisciplinary fields.\n\nSome entire institutions of higher education (tertiary education) are devoted solely to area studies such as School of Oriental and African Studies, part of the University of London, or the Tokyo University of Foreign Studies in Japan. At the University of Oxford, the School of Interdisciplinary Area Studies (SIAS)School of Interdiscplinary Area Studies, Oxford and St Antony's College specialise in area studies, and hosts a number of post-graduate teaching programmes and research centres covering various regions of the world.\nJawaharlal Nehru University, New Delhi, is the only institution with immense contribution towards popularising area studies in India.\nAn institution which exclusively deals with Area Studies is the GIGA (German Institute of Global Area Studies) in Germany. Additionally, Lund University in Sweden offers the largest Asian Studies masters program in Northern Europe and is dedicated to promoting studies related to South Asia through its SASNet.\n\n\n\n"}
{"id": "45642", "url": "https://en.wikipedia.org/wiki?curid=45642", "title": "Demography", "text": "Demography\n\nDemography (from prefix \"demo-\" from Ancient Greek δῆμος \"dēmos\" meaning \"the people\", and \"-graphy\" from γράφω \"graphō\", ies \"writing, description or measurement\") is the statistical study of populations, especially human beings. \n\nDemography encompasses the study of the size, structure, and distribution of these populations, and spatial or temporal changes in them in response to birth, migration, aging, and death. As a very general science, it can analyze any kind of dynamic living population, i.e., one that changes over time or space (see population dynamics). Demographics are quantifiable characteristics of a given population.\n\nDemographic analysis can cover whole societies or groups defined by criteria such as education, nationality, religion, and ethnicity. Educational institutions usually treat demography as a field of sociology, though there are a number of independent demography departments. Based on the demographic research of the earth, earth's population up to the year 2050 and 2100 can be estimated by demographers. \n\nFormal demography limits its object of study to the measurement of population processes, while the broader field of social demography or population studies also analyses the relationships between economic, social, cultural, and biological processes influencing a population.\n\nDemographic thoughts traced back to antiquity, and were present in many civilisations and cultures, like Ancient Greece, Ancient Rome, China and India. Demography is made up of two word Demos and Graphy . The term Demography refers to the overall study of population. \n\nIn ancient Greece, this can be found in the writings of Herodotus, Thucidides, Hippocrates, Epicurus, Protagoras, Polus, Plato and Aristotle. In Rome, writers and philosophers like Cicero, Seneca, Pliny the elder, Marcus Aurelius, Epictetus, Cato, and Columella also expressed important ideas on this ground.\n\nIn the Middle ages, Christian thinkers devoted much time in refuting the Classical ideas on demography. Important contributors to the field were William of Conches, Bartholomew of Lucca, William of Auvergne, William of Pagula, and Muslim sociologists like Ibn Khaldun.\n\nOne of the earliest demographic studies in the modern period was \"Natural and Political Observations Made upon the Bills of Mortality\" (1662) by John Graunt, which contains a primitive form of life table. Among the study's findings were that one third of the children in London died before their sixteenth birthday. Mathematicians, such as Edmond Halley, developed the life table as the basis for life insurance mathematics. Richard Price was credited with the first textbook on life contingencies published in 1771, followed later by Augustus de Morgan, ‘On the Application of Probabilities to Life Contingencies’ (1838).\n\nIn 1755, Benjamin Franklin published his essay \"Observations Concerning the Increase of Mankind, Peopling of Countries, etc.\", projecting exponential growth in British colonies. His work influenced Thomas Robert Malthus, who, writing at the end of the 18th century, feared that, if unchecked, population growth would tend to outstrip growth in food production, leading to ever-increasing famine and poverty (see Malthusian catastrophe). Malthus is seen as the intellectual father of ideas of overpopulation and the limits to growth. Later, more sophisticated and realistic models were presented by Benjamin Gompertz and Verhulst.\n\nIn 1855, a Belgian scholar Achille Guillard defined demography as the natural and social history of human species or the mathematical knowledge of populations, of their general changes, and of their physical, civil, intellectual and moral condition. \n\nThe period 1860-1910 can be characterised as a period of transition wherein demography emerged from statistics as a separate field of interest. This period included a panoply of international ‘great demographers’ like Adolphe Quételet (1796–1874), William Farr (1807–1883), Louis-Adolphe Bertillon (1821–1883) and his son Jacques (1851–1922), Joseph Körösi (1844–1906), Anders Nicolas Kaier (1838–1919), Richard Böckh (1824–1907), Émile Durkheim (1858-1917), Wilhelm Lexis (1837–1914), and Luigi Bodio (1840–1920) contributed to the development of demography and to the toolkit of methods and techniques of demographic analysis.\n\nThere are two types of data collection—direct and indirect—with several different methods of each type.\n\nDirect data comes from vital statistics registries that track all births and deaths as well as certain changes in legal status such as marriage, divorce, and migration (registration of place of residence). In developed countries with good registration systems (such as the United States and much of Europe), registry statistics are the best method for estimating the number of births and deaths.\n\nA census is the other common direct method of collecting demographic data. A census is usually conducted by a national government and attempts to enumerate every person in a country. In contrast to vital statistics data, which are typically collected continuously and summarized on an annual basis, censuses typically occur only every 10 years or so, and thus are not usually the best source of data on births and deaths. Analyses are conducted after a census to estimate how much over or undercounting took place. These compare the sex ratios from the census data to those estimated from natural values and mortality data.\n\nCensuses do more than just count people. They typically collect information about families or households in addition to individual characteristics such as age, sex, marital status, literacy/education, employment status, and occupation, and geographical location. They may also collect data on migration (or place of birth or of previous residence), language, religion, nationality (or ethnicity or race), and citizenship. In countries in which the vital registration system may be incomplete, the censuses are also used as a direct source of information about fertility and mortality; for example the censuses of the People's Republic of China gather information on births and deaths that occurred in the 18 months immediately preceding the census.\n\nIndirect methods of collecting data are required in countries and periods where full data are not available, such as is the case in much of the developing world, and most of historical demography. One of these techniques in contemporary demography is the sister method, where survey researchers ask women how many of their sisters have died or had children and at what age. With these surveys, researchers can then indirectly estimate birth or death rates for the entire population. Other indirect methods in contemporary demography include asking people about siblings, parents, and children. Other indirect methods are necessary in historical demography.\n\nThere are a variety of demographic methods for modelling population processes. They include models of mortality (including the life table, Gompertz models, hazards models, Cox proportional hazards models, multiple decrement life tables, Brass relational logits), fertility (Hernes model, Coale-Trussell models, parity progression ratios), marriage (Singulate Mean at Marriage, Page model), disability (Sullivan's method, multistate life tables), population projections (Lee-Carter model, the Leslie Matrix), and population momentum (Keyfitz).\n\nThe United Kingdom has a series of four national birth cohort studies, the first three spaced apart by 12 years: the 1946 National Survey of Health and Development, the 1958 National Child Development Study, the 1970 British Cohort Study, and the Millennium Cohort Study, begun much more recently in 2000. These have followed the lives of samples of people (typically beginning with around 17,000 in each study) for many years, and are still continuing. As the samples have been drawn in a nationally representative way, inferences can be drawn from these studies about the differences between four distinct generations of British people in terms of their health, education, attitudes, childbearing and employment patterns.\n\n\nA stable population does not necessarily remain fixed in size. It can be expanding or shrinking.\n\nNote that the crude death rate as defined above and applied to a whole population can give a misleading impression. For example, the number of deaths per 1,000 people can be higher for developed nations than in less-developed countries, despite standards of health being better in developed countries. This is because developed countries have proportionally more older people, who are more likely to die in a given year, so that the overall mortality rate can be higher even if the mortality rate at any given age is lower. A more complete picture of mortality is given by a life table, which summarizes mortality separately at each age. A life table is necessary to give a good estimate of life expectancy.\n\nSuppose that a country (or other entity) contains \"Population\" persons at time \"t\".\nWhat is the size of the population at time \"t\" + 1 ?\n\nNatural increase from time \"t\" to \"t\" + 1:\n\nNet migration from time \"t\" to \"t\" + 1:\n\nThis basic equation can also be applied to subpopulations. For example, the population size of ethnic groups or nationalities within a given society or country is subject to the same sources of change. When dealing with ethnic groups, however, \"net migration\" might have to be subdivided into physical migration and ethnic reidentification (assimilation). Individuals who change their ethnic self-labels or whose ethnic classification in government statistics changes over time may be thought of as migrating or moving from one population subcategory to another.\n\nMore generally, while the basic demographic equation holds true by definition, in practice the recording and counting of events (births, deaths, immigration, emigration) and the enumeration of the total population size are subject to error. So allowance needs to be made for error in the underlying statistics when any accounting of population size or change is made.\n\nThe figure in this section shows the latest (2004) UN projections of world population out to the year 2150 (red = high, orange = medium, green = low). The UN \"medium\" projection shows world population reaching an approximate equilibrium at 9 billion by 2075. Working independently, demographers at the International Institute for Applied Systems Analysis in Austria expect world population to peak at 9 billion by 2070. Throughout the 21st century, the average age of the population is likely to continue to rise.\n\nPopulations can change through three processes: fertility, mortality, and migration. Fertility involves the number of children that women have and is to be contrasted with fecundity (a woman's childbearing potential). Mortality is the study of the causes, consequences, and measurement of processes affecting death to members of the population. Demographers most commonly study mortality using the Life Table, a statistical device that provides information about the mortality conditions (most notably the life expectancy) in the population.\n\nMigration refers to the movement of persons from a locality of origin to a destination place across some predefined, political boundary. Migration researchers do not designate movements 'migrations' unless they are somewhat permanent. Thus demographers do not consider tourists and travellers to be migrating. While demographers who study migration typically do so through census data on place of residence, indirect sources of data including tax forms and labour force surveys are also important.\n\nDemography is today widely taught in many universities across the world, attracting students with initial training in social sciences, statistics or health studies. Being at the crossroads of several disciplines such as sociology, economics, epidemiology, geography, anthropology and history, demography offers tools to approach a large range of population issues by combining a more technical quantitative approach that represents the core of the discipline with many other methods borrowed from social or other sciences. Demographic research is conducted in universities, in research institutes as well as in statistical departments and in several international agencies. Population institutions are part of the Cicred (International Committee for Coordination of Demographic Research) network while most individual scientists engaged in demographic research are members of the International Union for the Scientific Study of Population, or a national association such as the Population Association of America in the United States, or affiliates of the Federation of Canadian Demographers in Canada.\n\nSocial surveys:\n\nOrganizations:\n\nScientific journals:\n\n\n"}
{"id": "149354", "url": "https://en.wikipedia.org/wiki?curid=149354", "title": "Information science", "text": "Information science\n\nInformation science (also known as information studies) is a field primarily concerned with the analysis, collection, classification, manipulation, storage, retrieval, movement, dissemination, and protection of information. Practitioners within and outside the field study application and usage of knowledge in organizations along with the interaction between people, organizations, and any existing information systems with the aim of creating, replacing, improving, or understanding information systems. Historically, information science is associated with computer science, psychology, technology and intelligence agencies. However, information science also incorporates aspects of diverse fields such as archival science, cognitive science, commerce, law, linguistics, museology, management, mathematics, philosophy, public policy, and social sciences.\n\nInformation science focuses on understanding problems from the perspective of the stakeholders involved and then applying information and other technologies as needed. In other words, it tackles systemic problems first rather than individual pieces of technology within that system. In this respect, one can see information science as a response to technological determinism, the belief that technology \"develops by its own laws, that it realizes its own potential, limited only by the material resources available and the creativity of its developers. It must therefore be regarded as an autonomous system controlling and ultimately permeating all other subsystems of society.\"\n\nMany universities have entire colleges, departments or schools devoted to the study of information science, while numerous information-science scholars work in disciplines such as communication, computer science, law, and sociology. Several institutions have formed an I-School Caucus (see \"List of I-Schools\"), but numerous others besides these also have comprehensive information foci.\n\nWithin information science, current issues include:\n\n\nThe first known usage of the term \"information science\" was in 1955. An early definition of Information science (going back to 1968, the year when the \"American Documentation Institute\" renamed itself as the \"American Society for Information Science and Technology\") states:\n\nSome authors use informatics as a synonym for \"information science\". This is especially true when related to the concept developed by A. I. Mikhailov and other Soviet authors in the mid-1960s. The Mikhailov school saw informatics as a discipline related to the study of scientific information.\nInformatics is difficult to precisely define because of the rapidly evolving and interdisciplinary nature of the field. Definitions reliant on the nature of the tools used for deriving meaningful information from data are emerging in Informatics academic programs.\n\nRegional differences and international terminology complicate the problem. Some people note that much of what is called \"Informatics\" today was once called \"Information Science\" – at least in fields such as Medical Informatics. For example, when library scientists began also to use the phrase \"Information Science\" to refer to their work, the term \"informatics\" emerged:\n\n\nAnother term discussed as a synonym for \"information studies\" is \"information systems\". Brian Campbell Vickery's \"Information Systems\" (1973) places information systems within IS. Ellis, Allen, & Wilson (1999), on the other hand, provide a bibliometric investigation describing the relation between two different fields: \"information science\" and \"information systems\".\n\nPhilosophy of information studies conceptual issues arising at the intersection of computer science, information technology, and philosophy. It includes the investigation of the conceptual nature and basic principles of information, including its dynamics, utilisation and sciences, as well as the elaboration and application of information-theoretic and computational methodologies to its philosophical problems.\n\nIn science and information science, an ontology formally represents knowledge as a set of concepts within a domain, and the relationships between those concepts. It can be used to reason about the entities within that domain and may be used to describe the domain.\n\nMore specifically, an ontology is a model for describing the world that consists of a set of types, properties, and relationship types. Exactly what is provided around these varies, but they are the essentials of an ontology. There is also generally an expectation that there be a close resemblance between the real world and the features of the model in an ontology.\n\nIn theory, an ontology is a \"formal, explicit specification of a shared conceptualisation\". An ontology renders shared vocabulary and taxonomy which models a domain with the definition of objects and/or concepts and their properties and relations.\n\nOntologies are the structural frameworks for organizing information and are used in artificial intelligence, the Semantic Web, systems engineering, software engineering, biomedical informatics, library science, enterprise bookmarking, and information architecture as a form of knowledge representation about the world or some part of it. The creation of domain ontologies is also fundamental to the definition and use of an enterprise architecture framework.\n\nAn information scientist is an individual, usually with a relevant subject degree or high level of subject knowledge, providing focused information to scientific and technical research staff in industry, a role quite distinct from that of a librarian. The title also applies to an individual carrying out research in information science.\n\nA systems analyst works on creating, designing, and improving information systems for a specific need. Oftentimes a systems analyst works with a business to evaluate and implement organizational processes and techniques for accessing information in order to improve efficiency and productivity within the business.\n\nAn information professional is an individual who preserves, organizes, and disseminates information. Information professionals are skilled in the organization and retrieval of recorded knowledge. Traditionally, their work has been with print materials, but these skills are being increasingly used with electronic, visual, audio, and digital materials. Information professionals work in a variety of public, private, non-profit, and academic institutions. Information professionals can also be found within organisational and industrial contexts. Performing roles that include system design and development and system analysis.\n\nInformation science, in studying the collection, classification, manipulation, storage, retrieval and dissemination of information has origins in the common stock of human knowledge. Information analysis has been carried out by scholars at least as early as the time of the Abyssinian Empire with the emergence of cultural depositories, what is today known as libraries and archives. Institutionally, information science emerged in the 19th century along with many other social science disciplines. As a science, however, it finds its institutional roots in the history of science, beginning with publication of the first issues of \"Philosophical Transactions,\" generally considered the first scientific journal, in 1665 by the Royal Society (London).\n\nThe institutionalization of science occurred throughout the 18th century. In 1731, Benjamin Franklin established the Library Company of Philadelphia, the first library owned by a group of public citizens, which quickly expanded beyond the realm of books and became a center of scientific experiment, and which hosted public exhibitions of scientific experiments. Benjamin Franklin invested a town in Massachusetts with a collection of books that the town voted to make available to all free of charge, forming the first Public Library. Academie de Chirurgia (Paris) published \"Memoires pour les Chirurgiens\", generally considered to be the first medical journal, in 1736. The American Philosophical Society, patterned on the Royal Society (London), was founded in Philadelphia in 1743. As numerous other scientific journals and societies were founded, Alois Senefelder developed the concept of lithography for use in mass printing work in Germany in 1796.\n\nBy the 19th century the first signs of information science emerged as separate and distinct from other sciences and social sciences but in conjunction with communication and computation. In 1801, Joseph Marie Jacquard invented a punched card system to control operations of the cloth weaving loom in France. It was the first use of \"memory storage of patterns\" system. As chemistry journals emerged throughout the 1820s and 1830s, Charles Babbage developed his \"difference engine,\" the first step towards the modern computer, in 1822 and his \"analytical engine” by 1834. By 1843 Richard Hoe developed the rotary press, and in 1844 Samuel Morse sent the first public telegraph message. By 1848 William F. Poole begins the \"Index to Periodical Literature,\" the first general periodical literature index in the US.\n\nIn 1854 George Boole published \"An Investigation into Laws of Thought...,\" which lays the foundations for Boolean algebra, which is later used in information retrieval. In 1860 a congress was held at Karlsruhe Technische Hochschule to discuss the feasibility of establishing a systematic and rational nomenclature for chemistry. The congress did not reach any conclusive results, but several key participants returned home with Stanislao Cannizzaro's outline (1858), which ultimately convinces them of the validity of his scheme for calculating atomic weights.\n\nBy 1865, the Smithsonian Institution began a catalog of current scientific papers, which became the \"International Catalogue of Scientific Papers\" in 1902. The following year the Royal Society began publication of its \"Catalogue of Papers\" in London. In 1868, Christopher Sholes, Carlos Glidden, and S. W. Soule produced the first practical typewriter. By 1872 Lord Kelvin devised an analogue computer to predict the tides, and by 1875 Frank Stephen Baldwin was granted the first US patent for a practical calculating machine that performs four arithmetic functions. Alexander Graham Bell and Thomas Edison invented the telephone and phonograph in 1876 and 1877 respectively, and the American Library Association was founded in Philadelphia. In 1879 \"Index Medicus\" was first issued by the Library of the Surgeon General, U.S. Army, with John Shaw Billings as librarian, and later the library issues \"Index Catalogue,\" which achieved an international reputation as the most complete catalog of medical literature.\n\nThe discipline of \"documentation science\", which marks the earliest theoretical foundations of modern information science, emerged in the late part of the 19th century in Europe together with several more scientific indexes whose purpose was to organize scholarly literature. Many information science historians cite Paul Otlet and Henri La Fontaine as the fathers of information science with the founding of the International Institute of Bibliography (IIB) in 1895. A second generation of European Documentalists emerged after the Second World War, most notably Suzanne Briet. However, \"information science\" as a term is not popularly used in academia until sometime in the latter part of the 20th century.\n\nDocumentalists emphasized the utilitarian integration of technology and technique toward specific social goals. According to Ronald Day, \"As an organized system of techniques and technologies, documentation was understood as a player in the historical development of global organization in modernity – indeed, a major player inasmuch as that organization was dependent on the organization and transmission of information.\"\nOtlet and Lafontaine (who won the Nobel Prize in 1913) not only envisioned later technical innovations but also projected a global vision for information and information technologies that speaks directly to postwar visions of a global \"information society\". Otlet and Lafontaine established numerous organizations dedicated to standardization, bibliography, international associations, and consequently, international cooperation. These organizations were fundamental for ensuring international production in commerce, information, communication and modern economic development, and they later found their global form in such institutions as the League of Nations and the United Nations. Otlet designed the Universal Decimal Classification, based on Melville Dewey’s decimal classification system.\n\nAlthough he lived decades before computers and networks emerged, what he discussed prefigured what ultimately became the World Wide Web. His vision of a great network of knowledge focused on documents and included the notions of hyperlinks, search engines, remote access, and social networks.\n\nOtlet not only imagined that all the world's knowledge should be interlinked and made available remotely to anyone, but he also proceeded to build a structured document collection. This collection involved standardized paper sheets and cards filed in custom-designed cabinets according to a hierarchical index (which culled information worldwide from diverse sources) and a commercial information retrieval service (which answered written requests by copying relevant information from index cards). Users of this service were even warned if their query was likely to produce more than 50 results per search.\nBy 1937 documentation had formally been institutionalized, as evidenced by the founding of the American Documentation Institute (ADI), later called the American Society for Information Science and Technology.\n\nWith the 1950s came increasing awareness of the potential of automatic devices for literature searching and information storage and retrieval. As these concepts grew in magnitude and potential, so did the variety of information science interests. By the 1960s and 70s, there was a move from batch processing to online modes, from mainframe to mini and microcomputers. Additionally, traditional boundaries among disciplines began to fade and many information science scholars joined with other programs. They further made themselves multidisciplinary by incorporating disciplines in the sciences, humanities and social sciences, as well as other professional programs, such as law and medicine in their curriculum. By the 1980s, large databases, such as Grateful Med at the National Library of Medicine, and user-oriented services such as Dialog and Compuserve, were for the first time accessible by individuals from their personal computers. The 1980s also saw the emergence of numerous special interest groups to respond to the changes. By the end of the decade, special interest groups were available involving non-print media, social sciences, energy and the environment, and community information systems. Today, information science largely examines technical bases, social consequences, and theoretical understanding of online databases, widespread use of databases in government, industry, and education, and the development of the Internet and World Wide Web.\n\nDissemination has historically been interpreted as unilateral communication of information. With the advent of the internet, and the explosion in popularity of online communities, \"social media has changed the information landscape in many respects, and creates both new modes of communication and new types of information\", changing the interpretation of the definition of dissemination. The nature of social networks allows for faster diffusion of information than through organizational sources. The internet has changed the way we view, use, create, and store information, now it is time to re-evaluate the way we share and spread it.\n\nSocial media networks provide an open information environment for the mass of people who have limited time or access to traditional outlets of information diffusion, this is an \"increasingly mobile and social world [that] demands...new types of information skills\". Social media integration as an access point is a very useful and mutually beneficial tool for users and providers. All major news providers have visibility and an access point through networks such as Facebook and Twitter maximizing their breadth of audience. Through social media people are directed to, or provided with, information by people they know. The ability to \"share, like, and comment on...content\" increases the reach farther and wider than traditional methods. People like to interact with information, they enjoy including the people they know in their circle of knowledge. Sharing through social media has become so influential that publishers must \"play nice\" if they desire to succeed. Although, it is often mutually beneficial for publishers and Facebook to \"share, promote and uncover new content\" to improve both user base experiences. The impact of popular opinion can spread in unimaginable ways. Social media allows interaction through simple to learn and access tools; \"The Wall Street Journal\" offers an app through Facebook, and \"The Washington Post\" goes a step further and offers an independent social app that was downloaded by 19.5 million users in 6 months, proving how interested people are in the new way of being provided information.\n\nThe connections and networks sustained through social media help information providers learn what is important to people. The connections people have throughout the world enable the exchange of information at an unprecedented rate. It is for this reason that these networks have been realized for the potential they provide. \"Most news media monitor Twitter for breaking news\", as well as news anchors frequently request the audience to tweet pictures of events. The users and viewers of the shared information have earned \"opinion-making and agenda-setting power\" This channel has been recognized for the usefulness of providing targeted information based on public demand.\n\nThe following areas are some of those that information science investigates and develops.\n\nInformation access is an area of research at the intersection of Informatics, Information Science, Information Security, Language Technology, and Computer Science. The objectives of information access research are to automate the processing of large and unwieldy amounts of information and to simplify users' access to it. What about assigning privileges and restricting access to unauthorized users? The extent of access should be defined in the level of clearance granted for the information. Applicable technologies include information retrieval, text mining, text editing, machine translation, and text categorisation. In discussion, information access is often defined as concerning the insurance of free and closed or public access to information and is brought up in discussions on copyright, patent law, and public domain. Public libraries need resources to provide knowledge of information assurance.\n\nInformation architecture (IA) is the art and science of organizing and labelling websites, intranets, online communities and software to support usability. It is an emerging discipline and \"community of practice\" focused on bringing together principles of design and architecture to the \"digital landscape\". Typically it involves a model or concept of information which is used and applied to activities that require explicit details of complex information systems. These activities include library systems and database development.\n\nInformation management (IM) is the collection and management of information from one or more sources and the distribution of that information to one or more audiences. This sometimes involves those who have a stake in, or a right to that information. Management means the organization of and control over the structure, processing and delivery of information. Throughout the 1970s this was largely limited to files, file maintenance, and the life cycle management of paper-based files, other media and records. With the proliferation of information technology starting in the 1970s, the job of information management took on a new light and also began to include the field of data maintenance.\n\nInformation retrieval (IR) is the area of study concerned with searching for documents, for information within documents, and for metadata about documents, as well as that of searching structured storage, relational databases, and the World Wide Web. Automated information retrieval systems are used to reduce what has been called \"information overload\". Many universities and public libraries use IR systems to provide access to books, journals and other documents. Web search engines are the most visible IR applications.\n\nAn information retrieval process begins when a user enters a query into the system. Queries are formal statements of information needs, for example search strings in web search engines. In information retrieval a query does not uniquely identify a single object in the collection. Instead, several objects may match the query, perhaps with different degrees of relevancy.\n\nAn object is an entity that is represented by information in a database. User queries are matched against the database information. Depending on the application the data objects may be, for example, text documents, images, audio, mind maps or videos. Often the documents themselves are not kept or stored directly in the IR system, but are instead represented in the system by document surrogates or metadata.\n\nMost IR systems compute a numeric score on how well each object in the database match the query, and rank the objects according to this value. The top ranking objects are then shown to the user. The process may then be iterated if the user wishes to refine the query.\n\nInformation seeking is the process or activity of attempting to obtain information in both human and technological contexts. Information seeking is related to, but different from, information retrieval (IR).\n\nMuch library and information science (LIS) research has focused on the information-seeking practices of practitioners within various fields of professional work. Studies have been carried out into the information-seeking behaviors of librarians, academics, medical professionals, engineers and lawyers (among others). Much of this research has drawn on the work done by Leckie, Pettigrew (now Fisher) and Sylvain, who in 1996 conducted an extensive review of the LIS literature (as well as the literature of other academic fields) on professionals' information seeking. The authors proposed an analytic model of professionals' information seeking behaviour, intended to be generalizable across the professions, thus providing a platform for future research in the area. The model was intended to \"prompt new insights... and give rise to more refined and applicable theories of information seeking\" (1996, p. 188). The model has been adapted by Wilkinson (2001) who proposes a model of the information seeking of lawyers.\n\nAn information society is a society where the creation, distribution, diffusion, uses, integration and manipulation of information is a significant economic, political, and cultural activity. The aim of an information society is to gain competitive advantage internationally, through using IT in a creative and productive way. The knowledge economy is its economic counterpart, whereby wealth is created through the economic exploitation of understanding. People who have the means to partake in this form of society are sometimes called digital citizens.\n\nBasically, an information society is the means of getting information from one place to another (Wark, 1997, p. 22). As technology has become more advanced over time so too has the way we have adapted in sharing this information with each other.\n\nInformation society theory discusses the role of information and information technology in society, the question of which key concepts should be used for characterizing contemporary society, and how to define such concepts. It has become a specific branch of contemporary sociology.\n\nKnowledge representation (KR) is an area of artificial intelligence research aimed at representing knowledge in symbols to facilitate inferencing from those knowledge elements, creating new elements of knowledge. The KR can be made to be independent of the underlying knowledge model or knowledge base system (KBS) such as a semantic network.\n\nKnowledge Representation (KR) research involves analysis of how to reason accurately and effectively and how best to use a set of symbols to represent a set of facts within a knowledge domain. A symbol vocabulary and a system of logic are combined to enable inferences about elements in the KR to create new KR sentences. Logic is used to supply formal semantics of how reasoning functions should be applied to the symbols in the KR system. Logic is also used to define how operators can process and reshape the knowledge. Examples of operators and operations include, negation, conjunction, adverbs, adjectives, quantifiers and modal operators. The logic is interpretation theory. These elements—symbols, operators, and interpretation theory—are what give sequences of symbols meaning within a KR.\n\n\nBuckland, Michael (2011). What kind of science \"can\" information science be? Journal of the American Society for Information Science and Technology, published as early view October 2011.\n\nEllis, D., Allen, D. and Wilson, T. 1999. Information Science and Information Systems: Conjunct Subjects Disjunct Disciplines. JASIS 50(12):1095–1107 (see also: https://web.archive.org/web/20120425073115/http://www.cais-acsi.ca/proceedings/2000/monarch_2000.pdf )\n\nVickery; B. C. (1973). Information Systems. London: Butterworth.\n\n"}
{"id": "215214", "url": "https://en.wikipedia.org/wiki?curid=215214", "title": "Mandate of Heaven", "text": "Mandate of Heaven\n\nThe Mandate of Heaven (, literally \"Heaven's will\") is a Chinese political and religious doctrine used since ancient times to justify the rule of the King or Emperor of China. According to this belief, Heaven (天, \"Tian\") — which embodies the natural order and will of the universe — bestows the mandate on a just ruler of China, the \"Son of Heaven\" of the \"Celestial Empire\". If a ruler was overthrown, this was interpreted as an indication that the ruler was unworthy, and had lost the mandate. It was also a common belief that natural disasters such as famine and flood were divine retributions bearing signs of Heaven's displeasure with the ruler, so there would often be revolts following major disasters as the people saw these calamities as signs that the Mandate of Heaven had been withdrawn.\n\nThe Mandate of Heaven does not require a legitimate ruler to be of noble birth, depending instead on the just and able performance of the rulers and their heirs. Dynasties such as the Han and Ming dynasties were founded by men of common origins, but they were seen as having succeeded because they had gained the Mandate of Heaven. The concept is in some ways similar to the European concept of the divine right of kings; however, unlike the European concept, it does not confer an unconditional right to rule. Intrinsic to the concept of the Mandate of Heaven was the right of rebellion against an unjust ruler. The Mandate of Heaven was often invoked by philosophers and scholars in China as a way to curtail the abuse of power by the ruler, in a system that had few other checks. Chinese historians interpreted a successful revolt as evidence that Heaven had withdrawn its mandate from the ruler. Throughout Chinese history, times of poverty and natural disasters were often taken as signs that heaven considered the incumbent ruler unjust and thus in need of replacement. \n\nThe concept of the Mandate of Heaven was first used to support the rule of the kings of the Zhou dynasty (1046–256 BCE), and legitimize their overthrow of the earlier Shang dynasty (1600–1069 BCE). It was used throughout the history of China to legitimize the successful overthrow and installation of new emperors, including by non-Han Chinese monarchs such as the Qing (1636–1912).\n\nThe prosperous Shang dynasty saw its rule filled with many outstanding accomplishments. Notably, the dynasty lasted for a considerable time during which 31 kings ruled over an extended period of 17 generations. During this period, the dynasty enjoyed a period of peace and tranquility in which citizens could make a good living. The government was originally able to control most of its internal affairs due to the firm support provided by the people. As time went on, however, the rulers' abuse of the other social classes led to social unrest and instability. The corruption in this dynasty created the conditions necessary for a new ruling house to rise the Zhou dynasty. Rebellion against the Shang was led by Zhou Wu. They created the Mandate of Heaven to explain their right to assume rule and presumed that the only way to hold the mandate was to rule well in the eyes of Heaven. They believed that the Shang ruling house had become morally corrupt, and that the Shang leaders' loss of virtue entitled their own house to take over. The overthrow of the Shang Dynasty, they said, was in accordance with the mandate given by Heaven.\n\nAfter the Zhou became the ruling dynasty, they mostly appointed their own officials. The Zhou Dynasty had their own way of assigning their officials. However, in order to appease some of the citizens, they allowed some Shang beneficiaries to continue governing their small kingdoms in compliance with Zhou rules and regulations. As the empire continued to expand, intermarriage increased because the rulers believed that it was a method of forming strong alliances that enabled them to absorb more countries into the dynasty. In case of a war, the Zhou dynasty boasted an excellent military and technology mostly because of influence from annexed countries. They also excelled in shipbuilding, which, coupled with their discovery of celestial navigation, made them excellent mariners. Intellectually, the Zhou excelled in fields of literature and philosophy while many governmental positions were filled according to the intellectual ability of a candidate. A large amount of literature survives from the Zhou period, including the \"Book of Changes\", \"Book of History\", \"Book of Etiquette\", \"Book of Song\", \"Book of Odes\", and the \"Book of Rites\". Most of these works are commentaries on the progress and political movement of the dynasty. In philosophical terms, Confucius and his followers played an important role in shaping the mentality of the government as defined by the Five Confucian Relationships. These critical thinkers served as a foundation for the government. Their works primarily stressed the importance of the ruling class, respect and their relationship with the lower class. Due to the growing size of the dynasty, it became apparent that a centralized government would lead to a lot of confusion and corruption because the government would not be able to exert its influence or accede to the needs of everyone. To address this political barrier, the dynasty formed a decentralized government in which the empire was broken down into sections. Within these districts were administrators who were appointed by the government, in return, they had to maintain their allegiance to the main internal government. In effect, the Zhou dynasty became a collection of districts. Consequently, this marked the fall of the dynasty as it became difficult for the central government to exert influence on all other regions of the empire.\n\nFinally, when the Zhou dynasty's power decreased, it was wiped out by the State of Qin, which believed that the Zhou had become weak and their rule unjust. This transition emphasizes the customary trend of the Mandate of Heaven, which provided leeway for the rise of a new power. The Qin initially attempted to capitalize on the errors made by the Zhou, either by eliminating the source of error or reforming it. During this reformation, administrative changes were made and a system of legalism was developed which stated that the law is supreme over every individual, including the rulers. Although significant progress was made during the Qin dynasty, the persecution of scholars and ordinary citizens led to an unstable state.\n\nAfter the death of Qin Shihuang, first emperor of the Qin dynasty, a widespread revolt by prisoners, peasants, and unhappy soldiers inevitably led to the fall of the Qin dynasty due to its tyrannical practices. The establishment of the Han dynasty marked a great period in China’s history marked by significant changes in the political structure of the country. Under the Han emperors, significant changes were made in which the government introduced entrance examinations known as civil service or imperial examinations for governmental positions. Additionally, the Han dynasty prospered economically through the Silk Road and other trading means.\n\nDuring the Five Dynasties and Ten Kingdoms Period, there was no dominant Chinese dynasty that ruled all of China. This created a problem for the Song dynasty that followed, as they wanted to legitimize their rule by claiming that the Mandate of Heaven had passed on them. The scholar-official Xue Juzheng compiled the \"Old History of the Five Dynasties\" (五代史) during the 960s and 970s, after the Song dynasty had taken northern China from the last of the Five Dynasties, the Later Zhou. A major purpose was to establish justification for the transference of the Mandate of Heaven through these five dynasties, and thus to the Song dynasty. He argued that these dynasties met certain vital criteria to be considered as having attained the Mandate of Heaven despite never having ruled all of China. One is that they all ruled the traditional Chinese heartland. They also held considerably more territory than any of the other Chinese states that had existed conterminously in the south.\n\nHowever, there were certain other areas where these dynasties all clearly fell short. The brutal behavior of Zhu Wen and the Later Liang was a source of considerable embarrassment, and thus there was pressure to exclude them from the Mandate. The following three dynasties, the Later Tang, Later Jin, and Later Han were all non-Han Chinese dynasties, all having been ruled by the Shatuo ethnic minority. There is also the concern that though each of them was the most powerful Chinese kingdom of its respective era, none of them ever really had the ability to unify the entire Chinese realm as there were several powerful states to the south. However, it was the conclusion of Xue Juzheng that the Mandate had indeed passed through each of the Five Dynasties, and thus onto the Song Dynasty when it conquered the last of those dynasties.\n\nIn previous dynasties; the Song, Jin, and Yuan dynasties reigned for much of the beginning three centuries where the mandate of heaven was questioned heavily between dynastic councils among each emperor. Some emperors were not entirely sure of their validity when it came to claiming the mandate, for it was ambiguous. Especially for the case of the Jurchen Jin, where much of the council was not sure how to discern the validity of their rulers. From the Emperor Gaozong of the Tang Dynasty to Kangxi Emperor much of the chosen emperors contemplated much of this when they became a contender for the mandate. The reason for this was because of the ambiguity of the Mandate and overwhelmingly unofficial formality when declaring the Mandate of Heaven. However, Kublai Khan was the only indifferent ruler when he claimed the Mandate of Heaven over the Yuan Dynasty since he had a sizable military and was part of the Khitan people, as with many others from the same background since they did not have the same traditions and culture as their Chinese adversaries.\n\nIt was said that the peasant group of the Ming dynasty were the real selectors which allowed for the Mandate of Heaven to be claimed by the ruler. As a prospective candidate to the Mandate, they could please the peasantry group in order to win favor amongst the dynasty. It was solely politics from beginning to end and an attempt from the emperor to maintain a favorable act towards Heaven. Many emperors within the Qing dynasty looked immensely within themselves trying to come to terms with their ruling if natural disasters occurred within their time. This was interpreted as a warning of Heaven's displeased wrath towards an emperors ruling, such that the Mandate under their rule was unstable. Furthermore, Qing emperors would take their advisors feedback very seriously when pertaining to ruling and take it upon themselves to reflect on their current decisions of the dynastic overview in hopes that it favors Heaven.\n\nMencius stated that:\n\nChinese historians interpreted a successful revolt as evidence that the Mandate of Heaven had passed. In China, the right of rebellion against an unjust ruler has been a part of political philosophy ever since the Zhou dynasty, and the successful rebellion was interpreted by Chinese historians as evidence that divine approval had passed on to the successive dynasty. The Right of Rebellion is not coded into any official law. Rather, rebellion is always outlawed and severely punished; but is still a positive right grounded in the Chinese moral system. Often, it is used as a justification for actions to overthrow a previous dynasty after a rebellion has been successful and a new dynastic rule has been established. Since the winner is the one who determines who has obtained the Mandate of Heaven and who has lost it, some Chinese scholars consider it to be a sort of Victor's justice, best characterized in the popular Chinese saying \"The winner becomes king, the loser becomes outlaw\" (Chinese: “”). Due to this, it is considered that Chinese historical accounts of the fall of a dynasty and the rise of a new one must be handled with caution. Chinese traditional historical compilation methods produce accounts that tend to fit their account to the theory, emphasizing aspects tending to prove that the old dynasty lost the Mandate of Heaven and the new one gained it, and de-emphasizing other aspects.\n\nIn the 20th and 21st centuries, student rebellions typically claimed the Mandate of Heaven has been forfeited, as demonstrated by their large-scale activism. Important instances include the Taiwan's Sunflower Student Movement in 2014 and Hong Kong's Umbrella Movement in 2019.\n\nBecause of China's influence in medieval times, the concept of the Mandate of Heaven spread to other East Asian countries as a justification for rule by divine political legitimacy. In Korea, it was first adopted by the Joseon dynasty and became an enduring state ideology.\n\nIn Japan, the Japanese government found the concept ideologically problematic, preferring not to have divine political legitimacy that was conditional and that could be withdrawn. The Japanese Taihō Code, formulated in 703, was largely an adaptation of the governmental system of China's then Tang dynasty, but the Mandate of Heaven was specifically omitted. In later times, this need was obviated because the Imperial House of Japan claimed to be descended in an unbroken line from the Japanese sun goddess, Amaterasu. Nevertheless, while maintaining this role, the Japanese emperor became politically marginalized in the Nara and Heian periods by powerful regents of the Fujiwara clan who seized executive control of state. Even though the Japanese imperial line itself remained unbroken after the eighth century, actual political authority passed through successive dynasties of regents and \"shōguns\" which cycled in a manner similar to that of Chinese dynasties. Even after the Meiji Restoration in 1868, when the emperor was placed back in the center of the political bureaucracy, the throne itself had very little power vis-à-vis the Meiji oligarchy. Actual political power has passed through at least four systems since the Meiji restoration: the Taishō democracy, the militarists, the Occupation of Japan, and postwar democracy. The emperor today is a political figurehead and not a ruling sovereign. It could be said the imperial line of Japan survived for so long precisely because it did not have control over the state, and that the turmoil of succession was projected onto a series of proxy rulers.\n\n\n"}
{"id": "19552", "url": "https://en.wikipedia.org/wiki?curid=19552", "title": "Media studies", "text": "Media studies\n\nResearchers may also develop and employ theories and methods from disciplines including cultural studies, rhetoric (including digital rhetoric), philosophy, literary theory, psychology, political science, political economy, economics, sociology, anthropology, social theory, art history and criticism, film theory, and information theory.\n\nFor a history of the field, see \"History of media studies\".The first Media Studies M.A. program in the U.S. was introduced by John Culkin at The New School in 1975, which has since graduated more than 2,000 students. Culkin was responsible for bringing Marshall McLuhan to Fordham in 1968 and subsequently founded the Center for Understanding Media, which became the New School program.\n\nMedia is studied as a broad subject in most states in Australia, with the state of Victoria being world leaders in curriculum development . Media studies in Australia was first developed as an area of study in Victorian universities in the early 1960s, and in secondary schools in the mid 1960s.\n\nToday, almost all Australian universities teach media studies. According to the Government of Australia's \"Excellence in Research for Australia\" report, the leading universities in the country for media studies (which were ranked well above World standards by the report's scoring methodology) are Monash University, QUT, RMIT, University of Melbourne, University of Queensland and UTS.\n\nIn secondary schools, an early film studies course first began being taught as part of the Victorian junior secondary curriculum during the mid 1960s. And, by the early 1970s, an expanded media studies course was being taught. The course became part of the senior secondary curriculum (later known as the Victorian Certificate of Education or \"VCE\") in the 1980s. It has since become, and continues to be, a strong component of the VCE. Notable figures in the development of the Victorian secondary school curriculum were the long time Rusden College media teacher Peter Greenaway (not the British film director), Trevor Barr (who authored one of the first media text books \"Reflections of Reality\") and later John Murray (who authored \"The Box in the Corner\", \"In Focus\", and \"10 Lessons in Film Appreciation\").\n\nToday, Australian states and territories that teach media studies at a secondary level are Australian Capital Territory, Northern Territory, Queensland, South Australia, Victoria and Western Australia. Media studies does not appear to be taught in the state of New South Wales at a secondary level.\n\nIn Victoria, the VCE media studies course is structured as: Unit 1 - Representation, Technologies of Representation, and New Media; Unit 2 - Media Production, Australian Media Organisations; Unit 3 - Narrative Texts, Production Planning; and Unit 4 - Media Process, Social Values, and Media Influence. Media studies also form a major part of the primary and junior secondary curriculum, and includes areas such as photography, print media and television.\n\nVictoria also hosts the peak media teaching body known as ATOM which publishes \"Metro\" and \"Screen Education\" magazines.\n\nIn Canada, media studies and communication studies are incorporated in the same departments and cover a wide range of approaches (from critical theory to organizations to research-creation and political economy, for example). Over time, research developed to employ theories and methods from cultural studies, philosophy, political economy, gender, sexuality and race theory, management, rhetoric, film theory, sociology, and anthropology. Harold Innis and Marshall McLuhan are famous Canadian scholars for their contributions to the fields of media ecology and political economy in the 20th century. They were both important members of the Toronto School of Communication at the time. More recently, the School of Montreal and its founder James R. Taylor significantly contributed to the field of organizational communication by focusing on the ontological processes of organizations.\n\nCarleton University and the University of Western Ontario, 1945 and 1946 prospectively, created Journalism specific programs or schools. A Journalism specific program was also created at Ryerson in 1950. The first communication programs in Canada were started at Ryerson and Concordia Universities. The Radio and Television Arts program at Ryerson were started in the 1950s, while the Film, Media Studies/Media Arts, and Photography programs also originated from programs started in the 1950s. The Communication studies department at Concordia was created in the late 1960s. Ryerson's Radio and Television, Film, Media and Photography programs were renowned by the mid 1970s, and its programs were being copied by other colleges and universities nationally and Internationally.\n\nToday, most universities offer undergraduate degrees in Media and Communication Studies, and many Canadian scholars actively contribute to the field, among which: Brian Massumi (philosophy, cultural studies), Kim Sawchuk (cultural studies, feminist, ageing studies), Carrie Rentschler (feminist theory), and François Cooren (organizational communication).\n\nIn his book “Understanding Media, The Extensions of Man”, media theorist Marshall McLuhan suggested that \"the medium is the message\", and that all human artefacts and technologies are media. His book introduced the usage of terms such as “media” into our language along with other precepts, among them “global village” and “Age of Information”. A medium is anything that mediates our interaction with the world or other humans. Given this perspective, media study is not restricted to just media of communications but all forms of technology. Media and their users form an ecosystem and the study of this ecosystem is known as media ecology.\n\nMcLuhan says that the “technique of fragmentation that is the essence of machine technology” shaped the restructuring of human work and association and “the essence of automation technology is the opposite”. He uses an example of the electric light to make this connection and to explain “the medium is the message”. The electric light is pure information and it is a medium without a message unless it is used to spell out some verbal ad or a name. The characteristic of all media means the “content” of any medium is always another medium. For example, the content of writing is speech, the written word is the content of print, and print is the content of the telegraph. The change that the medium or technology introduces into human affairs is the “message”. If the electric light is used for Friday night football or to light up your desk you could argue that the content of the electric light is these activities. The fact that it is the medium that shapes and controls the form of human association and action makes it the message. The electric light is over looked as a communication medium because it doesn't have any content. It is not until the electric light is used to spell a brand name that it is recognized as medium. Similar to radio and other mass media electric light eliminates time and space factors in human association creating deeper involvement. McLuhan compared the “content” to a juicy piece of meat being carried by a burglar to distract the “watchdog of the mind”. The effect of the medium is made strong because it is given another media “content”. The content of a movie is a book, play or maybe even an opera.\n\nMcLuhan talks about media being “hot” or “cold” and touches on the principle that distinguishes them from one another. A hot medium (i.e., radio or Movie) extends a single sense in “high definition”. High definition means the state of being well filled with data. A cool medium (i.e., Telephone and TV) is considered “low definition” because a small amount of data/information is given and has to be filled in. Hot media are low in participation and cool media are high in participation. Hot media are low in participation because it is giving most of the information and it excludes. Cool media are high in participation because it gives you information but you have to fill in the blanks and it is inclusive. He used lecturing as an example for hot media and seminars as an example for low media. If you use a hot medium in a hot or cool culture makes a difference.\n\nThere are two universities in China that specialize in media studies. Communication University of China, formerly known as the Beijing Broadcasting Institute, that dates back to 1954. CUC has 15,307 full-time students, including 9264 undergraduates, 3512 candidates for doctor and master's degrees and 16780 students in programs of continuing education. The other university known for media studies in China is Zhejiang University of Media and Communications (ZUMC) which has campuses in Hangzhou and Tongxiang. Almost 10,000 full-time students are currently studying in over 50 programs at the 13 Colleges and Schools of ZUMC. Both institutions have produced some of China's brightest broadcasting talents for television as well as leading journalists at magazines and newspapers.\n\nThere is no university specialized on journalism and media studies, but there are seven public universities which have a department of media studies. Three biggest are based in Prague (Charles University), Brno (Masaryk University) and Olomouc (Palacký University). There are another nine private universities and colleges which has media studies department.\n\nOne prominent French media critic is the sociologist Pierre Bourdieu who wrote among other books \"On Television\" (New Press, 1999). Bourdieu's analysis is that television provides far less autonomy, or freedom, than we think. In his view, the market (which implies the hunt for higher advertising revenue) not only imposes uniformity and banality, but also a form of invisible censorship. When, for example, television producers \"pre-interview\" participants in news and public affairs programs, to ensure that they will speak in simple, attention-grabbing terms, and when the search for viewers leads to an emphasis on the sensational and the spectacular, people with complex or nuanced views are not allowed a hearing.\n\nIn Germany two main branches of media theory or media studies can be identified.\n\nThe first major branch of media theory has its roots in the humanities and cultural studies, such as film studies (\"Filmwissenschaft\"), theater studies (\"Theaterwissenschaft\") and German language and literature studies (\"Germanistik\") as well as Comparative Literature Studies (\"Komparatistik\"). This branch has broadened out substantially since the 1990s. And it is on this initial basis that a culturally-based media studies (often emphasised more recently through the disciplinary title \"Medienkulturwissenschaft\") in Germany has primarily developed and established itself.\n\nThis plurality of perspectives make it difficult to single out one particular site where this branch of Medienwissenschaft originated. While the Frankfurt-based theatre scholar, Hans-Theis Lehmanns term \"post dramatic theater\" points directly to the increased blending of co-presence and mediatized material in the German theater (and elsewhere) since the 1970s, the field of theater studies from the 1990s onwards at the Freie Universität Berlin, led in particular by Erika Fischer-Lichte, showed particular interest in the ways in which theatricality influenced notions of performativity in aesthetic events. Within the field of Film Studies, again, both Frankfurt and Berlin were dominant in the development of new perspectives on moving image media. Heide Schlüpman in Frankfurt and Gertrud Koch, first in Bochum then in Berlin, were key theorists contributing to an aesthetic theory of the cinema (Schlüpmann) as \"dispositif\" and the moving image as medium, particularly in the context of illusion (Koch). Many scholars who became known as media scholars in Germany originally were scholars of German, such as Friedrich Kittler, who taught at the Humboldt Universität zu Berlin, completed both his dissertation and habilitation in the context of \"Germanistik\". One of the early publications in this new direction is a volume edited by Helmut Kreuzer, \"Literature Studies - Media Studies\" (\"Literaturwissenschaft – Medienwissenschaft\"), which summarizes the presentations given at the Düsseldorfer Germanistentag 1976.\n\nThe second branch of media studies in Germany is comparable to Communication Studies. Pioneered by Elisabeth Noelle-Neumann in the 1940s, this branch studies mass media, its institutions and its effects on society and individuals. The German Institute for Media and Communication Policy, founded in 2005 by media scholar Lutz Hachmeister, is one of the few independent research institutions that is dedicated to issues surrounding media and communications policies.\n\nThe term \"Wissenschaft\" cannot be translated straightforwardly as \"studies\", as it calls to mind both scientific methods and the humanities. Accordingly, German media theory combines philosophy, psychoanalysis, history, and scienctific studies with media-specific research.\n\n\"Medienwissenschaften\" is currently one of the most popular courses of study at universities in Germany, with many applicants mistakenly assuming that studying it will automatically lead to a career in TV or other media. This has led to widespread disillusionment, with students blaming the universities for offering highly theoretical course content. The universities maintain that practical journalistic training is not the aim of the academic studies they offer.\n\nMedia Studies is a fast growing academic field in India, with several dedicated departments and research institutes. With a view to making the best use of communication facilities for information, publicity and development, the Government of India in 1962-63 sought the advice of the Ford Foundation/UNESCO team of internationally known mass communication specialists who recommended the setting up of a national institute for training, teaching and research in mass communication. Anna University was the first university to start Master of Science in Electronic Media programmes. It offers a five-year integrated programme and a two-year programme in Electronic Media. The Department of Media Sciences was started in January 2002, branching off from the UGC's Educational Multimedia Research Centre (EMMRC). National Institute of Open Schooling, the world's largest open schooling system, offers Mass Communication as a subject of studies at senior secondary level. All the major universities in the country have mass media and journalism studies departments. Centre for the Study of Developing Societies (CSDS), Delhi has media studies as one of their major emphasis. Centre for Internet and Society, Bangaluru that does interdisciplinary research on internet and digital technologies also is worth mentioning.\nMain scholars who are working on Indian media include Arvind Rajagopal, Ravi Sundaram, Robin Jeffrey, Sevanti Ninan, Shohini Ghosh, and Usha M. Rodrigues and Maya Ranganathan. \nAs a founding director of the Centre for Culture, Media & Governance at Jamia Millia Islamia, Biswajit Das enabled various innovative aspects of media and communication studies in India. He is also founding president of the All India Communication and Media Association (AICMA) that is dedicated for the teachers, researchers and scholars engaged in research, pedagogical concerns and teaching with an interdisciplinary inquiry. The work of Nalin Mehta on the expansion of private television channels in India, Amelia Bonea's research on the history of telegraph and journalism, and Shiju Sam Varughese's work on science and mass media open new areas of research in Indian media studies.\n\nIn the Netherlands, media studies are split into several academic courses such as (applied) communication sciences, communication- and information sciences, communication and media, media and culture or theater, film and television sciences. Whereas communication sciences focuses on the way people communicate, be it mediated or unmediated, media studies tends to narrow the communication down to just mediated communication. However, it would be a mistake to consider media studies a specialism of communication sciences, since media make up just a small portion of the overall course. Indeed, both studies tend to borrow elements from one another.\n\nCommunication sciences (or a derivative thereof) can be studied at Erasmus University Rotterdam, Radboud University, Tilburg University, University of Amsterdam, University of Groningen, University of Twente, Roosevelt Academy, University of Utrecht, VU University Amsterdam and Wageningen University and Research Centre.\n\nMedia studies (or something similar) can be studied at the University of Amsterdam, VU University Amsterdam, Erasmus University Rotterdam, University of Groningen and the University of Utrecht.\n\nMedia studies in New Zealand is healthy, especially due to renewed activity in the country's film industry and is taught at both secondary and tertiary education institutes. Media studies in NZ can be regarded as a singular success, with the subject well-established in the tertiary sector (such as Screen and Media Studies at the University of Waikato; Media Studies, Victoria University of Wellington; Film, Television and Media Studies, University of Auckland; Media Studies, Massey University; Communication Studies, University of Otago). \n\nDifferent Media Studies courses can offer students a range of specialisations- such as cultural studies, media theory and analysis, practical film-making, journalism and communications studies. But what makes the case of New Zealand particularly significant in respect of Media Studies is that for more than a decade it has been a nationally mandated and very popular subject in secondary (high) schools, taught across three years in a very structured and developmental fashion, with Scholarship in Media Studies available for academically gifted students. According to the New Zealand Ministry of Education Subject Enrolment figures 229 New Zealand schools offered Media Studies as a subject in 2016, representing more than 14,000 students.\n\nIn Pakistan, media studies programs are widely offered. University of the Punjab Lahore is the oldest department. Later on University of Karachi, Peshawar University, BZU Multaan, Islamia University Bahwalpur also started communication programs. Now, newly established universities are also offering mass communication program in which University of Gujrat emerged as a leading department. Bahria University which is established by Pakistan Navy is also offering BS in media studies.\n\nIn Switzerland, media and communication studies are offered by several higher education institutions including the International University in Geneva, Zurich University of Applied Sciences, University of Lugano, University of Fribourg and others.\n\nIn the United Kingdom, media studies developed in the 1960s from the academic study of English, and from literary criticism more broadly. The key date, according to Andrew Crisell, is 1959:\n\nWhen Joseph Trenaman left the BBC's Further Education Unit to become the first holder of the Granada Research Fellowship in Television at Leeds University. Soon after in 1966, the Centre for Mass Communication Research was founded at Leicester University, and degree programmes in media studies began to sprout at polytechnics and other universities during the 1970s and 1980s.\n\nJames Halloran at Leicester University is credited with much influence in the development of media studies and communication studies, as the head of the university's Centre for Mass Communication Research, and founder of the International Association for Media and Communication Research. Media Studies is now taught all over the UK. It is taught at Key Stages 1– 3, Entry Level, GCSE and at A level and the Scottish Qualifications Authority offers formal qualifications at a number of different levels. It is offered through a large area of exam boards including AQA and WJEC.\n\nMuch research in the field of news media studies has been led by the Reuters Institute for the Study of Journalism. Details of the research projects and results are published in the RISJ annual report.\n\nMass communication, Communication studies or simply 'Communication' may be more popular names than “media studies” for academic departments in the United States. However, the focus of such programs sometimes excludes certain media—film, book publishing, video games, etc. The title “media studies” may be used alone, to designate film studies and rhetorical or critical theory, or it may appear in combinations like “media studies and communication” to join two fields or emphasize a different focus. It is a very broad study as media has many platforms in the modern world. Social Media is an industry that has gotten a lot of attention in recent years. Our primary form of entertainment is no longer our TVs but we have access to a screen about worldwide events all the time.\nIn 1999, the MIT Comparative Media Studies program started under the leadership of Henry Jenkins, since growing into a graduate program, MIT's largest humanities major, and, following a 2012 merger with the Writing and Humanistic Studies program, a roster of twenty faculty, including Pulitzer Prize-winning author Junot Diaz, science fiction writer Joe Haldeman, games scholar T. L. Taylor, and media scholars William Uricchio (a CMS co-founder), Edward Schiappa, and Heather Hendershot. Now named Comparative Media Studies/Writing, the department places an emphasis on what Jenkins and colleagues had termed \"applied humanities\": it hosts several research groups for civic media, digital humanities, games, computational media, documentary, and mobile design, and these groups are used to provide graduate students with research assistantships to cover the cost of tuition and living expenses. The incorporation of Writing and Humanistic Studies also placed MIT's Science Writing program, Writing Across the Curriculum, and Writing and Communications Center under the same roof.\n\nFormerly an interdisciplinary major at the University of Virginia the Department of Media Studies was officially established in 2001 and has quickly grown to wide recognition. This is partly thanks to the acquisition of Professor Siva Vaidhyanathan, a cultural historian and media scholar, as well as the Inaugural Verklin Media Policy and Ethics Conference, endowed by the CEO of Canoe Ventures and UVA alumnus David Verklin. In 2010, a group of undergraduate students in the Media Studies Department established the Movable Type Academic Journal, the first ever undergraduate academic journal of its kind. The department is expanding rapidly and doubled in size in 2011.\n\nBrooklyn College, part of the City University of New York, has been offering graduate studies in television and media since 1961. Currently, the Department of Television and Radio administers an MS in Media Studies, and hosts the Center for the Study of World Television.\n\nThe University of Southern California has three distinct centers for media studies: the Center for Visual Anthropology (founded in 1984), the Institute for Media Literacy at the School of Cinematic Arts (founded in 1998) and the Annenberg School for Communication and Journalism (founded in 1971).\n\nUniversity of California, Irvine had in Mark Poster one of the first and foremost theorists of media culture in the US, and can boast a strong Department of Film & Media Studies. University of California, Berkeley has three institutional structures within which media studies can take place: the department of Film and Media (formerly Film Studies Program), including famous theorists as Mary Ann Doane and Linda Williams, the Center for New Media, and a long established interdisciplinary program formerly titled Mass Communications, which recently changed its name to Media Studies, dropping any connotations which accompany the term “Mass” in the former title. Until recently, Radford University in Virginia used the title \"media studies\" for a department that taught practitioner-oriented major concentrations in journalism, advertising, broadcast production and Web design. In 2008, those programs were combined with a previous department of communication (speech and public relations) to create a School of Communication. (A media studies major at Radford still means someone concentrating on journalism, broadcasting, advertising or Web production.)\n\nThe University of Denver has a renowned program for digital media studies. It is an interdisciplinary program combining Communications, Computer Science, and the arts.\n\n\n"}
{"id": "353672", "url": "https://en.wikipedia.org/wiki?curid=353672", "title": "Open society", "text": "Open society\n\nThe French philosopher Henri Bergson coined the term open society in 1932. The idea was further developed during World War II by the Austrian-born British philosopher Karl Popper.\nBergson describes a closed society as a closed system of law or religion. It is static, like a closed mind. Bergson suggests that if all traces of civilization were to disappear, the instincts of the closed society for including or excluding others would remain. In contrast, an open society is dynamic and inclined to moral universalism.\n\nPopper saw the open society as part of a historical continuum reaching from the organic, tribal, or closed society, through the open society - marked by a critical attitude to tradition - to the abstract or depersonalized society lacking all face-to-face interaction transactions.\n\nIn open societies, the government is expected to be responsive and tolerant, and its political mechanisms transparent and flexible. It can be characterized as opposed to authoritarianism.\n\nPopper saw the classical Greeks as initiating the slow transition from tribalism towards the open society, and as facing for the first time the strain imposed by the less personal group relations entailed thereby.\n\nWhereas tribalistic and collectivist societies do not distinguish between natural laws and social customs, so that individuals are unlikely to challenge traditions they believe to have a sacred or magical basis, the beginnings of an open society are marked by a distinction between natural and man-made law, and an increase in personal responsibility and accountability for moral choices (not incompatible with religious belief).\n\nPopper argued that the ideas of individuality, criticism, and humanitarianism cannot be suppressed once people have become aware of them, and therefore that it is impossible to return to the closed society, but at the same time recognized the continuing emotional pull of what he called “the lost group spirit of tribalism”, as manifested for example in the totalitarianisms of the 20th century.\n\nWhile the period since Popper's study has undoubtedly been marked by the spread of the open society, this may be attributed less to Popper's advocacy and more to the role of the economic advances of late modernity. Growth-based industrial societies require literacy, anonymity and social mobility from their members — elements incompatible with much traditional-based behavior but demanding the ever-wider spread of the abstract social relations Georg Simmel saw as characterizing the metropolitan mental stance.\n\nKarl Popper defined the open society as one \"in which individuals are confronted with personal decisions\" as opposed to a \"magical or tribal or collectivist society.\"\n\nHe considered that only democracy provides an institutional mechanism for reform and leadership change without the need for bloodshed, revolution or coup d'état.\n\nModern advocates of the open society suggest that society would keep no secrets from itself in the public sense, as all are trusted with the knowledge of all. Political freedoms and human rights are claimed to be the foundation of an open society.\n\nPopper's concept of the open society is epistemological rather than political. When Popper wrote \"The Open Society and its Enemies\", he believed that the social sciences had failed to grasp the significance and the nature of fascism and communism because these sciences were based on what he saw to be faulty epistemology. Totalitarianism forced knowledge to become political which made critical thinking impossible and led to the destruction of knowledge in totalitarian countries.\n\nPopper's theory that knowledge is provisional and fallible implies that society must be open to alternative points of view. An open society is associated with cultural and religious pluralism; it is always open to improvement because knowledge is never completed but always ongoing: “if we wish to remain human, then there is only one way, the way into the open society... into the unknown, the uncertain and insecure”.\n\nIn the closed society, claims to certain knowledge and ultimate truth lead to the attempted imposition of one version of reality. Such a society is closed to freedom of thought. In contrast, in an open society each citizen needs to engage in critical thinking, which requires freedom of thought and expression and the cultural and legal institutions that can facilitate this.\n\nHumanitarianism, equality and political freedom are ideally fundamental characteristics of an open society. This was recognized by Pericles, a statesman of the Athenian democracy, in his laudatory funeral oration: \"advancement in public life falls to reputation for capacity, class considerations not being allowed to interfere with merit; nor again does poverty bar the way, if a man is able to serve the state, he is not hindered by the obscurity of his condition. The freedom which we enjoy in our government extends also to our ordinary life.\"\n\nArguably however it was the tension between a traditional society and the new, more open space of the emerging \"polis\" which most fully marked classical Athens, and Popper was very aware of the continuing emotional appeal of what he called \"holism...longing for the lost unity of tribal life\" into the modern world.\n\nInvestor and philanthropist George Soros, a self-described follower of Karl Popper, argued that sophisticated use of powerful techniques of subtle deception borrowed from modern advertising and cognitive science by conservative political operatives such as Frank Luntz and Karl Rove casts doubt on Popper's view of open society. Because the electorate's perception of reality can easily be manipulated, democratic political discourse does not necessarily lead to a better understanding of reality. Soros argues that in addition to the need for separation of powers, free speech, and free elections, an explicit commitment to the pursuit of truth is imperative. \"Politicians will respect, rather than manipulate, reality only if the public cares about the truth and punishes politicians when it catches them in deliberate deception.\"\n\nPopper however, did not identify the open society either with democracy or with capitalism or a \"laissez-faire\" economy, but rather with a critical frame of mind on the part of the individual, in the face of communal group think of whatever kind. An important aspect in Popper's thinking is the notion that the truth can be lost. Critical attitude does not mean that the truth is found.\n\n"}
{"id": "364319", "url": "https://en.wikipedia.org/wiki?curid=364319", "title": "Learned society", "text": "Learned society\n\nA learned society (; also known as a learned academy, scholarly society, or academic association) is an organisation that exists to promote an academic discipline, profession, or a group of related disciplines such as the arts and science. Membership may be open to all, may require possession of some qualification, or may be an honour conferred by election.\n\nMost learned societies are non-profit organisations, and many are professional associations. Their activities typically include holding regular conferences for the presentation and discussion of new research results and publishing or sponsoring academic journals in their discipline. Some also act as professional bodies, regulating the activities of their members in the public interest or the collective interest of the membership.\n\nSome of the oldest learned societies are the Académie des Jeux floraux (founded 1323), the Sodalitas Litterarum Vistulana (founded 1488), the Accademia della Crusca (founded 1585), the Accademia dei Lincei (founded 1603), the Académie Française (founded 1635), the Academy of Sciences Leopoldina (founded 1652), the Royal Society of London (founded 1660) and the French Academy of Sciences (founded 1666).\n\nScholars in the sociology of science argue that learned societies are of key importance and their formation assists in the emergence and development of new disciplines or professions.\n\nSocieties can be very general in nature, such as the American Association for the Advancement of Science, specific to a given discipline, such as the Modern Language Association, or specific to a given area of study, such as the Royal Entomological Society.\n\nMost are either specific to a particular country (e.g. the Entomological Society of Israel), though they generally include some members from other countries as well, often with local branches, or are international, such as the International Federation of Library Associations and Institutions (IFLA) or the Regional Studies Association, in which case they often have national branches. But many are local, such as the Massachusetts Medical Society, the publishers of the internationally known \"New England Journal of Medicine\".\n\nSome learned societies (such as the Royal Society Te Apārangi) have been rechartered by legislation to form quasi-autonomous non-governmental organizations.\n\nMembership may be open to all, may require possession of some qualification, or may be an honor conferred by election. This is the case with some learned societies, such as the Polish Sodalitas Litterarum Vistulana (founded 1488), the Italian Accademia dei Lincei, the Académie Française, the German Academy of Sciences Leopoldina, the UK's Royal Society and Royal Academy of Engineering or the French Academy of Sciences.\n\nSome societies offer membership to those who have an interest in a particular subject or discipline, provided they pay their membership fees. Older and more academic/professional societies may offer associateships and/or fellowships to fellows who are appropriately qualified by \"honoris causa\", or by submission of a portfolio of work or an original thesis. A benefit of membership may be discounts on the subscription rates for the publications of the society. Many of these societies award post-nominal letters to their memberships.\n\nFollowing the globalization and the development of information technology, certain scholarly societies—such as the Modern Language Association—have created virtual communities for their members. In addition to established academic associations, academic virtual communities have been so organized that, in some cases, they have become more important platforms for interaction and scientific collaborations among researchers and faculty than have traditional scholarly societies.\nMembers of these online academic communities, grouped by areas of interests, use for their communication shared and dedicated listservs (for example JISCMail), social networking services (like Facebook, LinkedIn) and academic oriented social networks (like Mendeley, Academia.edu).\n\n\n"}
{"id": "1696316", "url": "https://en.wikipedia.org/wiki?curid=1696316", "title": "Social actions", "text": "Social actions\n\nIn sociology, social action, also known as Weberian social action, is an act which takes into account the actions and reactions of individuals (or 'agents'). According to Max Weber, \"an Action is 'social' if the acting individual takes account of the behavior of others and is thereby oriented in its course\".\n\nThe basic concept was primarily developed in the non-positivist theory of Max Weber to observe how human behaviors relate to cause and effect in the social realm. For Weber, sociology is the study of society and behavior and must therefore look at the heart of interaction. The theory of social action, more than structural functionalist positions, accepts and assumes that humans vary their actions according to social contexts and how it will affect other people; when a potential reaction is not desirable, the action is modified accordingly. Action can mean either a basic action (one that has a meaning) or an advanced social action, which not only has a meaning but is directed at other actors and causes action (or, perhaps, \"inaction\").\n\nThe term is more practical and encompassing than Florian Znaniecki's \"social phenomena\", since the individual performing social action is not passive, but rather active and reactive. Although Weber himself used the word 'agency', in modern social science this term is often appropriated with a given acceptance of Weberian conceptions of social action, unless a work intends to make the direct allusion. Similarly, 'reflexivity' is commonly used as a shorthand to refer to the circular relationship of cause and effect between structure and agency which Weber was integral in hypothesising.\n\n\nAnother example would be most economic transactions. Value Relation is divided into the subgroups commands and demands. According to the law, people are given commands and must use the whole system of private laws to break down the central government or domination in the legal rights in which a citizen possess. Demands can be based on justice or human dignity just for morality. These demands have posed several problems even legal formalism has been put to the test. These demands seem to weigh on the society and at times can make them feel immoral.\n\nThe rational choice approach to religion draws a close analogy between religion and the market economy. Religious firms compete against one another to offer religious products and services to consumers, who choose between the firms. To the extent that there are many religious firms competing against each other, they will tend to specialize and cater to the particular needs of some segments of religious consumers. This specialization and catering in turn increase the number of religious consumers actively engaged in the religious economy. This proposition has been confirmed in a number of empirical studies.\n\nIt is well known that strict churches are strong and growing in the contemporary United States, whereas liberal ones are declining. For Iannaccone's religious experience is a jointly produced collective good. Thus members of a church face a collective action problem. Strict churches, which often impose costly and esoteric requirements on their members, are able to solve this problem by weeding out potential free riders, since only the very committed would join the church in the face of such requirements. Consistent with the notion that religious experience is a collective good, Iannaccone et al. show that churches that extract more resources from their members (in the form of time and money) tend to grow in membership.\n\nEmotion: Emotions are one's feelings in response to a certain situation. There are six types of emotion: social emotions, counterfactual emotions, emotions generated by what may happen (often manifested as anxiety), emotions generated by joy and grief (examples found in responses typically seen when a student gets a good grade, and when a person is at a funeral, respectively), thought-triggered emotions (sometimes manifested as flashbacks), and finally emotions of love and disgust. All of these emotions are considered to be unresolved. There are six features that are used to define emotions: intentional objects, valence, cognitive antecedents, physiological arousal, action tendencies, and lastly physiological expressions. These six concepts were identified by Aristotle and are still the topic of several talks.\nMacro institutional theory of Economic Order: Nicole Biggart and Thomas Beamish have a slightly different approach to human habit then Max Weber. Whereas Weber believed economic organization is based on structures of material interest and ideas, institutional sociologist like Biggart and Beamish stress macro-institutional sources of arrangements of market capitalism.\n\nMicrological theories of economy consider acts of a group of individuals. Economic theory is based on the assumption that when the highest bidder succeeds the market clears. Microeconomics theories believes that individuals are going to find the cheapest way to buy the things they need. By doing this it causes providers to be competitive and therefore creates order in the economy.\n\n\nIn sociological hierarchy, social action is more advanced than behavior, action and social behavior, and is in turn followed by more advanced social contact, social interaction and social relation. \n\n"}
{"id": "45802", "url": "https://en.wikipedia.org/wiki?curid=45802", "title": "Social capital", "text": "Social capital\n\nSocial capital is the effective functioning of social groups through interpersonal relationships, a shared sense of identity, a shared understanding, shared norms, shared values, trust, cooperation, and reciprocity. Social capital is a measure of the value of resources, both tangible (public spaces, private property) and intangible (\"actors\", \"human capital\", people), and the impact that these relationships have on the resources involved in each relationship, and on larger groups. It is generally seen as a form of capital that produces public goods for a common good.\n\nSocial capital has been used to explain the improved performance of diverse groups, the growth of entrepreneurial firms, superior managerial performance, enhanced supply chain relations, the value derived from strategic alliances, and the evolution of communities.\n\nThe term \"social capital\" was in intermittent use from about 1890, before becoming widely used in the late 1990s.\n\nIn the first half of the 19th century, Alexis de Tocqueville had observations about American life that seemed to outline and define social capital. He observed that Americans were prone to meeting at as many gatherings as possible to discuss all possible issues of state, economics, or the world that could be witnessed. The high levels of transparency caused greater participation from the people and thus allowed for democracy to work better.\n\nL. J. Hanifan's 1916 article regarding local support for rural schools is one of the first occurrences of the term \"social capital\" in reference to social cohesion and personal investment in the community. In defining the concept, Hanifan contrasts social capital with material goods by defining it as:\n\nI do not refer to real estate, or to personal property or to cold cash, but rather to that in life which tends to make these tangible substances count for most in the daily lives of people, namely, goodwill, fellowship, mutual sympathy and social intercourse among a group of individuals and families who make up a social unit… If he may come into contact with his neighbour, and they with other neighbours, there will be an accumulation of social capital, which may immediately satisfy his social needs and which may bear a social potentiality sufficient to the substantial improvement of living conditions in the whole community. The community as a whole will benefit by the cooperation of all its parts, while the individual will find in his associations the advantages of the help, the sympathy, and the fellowship of his neighbours (pp. 130-131).\nJane Jacobs used the term early in the 1960s. Although she did not explicitly define the term \"social capital\", her usage referred to the value of networks. Political scientist Robert Salisbury advanced the term as a critical component of interest group formation in his 1969 article \"An Exchange Theory of Interest Groups\" in the \"Midwest Journal of Political Science\". Sociologist Pierre Bourdieu used the term in 1972 in his \"Outline of a Theory of Practice\", and clarified the term some years later in contrast to cultural, economic, administrative capital, physical capital, political capital, social capital and symbolic capital. Sociologists James Coleman, and Barry Wellman & Scot Wortley adopted Glenn Loury's 1977 definition in developing and popularising the concept. In the late 1990s the concept gained popularity, serving as the focus of a World Bank research programme and the subject of several mainstream books, including Robert Putnam's \"Bowling Alone\" and Putnam and Lewis Feldstein's \"Better Together\".\n\nThe concept that underlies social capital has a much longer history; thinkers exploring the relation between associational life and democracy were using similar concepts regularly by the 19th century, drawing on the work of earlier writers such as James Madison (\"The Federalist Papers\") and Alexis de Tocqueville (\"Democracy in America\") to integrate concepts of social cohesion and connectedness into the pluralist tradition in American political science. John Dewey may have made the first direct mainstream use of \"social capital\" in \"The School and Society\" in 1899, though he did not offer a definition.\n\nThe power of \"community governance\" has been stressed by many philosophers from antiquity to the 18th century, from Aristotle to Thomas Aquinas and Edmund Burke (Bowles and Gintis, 2002). This vision was strongly criticised at the end of the 18th century, with the development of the idea of \"Homo Economicus\" and subsequently with \"rational choice theory\". Such a set of theories became dominant in the last centuries, but many thinkers questioned the complicated relationship between \"modern society\" and the importance of \"old institutions\", in particular family and traditional communities. The debate of community versus modernization of society and individualism has been the most discussed topic among the founders of sociology (Tönnies, 1887; Durkheim, 1893; Simmel, 1905; Weber, 1946). They were convinced that industrialisation and urbanization were transforming social relationships in an irreversible way. They observed a breakdown of traditional bonds and the progressive development of anomie and alienation in society (Wilmott, 1986).\n\nAfter Tönnies' and Weber's works, reflection on social links in modern society continued with interesting contributions in the 1950s and in the 1960s, in particular \"mass society theory\" (Bell, 1962; Nisbet, 1969; Stein, 1960; Whyte, 1956). They proposed themes similar to those of the founders, with a more pessimistic emphasis on the development of society. In the words of Stein (1960:1): \"The price for maintaining a society that encourages cultural differentiation and experimentation is unquestionably the acceptance of a certain amount of disorganization on both the individual and social level.\" All these reflections contributed remarkably to the development of the social capital concept in the following decades.\n\nThe appearance of the modern social capital conceptualization is a new way to look at this debate, keeping together the importance of community to build generalized trust and the same time, the importance of individual free choice, in order to create a more cohesive society. It is for this reason that social capital generated so much interest in the academic and political world\n(Rose, 2000).\n\nPierre Bourdieu's work tends to show how social capital can be used practically to produce or reproduce inequality, demonstrating for instance how people gain access to powerful positions through the direct and indirect employment of social connections. Robert Putnam has used the concept in a much more positive light: though he was at first careful to argue that social capital was a neutral term, stating \"whether or not [the] shared are praiseworthy is, of course, entirely another matter\", his work on American society tends to frame social capital as a producer of \"civic engagement\" and also a broad societal measure of communal health. He also transforms social capital from a resource possessed by individuals to an attribute of collectives, focusing on norms and trust as producers of social capital to the exclusion of networks.\n\nMahyar Arefi identifies consensus building as a direct positive indicator of social capital. Consensus implies \"shared interest\" and agreement among various actors and stakeholders to induce collective action. Collective action is thus an indicator of increased social capital.\n\nEdwards and Foley, as editors of a special edition of the \"American Behavioral Scientist\" on \"Social Capital, Civil Society and Contemporary Democracy\", raised two key issues in the study of social capital. First, social capital is not equally available to all, in much the same way that other forms of capital are differently available. Geographic and social isolation limit access to this resource. Second, not all social capital is created equally. The value of a specific source of social capital depends in no small part on the socio-economic position of the source with society. On top of this, Portes has identified four negative consequences of social capital: exclusion of outsiders; excess claims on group members; restrictions on individual freedom; and downward levelling norms.\n\nVarshney studied the correlation between the presence of interethnic networks (bridging) versus intra-ethnic ones (bonding) on ethnic violence in India.\nHe argues that interethnic networks are agents of peace because they build bridges and manage tensions, by noting that if communities are organized only along intra-ethnic lines and the interconnections with other communities are very weak or even nonexistent, then ethnic violence is quite likely.\nThree main implications of intercommunal ties explain their worth:\n\nThis is a useful distinction; nevertheless its implication on social capital can only be accepted if one espouses the functionalist understanding of the latter concept. Indeed, it can be argued that interethnic, as well as intra-ethnic networks can serve various purposes, either increasing or diminishing social capital. In fact, Varshney himself notes that intraethnic policing (equivalent to the \"self-policing\" mechanism proposed by Fearon and Laitin) may lead to the same result as interethnic engagement.\n\nSocial capital is often linked to the success of democracy and political involvement. Robert D. Putnam, in his book \"Bowling Alone\" makes the argument that social capital is linked to the recent decline in American political participation.\n\nSocial capital has multiple definitions, interpretations, and uses. Thomas Sander defines it as \"the collective value of all social networks (who people know), and the inclinations that arise from these networks to do things for each other (norms of reciprocity).\" Social capital, in this view, emphasizes \"specific benefits that flow from the trust, reciprocity, information, and cooperation associated with social networks\". It \"creates value for the people who are connected, and for bystanders as well.\" Meanwhile, negative norms of reciprocity serve as disincentives for detrimental and violent behaviors.\n\nDavid Halpern argues that the popularity of social capital for policymakers is linked to the concept's duality, coming because \"it has a hard nosed economic feel while restating the importance of the social.\" For researchers, the term is popular partly due to the broad range of outcomes it can explain; the multiplicity of uses for social capital has led to a multiplicity of definitions. Social capital has been used at various times to explain superior managerial performance, the growth of entrepreneurial firms, improved performance of functionally diverse groups, the value derived from strategic alliances, and enhanced supply chain relations.\n'A resource that actors derive from specific social structures and then use to pursue their interests; it is created by changes in the relationship among actors'; (Baker 1990, p. 619).\n\nEarly attempts to define social capital focused on the degree to which social capital as a resource should be used for public good or for the benefit of individuals. Putnam suggested that social capital would facilitate co-operation and mutually supportive relations in communities and nations and would therefore be a valuable means of combating many of the social disorders inherent in modern societies, for example crime. In contrast to those focusing on the individual benefit derived from the web of social relationships and ties individual actors find themselves in, attribute social capital to increased personal access to information and skill sets and enhanced power. According to this view, individuals could use social capital to further their own career prospects, rather than for the good of organisations.\n\nIn \"The Forms of Capital\" Pierre Bourdieu distinguishes between three forms of capital: economic capital, cultural capital and social capital. He defines social capital as \"the aggregate of the actual or potential resources which are linked to possession of a durable network of more or less institutionalized relationships of mutual acquaintance and recognition.\" His treatment of the concept is instrumental, focusing on the advantages to possessors of social capital and the \"deliberate construction of sociability for the purpose of creating this resource.\" Quite contrary to Putnam's positive view of social capital, Bourdieu employs the concept to demonstrate a mechanism for the generational reproduction of inequality. Bourdieu thus points out that the wealthy and powerful use their \"old boys network\" or other social capital to maintain advantages for themselves, their social class, and their children.\n\nJames Coleman defined social capital functionally as \"a variety of entities with two elements in common: they all consist of some aspect of social structure, and they facilitate certain actions of actors...within the structure\"—that is, social capital is anything that facilitates individual or collective action, generated by networks of relationships, reciprocity, trust, and social norms. In Coleman's conception, social capital is a neutral resource that facilitates any manner of action, but whether society is better off as a result depends entirely on the individual uses to which it is put.\n\nAccording to Robert Putnam, social capital refers to \"connections among individuals – social networks and the norms of reciprocity and trustworthiness that arise from them.\" According to Putnam and his followers, social capital is a key component to building and maintaining democracy. Putnam says that social capital is declining in the United States. This is seen in lower levels of trust in government and lower levels of civic participation. Putnam also says that television and urban sprawl have had a significant role in making America far less 'connected'. Putnam believes that social capital can be measured by the amount of trust and \"reciprocity\" in a community or between individuals.\n\nPutnam also suggests that a root cause of the decline in social capital is women's entry the workforce, which could correlate with time restraints that inhibit civic organizational involvement like parent-teacher associations. Technological transformation of leisure (e.g., television) is another cause of declining social capital, as stated by Putnam. This offered a reference point from which several studies assessed social capital measurements by how media is engaged strategically to build social capital.\n\nNan Lin's concept of social capital has a more individualistic approach: \"Investment in social relations with expected returns in the marketplace.\" This may subsume the concepts of some others such as Bourdieu, Flap and Eriksson.\n\nNewton (1997) considered social capital as subjective phenomenon formed by values and attitudes which influence interactions.\n\nIn “Social capital, civil society, and development,” political economist Francis Fukuyama defines social capital as generally understood rules that enable people to cooperate such as the norm of reciprocity or religious doctrine like Christianity. Social capital is formed by repeated interactions over time and, he argues, is critical for development and difficult to generate through public policy. The importance of social capital for economic development is that these norms of behavior reduce transaction cost of exchange such as legal contracts and government regulations. Fukuyama suggests that while social capital is beneficial for development, it also imposes cost on non-group members with unintended consequences for general welfare. Referencing Alexis de Tocqueville in \"Democracy in America,\" and what he described as the ‘art of association’ of Americans’ propensity for civil association, Fukuyama argues social capital is what produces a civil society. While civic engagement is an important part of democracy and development, Fukuyama states that, “one person’s civic engagement is another’s rent-seeking.” Therefore, while social capital can facilitate economic development by reducing transaction cost and increasing productivity, social capital can also distort democracy if civic association enables special interest to gain special favors. However, Fukuyama argues despite the risk of society having too much social capital, it is nonetheless worse to have too little and be unable to organize for public goods and welfare enhancing activity.\n\nNahapiet and Ghoshal in their examination of the role of social capital in the creation of intellectual capital, suggest that social capital should be considered in terms of three clusters: structural, relational, and cognitive. Carlos García Timón describes that the structural dimensions of social capital relate to an individual ability to make weak and strong ties to others within a system. This dimension focuses on the advantages derived from the configuration of an actor's, either individual or collective, network. The differences between weak and strong ties are explained by Granovetter. The relational dimension focuses on the character of the connection between individuals. This is best characterized through trust of others and their cooperation and the identification an individual has within a network. Hazleton and Kennan added a third angle, that of communication. Communication is needed to access and use social capital through exchanging information, identifying problems and solutions, and managing conflict. According to Boisot and Boland and Tenkasi, meaningful communication requires at least some sharing context between the parties to such exchange. The cognitive dimension focuses on the shared meaning, representations and interpretations that individuals or groups have with one another.\n\nA number of scholars have raised concerns about lack of precise definition of social capital. Portes, for example, noted that the term has become so widely used, including in mainstream media, that \"the point is approaching at which social capital comes to be applied to so many events and in so many different contexts as to lose any distinct meaning.\" Robison, Schmid, and Siles reviewed various definitions of social capital and concluded that many did not satisfy the formal requirement of a definition. They noted that definitions must be of the form A=B while many definition of social capital described what it can be used to achieve, where it resides, how it can be created, and what it can transform. In addition, they argue that many proposed definition of social capital fail to satisfy the requirements of capital. They propose that social capital be defined as \"sympathy\". The object of another's sympathy has social capital. Those who have sympathy for others provide social capital. One of the main advantages of having social capital is that it provides access to resources on preferential terms. Their definition of sympathy follows that used by Adam Smith, the title of his first chapter in the \"Theory of Moral Sentiments.\"\n\nA network-based conception can also be used for characterizing the social capital of collectivities (such as organizations or business clusters). Lester (name change to Amber Persons) noted that negative social capital may be the cause for disadvantageous differences among minority firms versus majority firms. While studying norms among African-American family firms and Euro-American family firms, Lester noted that negative social capital was created when the owner of the company was pressured to engage in social behavior not conducive to firm profits.\n\nThe term \"capital\" is used by analogy with other forms of economic capital, as social capital is argued to have similar (although less measurable) benefits. However, the analogy with capital is misleading to the extent that, unlike traditional forms of capital, social capital is not depleted by use; in fact it is depleted by non-use (\"use it or lose it\"). In this respect, it is similar to the now well-established economic concept of human capital.\n\nSocial capital is also distinguished from the economic theory social capitalism. Social capitalism as a theory challenges the idea that socialism and capitalism are mutually exclusive. Social capitalism posits that a strong social support network for the poor enhances capital output. By decreasing poverty, capital market participation is enlarged.\n\nIn \"Bowling Alone: The Collapse and Revival of American Community\" (Putnam, 2000), Harvard political scientist Robert D. Putnam wrote: \"Henry Ward Beecher's advice a century ago to 'multiply picnics' is not entirely ridiculous today. We should do this, ironically, not because it will be good for America — though it will be — but because it will be good for us.\"\n\nDaniel P. Aldrich, Associate Professor at Purdue University, describes three mechanisms of social capital. Aldrich defines the three differences as bonding, bridging, and linking social capital. Bonding capital are the relationships a person has with friends and family, making it also the strongest form of social capital. Bridging capital is the relationship between friends of friends, making its strength secondary to bonding capital. Linking capital is the relationship between a person and a government official or other elected leader. Aldrich also applies the ideas of social capital to the fundamental principles of disaster recovery, and discusses factors that either aid or impede recovery, such as extent of damage, population density, quality of government and aid. He primarily examines Japanese recovery following the 2011 Fukishima nuclear meltdown in his book \"Building Resilience: Social Capital in Post-Disaster Recovery.\"\n\nPutnam speaks of two main components of the concept: \"bonding social capital\" and \"bridging social capital\", the creation of which Putnam credits to Ross Gittell and Avis Vidal. Bonding refers to the value assigned to social networks between homogeneous groups of people and Bridging refers to that of social networks between socially heterogeneous groups. Typical examples are that criminal gangs create bonding social capital, while choirs and bowling clubs (hence the title, as Putnam lamented their decline) create bridging social capital.\n\nThe distinction is useful in highlighting how social capital may not always be beneficial for society as a whole (though it is always an asset for those individuals and groups involved). Horizontal networks of individual citizens and groups that enhance community productivity and cohesion are said to be positive social capital assets whereas self-serving exclusive gangs and hierarchical patronage systems that operate at cross purposes to societal interests can be thought of as negative social capital burdens on society.\n\nSocial capital development on the internet via social networking websites such as Facebook or Myspace tends to be bridging capital according to one study, though \"virtual\" social capital is a new area of research.\n\nThere are two other sub-sources of social capital. These are consummatory, or a behavior that is made up of actions that fulfill a basis of doing what is inherent, and instrumental, or behavior that is taught through ones surroundings over time.\n\nTwo examples of consummatory social capital are value interjection and solidarity. Value interjection pertains to a person or community that fulfills obligations such as paying bills on time, philanthropy, and following the rules of society. People that live their life this way feel that these are norms of society and are able to live their lives free of worry for their credit, children, and receive charity if needed. Coleman goes on to say that when people live in this way and benefit from this type of social capital, individuals in the society are able to rest assured that their belongings and family will be safe. This understanding of solidarity may be traced to 19th century socialist thinkers. The main focus of these thinkers was the urban working class of the Industrial Revolution. They analyzed the reasons these workers supported each other for the benefit of the group and held that this support was an adaptation to the immediate social environment, as opposed to a trait that had been taught to the workers in their youth. As another example, Coleman states that possessing this type of social capital individuals to stand up for what they believe in, and even die for it, in the face of adversity. (While the notion of solidarity as social capital is sometimes attributed to Karl Marx, in particular, the term \"social capital\" had a quite different meaning for Marx. All forms of \"capital\" were, for Marx, possessed only by capitalists and he emphasized the basis of labour in capitalist society, as a class constituted by individuals obliged to sell their labour power, because they lacked sufficient capital, in any sense of the word, to do otherwise. Marx saw \"social capital\" as a theoretical total amount of capital, purely in the sense of accumulated wealth or property, that existed within in a particular society. He thereby contrasted it with specific and discrete \"individual capital\".)\n\nThe second of these two other sub-sources of social capital is that of instrumental social capital. The basis of the category of social capital is that an individual who donates his or her resources not because he is seeking direct repayment from the recipient, but because they are part of the same social structure. By his or her donation, the individual might not see a direct repayment, but, most commonly, they will be held by the society in greater honor. The best example of this, and the one that Portes mentions, is the donation of a scholarship to a member of the same ethnic group. The donor is not freely giving up his resources to be directly repaid by the recipient, but, as stated above, the honor of the community. With this in mind, the recipient might not know the benefactor personally, but he or she prospers on the sole factor that he or she is a member of the same social group.\n\nSocial capital is also linked with religious communities. Religion represents important aspect of social capital (religious social capital).\n\nThere is no widely held consensus on how to measure social capital, which has become a debate in itself. Why refer to this phenomenon as 'capital' if there is no true way to measure it? While one can usually intuitively sense the level/amount of social capital present in a given relationship(regardless of type or scale), quantitative measuring has proven somewhat complicated. This has resulted in different metrics for different functions.\n\nOne type of quantitative social capital measure uses name generators to construct social networks and to measure the level of social capital. These networks are constructed by asking participants to name people that they interact with, such as \"Name all the people you've discussed important matters within the past six months.\" Name generators are often useful to construct core discussion networks of close ties, rather than weaker ties.\n\nMany studies measure social capital by asking the question: \"do you trust the others?\" Other researches analyse the participation in voluntary associations or civic activities.\n\nTo expand upon the methodological potential of measuring online and offline social bonding, as it relates to social capital, offers a matrix of social capital measures that distinguishes social bridging as a form of less emotionally tethered relationships compared to bonding. Bonding and bridging sub-scales are proposed, which have been adopted by over 300 scholarly articles. Lin, Peng, Kim, Kim & LaRose (2012) offer a noteworthy application of the scale by measuring international residents originating from locations outside of the United States. The study found that social media platforms like Facebook provide an opportunity for increased social capital, but mostly for extroverts. However, less introverted social media users could engage social media and build social capital by connecting with Americans before arriving and then maintaining old relationships from home upon arriving to the states. The ultimate outcome of the study indicates that social capital is measurable and is a concept that may be operationalized to understand strategies for coping with cross-cultural immersion through online engagement.\n\nThe level of cohesion of a group also affects its social capital and vice versa. However, there is no one quantitative way of determining the level of cohesiveness, but rather a collection of social network models that researchers have used over the decades to operationalize social capital. One of the dominant methods is Ronald Burt's constraint measure, which taps into the role of tie strength and group cohesion. Another network-based model is network transitivity.\n\nIn measuring political social capital, it is common to take the sum of society's membership of its groups. Groups with higher membership (such as political parties) contribute more to the amount of capital than groups with lower membership, although many groups with low membership (such as communities) still add up to be significant. While it may seem that this is limited by population, this need not be the case as people join multiple groups. In a study done by Yankee City, a community of 17,000 people was found to have over 22,000 different groups.\n\nKnack and Keefer (1996) measured econometrically correlations between confidence and civic cooperation norms, with economic growth in a big group of countries. They found that confidence and civic cooperation have a great impact in economic growth, and that in less polarized societies in terms of inequality and ethnic differences, social capital is bigger.\n\nNarayan and Pritchet (1997) researched the associativity degree and economic performance in rural homes of Tanzania. They saw that even in high poverty indexes, families with higher levels of incomes had more participation in collective organizations. The social capital they accumulated because of this participation had individual benefits for them, and created collective benefits through different routes, for example: their agricultural practices were better than those of the families without participation (they had more information about agrochemicals, fertilizers and seeds); they had more information about the market; they were prepared to take more risks, because being part of a social network made them feel more protected; they had an influence on the improvement of public services, showing a bigger level of participation in schools; they cooperated more in the municipality level.\n\nHow a group relates to the rest of society also affects social capital, but in a different manner. Strong internal ties can in some cases weaken the group's perceived capital in the eyes of the general public, as in cases where the group is geared towards crime, distrust, intolerance, violence or hatred towards others. The Ku Klux Klan is an example of this kind of organizations.\n\nSociologists Carl L. Bankston and Min Zhou have argued that one of the reasons social capital is so difficult to measure is that it is neither an individual-level nor a group-level phenomenon, but one that emerges across levels of analysis as individuals participate in groups. They argue that the metaphor of \"capital\" may be misleading because unlike financial capital, which is a resource held by an individual, the benefits of forms of social organization are not held by actors, but are results of the participation of actors in advantageously organized groups.\n\nRecently, Foschi and Lauriola presented a measure of sociability as a proxy of social capital. The authors demonstrated that facets of sociability can mediate between general personality traits and measures of civic involvement and political participation, as predictors of social capital, in a holistic model of political behavior.\n\nThe World Social Capital Monitor is an instrument for measuring social goods and social capital created by the United Nations Sustainable Development Group in partnership with civil society actors. The project identifies social values such as trust, solidarity, helpfulness, friendliness, hospitality and the willingness to finance public goods with the help of anonymous surveys. The surveys started in 2016.\n\n\nRobison and colleagues measured the relative importance of selfishness and four social capital motives using resource allocation data collected in hypothetical surveys and non-hypothetical experiments. The selfishness motive assumes that an agent's allocation of a scarce resource is independent of his relationships with others. This motive is sometimes referred to as the selfishness of preference assumption in neoclassical economics. Social capital motives assume that agents' allocation of a scarce resource may be influenced by their social capital or sympathetic relationships with others which may produce socio-emotional goods that satisfy socio-emotional needs for validation and belonging. The first social capital motive seeks for validation by acting consistently with the values of one's ideal self. The second social capital motive seeks to be validated by others by winning their approval. The third social capital motive seeks to belong. Recognizing that one may not be able to influence the sympathy of others, persons seeking to belong may act to increase their own sympathy for others and the organizations or institutions they represent. The fourth social capital motive recognizes that our sympathy or social capital for another person will motivate us to act in their interest. In doing so we satisfy our own needs for validation and belonging. Empirical results reject the hypothesis often implied in economics that we are 95% selfish.\n\nA number of authors give definitions of civil society that refer to voluntary associations and organisations outside the market and state. This definition is very close to that of the third sector, which consists of \"private organisations that are formed and sustained by groups of people acting voluntarily and without seeking personal profit to provide benefits for themselves or for others\". According to such authors as Walzer, Alessandrini, Newtown, Stolle and Rochon, Foley and Edwards, and Walters, it is through civil society, or more accurately, the third sector, that individuals are able to establish and maintain relational networks. These voluntary associations also connect people with each other, build trust and reciprocity through informal, loosely structured associations, and consolidate society through altruism without obligation. It is \"this range of activities, services and associations produced by... civil society\" that constitutes the sources of social capital.\n\nIf civil society, then, is taken to be synonymous with the third sector then the question it seems is not 'how important is social capital to the production of a civil society?' but 'how important is civil society to the production of social capital?'. Not only have the authors above documented how civil society produces sources of social capital, but in Lyons work \"Third Sector\", social capital does not appear in any guise under either the factors that enable or those that stimulate the growth of the third sector, and Onyx describes how social capital depends on an already functioning community.\n\nThe idea that creating social capital (i.e., creating networks) will strengthen civil society underlies current Australian social policy aimed at bridging deepening social divisions. The goal is to reintegrate those marginalised from the rewards of the economic system into \"the community\". However, according to Onyx (2000), while the explicit aim of this policy is inclusion, its effects are exclusionary.\n\nFoley and Edwards believe that \"political systems... are important determinants of both the character of civil society and of the uses to which whatever social capital exists might be put\". Alessandrini agrees, saying, \"in Australia in particular, neo-liberalism has been recast as economic rationalism and identified by several theorists and commentators as a danger to society at large because of the use to which they are putting social capital to work\".\n\nThe resurgence of interest in social capital as a remedy for the cause of today's social problems draws directly on the assumption that these problems lie in the weakening of civil society. However this ignores the arguments of many theorists who believe that social capital leads to exclusion rather than to a stronger civil society. In international development, Ben Fine and John Harriss have been heavily critical of the inappropriate adoption of social capital as a supposed panacea (promoting civil society organisations and NGOs, for example, as agents of development) for the inequalities generated by neo liberal economic development. This leads to controversy as to the role of state institutions in the promotion of social capital.\nAn abundance of social capital is seen as being almost a necessary condition for modern liberal democracy. A low level of social capital leads to an excessively rigid and unresponsive political system and high levels of corruption, in the political system and in the region as a whole. Formal public institutions require social capital in order to function properly, and while it is possible to have too much social capital (resulting in rapid changes and excessive regulation), it is decidedly worse to have too little.\n\nKathleen Dowley and Brian Silver published an article entitled \"Social Capital, Ethnicity and Support for Democracy in the Post-Communist States\". This article found that in post-communist states, higher levels of social capital did not equate to higher levels of democracy. However, higher levels of social capital led to higher support for democracy.\n\nA number of intellectuals in developing countries have argued that the idea of social capital, particularly when connected to certain ideas about civil society, is deeply implicated in contemporary modes of donor and NGO driven imperialism and that it functions, primarily, to blame the poor for their condition.\n\nThe concept of social capital in a Chinese social context has been closely linked with the concept of \"guanxi\".\n\nAn interesting attempt to measure social capital spearheaded by Corporate Alliance in the English speaking market segment of the United States of America and Xentrum through the Latin American Chamber of Commerce in Utah on the Spanish speaking population of the same country, involves the quantity, quality and strength of an individual social capital. With the assistance of software applications and web-based relationship-oriented systems such as LinkedIn, these kinds of organizations are expected to provide its members with a way to keep track of the \"number\" of their relationships, meetings designed to boost the \"strength\" of each relationship using group dynamics, executive retreats and networking events as well as training in how to reach out to higher circles of \"influential\" people.\n\nThere are many factors that drive volume towards the ballot box, including education, employment, civil skills, and time. Careful evaluation of these fundamental factors often suggests that women do not vote at similar levels as men. However the gap between women and men voter turnout is diminishing and in some cases women are becoming more prevalent at the ballot box than their male counterparts. Recent research on social capital is now serving as an explanation for this change.\n\nSocial capital offers a wealth of resources and networks that facilitate political engagement. Since social capital is readily available no matter the type of community, it is able to override more traditional queues for political engagement; e.g.: education, employment, civil skills, etc.\n\nThere are unique ways in which women organize. These differences from men make social capital more personable and impressionable to women audiences thus creating a stronger presence in regards to political engagement. A few examples of these characteristics are:\n\nThe often informal nature of female social capital allows women to politicize apolitical environments without conforming to masculine standards, thus keeping this activity at a low public profile. These differences are hard to recognize within the discourse of political engagement and may explain why social capital has not been considered as a tool for female political engagement until as of late.\n\nA growing body of research has found that the presence of social capital through social networks and communities has a protective quality on health. Social capital affects health risk behavior in the sense that individuals who are embedded in a network or community rich in support, social trust, information, and norms, have resources that help achieve health goals. For example, a person who is sick with cancer may receive information, money, or moral support he or she needs to endure treatment and recover. Social capital also encourages social trust and membership. These factors can discourage individuals from engaging in risky health behaviors such as smoking and binge drinking. Furthermore, neighbourhood social capital may also aid in buffering health inequities amongst children and adolescents.. Social capital indicators such as neighbourhood cohesion, social support, and ties providing a bond between members of the same religion, have been found to be associated with better health despite financial or socioeconomic hardship. The function of social capital as a health buffer in circumstances of social disadvantage has also received attention in research on the health of minority ethnic populations. The relationships and networks that are maintained by an ethnic minority population in a geographical area where a high percentage of residents belong to the same ethnic group may lead to better health outcomes than would be expected based on other individual and neighbourhood characteristics. Such effects have been investigated in England, New Zealand, and the United States.\n\nInversely, a lack of social capital can impair health. For example, results from a survey given to 13- to 18-year-old students in Sweden showed that low social capital and low social trust are associated with higher rates of psychosomatic symptoms, musculoskeletal pain, and depression. Additionally, negative social capital can detract from health. Although there are only a few studies that assess social capital in criminalized populations, there is information that suggests that social capital does have a negative effect in broken communities. Deviant behavior is encouraged by deviant peers via favorable definitions and learning opportunities provided by network-based norms. However, in these same communities, an adjustment of norms (i.e. deviant peers being replaced by positive role models) can pose a positive effect.\nResearchers have also investigated the hypothesis that the health benefits of social capital depend on the socioeconomic resources an individual or community has available to them. For example, social capital may boost health only for those with higher levels of education, or more so for those with a higher rather than a lower income.. This research is based on Bourdieu's notion that social, economic, and cultural capital are dependent on each other.\n\nSimilar to watching the news and keeping abreast of current events, the use of the Internet can relate to an individual's level of social capital. In one study, informational uses of the Internet correlated positively with an individual's production of social capital, and social-recreational uses were negatively correlated (higher levels of these uses correlated with lower levels of social capital). An example supporting the former argument is the contribution of Peter Maranci's blog (Charlie on the Commuter Line) to address the train problems in Massachusetts. He created it after an incident where a lady passed out during a train ride due to the congestion in the train and help was delayed because of the congestion in the train and the inefficiency of the train conductor. His blog exposed the poor conditions of train stations, overcrowding train rides and inefficiency of the train conductor which eventually influenced changes within the transit system. Another perspective holds that the rapid growth of social networking sites such as Facebook and Myspace suggests that individuals are creating a virtual-network consisting of both bonding and bridging social capital. Unlike face to face interaction, people can instantly connect with others in a targeted fashion by placing specific parameters with internet use. This means that individuals can selectively connect with others based on ascertained interests, and backgrounds. Facebook is currently the most popular social networking site and touts many advantages to its users including serving as a \"social lubricant\" for individuals who otherwise have difficulties forming and maintaining both strong and weak ties with others.\n\nThis argument continues, although the preponderance of evidence shows a positive association between social capital and the internet. Critics of virtual communities believe that the Internet replaces our strong bonds with online \"weak-ties\" or with socially empty interactions with the technology itself. Others fear that the Internet can create a world of \"narcissism of similarity,\" where sociability is reduced to interactions between those that are similar in terms of ideology, race, or gender. A few articles suggest that technologically based interactions has a negative relationship with social capital by displacing time spent engaging in geographical/ in-person social activities. However, the consensus of research shows that the more time people spend online the more in-person contact they have, thus positively enhancing social capital.\n\nRecent research, conducted in 2006, also shows that Internet users often have wider networks than those who uses internet irregularly or not at all. When not considering family and work contacts, Internet users actually tend to have contact with a higher number of friends and relatives. This is supported by another study that shows that internet users and non-internet users do feel equally close to the same number of people; also the internet users maintain relationships with 20% more people that they \"feel somewhat close\" to.\n\nOther research shows that younger people use the Internet as a supplemental medium for communication, rather than letting the Internet communication replace face-to-face contact. This supports the view that Internet communication does not hinder development of social capital and does not make people feel lonelier than before.\n\nEllison, Steinfield & Lampe (2007) suggest social capital exercised online is a result of relationships formed offline; whereby, bridging capital is enabled through a \"maintenance\" of relationships. Among respondents of this study, social capital built exclusively online creates weaker ties. A distinction of social bonding is offered by Ellison et al., 2007, suggesting bonds, or strong ties, are possible through social media, but less likely.\n\nColeman and Hoffer collected quantitative data of 28,000 students in total 1,015 public, Catholic and other private high schools in America from the 7 years' period from 1980 to 1987. It was found from this longitudinal research that social capital in students' families and communities attributed to the much lower dropout rates in Catholic schools compared with the higher rates in public.\n\nTeachman et al. further develop the family structure indicator suggested by Coleman. They criticise Coleman, who used only the number of parents present in the family, neglected the unseen effect of more discrete dimensions such as stepparents' and different types of single-parent families. They take into account of a detailed counting of family structure, not only with two biological parents or stepparent families, but also with types of single-parent families with each other (mother-only, father-only, never-married, and other). They also contribute to the literature by measuring parent-child interaction by the indicators of how often parents and children discuss school-related activities.\n\nMorgan and Sorensen directly challenge Coleman for his lacking of an explicit mechanism to explain why Catholic schools students perform better than public school students on standardised tests of achievement. Researching students in Catholic schools and public schools again, they propose two comparable models of social capital effect on mathematic learning. One is on Catholic schools as norm-enforcing schools whereas another is on public schools as horizon-expanding schools. It is found that while social capital can bring about positive effect of maintaining an encompassing functional community in norm-enforcing schools, it also brings about the negative consequence of excessive monitoring. Creativity and exceptional achievement would be repressed as a result. Whereas in horizon expanding school, social closure is found to be negative for student's mathematic achievement. These schools explore a different type of social capital, such as information about opportunities in the extended social networks of parents and other adults. The consequence is that more learning is fostered than norm-enforcing Catholic school students. In sum, Morgan and Sorensen's (1999) study implies that social capital is contextualised, one kind of social capital may be positive in this setting but is not necessarily still positive in another setting.\n\nIn the setting of education through Kilpatrick et al., (2010) state, '... social capital is a useful lens for analysing lifelong learning and its relationship to community development'. Social capital is particularly important in terms of education. Also the importance of education with '...schools being designed to create \"functioning community\"- forging tighter links between parents and the school' (Coleman & Hoffer, 1987) linking that without this interaction, the social capital in this area is disadvantaged and demonstrates that social capital plays a major role in education.\n\nWithout social capital in the area of education, teachers and parents that play a responsibility in a students learning, the significant impacts on their child's academic learning can rely on these factors. With focus on parents contributing to their child's academic progress as well as being influenced by social capital in education. Without the contribution by the parent in their child's education, gives parents less opportunity and participation in the student's life. As Tedin et al. (2010) state '...one of the most important factors in promoting student success is the active involvement of parents in a child's education.' With parents also involved in activities and meetings the school conducts, the more involved parents are with other parents and the staff members. Thus parent involvement contributes to social capital with becoming more involved in the school community and participating makes the school a sustainable and easy to run community.\n\nIn their journal article \"Beyond social capital: Spatial dynamics of collective efficacy for children\", Sampson et al. stress the normative or goal-directed dimension of social capital. They claim, \"resources or networks alone (e.g. voluntary associations, friendship ties, organisational density) are neutral--- they may or may not be effective mechanism for achieving intended effect\"\n\nMarjoribanks and Kwok conducted a survey in Hong Kong secondary schools with 387 fourteen-year-old students with an aim to analyse female and male adolescents differential educational achievement by using social capital as the main analytic tool. In that research, social capital is approved of its different effects upon different genders. In his thesis \"New Arrival Students in Hong Kong: Adaptation and School Performance\", Hei Hang Hayes Tang argues that adaptation is a process of activation and accumulation of (cultural and social) capitals. The research findings show that supportive networks is the key determinant differentiating the divergent adaptation pathways. Supportive networks, as a form of social capital, is necessary for activating the cultural capital the newly arrived students possessed. The amount of accumulated capital is also relevant to further advancement in the ongoing adaptation process.\n\nMin Zhou and Carl L. Bankston in their study of a Vietnamese community in New Orleans find that preserving traditional ethnic values enable immigrants to integrate socially and to maintain solidarity in an ethnic community. Ethnic solidarity is especially important in the context where immigrants just arrive in the host society. In her article \"Social Capital in Chinatown\", Zhou examines how the process of adaptation of young Chinese Americans is affected by tangible forms of social relations between the community, immigrant families, and the younger generations. Chinatown serves as the basis of social capital that facilitates the accommodation of immigrant children in the expected directions. Ethnic support provides impetus to academic success. Furthermore, maintenance of literacy in native language also provides a form of social capital that contributes positively to academic achievement. Stanton-Salazar and Dornbusch found that bilingual students were more likely to obtain the necessary forms of institutional support to advance their school performance and their life chances.\n\nPutnam (2000) mentions in his book \"Bowling Alone\", \"Child development is powerfully shaped by social capital\" and continues \"presence of social capital has been linked to various positive outcomes, particularly in education\". According to his book, these positive outcomes are the result of parents' social capital in a community. In states where there is a high social capital, there is also a high education performance. The similarity of these states is that parents were more associated with their children's education. Teachers have reported that when the parents participate more in their children's education and school life, it lowers levels of misbehavior, such as bringing weapons to school, engaging in physical violence, unauthorized absence, and being generally apathetic about education. Borrowing Coleman's quotation from Putnam's book, Coleman once mentioned we cannot understate \"the importance of the embeddedness of young persons in the enclaves of adults most proximate to them, first and most prominent the family and second, a surrounding community of adults\".\n\nIn order to understand social capital as a subject in geography, one must look at it in a sense of space, place, and territory. In its relationship, the tenets of geography relate to the ideas of social capital in the family, community, and in the use of social networks. The biggest advocate for seeing social capital as a geographical subject was American economist and political scientist Robert Putnam. His main argument for classifying social capital as a geographical concept is that the relationships of people is shaped and molded by the areas in which they live.\n\nThere are many areas in which social capital can be defined by the theories and practices. Anthony Giddens developed a theory in 1984 in which he relates social structures and the actions that they produce. In his studies, he does not look at the individual participants of these structures, but how the structures and the social connections that stem from them are diffused over space. If this is the case, the continuous change in social structures could bring about a change in social capital, which can cause changes in community atmosphere. If an area is plagued by social organizations whose goals are to revolt against social norms, such as gangs, it can cause a negative social capital for the area causing those who disagreed with these organizations to relocate thus taking their positive social capital to a different space than the negative.\n\nAnother area where social capital can be seen as an area of study in geography is through the analysis of participation in volunteerism and its support of different governments. One area to look into with this is through those who participate in social organizations. People that participate are of different races, ages, and economic status. With these in mind, variances of the space in which these different demographics may vary, causing a difference in involvement among areas. Secondly, there are different social programs for different areas based on economic situation. A governmental organization would not place a welfare center in a wealthier neighborhood where it would have very limited support to the community, as it is not needed. Thirdly, social capital can be affected by the participation of individuals of a certain area based on the type of institutions that are placed there. Mohan supports this with the argument of J. Fox in his paper \"Decentralization and Rural Development in Mexico\", which states \"structures of local governance in turn influence the capacity of grassroots communities to influence social investments.\" With this theory, if the involvement of a government in specific areas raises the involvement of individuals in social organizations and/or communities, this will in turn raise the social capital for that area. Since every area is different, the government takes that into consideration and will provide different areas with different institutions to fit their needs thus there will be different changes in social capital in different areas.\n\nIn the context of leisure studies, social capital is seen as the consequence of investment in and cultivation of social relationships allowing an individual access to resources that would otherwise be unavailable to him or her. The concept of social capital in relation to leisure is grounded in a perspective that emphasizes the interconnectedness rather than the separateness of human activity and human goals. There is a significant connection between leisure and democratic social capital. Specific forms of leisure activity contribute to the development of the social capital central to democracy and democratic citizenship. The more an individual participates in social activities, the more autonomy the individual experiences, which will help her or his individual abilities and skills to develop. The greater the accumulation of social capital a person experiences, may transfer to other leisure activities as well as personal social roles, relationships and in other roles within a social structure.\n\nIt has been noted that social capital may not always be used for positive ends. While pursuing doctoral studies, Lester was the first to create figures and equate negative social capital with negative returns. Before Lester, negative social capital was a societal ill, not a business one. An example of the complexities of the effects of negative social capital is violence or criminal gang activity that is encouraged through the strengthening of intra-group relationships (bonding social capital). The negative consequences of social capital are more often associated with \"bonding\" vis-à-vis \"bridging\".\n\nWithout \"bridging\" social capital, \"bonding\" groups can become isolated and disenfranchised from the rest of society and, most importantly, from groups with which bridging must occur in order to denote an \"increase\" in social capital. Bonding social capital is a necessary antecedent for the development of the more powerful form of bridging social capital. Bonding and bridging social capital can work together productively if in balance, or they may work against each other. As social capital bonds and stronger homogeneous groups form, the likelihood of bridging social capital is attenuated. Bonding social capital can also perpetuate sentiments of a certain group, allowing for the bonding of certain individuals together upon a common radical ideal. The strengthening of insular ties can lead to a variety of effects such as ethnic marginalization or social isolation. In extreme cases ethnic cleansing may result if the relationship between different groups is so strongly negative. In mild cases, it just isolates certain communities such as suburbs of cities because of the bonding social capital and the fact that people in these communities spend so much time away from places that build bridging social capital.\n\nSocial capital (in the institutional Robert Putnam sense) may also lead to bad outcomes if the political institution and democracy in a specific country is not strong enough and is therefore overpowered by the social capital groups. \"Civil society and the collapse of the Weimar Republic\" suggests that \"it was weak political institutionalization rather than a weak civil society that was Germany's main problem during the Wihelmine and Weimar eras.\" Because the political institutions were so weak people looked to other outlets. \"Germans threw themselves into their clubs, voluntary associations, and professional organizations out of frustration with the failures of the national government and political parties, thereby helping to undermine the Weimar Republic and facilitate Hitler's rise to power.\" In this article about the fall of the Weimar Republic, the author makes the claim that Hitler rose to power so quickly because he was able to mobilize the groups towards one common goal. Even though German society was, at the time, a \"joining\" society these groups were fragmented and their members did not use the skills they learned in their club associations to better their society. They were very introverted in the Weimar Republic. Hitler was able to capitalize on this by uniting these highly bonded groups under the common cause of bringing Germany to the top of world politics. The former world order had been destroyed during World War I, and Hitler believed that Germany had the right and the will to become a dominant global power. Additionally, in his essay \"A Criticism of Putnam's Theory of Social Capital\", Michael Shindler expands upon Berman's argument that Weimar social clubs and similar associations in countries that did not develop democracy, were organized in such a way that they fostered a \"we\" instead of an \"I\" mentality among their members, by arguing that groups which possess cultures that stress solidarity over individuality, even ones that are \"horizontally\" structured and which were also common to pre-soviet eastern europe, will not engender democracy if they are politically aligned with non-democratic ideologies.\n\nLater work by Putnam also suggests that social capital, and the associated growth of public trust are inhibited by immigration and rising racial diversity in communities. Putnam's study regarding the issue argued that in American areas with a lack of homogeneity, some individuals neither participated in bonding nor bridging social capital. In societies where immigration is high (USA) or where ethnic heterogeneity is high (Eastern Europe), it was found that citizens lacked in both kinds of social capital and were overall far less trusting of others than members of homogenous communities were found to be. Lack of homogeneity led to people withdrawing from even their closest groups and relationships, creating an atomized society as opposed to a cohesive community. These findings challenge previous beliefs that exposure to diversity strengthens social capital, either through bridging social gaps between ethnicities or strengthening in-group bonds. It is very important for policy makers to monitor the level of perceived socio-economic threat from immigrants because negative attitudes towards immigrants make integration difficult and affect social capital.\n\nJames Coleman has indicated that social capital eventually led to the creation of human capital for the future generation. Human capital, a private resource, could be accessed through what the previous generation accumulated through social capital. Field suggested that such a process could lead to the very inequality social capital attempts to resolve. While Coleman viewed social capital as a relatively neutral resource, he did not deny the class reproduction that could result from accessing such capital, given that individuals worked toward their own benefit. Even though Coleman never truly addresses Bourdieu in his discussion, this coincides with Bourdieu's argument set forth in \"Reproduction in Education, Society and Culture\". Bourdieu and Coleman were fundamentally different at the theoretical level (as Bourdieu believed the actions of individuals were rarely ever conscious, but more so only a result of their habitus (see below) being enacted within a particular field, but this realization by both seems to undeniably connect their understanding of the more latent aspects of social capital.\n\nAccording to Bourdieu, habitus refers to the social context within which a social actor is socialized. Thus, it is the social platform, itself, that equips one with the social reality they become accustomed to. Out of habitus comes field, the manner in which one integrates and displays his or her habitus. To this end, it is the social exchange and interaction between two or more social actors. To illustrate this, we assume that an individual wishes to better his place in society. He therefore accumulates social capital by involving himself in a social network, adhering to the norms of that group, allowing him to later access the resources (e.g. social relationships) gained over time. If, in the case of education, he uses these resources to better his educational outcomes, thereby enabling him to become socially mobile, he effectively has worked to reiterate and reproduce the stratification of society, as social capital has done little to alleviate the system as a whole. This may be one negative aspect of social capital, but seems to be an inevitable one in and of itself, as are all forms of capital.\n\nSocial capital has been associated with the reduction in access to informal credit in informal economies (especially in developing countries). Isaac Wachira Mwangi and Shem Alfred Ouma ran a bivariate probit model on financial access national survey data to the impact of social capital on financial inclusion in Kenya. They determined that membership to groups increased one's probability of getting an informal loan by 1.45% and also the more group memberships one held, the more likely they were to access an informal loan. Similar results were revealed in a cross-sectional study run by Sarker in Bangladesh. Some other authors also note the importance of social capital among female entrepreneurship. Epo presented the case that social capital and micro loans increase the likelihood of female entrepreneurship in Cameroon. Epo did this by comparing the welfare outcomes of the entrepreneurs who both had access and no access. Other authors however disagree about the positive correlation between social capital and Microfinance, Kanak and Iiguni argue that formation of social capital is largely dependent on strategies implemented by Microfinance Institutions. Kanak and Iiguni determined this while investigating social capital formation in a rural village in Bangladesh.\n\n\n\n"}
{"id": "13854259", "url": "https://en.wikipedia.org/wiki?curid=13854259", "title": "Group cohesiveness", "text": "Group cohesiveness\n\nGroup cohesiveness (also called group cohesion and social cohesion) arises when bonds link members of a social group to one another and to the group as a whole. Although cohesion is a multi-faceted process, it can be broken down into four main components: social relations, task relations, perceived unity, and emotions. Members of strongly cohesive groups are more inclined to participate readily and to stay with the group.\n\nFrom Neo-Latin \"cohaesio\" and French \"cohésion\", in physics, cohesion means \"the force that unites the molecules of a liquid or of a solid\". Thereby, there are different ways to define group cohesion, depending on how researchers conceptualize this concept. However, most researchers define cohesion to be task commitment and interpersonal attraction to the group.\n\nCohesion can be more specifically defined as the tendency for a group to be in unity while working towards a goal or to satisfy the emotional needs of its members. This definition includes important aspects of cohesiveness, including its multidimensionality, dynamic nature, instrumental basis, and emotional dimension. Its multidimensionality refers to how cohesion is based on many factors. Its dynamic nature refers to how it gradually changes over time in its strength and form from the time a group is formed to when a group is disbanded. Its instrumental basis refers to how people cohere for some purpose, whether it be for a task or for social reasons. Its emotional dimension refers to how cohesion is pleasing to its group members. This definition can be generalized to most groups characterized by the group definition discussed above. These groups include sports teams, work groups, military units, fraternity groups, and social groups. However, it is important to note that other researchers claim that cohesion cannot be generalized across many groups.\n\nThe bonds that link group members to one another and to their group as a whole are not believed to develop spontaneously. Over the years, social scientists have explained the phenomenon of group cohesiveness in different ways. Some have suggested that cohesiveness among group members develops from a heightened sense of belonging, teamwork, and interpersonal and group-level attraction.\n\nAttraction, task commitment and group pride are also said to cause group cohesion. Each cause is expanded upon below.\n\nFestinger and colleagues (1951) proposed the theory of group cohesiveness as attractiveness to people which have the best care within the group and attractiveness to the group as a whole. Lott and Lott (1965) argued that interpersonal attraction within the group is sufficient to account for group cohesion. In other words, group cohesion exists when its members have mutual positive feelings towards one another.\n\nLater theorists (1992) wrote that attraction to the group as a whole causes group cohesion, a concept reminiscent of the social identity theory. According to Hogg, group cohesiveness is based on social attraction, which refers to \"attraction among members of a salient social group\". Hogg explains how group cohesiveness develops from social attraction with self-categorization theory according to which individuals when looking at others' similarities and differences, mentally categorize themselves and others as part of a group, in-group members, or as not part of a group, out-group members. From this type of categorizing, the stereotypes of the group becomes more prominent in the individual's mind. This leads the individual to think and behave according to group norms, thus resulting in attraction to the group as a whole. This process is known as depersonalization of self-perception. In Hogg's theory social attraction refers to the liking of depersonalized characteristics, the prototype of the group, which is distinct from interpersonal attraction among individuals within the group. It is also important to note that group cohesiveness is more associated with group attraction than with attraction to individual members.\n\nTheorists believe that group cohesion results from a deep sense of \"we-ness\", or belonging to a group as a whole. By becoming enthusiastically involved in the efforts of the group and by recognizing the similarities among group members, a group becomes more cohesive. Group pride creates a sense of community which strengthens the bonds of unity.\n\nSport (1984) and organizational theorists (1995) have pointed out that group members' commitment to work together to complete their shared tasks and accomplish their collective goals creates cohesion. Members of task-oriented groups typically exhibit great interdependence and often possess feelings of responsibility for the group's outcomes. The bonds of unity which develop from members' concerted effort to achieve their common goals are considered indicative of group cohesion. The commitment to the task had a significant and positive relationship with performance, while group attractiveness and group pride were not significantly related to performance.\n\nThe forces that push group members together can be positive (group-based rewards) or negative (things lost upon leaving the group). The main factors that influence group cohesiveness are: members' similarity, group size, entry difficulty, group success and external competition and threats. Often, these factors work through enhancing the identification of individuals with the group they belong to as well as their beliefs of how the group can fulfill their personal needs.\n\nSimilarity of group members has different influences on group cohesiveness depending on how to define this concept. Lott and Lott (1965) who refer to interpersonal attraction as group cohesiveness conducted an extensive review on the literature and found that individuals' similarities in background (e.g., race, ethnicity, occupation, age), attitudes, values and personality traits have generally positive association with group cohesiveness.\n\nOn the other hand, from the perspective of social attraction as the basis of group cohesiveness, similarity among group members is the cue for individuals to categorize themselves and others into either an ingroup or outgroup. In this perspective, the more prototypical similarity individuals feel between themselves and other ingroup members, the stronger the group cohesiveness will be.\n\nIn addition, similar background makes it more likely that members share similar views on various issues, including group objectives, communication methods and the type of desired leadership. In general, higher agreement among members on group rules and norms results in greater trust and less dysfunctional conflict. This, in turn, strengthens both emotional and task cohesiveness.\n\nDifficult entry criteria or procedures to a group tend to present it in more exclusive light. The more elite the group is perceived to be, the more prestigious it is to be a member in that group. As shown in dissonance studies conducted by Aronson and Mills (1959) and confirmed by Gerard and Mathewson (1966), this effect can be due to dissonance reduction (see cognitive dissonance). Dissonance reduction can occur when a person has endured arduous initiation into a group; if some aspects of the group are unpleasant, the person may distort their perception of the group because of the difficulty of entry. Thus, the value of the group increases in the group member's mind.\n\nSmall groups are more cohesive than large groups. This is often caused by social loafing, a theory that says individual members of a group will actually put in less effort, because they believe other members will make up for the slack. It has been found that social loafing is eliminated when group members believe their individual performances are identifiable – much more the case in smaller groups.\n\nIn primatology and anthropology, the limits to group size are theorized to accord with Dunbar's number.\n\nGroup cohesion has been linked to a range of positive and negative consequences. Its consequences on motivation, performance, member satisfaction, member emotional adjustment, and the pressures felt by the member will be examined in the sections below.\n\nCohesion and motivation of team members are key factors that contribute to a company's performance. By adaptability development, self-worth, and personal motivation growth, each member becomes able to feel confident and progress in the team. Social loafing is less frequent when there is cohesion in a team; the motivation of each team member is considerably greater.\n\nStudies have shown that cohesion can cause performance and that performance can cause cohesion. Most meta-analyses (studies that have summarized the results of many studies) have shown that there is a relationship between cohesion and performance. This is the case even when cohesion is defined in different ways. When cohesion is defined as attraction, it is better correlated with performance. When it is defined as task commitment, it is also correlated with performance, though to a lesser degree than cohesion as attraction. Not enough studies were performed with cohesion defined as group pride. In general, cohesion defined in all these ways was positively related with performance.\n\nHowever, some groups may have a stronger cohesion-performance relationship than others. Smaller groups have a better cohesion-performance relationship than larger groups. Carron (2002) found cohesion-performance relationships to be strongest in sports teams and ranked the strength of the relationship in this order (from strongest to weakest): sports teams, military squads, groups that form for a purpose, groups in experimental settings. There is some evidence that cohesion may be more strongly related to performance for groups that have highly interdependent roles than for groups in which members are independent.\n\nIn regards to group productivity, having attraction and group pride may not be enough. It is necessary to have task commitment in order to be productive. Furthermore, groups with high performance goals were extremely productive.\n\nHowever, it is important to note that the link between cohesion and performance can differ depending on the nature of the group that is studied. Some studies that have focused on this relationship have led to divergent results. For example, a study conducted on the link between cohesion and performance in a governmental social service department found a low positive association between these two variables, while a separate study on groups in a Danish military unit found a high negative association between these two variables.\n\nStudies have shown that people in cohesive groups have reported more satisfaction than members of a noncohesive group. This is the case across many settings, including industrial, athletic, and educational settings. Members in cohesive groups also are more optimistic and suffer less from social problems than those in non-cohesive groups.\n\nOne study involved a team of masons and carpenters working on a housing development. For the first five months, their supervisor formed the groups they were to work in. These groups changed over the course of five months. This was to help the men get to know everyone working on this development project and naturally, likes and dislikes for the people around them emerged. The experimenter then formed cohesive groups by grouping people who liked each other. It was found that the masons and carpenters were more satisfied when they worked in cohesive groups. As quoted from one of the workers \"the work is more interesting when you've got a buddy working with you. You certainly like it a lot better anyway.\"\n\nPeople in cohesive groups experience better emotional adjustment. In particular, people experience less anxiety and tension. It was also found that people cope better with stress when they belong to a cohesive group.\n\nOne study showed that cohesion as task commitment can improve group decision making when the group is under stress, more than when it is not under stress. The study studied forty-six three-person teams, all of whom were faced with the task of selecting the best oil drilling sites based on information given to them. The study manipulated whether or not the teams had high cohesion or low cohesion and how urgent the task was to be done. The study found that teams with low cohesion and high urgency performed worse than teams with high cohesion and high urgency. This indicates that cohesion can improve group decision-making in times of stress.\n\nAttachment theory has also asserted that adolescents with behavioral problems do not have close interpersonal relationships or have superficial ones. Many studies have found that an individual without close peer relationships are at a higher risk for emotional adjustment problems currently and later in life.\n\nWhile people may experience better emotional in cohesive groups, they may also face many demands on their emotions, such as those that result from scapegoating and hostility.\n\nPeople in cohesive groups have greater pressure to conform than people in non-cohesive groups. The theory of groupthink suggests that the pressures hinder the group from critically thinking about the decisions it is making. Giordano (2003) has suggested that this is because people within a group frequently interact with one another and create many opportunities for influence. It is also because a person within a group perceive other members as similar to themselves and are thus, more willing to give into conformity pressures. Another reason is because people value the group and are thus, more willing to give into conformity pressures to maintain or enhance their relationships.\n\nIllegal activities have been stemmed from conformity pressures within a group. Haynie (2001) found that the degree to which a group of friends engaged in illegal activities was a predictor of an individual's participation in the illegal activity. This was even after the individual's prior behavior was controlled for and other controls were set in place. Furthermore, those with friends who all engaged in illegal activities were most likely to engage in illegal activities themselves. Another study found that adolescents with no friends did not engage in as many illegal activities as those with at least one friend. Other studies have found similar results.\n\nAlbert Lott and Bernice Lott investigated how group cohesiveness influenced individual learning. They wanted to test whether learning would be better if children studied with peers they liked than peers they didn't. The degree of member liking was presumed to indicate group cohesiveness. They found that children with high IQ performed better on learning tests when they learnt in high cohesive groups than low cohesive groups. For low IQ children, however, the cohesiveness factor made little difference. Still, there was a slight tendency for low IQ children to perform better in high cohesive groups. The researchers believed that if children worked with other students whom they liked, they would more likely have a greater drive to learn than if they had neutral or negative attitudes towards the group.\n\nSocial cohesion has become an important theme in British social policy in the period since the disturbances in Britain's Northern mill towns (Oldham, Bradford and Burnley) in the summer of 2001 (see Oldham riots, Bradford riots, Burnley riots). In investigating these, academic Ted Cantle drew heavily on the concept of social cohesion, and the New Labour government (particularly then Home Secretary David Blunkett) in turn widely promoted the notion. As the Runnymede Trust noted in their \"The Year of Cohesion\" in 2003:\n\"If there has been a key word added to the Runnymede lexicon in 2002, it is cohesion. A year from publication of the report of the Commission on the Future of Multi-Ethnic Britain, the Cantle, Denham, Clarke, Ouseley and Ritchie reports moved cohesion to the forefront of the UK race debate.\"\n\nAccording to the government-commissioned, \"State of the English Cities\" thematic reports, there are five different dimensions of social cohesion: material conditions, passive relationships, active relationships, solidarity, inclusion and equality.\n\nOn a societal level Albrekt Larsen defines social cohesion 'as the belief—held by citizens in a given nation state—that they share a moral community, which enables them to trust each other'. In a comparative study of the US, UK, Sweden and Denmark he shows that the perceived trustworthiness of fellow citizens is strongly influenced by the level of social inequality and how 'poor' and 'middle classes' are represented in the mass media.\n\nAnalysts at the credit rating agency Moody's have also introduced the possibility of adding social cohesion as a formal rating into their sovereign debt indices.\n\n\n\n"}
{"id": "634444", "url": "https://en.wikipedia.org/wiki?curid=634444", "title": "Social structure", "text": "Social structure\n\nIn the social sciences, \"social structure\" is the patterned social arrangements in society that are both emergent from and determinant of the actions of the individuals. On the macro scale, social structure is the system of socioeconomic stratification (most notably the class structure), social institutions, or other patterned relations between large social groups. On the meso scale, it is the structure of social network ties between individuals or organizations. On the micro scale, it can be the way norms shape the behavior of individuals within the social system.\n\nSocial norms influence social structure through relations between the majority and the minority. Because those who align with the majority are considered normal while those who align with the minority are considered abnormal, majority-minority relations create a hierarchical stratification within social structures that favors the majority in all aspects of society.\n\nThese scales are not always kept separate. For example, recent scholarship by John Levi Martin has theorized that certain macro-scale structures are the emergent properties of micro-scale cultural institutions (this meaning of \"structure\" resembles that used by anthropologist Claude Levi-Strauss). Likewise, another recent study, in ethnography, describes how indigenous social structure in the Republic of Panama changed macro social structures and impeded a planned Panama Canal expansion. Marxist sociology also has a history of mixing different meanings of social structure, though it has done so by simply treating the cultural aspects of social structure as phenomenal of its economic ones.\n\nSince the 1920s, the term has been in general use in social science, especially as a variable whose sub-components needed to be distinguished in relationship to other sociological variables.\n\nThe notion of social structure \"as relationship between different entities or groups\" or as \"enduring and relatively stable patterns of relationship\" emphasises the idea that society is grouped into structurally related groups or sets of roles, with different functions, meanings or purposes. One example of social structure is the idea of \"social stratification\", which refers to the idea that most societies are separated into different strata (levels), guided (if only partially) by the underlying structures in the social system. This approach has been important in the academic literature with the rise of various forms of structuralism. It is important in the modern study of organizations, because an organization's structure may determine its flexibility, capacity to change, and many other factors. Therefore, structure is an important issue for management.\n\nSocial structure may be seen to influence important social systems including the economic system, legal system, political system, cultural system, and others. Family, religion, law, economy, and class are all social structures. The \"social system\" is the parent system of those various systems that are embedded in it.\n\nThe early study of social structures has informed the study of institutions, culture and agency, social interaction, and history. Alexis de Tocqueville was apparently the first to use the term social structure; later, Karl Marx, Herbert Spencer, Max Weber, Ferdinand Tönnies, and Émile Durkheim all contributed to structural concepts in sociology. Weber investigated and analyzed the institutions of modern society: market, bureaucracy (private enterprise and public administration), and politics (e.g. democracy).\n\nOne of the earliest and most comprehensive accounts of social structure was provided by Karl Marx, who related political, cultural, and religious life to the mode of production (an underlying economic structure). Marx argued that the economic base substantially determined the cultural and political superstructure of a society. Subsequent Marxist accounts, such as that by Louis Althusser, proposed a more complex relationship that asserted the relative autonomy of cultural and political institutions, and a general determination by economic factors only \"in the last instance\".\n\nIn 1905, the German sociologist Ferdinand Tönnies first published his study \"The Present Problems of Social Structure\" in the US, arguing that only the \"constitution\" of a multitude into a unity creates a \"social structure\" (basing this approach on his concept of social will).\n\nÉmile Durkheim (drawing on the analogies between biological and social systems popularized by Herbert Spencer and others) introduced the idea that diverse social institutions and practices played a role in assuring the functional integration of society through assimilation of diverse parts into a unified and self-reproducing whole. In this context, Durkheim distinguished two forms of structural relationship: mechanical solidarity and organic solidarity. The former describes structures that unite similar parts through a shared culture; the latter describes differentiated parts united through social exchange and material interdependence.\n\nAs did Marx and Weber, more generally, Georg Simmel developed a wide-ranging approach that provided observations and insights into domination and subordination, competition, division of labor, formation of parties, representation, inner solidarity coupled with exclusiveness toward the outside, and many similar features in the state, in a religious community, in an economic association, in an art school, and in family and kinship networks (however diverse the interests that give rise to these associations, the forms in which interests are realized may yet be identical (Crothers, 1996)).\n\nThe notion of social structure was extensively developed in the 20th century, with key contributions from structuralist perspectives drawing on the theories of Claude Lévi-Strauss, Feminist or Marxist perspectives, from functionalist perspectives such as those developed by Talcott Parsons and his followers, or from a variety of analytic perspectives (see Blau 1975, Lopez and Scott 2000). Some follow Marx in trying to identify the basic dimensions of society that explain the other dimensions, most emphasizing either economic production or political power. Others follow Lévi-Strauss in seeking logical order in cultural structures. Still others, notably Peter Blau, follow Simmel in attempting to base a formal theory of social structure on numerical patterns in relationships—analyzing, for example, the ways in which factors like group size shape intergroup relations.\n\nThe notion of social structure is intimately related to a variety of central topics in social science, including the relation of structure and agency. The most influential attempts to combine the concept of social structure with agency are Anthony Giddens' theory of structuration and Pierre Bourdieu's practice theory. Giddens emphasizes the duality of structure and agency, in the sense that structures and agency cannot be conceived apart from one another. This permits him to argue that structures are neither independent of actors nor determining of their behavior, but rather sets of rules and competencies on which actors draw, and which, in the aggregate, they reproduce. Giddens's analysis, in this respect, closely parallels Jacques Derrida's deconstruction of the binaries that underlie classic sociological and anthropological reasoning (notably the universalizing tendencies of Lévi-Strauss's structuralism). Bourdieu's practice theory also seeks a more supple account of social structure as embedded in, rather than determinative of, individual behavior.\n\nOther recent work by Margaret Archer (morphogenesis theory), Tom R. Burns and collaborators (actor-system dynamics theory and social rule system theory), and Immanuel Wallerstein (World Systems Theory) provided elaborations and applications of the sociological classics in structural sociology.\n\nAs noted above, social structure has been identified as\n\nLopez and Scott (2000) distinguish between \"institutional structure\" and \"relational structure\", where in the former:\n\nwhereas in the latter:\n\nSocial structure can also be divided into microstructure and macrostructure. Microstructure is the pattern of relations between most basic elements of social life, that cannot be further divided and have no social structure of their own (for example, pattern of relations between individuals in a group composed of individuals - where individuals have no social structure, or a structure of organizations as a pattern of relations between social positions or social roles, where those positions and roles have no structure by themselves). Macrostructure is thus a kind of 'second level' structure, a pattern of relations between objects that have their own structure (for example, a political social structure between political parties, as political parties have their own social structure). Some types of social structures that modern sociologist differentiate are \"relation structures\" (in family or larger family-like clan structures), \"communication structures\" (how information is passed in organizations) and \"sociometric structures\" (structures of sympathy, antipathy and indifference in organisations - this was studied by Jacob L. Moreno).\n\nSocial rule system theory reduces the structures of (3) to particular rule system arrangements, that is, the types of basic structures of (1 and 2). It shares with role theory, organizational and institutional sociology, and network analysis the concern with structural properties and developments and at the same time provides detailed conceptual tools needed to generate interesting, fruitful propositions and models and analyses.\n\nSociologists also distinguish between:\n\nSome believe that social structure is naturally developed. It may be caused by larger system needs, such as the need for labour, management, professional and military classes, or by conflicts between groups, such as competition among political parties or among elites and masses. Others believe that this structuring is not a result of natural processes, but is socially constructed. It may be created by the power of elites who seek to retain their power, or by economic systems that place emphasis upon competition or cooperation.\n\nEthnography has contributed to understandings about social structure by revealing local practices and customs that differ from Western practices of hierarchy and economic power in its construction.\n\nThe most thorough account of the evolution of social structure is perhaps provided by structure and agency accounts that allow for a sophisticated analysis of the co-evolution of social structure and human agency, where socialised agents with a degree of autonomy take action in social systems where their action is on the one hand mediated by existing institutional structure and expectations but may, on the other hand, influence or transform that institutional structure.\n\nThe notion of social structure may mask systematic biases, as it involves many identifiable subvariables, for example, gender. Some argue that men and women who have otherwise equal qualifications receive different treatment in the workplace because of their gender, which would be termed a \"social structural\" bias, but other variables (such as time on the job or hours worked) might be masked. Modern social structural analysis takes this into account through multivariate analysis and other techniques, but the analytic problem of how to combine various aspects of social life into a whole remains.\n\n\n\n"}
{"id": "27919", "url": "https://en.wikipedia.org/wiki?curid=27919", "title": "Sociobiology", "text": "Sociobiology\n\nSociobiology is a field of biology that aims to examine and explain social behavior in terms of evolution. It draws from disciplines including psychology, ethology, anthropology, evolution, zoology, archaeology, and population genetics. Within the study of human societies, sociobiology is closely allied to Darwinian anthropology, human behavioral ecology and evolutionary psychology.\n\nSociobiology investigates social behaviors such as mating patterns, territorial fights, pack hunting, and the hive society of social insects. It argues that just as selection pressure led to animals evolving useful ways of interacting with the natural environment, so also it led to the genetic evolution of advantageous social behavior.\n\nWhile the term \"sociobiology\" originated at least as early as the 1940s, the concept did not gain major recognition until the publication of E. O. Wilson's book \"\" in 1975. The new field quickly became the subject of controversy. Critics, led by Richard Lewontin and Stephen Jay Gould, argued that genes played a role in human behavior, but that traits such as aggressiveness could be explained by social environment rather than by biology. Sociobiologists responded by pointing to the complex relationship between nature and nurture.\n\nE. O. Wilson defined sociobiology as \"the extension of population biology and evolutionary theory to social organization\".\n\nSociobiology is based on the premise that some behaviors (social and individual) are at least partly inherited and can be affected by natural selection. It begins with the idea that behaviors have evolved over time, similar to the way that physical traits are thought to have evolved. It predicts that animals will act in ways that have proven to be evolutionarily successful over time. This can, among other things, result in the formation of complex social processes conducive to evolutionary fitness.\n\nThe discipline seeks to explain behavior as a product of natural selection. Behavior is therefore seen as an effort to preserve one's genes in the population. Inherent in sociobiological reasoning is the idea that certain genes or gene combinations that influence particular behavioral traits can be inherited from generation to generation.\n\nFor example, newly dominant male lions often kill cubs in the pride that they did not sire. This behavior is adaptive because killing the cubs eliminates competition for their own offspring and causes the nursing females to come into heat faster, thus allowing more of his genes to enter into the population. Sociobiologists would view this instinctual cub-killing behavior as being inherited through the genes of successfully reproducing male lions, whereas non-killing behavior may have died out as those lions were less successful in reproducing.\n\nThe philosopher of biology Daniel Dennett suggested that the political philosopher Thomas Hobbes was the first sociobiologist, arguing that in his 1651 book \"Leviathan\" Hobbes had explained the origins of morals in human society from an amoral sociobiological perspective. \n\nThe geneticist of animal behavior John Paul Scott coined the word \"sociobiology\" at a 1948 conference on genetics and social behaviour which called for a conjoint development of field and laboratory studies in animal behavior research. With John Paul Scott's organizational efforts, a \"Section of Animal Behavior and Sociobiology\" of the ESA (acronym stands for?) was created in 1956, which became a Division of Animal Behavior of the American Society of Zoology in 1958. In 1956, E. O. Wilson came in contact this emerging sociobiology through his PhD student Stuart A. Altmann, who had been in close relation with the participants to the 1948 conference. Altmann developed his own brand of sociobiology to study the social behavior of rhesus macaques, using statistics, and was hired as a \"sociobiologist\" at the Yerkes Regional Primate Research Center in 1965.\nWilson's sociobiology is different from John Paul Scott's or Altmann's, insofar as he drew on mathematical models of social behavior centered on the maximisation of the genetic fitness by W. D. Hamilton, Robert Trivers, John Maynard Smith, and George R. Price. The three sociobiologies by Scott, Altmann and Wilson have in common to place naturalist studies at the core of the research on animal social behavior and by drawing alliances with emerging research methodologies, at a time when \"biology in the field\" was threatened to be made old-fashioned by \"modern\" practices of science (laboratory studies, mathematical biology, molecular biology).\n\nOnce a specialist term, \"sociobiology\" became widely known in 1975 when Wilson published his book \"Sociobiology: The New Synthesis\", which sparked an intense controversy. Since then \"sociobiology\" has largely been equated with Wilson's vision. The book pioneered and popularized the attempt to explain the evolutionary mechanics behind social behaviors such as altruism, aggression, and nurturance, primarily in ants (Wilson's own research specialty) and other Hymenoptera, but also in other animals. However, the influence of evolution on behavior has been of interest to biologists and philosophers since soon after the discovery of evolution itself. Peter Kropotkin's \"\", written in the early 1890s, is a popular example. The final chapter of the book is devoted to sociobiological explanations of human behavior, and Wilson later wrote a Pulitzer Prize winning book, \"On Human Nature\", that addressed human behavior specifically.\n\nEdward H. Hagen writes in \"The Handbook of Evolutionary Psychology\" that sociobiology is, despite the public controversy regarding the applications to humans, \"one of the scientific triumphs of the twentieth century.\" \"Sociobiology is now part of the core research and curriculum of virtually all biology departments, and it is a foundation of the work of almost all field biologists\" Sociobiological research on nonhuman organisms has increased dramatically and continuously in the world's top scientific journals such as \"Nature\" and \"Science\". The more general term behavioral ecology is commonly substituted for the term sociobiology in order to avoid the public controversy.\n\nSociobiologists maintain that human behavior, as well as nonhuman animal behavior, can be partly explained as the outcome of natural selection. They contend that in order to fully understand behavior, it must be analyzed in terms of evolutionary considerations.\n\nNatural selection is fundamental to evolutionary theory. Variants of hereditary traits which increase an organism's ability to survive and reproduce will be more greatly represented in subsequent generations, i.e., they will be \"selected for\". Thus, inherited behavioral mechanisms that allowed an organism a greater chance of surviving and/or reproducing in the past are more likely to survive in present organisms. That inherited adaptive behaviors are present in nonhuman animal species has been multiply demonstrated by biologists, and it has become a foundation of evolutionary biology. However, there is continued resistance by some researchers over the application of evolutionary models to humans, particularly from within the social sciences, where culture has long been assumed to be the predominant driver of behavior.\n\nSociobiology is based upon two fundamental premises:\n\nSociobiology uses Nikolaas Tinbergen's four categories of questions and explanations of animal behavior. Two categories are at the species level; two, at the individual level. The species-level categories (often called \"ultimate explanations\") are\nThe individual-level categories (often called \"proximate explanations\") are\n\nSociobiologists are interested in how behavior can be explained logically as a result of selective pressures in the history of a species. Thus, they are often interested in instinctive, or intuitive behavior, and in explaining the similarities, rather than the differences, between cultures. For example, mothers within many species of mammals – including humans – are very protective of their offspring. Sociobiologists reason that this protective behavior likely evolved over time because it helped the offspring of the individuals which had the characteristic to survive. This parental protection would increase in frequency in the population. The social behavior is believed to have evolved in a fashion similar to other types of nonbehavioral adaptations, such as a coat of fur, or the sense of smell.\n\nIndividual genetic advantage fails to explain certain social behaviors as a result of gene-centred selection. E.O. Wilson argued that evolution may also act upon groups. The mechanisms responsible for group selection employ paradigms and population statistics borrowed from evolutionary game theory. Altruism is defined as \"a concern for the welfare of others\". If altruism is genetically determined, then altruistic individuals must reproduce their own altruistic genetic traits for altruism to survive, but when altruists lavish their resources on non-altruists at the expense of their own kind, the altruists tend to die out and the others tend to increase. An extreme example is a soldier losing his life trying to help a fellow soldier. This example raises the question of how altruistic genes can be passed on if this soldier dies without having any children.\n\nWithin sociobiology, a social behavior is first explained as a sociobiological hypothesis by finding an evolutionarily stable strategy that matches the observed behavior. Stability of a strategy can be difficult to prove, but usually, it will predict gene frequencies. The hypothesis can be supported by establishing a correlation between the gene frequencies predicted by the strategy, and those expressed in a population.\n\nAltruism between social insects and littermates has been explained in such a way. Altruistic behavior, behavior that increases the reproductive fitness of others at the apparent expense of the altruist, in some animals has been correlated to the degree of genome shared between altruistic individuals. A quantitative description of infanticide by male harem-mating animals when the alpha male is displaced as well as rodent female infanticide and fetal resorption are active areas of study. In general, females with more bearing opportunities may value offspring less, and may also arrange bearing opportunities to maximize the food and protection from mates.\n\nAn important concept in sociobiology is that temperament traits exist in an ecological balance. Just as an expansion of a sheep population might encourage the expansion of a wolf population, an expansion of altruistic traits within a gene pool may also encourage increasing numbers of individuals with dependent traits.\n\nStudies of human behavior genetics have generally found behavioral traits such as creativity, extroversion, aggressiveness, and IQ have high heritability. The researchers who carry out those studies are careful to point out that heritability does not constrain the influence that environmental or cultural factors may have on those traits.\n\nCriminality is actively under study, but extremely controversial. There are arguments that in some environments criminal behavior might be adaptive. The novelist Elias Canetti also has noted applications of sociobiological theory to cultural practices such as slavery and autocracy.\n\nGenetic mouse mutants illustrate the power that genes exert on behaviour. For example, the transcription factor FEV (aka Pet1), through its role in maintaining the serotonergic system in the brain, is required for normal aggressive and anxiety-like behavior. Thus, when FEV is genetically deleted from the mouse genome, male mice will instantly attack other males, whereas their wild-type counterparts take significantly longer to initiate violent behaviour. In addition, FEV has been shown to be required for correct maternal behaviour in mice, such that offspring of mothers without the FEV factor do not survive unless cross-fostered to other wild-type female mice.\n\nA genetic basis for instinctive behavioural traits among non-human species, such as in the above example, is commonly accepted among many biologists; however, attempting to use a genetic basis to explain complex behaviours in human societies has remained extremely controversial.\n\nSteven Pinker argues that critics have been overly swayed by politics and a fear of biological determinism, accusing among others Stephen Jay Gould and Richard Lewontin of being \"radical scientists\", whose stance on human nature is influenced by politics rather than science, while Lewontin, Steven Rose and Leon Kamin, who drew a distinction between the politics and history of an idea and its scientific validity, argue that sociobiology fails on scientific grounds. Gould grouped sociobiology with eugenics, criticizing both in his book \"The Mismeasure of Man\".\n\nNoam Chomsky has expressed views on sociobiology on several occasions. During a 1976 meeting of the Sociobiology Study Group, as reported by Ullica Segerstråle, Chomsky argued for the importance of a sociobiologically informed notion of human nature. Chomsky argued that human beings are biological organisms and ought to be studied as such, with his criticism of the \"blank slate\" doctrine in the social sciences (which would inspire a great deal of Steven Pinker's and others' work in evolutionary psychology), in his 1975 \"Reflections on Language\". Chomsky further hinted at the possible reconciliation of his anarchist political views and sociobiology in a discussion of Peter Kropotkin's \"\", which focused more on altruism than aggression, suggesting that anarchist societies were feasible because of an innate human tendency to cooperate.\n\nWilson has claimed that he had never meant to imply what \"ought\" to be, only what \"is\" the case. However, some critics have argued that the language of sociobiology readily slips from \"is\" to \"ought\", an instance of the naturalistic fallacy. Pinker has argued that opposition to stances considered anti-social, such as ethnic nepotism, is based on moral assumptions, meaning that such opposition is not falsifiable by scientific advances. The history of this debate, and others related to it, are covered in detail by , , and .\n\n\n\n"}
{"id": "39206", "url": "https://en.wikipedia.org/wiki?curid=39206", "title": "Business", "text": "Business\n\nBusiness is the activity of making one's living or making money by producing or buying and selling products (such as goods and services). Simply put, it is \"any activity or enterprise entered into for profit. It does not mean it is a company, a corporation, partnership, or have any such formal organization, but it can range from a street peddler to General Motors.\" \n\nHaving a business name does not separate the business entity from the owner, which means that the owner of the business is responsible and liable for debts incurred by the business. If the business acquires debts, the creditors can go after the owner's personal possessions. A business structure does not allow for corporate tax rates. The proprietor is personally taxed on all income from the business.\n\nThe term is also often used colloquially (but not by lawyers or by public officials) to refer to a company. A company, on the other hand, is a separate legal entity and provides for limited liability, as well as corporate tax rates. A company structure is more complicated and expensive to set up, but offers more protection and benefits for the owner.\n\nForms of business ownership vary by jurisdiction, but several common entities exist:\n\n\"Less common types of companies are:\"\nNote that \"Ltd after the company's name signifies limited company, and PLC (public limited company) indicates that its shares are widely held.\"\n\nIn legal parlance, the owners of a company are normally referred to as the \"members\". In a company limited or unlimited by shares (formed or incorporated with a share capital), this will be the shareholders. In a company limited by guarantee, this will be the guarantors. Some offshore jurisdictions have created special forms of offshore company in a bid to attract business for their jurisdictions. Examples include \"segregated portfolio companies\" and restricted purpose companies.\n\nThere are, however, many, many sub-categories of types of company that can be formed in various jurisdictions in the world.\n\nCompanies are also sometimes distinguished into public companies and private companies for legal and regulatory purposes. Public companies are companies whose shares can be publicly traded, often (although not always) on a stock exchange which imposes listing requirements/Listing Rules as to the issued shares, the trading of shares and a future issue of shares to help bolster the reputation of the exchange or particular market of exchange. Private companies do not have publicly traded shares, and often contain restrictions on transfers of shares. In some jurisdictions, private companies have maximum numbers of shareholders.\n\nA parent company is a company that owns enough voting stock in another firm to control management and operations by influencing or electing its board of directors; the second company being deemed as a subsidiary of the parent company. The definition of a parent company differs by jurisdiction, with the definition normally being defined by way of laws dealing with companies in that jurisdiction.\n\n\nAccounting is the measurement, processing, and communication of financial information about economic entities such as businesses and corporations. The modern field was established by the Italian mathematician Luca Pacioli in 1494. Accounting, which has been called the \"language of business\", measures the results of an organization's economic activities and conveys this information to a variety of users, including investors, creditors, management, and regulators. Practitioners of accounting are known as accountants. The terms \"accounting\" and \"financial reporting\" are often used as synonyms.\n\nFinance is a field that deals with the study of investments. It includes the dynamics of assets and liabilities over time under conditions of different degrees of uncertainty and risk. Finance can also be defined as the science of money management. Finance aims to price assets based on their risk level and their expected rate of return. Finance can be broken into three different sub categories: public finance, corporate finance, and personal finance.\n\nManufacturing is the production of merchandise for use or sale using labour and machines, tools, chemical and biological processing, or formulation. The term may refer to a range of human activity, from handicraft to high tech, but is most commonly applied to industrial production, in which raw materials are transformed into finished goods on a large scale.\n\nMarketing is defined by the American Marketing Association as \"the activity, set of institutions, and processes for creating, communicating, delivering, and exchanging offerings that have value for customers, clients, partners, and society at large.\" The term developed from the original meaning which referred literally to going to a market to buy or sell goods or services. Marketing tactics include advertising as well as determining product pricing.\n\nWith the rise in technology, marketing is further divided into a class called digital marketing. It is marketing products and services using digital technologies.\n\nResearch and development refer to activities in connection with corporate or government innovation. Research and development constitute the first stage of development of a potential new service or product. Research and development are very difficult to manage since the defining feature of the research is that the researchers do not know in advance exactly how to accomplish the desired result. \n\nInjuries cost businesses billions of dollars annually. Studies have shown how company acceptance and implementation of comprehensive safety and health management systems reduce incidents, insurance costs, and workers’ compensation claims. New technologies, like wearable safety devices and available online safety training, continue to be developed to encourage employers to invest in protection beyond the \"canary in the coal mine\" and reduce the cost to businesses of protecting their employees.\n\nSales are activity related to selling or the number of goods or services sold in a given time period. Sales are often integrated with all lines of business and are key to a companies' success.\n\nThe efficient and effective operation of a business, and study of this subject, is called management. The major branches of management are financial management, marketing management, human resource management, strategic management, production management, operations management, service management, and information technology management. \n\nOwners may manage their businesses themselves, or employ managers to do so for them. Whether they are owners or employees, managers administer three primary components of the business' value: financial resources, capital (tangible resources), and human resources. These resources are administered in at least six functional areas: legal contracting, manufacturing or service production, marketing, accounting, financing, and human resources.\n\nIn recent decades, states modeled some of their assets and enterprises after business enterprises. In 2003, for example, the People's Republic of China modeled 80% of its state-owned enterprises on a company-type management system. Many state institutions and enterprises in China and Russia have transformed into joint-stock companies, with part of their shares being listed on public stock markets.\n\nBusiness process management (BPM) is a holistic management approach focused on aligning all aspects of an organization with the wants and needs of clients. BPM attempts to improve processes continuously. It can, therefore, be described as a \"process optimization process\". It is argued that BPM enables organizations to be more efficient, effective and capable of change than a functionally focused, traditional hierarchical management approach. \n\nMost legal jurisdictions specify the forms of ownership that a business can take, creating a body of commercial law for each type.\n\nThe major factors affecting how a business is organized are usually:\n\n\nMany businesses are operated through a separate entity such as a corporation or a partnership (either formed with or without limited liability). Most legal jurisdictions allow people to organize such an entity by filing certain charter documents with the relevant Secretary of State or equivalent and complying with certain other ongoing obligations. The relationships and legal rights of shareholders, limited partners, or members are governed partly by the charter documents and partly by the law of the jurisdiction where the entity is organized. Generally speaking, shareholders in a corporation, limited partners in a limited partnership, and members in a limited liability company are shielded from personal liability for the debts and obligations of the entity, which is legally treated as a separate \"person\". This means that unless there is misconduct, the owner's own possessions are strongly protected in law if the business does not succeed.\n\nWhere two or more individuals own a business together but have failed to organize a more specialized form of vehicle, they will be treated as a general partnership. The terms of a partnership are partly governed by a partnership agreement if one is created, and partly by the law of the jurisdiction where the partnership is located. No paperwork or filing is necessary to create a partnership, and without an agreement, the relationships and legal rights of the partners will be entirely governed by the law of the jurisdiction where the partnership is located. A single person who owns and runs a business is commonly known as a \"sole proprietor\", whether that person owns it directly or through a formally organized entity. Depending on the business needs, an adviser can decide what kind is proprietorship will be most suitable.\n\nA few relevant factors to consider in deciding how to operate a business include:\n\n\nA very detailed and well-established body of rules that evolved over a very long period of time applies to commercial transactions. The need to regulate trade and commerce and resolve business disputes helped shape the creation of law and courts. The Code of Hammurabi dates back to about 1772 BC for example and contains provisions that relate, among other matters, to shipping costs and dealings between merchants and brokers. The word \"corporation\" derives from the Latin \"corpus\", meaning body, and the Maurya Empire in Iron-Age India accorded legal rights to business entities.\n\nIn many countries, it is difficult to compile all the laws that can affect a business into a single reference source. Laws can govern the treatment of labour and employee relations, worker protection and safety, discrimination on the basis of age, gender, disability, race, and in some jurisdictions, sexual orientation, and the minimum wage, as well as unions, worker compensation, and working hours and leave.\n\nSome specialized businesses may also require licenses, either due to laws governing entry into certain trades, occupations or professions, that require special education or to raise revenue for local governments. Professions that require special licenses include law, medicine, piloting aircraft, selling liquor, radio broadcasting, selling investment securities, selling used cars, and roofing. Local jurisdictions may also require special licenses and taxes just to operate a business.\n\nSome businesses are subject to ongoing special regulation, for example, public utilities, investment securities, banking, insurance, broadcasting, aviation, and health care providers. Environmental regulations are also very complex and can affect many businesses.\n\n When businesses need to raise money (called capital), they sometimes offer securities for sale.\n\nCapital may be raised through private means, by an initial public offering or IPO on a stock exchange, or in other ways.\n\nMajor stock exchanges include the Shanghai Stock Exchange, Singapore Exchange, Hong Kong Stock Exchange, New York Stock Exchange and NASDAQ (the USA), the London Stock Exchange (UK), the Tokyo Stock Exchange (Japan), and Bombay Stock Exchange (India). Most countries with capital markets have at least one.\n\nBusinesses that have gone public are subject to regulations concerning their internal governance, such as how executive officers' compensation is determined, and when and how information is disclosed to shareholders and to the public. In the United States, these regulations are primarily implemented and enforced by the United States Securities and Exchange Commission (SEC). Other western nations have comparable regulatory bodies. The regulations are implemented and enforced by the China Securities Regulation Commission (CSRC) in China. In Singapore, the regulatory authority is the Monetary Authority of Singapore (MAS), and in Hong Kong, it is the Securities and Futures Commission (SFC).\n\nThe proliferation and increasing complexity of the laws governing business have forced increasing specialization in corporate law. It is not unheard of for certain kinds of corporate transactions to require a team of five to ten attorneys due to sprawling regulation. Commercial law spans general corporate law, employment and labor law, health-care law, securities law, mergers and acquisitions, tax law, employee benefit plans, food and drug regulation, intellectual property law on copyrights, patents, trademarks, telecommunications law, and financing.\n\nOther types of capital sourcing include crowdsourcing on the Internet, venture capital, bank loans, and debentures.\n\nBusinesses often have important \"intellectual property\" that needs protection from competitors for the company to stay profitable. This could require patents, copyrights, trademarks, or preservation of trade secrets. Most businesses have names, logos, and similar branding techniques that could benefit from trademarking. Patents and copyrights in the United States are largely governed by federal law, while trade secrets and trademarking are mostly a matter of state law. Because of the nature of intellectual property, a business needs protection in every jurisdiction in which they are concerned about competitors. Many countries are signatories to international treaties concerning intellectual property, and thus companies registered in these countries are subject to national laws bound by these treaties. In order to protect trade secrets, companies may require employees to sign noncompete clauses which will impose limitations on an employee's interactions with stakeholders, and competitors.\n\nA trade union (or labor union) is an organization of workers who have come together to achieve common goals such as protecting the integrity of its trade, improving safety standards, achieving higher pay and benefits such as health care and retirement, increasing the number of employees an employer assigns to complete the work, and better working conditions. The trade union, through its leadership, bargains with the employer on behalf of union members (rank and file members) and negotiates labor contracts (collective bargaining) with employers. The most common purpose of these associations or unions is \"maintaining or improving the conditions of their employment\". This may include the negotiation of wages, work rules, complaint procedures, rules governing hiring, firing, and promotion of workers, benefits, workplace safety and policies.\n"}
{"id": "9223", "url": "https://en.wikipedia.org/wiki?curid=9223", "title": "Economics", "text": "Economics\n\nEconomics () is the social science that studies the production, distribution, and consumption of goods and services.\n\nEconomics focuses on the behaviour and interactions of economic agents and how economies work. Microeconomics analyzes basic elements in the economy, including individual agents and markets, their interactions, and the outcomes of interactions. Individual agents may include, for example, households, firms, buyers, and sellers. Macroeconomics analyzes the entire economy (meaning aggregated production, consumption, saving, and investment) and issues affecting it, including unemployment of resources (labour, capital, and land), inflation, economic growth, and the public policies that address these issues (monetary, fiscal, and other policies). See glossary of economics.\n\nOther broad distinctions within economics include those between positive economics, describing \"what is\", and normative economics, advocating \"what ought to be\"; between economic theory and applied economics; between rational and behavioural economics; and between mainstream economics and heterodox economics.\n\nEconomic analysis can be applied throughout society, in real estate, business, finance, health care, and government. Economic analysis is sometimes also applied to such diverse subjects as crime, education, the family, law, politics, religion, social institutions, war, science, and the environment.\n\nThe discipline was renamed in the late 19th century, primarily due to Alfred Marshall, from \"political economy\" to \"economics\" as a shorter term for \"economic science\". At that time, it became more open to rigorous thinking and made increased use of mathematics, which helped support efforts to have it accepted as a science and as a separate discipline outside of political science and other social sciences.\n\nThere are a variety of modern definitions of economics; some reflect evolving views of the subject or different views among economists. Scottish philosopher Adam Smith (1776) defined what was then called political economy as \"an inquiry into the nature and causes of the wealth of nations\", in particular as:\n\nJean-Baptiste Say (1803), distinguishing the subject from its public-policy uses, defines it as the science \"of\" production, distribution, and consumption of wealth. On the satirical side, Thomas Carlyle (1849) coined \"the dismal science\" as an epithet for classical economics, in this context, commonly linked to the pessimistic analysis of Malthus (1798). John Stuart Mill (1844) defines the subject in a social context as:\n\nAlfred Marshall provides a still widely cited definition in his textbook \"Principles of Economics\" (1890) that extends analysis beyond wealth and from the societal to the microeconomic level:\n\nLionel Robbins (1932) developed implications of what has been termed \"[p]erhaps the most commonly accepted current definition of the subject\":\n\nRobbins describes the definition as not \"classificatory\" in \"pick[ing] out certain \"kinds\" of behaviour\" but rather \"analytical\" in \"focus[ing] attention on a particular \"aspect\" of behaviour, the form imposed by the influence of scarcity.\" He affirmed that previous economists have usually centred their studies on the analysis of wealth: how wealth is created (production), distributed, and consumed; and how wealth can grow. But he said that economics can be used to study other things, such as war, that are outside its usual focus. This is because war has as the goal winning it (as a sought after end), generates both cost and benefits; and, resources (human life and other costs) are used to attain the goal. If the war is not winnable or if the expected costs outweigh the benefits, the deciding actors (assuming they are rational) may never go to war (a decision) but rather explore other alternatives. We cannot define economics as the science that studies wealth, war, crime, education, and any other field economic analysis can be applied to; but, as the science that studies a particular common aspect of each of those subjects (they all use scarce resources to attain a sought after end).\n\nSome subsequent comments criticized the definition as overly broad in failing to limit its subject matter to analysis of markets. From the 1960s, however, such comments abated as the economic theory of maximizing behaviour and rational-choice modelling expanded the domain of the subject to areas previously treated in other fields. There are other criticisms as well, such as in scarcity not accounting for the macroeconomics of high unemployment.\n\nGary Becker, a contributor to the expansion of economics into new areas, describes the approach he favours as \"combin[ing the] assumptions of maximizing behaviour, stable preferences, and market equilibrium, used relentlessly and unflinchingly.\" One commentary characterizes the remark as making economics an approach rather than a subject matter but with great specificity as to the \"choice process and the type of social interaction that [such] analysis involves.\" The same source reviews a range of definitions included in principles of economics textbooks and concludes that the lack of agreement need not affect the subject-matter that the texts treat. Among economists more generally, it argues that a particular definition presented may reflect the direction toward which the author believes economics is evolving, or should evolve.\n\nEconomic writings date from earlier Mesopotamian, Greek, Roman, Indian subcontinent, Chinese, Persian, and Arab civilizations. Economic precepts occur throughout the writings of the Boeotian poet Hesiod and several economic historians have described Hesiod himself as the \"first economist\". Other notable writers from Antiquity through to the Renaissance include Aristotle, Xenophon, Chanakya (also known as Kautilya), Qin Shi Huang, Thomas Aquinas, and Ibn Khaldun. Joseph Schumpeter described Aquinas as \"coming nearer than any other group to being the \"founders' of scientific economics\" as to monetary, interest, and value theory within a natural-law perspective.\n\nTwo groups, later called \"mercantilists\" and \"physiocrats\", more directly influenced the subsequent development of the subject. Both groups were associated with the rise of economic nationalism and modern capitalism in Europe. Mercantilism was an economic doctrine that flourished from the 16th to 18th century in a prolific pamphlet literature, whether of merchants or statesmen. It held that a nation's wealth depended on its accumulation of gold and silver. Nations without access to mines could obtain gold and silver from trade only by selling goods abroad and restricting imports other than of gold and silver. The doctrine called for importing cheap raw materials to be used in manufacturing goods, which could be exported, and for state regulation to impose protective tariffs on foreign manufactured goods and prohibit manufacturing in the colonies.\n\nPhysiocrats, a group of 18th-century French thinkers and writers, developed the idea of the economy as a circular flow of income and output. Physiocrats believed that only agricultural production generated a clear surplus over cost, so that agriculture was the basis of all wealth. Thus, they opposed the mercantilist policy of promoting manufacturing and trade at the expense of agriculture, including import tariffs. Physiocrats advocated replacing administratively costly tax collections with a single tax on income of land owners. In reaction against copious mercantilist trade regulations, the physiocrats advocated a policy of \"laissez-faire\", which called for minimal government intervention in the economy.\n\nAdam Smith (1723–1790) was an early economic theorist. Smith was harshly critical of the mercantilists but described the physiocratic system \"with all its imperfections\" as \"perhaps the purest approximation to the truth that has yet been published\" on the subject.\n\nThe publication of Adam Smith's \"The Wealth of Nations\" in 1776, has been described as \"the effective birth of economics as a separate discipline.\" The book identified land, labour, and capital as the three factors of production and the major contributors to a nation's wealth, as distinct from the physiocratic idea that only agriculture was productive.\n\nSmith discusses potential benefits of specialization by division of labour, including increased labour productivity and gains from trade, whether between town and country or across countries. His \"theorem\" that \"the division of labor is limited by the extent of the market\" has been described as the \"core of a theory of the functions of firm and industry\" and a \"fundamental principle of economic organization.\" To Smith has also been ascribed \"the most important substantive proposition in all of economics\" and foundation of resource-allocation theory – that, under competition, resource owners (of labour, land, and capital) seek their most profitable uses, resulting in an equal rate of return for all uses in equilibrium (adjusted for apparent differences arising from such factors as training and unemployment).\n\nIn an argument that includes \"one of the most famous passages in all economics,\" Smith represents every individual as trying to employ any capital they might command for their own advantage, not that of the society, and for the sake of profit, which is necessary at some level for employing capital in domestic industry, and positively related to the value of produce. In this:\n\nThe Rev. Thomas Robert Malthus (1798) used the concept of diminishing returns to explain low living standards. Human population, he argued, tended to increase geometrically, outstripping the production of food, which increased arithmetically. The force of a rapidly growing population against a limited amount of land meant diminishing returns to labour. The result, he claimed, was chronically low wages, which prevented the standard of living for most of the population from rising above the subsistence level. Economist Julian Lincoln Simon has criticized Malthus's conclusions.\n\nWhile Adam Smith emphasized the production of income, David Ricardo (1817) focused on the distribution of income among landowners, workers, and capitalists. Ricardo saw an inherent conflict between landowners on the one hand and labour and capital on the other. He posited that the growth of population and capital, pressing against a fixed supply of land, pushes up rents and holds down wages and profits. Ricardo was the first to state and prove the principle of comparative advantage, according to which each country should specialize in producing and exporting goods in that it has a lower \"relative\" cost of production, rather relying only on its own production. It has been termed a \"fundamental analytical explanation\" for gains from trade.\n\nComing at the end of the classical tradition, John Stuart Mill (1848) parted company with the earlier classical economists on the inevitability of the distribution of income produced by the market system. Mill pointed to a distinct difference between the market's two roles: allocation of resources and distribution of income. The market might be efficient in allocating resources but not in distributing income, he wrote, making it necessary for society to intervene.\n\nValue theory was important in classical theory. Smith wrote that the \"real price of every thing ... is the toil and trouble of acquiring it\". Smith maintained that, with rent and profit, other costs besides wages also enter the price of a commodity. Other classical economists presented variations on Smith, termed the 'labour theory of value'. Classical economics focused on the tendency of any market economy to settle in a final stationary state made up of a constant stock of physical wealth (capital) and a constant population size.\n\nMarxist (later, Marxian) economics descends from classical economics and it derives from the work of Karl Marx. The first volume of Marx's major work, \"Das Kapital\", was published in German in 1867. In it, Marx focused on the labour theory of value and the theory of surplus value which, he believed, explained the exploitation of labour by capital. The labour theory of value held that the value of an exchanged commodity was determined by the labour that went into its production and the theory of surplus value demonstrated how the workers only got paid a proportion of the value their work had created.\n\nAt the dawn as a social science, economics was defined and discussed at length as the study of production, distribution, and consumption of wealth by Jean-Baptiste Say in his \"Treatise on Political Economy or, The Production, Distribution, and Consumption of Wealth\" (1803). These three items are considered by the science only in relation to the increase or diminution of wealth, and not in reference to their processes of execution. Say's definition has prevailed up to our time, saved by substituting the word \"wealth\" for \"goods and services\" meaning that wealth may include non-material objects as well. One hundred and thirty years later, Lionel Robbins noticed that this definition no longer sufficed, because many economists were making theoretical and philosophical inroads in other areas of human activity. In his \"Essay on the Nature and Significance of Economic Science\", he proposed a definition of economics as a study of a particular aspect of human behaviour, the one that falls under the influence of scarcity, which forces people to choose, allocate scarce resources to competing ends, and economize (seeking the greatest welfare while avoiding the wasting of scarce resources). For Robbins, the insufficiency was solved, and his definition allows us to proclaim, with an easy conscience, education economics, safety and security economics, health economics, war economics, and of course, production, distribution and consumption economics as valid subjects of the economic science.\" Citing Robbins: \"Economics is the science which studies human behavior as a relationship between ends and scarce means which have alternative uses\". After discussing it for decades, Robbins' definition became widely accepted by mainstream economists, and it has opened way into current textbooks. Although far from unanimous, most mainstream economists would accept some version of Robbins' definition, even though many have raised serious objections to the scope and method of economics, emanating from that definition. Due to the lack of strong consensus, and that production, distribution and consumption of goods and services is the prime area of study of economics, the old definition still stands in many quarters.\n\nA body of theory later termed \"neoclassical economics\" or \"marginalism\" formed from about 1870 to 1910. The term \"economics\" was popularized by such neoclassical economists as Alfred Marshall as a concise synonym for \"economic science\" and a substitute for the earlier \"political economy\". This corresponded to the influence on the subject of mathematical methods used in the natural sciences.\n\nNeoclassical economics systematized supply and demand as joint determinants of price and quantity in market equilibrium, affecting both the allocation of output and the distribution of income. It dispensed with the labour theory of value inherited from classical economics in favour of a marginal utility theory of value on the demand side and a more general theory of costs on the supply side. In the 20th century, neoclassical theorists moved away from an earlier notion suggesting that total utility for a society could be measured in favour of ordinal utility, which hypothesizes merely behaviour-based relations across persons.\n\nIn microeconomics, neoclassical economics represents incentives and costs as playing a pervasive role in shaping decision making. An immediate example of this is the consumer theory of individual demand, which isolates how prices (as costs) and income affect quantity demanded. In macroeconomics it is reflected in an early and lasting neoclassical synthesis with Keynesian macroeconomics.\n\nNeoclassical economics is occasionally referred as \"orthodox economics\" whether by its critics or sympathizers. Modern mainstream economics builds on neoclassical economics but with many refinements that either supplement or generalize earlier analysis, such as econometrics, game theory, analysis of market failure and imperfect competition, and the neoclassical model of economic growth for analysing long-run variables affecting national income.\n\nNeoclassical economics studies the behaviour of individuals, households, and organizations (called economic actors, players, or agents), when they manage or use scarce resources, which have alternative uses, to achieve desired ends. Agents are assumed to act rationally, have multiple desirable ends in sight, limited resources to obtain these ends, a set of stable preferences, a definite overall guiding objective, and the capability of making a choice. There exists an economic problem, subject to study by economic science, when a decision (choice) is made by one or more resource-controlling players to attain the best possible outcome under bounded rational conditions. In other words, resource-controlling agents maximize value subject to the constraints imposed by the information the agents have, their cognitive limitations, and the finite amount of time they have to make and execute a decision. Economic science centres on the activities of the economic agents that comprise society. They are the focus of economic analysis.\n\nAn approach to understanding these processes, through the study of agent behaviour under scarcity, may go as follows:\n\nThe continuous interplay (exchange or trade) done by economic actors in all markets sets the prices for all goods and services which, in turn, make the rational managing of scarce resources possible. At the same time, the decisions (choices) made by the same actors, while they are pursuing their own interest, determine the level of output (production), consumption, savings, and investment, in an economy, as well as the remuneration (distribution) paid to the owners of labour (in the form of wages), capital (in the form of profits) and land (in the form of rent). Each period, as if they were in a giant feedback system, economic players influence the pricing processes and the economy, and are in turn influenced by them until a steady state (equilibrium) of all variables involved is reached or until an external shock throws the system toward a new equilibrium point. Because of the autonomous actions of rational interacting agents, the economy is a complex adaptive system.\n\nKeynesian economics derives from John Maynard Keynes, in particular his book \"The General Theory of Employment, Interest and Money\" (1936), which ushered in contemporary macroeconomics as a distinct field. The book focused on determinants of national income in the short run when prices are relatively inflexible. Keynes attempted to explain in broad theoretical detail why high labour-market unemployment might not be self-correcting due to low \"effective demand\" and why even price flexibility and monetary policy might be unavailing. The term \"revolutionary\" has been applied to the book in its impact on economic analysis.\n\nKeynesian economics has two successors. Post-Keynesian economics also concentrates on macroeconomic rigidities and adjustment processes. Research on micro foundations for their models is represented as based on real-life practices rather than simple optimizing models. It is generally associated with the University of Cambridge and the work of Joan Robinson.\n\nNew-Keynesian economics is also associated with developments in the Keynesian fashion. Within this group researchers tend to share with other economists the emphasis on models employing micro foundations and optimizing behaviour but with a narrower focus on standard Keynesian themes such as price and wage rigidity. These are usually made to be endogenous features of the models, rather than simply assumed as in older Keynesian-style ones.\n\nThe Chicago School of economics is best known for its free market advocacy and monetarist ideas. According to Milton Friedman and monetarists, market economies are inherently stable if the money supply does not greatly expand or contract. Ben Bernanke, former Chairman of the Federal Reserve, is among the economists today generally accepting Friedman's analysis of the causes of the Great Depression.\n\nMilton Friedman effectively took many of the basic principles set forth by Adam Smith and the classical economists and modernized them. One example of this is his article in the 13 September 1970 issue of \"The New York Times Magazine\", in which he claims that the social responsibility of business should be \"to use its resources and engage in activities designed to increase its profits ... (through) open and free competition without deception or fraud.\"\n\nOther well-known schools or trends of thought referring to a particular style of economics practised at and disseminated from well-defined groups of academicians that have become known worldwide, include the Austrian School, the Freiburg School, the School of Lausanne, post-Keynesian economics and the Stockholm school. Contemporary mainstream economics is sometimes separated into the Saltwater approach of those universities along the Eastern and Western coasts of the US, and the Freshwater, or Chicago-school approach.\n\nWithin macroeconomics there is, in general order of their appearance in the literature; classical economics, Keynesian economics, the neoclassical synthesis, post-Keynesian economics, monetarism, new classical economics, and supply-side economics. Alternative developments include ecological economics, constitutional economics, institutional economics, evolutionary economics, dependency theory, structuralist economics, world systems theory, econophysics, feminist economics and biophysical economics.\n\nEconomic systems is the of economics that studies the methods and institutions by which societies determine the ownership, direction, and allocation of economic resources. An \"economic system\" of a society is the unit of analysis.\n\nAmong contemporary systems at different ends of the organizational spectrum are socialist systems and capitalist systems, in which most production occurs in respectively state-run and private enterprises. In between are mixed economies. A common element is the interaction of economic and political influences, broadly described as political economy. \"Comparative economic systems\" studies the relative performance and behaviour of different economies or systems.\n\nThe U.S. Export-Import Bank defines a Marxist–Leninist state as having a centrally planned economy. They are now rare; examples can still be seen in Cuba, North Korea and Laos.\n\nMainstream economic theory relies upon \"a priori\" quantitative economic models, which employ a variety of concepts. Theory typically proceeds with an assumption of \"ceteris paribus\", which means holding constant explanatory variables other than the one under consideration. When creating theories, the objective is to find ones which are at least as simple in information requirements, more precise in predictions, and more fruitful in generating additional research than prior theories. While neoclassical economic theory constitutes both the dominant or orthodox theoretical as well as methodological framework, economic theory can also take the form of other schools of thought such as in heterodox economic theories.\n\nIn microeconomics, principal concepts include supply and demand, marginalism, rational choice theory, opportunity cost, budget constraints, utility, and the theory of the firm. Early macroeconomic models focused on modelling the relationships between aggregate variables, but as the relationships appeared to change over time macroeconomists, including new Keynesians, reformulated their models in microfoundations.\n\nThe aforementioned microeconomic concepts play a major part in macroeconomic models – for instance, in monetary theory, the quantity theory of money predicts that increases in the growth rate of the money supply increase inflation, and inflation is assumed to be influenced by rational expectations. In development economics, slower growth in developed nations has been sometimes predicted because of the declining marginal returns of investment and capital, and this has been observed in the Four Asian Tigers. Sometimes an economic hypothesis is only \"qualitative\", not \"quantitative\".\n\nExpositions of economic reasoning often use two-dimensional graphs to illustrate theoretical relationships. At a higher level of generality, Paul Samuelson's treatise \"Foundations of Economic Analysis\" (1947) used mathematical methods beyond graphs to represent the theory, particularly as to maximizing behavioural relations of agents reaching equilibrium. The book focused on examining the class of statements called \"operationally meaningful theorems\" in economics, which are theorems that can conceivably be refuted by empirical data.\n\nMicroeconomics examines how entities, forming a market structure, interact within a market to create a market system. These entities include private and public players with various classifications, typically operating under scarcity of tradable units and light government regulation. The item traded may be a tangible product such as apples or a service such as repair services, legal counsel, or entertainment.\n\nIn theory, in a free market the aggregates (sum of) of \"quantity demanded\" by buyers and \"quantity supplied\" by sellers may reach economic equilibrium over time in reaction to price changes; in practice, various issues may prevent equilibrium, and any equilibrium reached may not necessarily be morally equitable. For example, if the supply of healthcare services is limited by external factors, the equilibrium price may be unaffordable for many who desire it but cannot pay for it.\n\nVarious market structures exist. In perfectly competitive markets, no participants are large enough to have the market power to set the price of a homogeneous product. In other words, every participant is a \"price taker\" as no participant influences the price of a product. In the real world, markets often experience imperfect competition.\n\nForms include monopoly (in which there is only one seller of a good), duopoly (in which there are only two sellers of a good), oligopoly (in which there are few sellers of a good), monopolistic competition (in which there are many sellers producing highly differentiated goods), monopsony (in which there is only one buyer of a good), and oligopsony (in which there are few buyers of a good). Unlike perfect competition, imperfect competition invariably means market power is unequally distributed. Firms under imperfect competition have the potential to be \"price makers\", which means that, by holding a disproportionately high share of market power, they can influence the prices of their products.\n\nMicroeconomics studies individual markets by simplifying the economic system by assuming that activity in the market being analysed does not affect other markets. This method of analysis is known as partial-equilibrium analysis (supply and demand). This method aggregates (the sum of all activity) in only one market. General-equilibrium theory studies various markets and their behaviour. It aggregates (the sum of all activity) across \"all\" markets. This method studies both changes in markets and their interactions leading towards equilibrium.\n\nIn microeconomics, production is the conversion of inputs into outputs. It is an economic process that uses inputs to create a commodity or a service for exchange or direct use. Production is a flow and thus a rate of output per period of time. Distinctions include such production alternatives as for consumption (food, haircuts, etc.) vs. investment goods (new tractors, buildings, roads, etc.), public goods (national defence, smallpox vaccinations, etc.) or private goods (new computers, bananas, etc.), and \"guns\" vs \"butter\".\n\nOpportunity cost is the economic cost of production: the value of the next best opportunity foregone. Choices must be made between desirable yet mutually exclusive actions. It has been described as expressing \"the basic relationship between scarcity and choice\". For example, if a baker uses a sack of flour to make pretzels one morning, then the baker cannot use either the flour or the morning to make bagels instead. Part of the cost of making pretzels is that neither the flour nor the morning are available any longer, for use in some other way. The opportunity cost of an activity is an element in ensuring that scarce resources are used efficiently, such that the cost is weighed against the value of that activity in deciding on more or less of it. Opportunity costs are not restricted to monetary or financial costs but could be measured by the real cost of output forgone, leisure, or anything else that provides the alternative benefit (utility).\n\nInputs used in the production process include such primary factors of production as labour services, capital (durable produced goods used in production, such as an existing factory), and land (including natural resources). Other inputs may include intermediate goods used in production of final goods, such as the steel in a new car.\n\nEconomic efficiency measures how well a system generates desired output with a given set of inputs and available technology. Efficiency is improved if more output is generated without changing inputs, or in other words, the amount of \"waste\" is reduced. A widely accepted general standard is Pareto efficiency, which is reached when no further change can make someone better off without making someone else worse off.\n\nThe production–possibility frontier (PPF) is an expository figure for representing scarcity, cost, and efficiency. In the simplest case an economy can produce just two goods (say \"guns\" and \"butter\"). The PPF is a table or graph (as at the right) showing the different quantity combinations of the two goods producible with a given technology and total factor inputs, which limit feasible total output. Each point on the curve shows potential total output for the economy, which is the maximum feasible output of one good, given a feasible output quantity of the other good.\n\nScarcity is represented in the figure by people being willing but unable in the aggregate to consume \"beyond the PPF\" (such as at \"X\") and by the negative slope of the curve. If production of one good \"increases\" along the curve, production of the other good \"decreases\", an inverse relationship. This is because increasing output of one good requires transferring inputs to it from production of the other good, decreasing the latter.\n\nThe slope of the curve at a point on it gives the trade-off between the two goods. It measures what an additional unit of one good costs in units forgone of the other good, an example of a \"real opportunity cost\". Thus, if one more Gun costs 100 units of butter, the opportunity cost of one Gun is 100 Butter. \"Along the PPF\", scarcity implies that choosing \"more\" of one good in the aggregate entails doing with \"less\" of the other good. Still, in a market economy, movement along the curve may indicate that the choice of the increased output is anticipated to be worth the cost to the agents.\n\nBy construction, each point on the curve shows \"productive efficiency\" in maximizing output for given total inputs. A point \"inside\" the curve (as at \"A\"), is feasible but represents \"production inefficiency\" (wasteful use of inputs), in that output of \"one or both goods\" could increase by moving in a northeast direction to a point on the curve. Examples cited of such inefficiency include high unemployment during a business-cycle recession or economic organization of a country that discourages full use of resources. Being on the curve might still not fully satisfy allocative efficiency (also called Pareto efficiency) if it does not produce a mix of goods that consumers prefer over other points.\n\nMuch applied economics in public policy is concerned with determining how the efficiency of an economy can be improved. Recognizing the reality of scarcity and then figuring out how to organize society for the most efficient use of resources has been described as the \"essence of economics\", where the subject \"makes its unique contribution.\"\n\nSpecialization is considered key to economic efficiency based on theoretical and empirical considerations. Different individuals or nations may have different real opportunity costs of production, say from differences in stocks of human capital per worker or capital/labour ratios. According to theory, this may give a comparative advantage in production of goods that make more intensive use of the relatively more abundant, thus \"relatively\" cheaper, input.\n\nEven if one region has an absolute advantage as to the ratio of its outputs to inputs in every type of output, it may still specialize in the output in which it has a comparative advantage and thereby gain from trading with a region that lacks any absolute advantage but has a comparative advantage in producing something else.\n\nIt has been observed that a high volume of trade occurs among regions even with access to a similar technology and mix of factor inputs, including high-income countries. This has led to investigation of economies of scale and agglomeration to explain specialization in similar but differentiated product lines, to the overall benefit of respective trading parties or regions.\n\nThe general theory of specialization applies to trade among individuals, farms, manufacturers, service providers, and economies. Among each of these production systems, there may be a corresponding \"division of labour\" with different work groups specializing, or correspondingly different types of capital equipment and differentiated land uses.\n\nAn example that combines features above is a country that specializes in the production of high-tech knowledge products, as developed countries do, and trades with developing nations for goods produced in factories where labour is relatively cheap and plentiful, resulting in different in opportunity costs of production. More total output and utility thereby results from specializing in production and trading than if each country produced its own high-tech and low-tech products.\n\nTheory and observation set out the conditions such that market prices of outputs and productive inputs select an allocation of factor inputs by comparative advantage, so that (relatively) low-cost inputs go to producing low-cost outputs. In the process, aggregate output may increase as a by-product or by design. Such specialization of production creates opportunities for gains from trade whereby resource owners benefit from trade in the sale of one type of output for other, more highly valued goods. A measure of gains from trade is the \"increased income levels\" that trade may facilitate.\n\nPrices and quantities have been described as the most directly observable attributes of goods produced and exchanged in a market economy. The theory of supply and demand is an organizing principle for explaining how prices coordinate the amounts produced and consumed. In microeconomics, it applies to price and output determination for a market with perfect competition, which includes the condition of no buyers or sellers large enough to have price-setting power.\n\nFor a given market of a commodity, \"demand\" is the relation of the quantity that all buyers would be prepared to purchase at each unit price of the good. Demand is often represented by a table or a graph showing price and quantity demanded (as in the figure). Demand theory describes individual consumers as rationally choosing the most preferred quantity of each good, given income, prices, tastes, etc. A term for this is \"constrained utility maximization\" (with income and wealth as the constraints on demand). Here, utility refers to the hypothesized relation of each individual consumer for ranking different commodity bundles as more or less preferred.\n\nThe law of demand states that, in general, price and quantity demanded in a given market are inversely related. That is, the higher the price of a product, the less of it people would be prepared to buy (other things unchanged). As the price of a commodity falls, consumers move toward it from relatively more expensive goods (the substitution effect). In addition, purchasing power from the price decline increases ability to buy (the income effect). Other factors can change demand; for example an increase in income will shift the demand curve for a normal good outward relative to the origin, as in the figure. All determinants are predominantly taken as constant factors of demand and supply.\n\n\"Supply\" is the relation between the price of a good and the quantity available for sale at that price. It may be represented as a table or graph relating price and quantity supplied. Producers, for example business firms, are hypothesized to be \"profit maximizers\", meaning that they attempt to produce and supply the amount of goods that will bring them the highest profit. Supply is typically represented as a function relating price and quantity, if other factors are unchanged.\n\nThat is, the higher the price at which the good can be sold, the more of it producers will supply, as in the figure. The higher price makes it profitable to increase production. Just as on the demand side, the position of the supply can shift, say from a change in the price of a productive input or a technical improvement. The \"Law of Supply\" states that, in general, a rise in price leads to an expansion in supply and a fall in price leads to a contraction in supply. Here as well, the determinants of supply, such as price of substitutes, cost of production, technology applied and various factors inputs of production are all taken to be constant for a specific time period of evaluation of supply.\n\nMarket equilibrium occurs where quantity supplied equals quantity demanded, the intersection of the supply and demand curves in the figure above. At a price below equilibrium, there is a shortage of quantity supplied compared to quantity demanded. This is posited to bid the price up. At a price above equilibrium, there is a surplus of quantity supplied compared to quantity demanded. This pushes the price down. The model of supply and demand predicts that for given supply and demand curves, price and quantity will stabilize at the price that makes quantity supplied equal to quantity demanded. Similarly, demand-and-supply theory predicts a new price-quantity combination from a shift in demand (as to the figure), or in supply.\n\nPeople frequently do not trade directly on markets. Instead, on the supply side, they may work in and produce through \"firms\". The most obvious kinds of firms are corporations, partnerships and trusts. According to Ronald Coase, people begin to organize their production in firms when the costs of doing business becomes lower than doing it on the market. Firms combine labour and capital, and can achieve far greater economies of scale (when the average cost per unit declines as more units are produced) than individual market trading.\n\nIn perfectly competitive markets studied in the theory of supply and demand, there are many producers, none of which significantly influence price. Industrial organization generalizes from that special case to study the strategic behaviour of firms that do have significant control of price. It considers the structure of such markets and their interactions. Common market structures studied besides perfect competition include monopolistic competition, various forms of oligopoly, and monopoly.\n\nManagerial economics applies microeconomic analysis to specific decisions in business firms or other management units. It draws heavily from quantitative methods such as operations research and programming and from statistical methods such as regression analysis in the absence of certainty and perfect knowledge. A unifying theme is the attempt to optimize business decisions, including unit-cost minimization and profit maximization, given the firm's objectives and constraints imposed by technology and market conditions.\n\nUncertainty in economics is an unknown prospect of gain or loss, whether quantifiable as risk or not. Without it, household behaviour would be unaffected by uncertain employment and income prospects, financial and capital markets would reduce to exchange of a single instrument in each market period, and there would be no communications industry. Given its different forms, there are various ways of representing uncertainty and modelling economic agents' responses to it.\n\nGame theory is a branch of applied mathematics that considers strategic interactions between agents, one kind of uncertainty. It provides a mathematical foundation of industrial organization, discussed above, to model different types of firm behaviour, for example in an solipsistic industry (few sellers), but equally applicable to wage negotiations, bargaining, contract design, and any situation where individual agents are few enough to have perceptible effects on each other. In behavioural economics, it has been used to model the strategies agents choose when interacting with others whose interests are at least partially adverse to their own.\n\nIn this, it generalizes maximization approaches developed to analyse market actors such as in the supply and demand model and allows for incomplete information of actors. The field dates from the 1944 classic \"Theory of Games and Economic Behavior\" by John von Neumann and Oskar Morgenstern. It has significant applications seemingly outside of economics in such diverse subjects as formulation of nuclear strategies, ethics, political science, and evolutionary biology.\n\nRisk aversion may stimulate activity that in well-functioning markets smooths out risk and communicates information about risk, as in markets for insurance, commodity futures contracts, and financial instruments. Financial economics or simply finance describes the allocation of financial resources. It also analyses the pricing of financial instruments, the financial structure of companies, the efficiency and fragility of financial markets, financial crises, and related government policy or regulation.\n\nSome market organizations may give rise to inefficiencies associated with uncertainty. Based on George Akerlof's \"Market for Lemons\" article, the paradigm example is of a dodgy second-hand car market. Customers without knowledge of whether a car is a \"lemon\" depress its price below what a quality second-hand car would be. Information asymmetry arises here, if the seller has more relevant information than the buyer but no incentive to disclose it. Related problems in insurance are adverse selection, such that those at most risk are most likely to insure (say reckless drivers), and moral hazard, such that insurance results in riskier behaviour (say more reckless driving).\n\nBoth problems may raise insurance costs and reduce efficiency by driving otherwise willing transactors from the market (\"incomplete markets\"). Moreover, attempting to reduce one problem, say adverse selection by mandating insurance, may add to another, say moral hazard. Information economics, which studies such problems, has relevance in subjects such as insurance, contract law, mechanism design, monetary economics, and health care. Applied subjects include market and legal remedies to spread or reduce risk, such as warranties, government-mandated partial insurance, restructuring or bankruptcy law, inspection, and regulation for quality and information disclosure.\n\nThe term \"market failure\" encompasses several problems which may undermine standard economic assumptions. Although economists categorize market failures differently, the following categories emerge in the main texts.\n\nInformation asymmetries and incomplete markets may result in economic inefficiency but also a possibility of improving efficiency through market, legal, and regulatory remedies, as discussed above.\n\nNatural monopoly, or the overlapping concepts of \"practical\" and \"technical\" monopoly, is an extreme case of \"failure of competition\" as a restraint on producers. Extreme economies of scale are one possible cause.\n\nPublic goods are goods which are under-supplied in a typical market. The defining features are that people can consume public goods without having to pay for them and that more than one person can consume the good at the same time.\n\nExternalities occur where there are significant social costs or benefits from production or consumption that are not reflected in market prices. For example, air pollution may generate a negative externality, and education may generate a positive externality (less crime, etc.). Governments often tax and otherwise restrict the sale of goods that have negative externalities and subsidize or otherwise promote the purchase of goods that have positive externalities in an effort to correct the price distortions caused by these externalities. Elementary demand-and-supply theory predicts equilibrium but not the speed of adjustment for changes of equilibrium due to a shift in demand or supply.\n\nIn many areas, some form of price stickiness is postulated to account for quantities, rather than prices, adjusting in the short run to changes on the demand side or the supply side. This includes standard analysis of the business cycle in macroeconomics. Analysis often revolves around causes of such price stickiness and their implications for reaching a hypothesized long-run equilibrium. Examples of such price stickiness in particular markets include wage rates in labour markets and posted prices in markets deviating from perfect competition.\n\nSome specialized fields of economics deal in market failure more than others. The economics of the public sector is one example. Much environmental economics concerns externalities or \"public bads\".\n\nPolicy options include regulations that reflect cost-benefit analysis or market solutions that change incentives, such as emission fees or redefinition of property rights.\n\nPublic finance is the field of economics that deals with budgeting the revenues and expenditures of a public sector entity, usually government. The subject addresses such matters as tax incidence (who really pays a particular tax), cost-benefit analysis of government programmes, effects on economic efficiency and income distribution of different kinds of spending and taxes, and fiscal politics. The latter, an aspect of public choice theory, models public-sector behaviour analogously to microeconomics, involving interactions of self-interested voters, politicians, and bureaucrats.\n\nMuch of economics is positive, seeking to describe and predict economic phenomena. Normative economics seeks to identify what economies \"ought\" to be like.\n\nWelfare economics is a normative branch of economics that uses microeconomic techniques to simultaneously determine the allocative efficiency within an economy and the income distribution associated with it. It attempts to measure social welfare by examining the economic activities of the individuals that comprise society.\n\nMacroeconomics examines the economy as a whole to explain broad aggregates and their interactions \"top down\", that is, using a simplified form of general-equilibrium theory. Such aggregates include national income and output, the unemployment rate, and price inflation and subaggregates like total consumption and investment spending and their components. It also studies effects of monetary policy and fiscal policy.\n\nSince at least the 1960s, macroeconomics has been characterized by further integration as to micro-based modelling of sectors, including rationality of players, efficient use of market information, and imperfect competition. This has addressed a long-standing concern about inconsistent developments of the same subject.\n\nMacroeconomic analysis also considers factors affecting the long-term level and growth of national income. Such factors include capital accumulation, technological change and labour force growth.\n\n\"Growth economics\" studies factors that explain economic growth – the increase in output \"per capita\" of a country over a long period of time. The same factors are used to explain differences in the \"level\" of output \"per capita\" \"between\" countries, in particular why some countries grow faster than others, and whether countries converge at the same rates of growth.\n\nMuch-studied factors include the rate of investment, population growth, and technological change. These are represented in theoretical and empirical forms (as in the neoclassical and endogenous growth models) and in growth accounting.\n\nThe economics of a depression were the spur for the creation of \"macroeconomics\" as a separate discipline. During the Great Depression of the 1930s, John Maynard Keynes authored a book entitled \"The General Theory of Employment, Interest and Money\" outlining the key theories of Keynesian economics. Keynes contended that aggregate demand for goods might be insufficient during economic downturns, leading to unnecessarily high unemployment and losses of potential output.\n\nHe therefore advocated active policy responses by the public sector, including monetary policy actions by the central bank and fiscal policy actions by the government to stabilize output over the business cycle.\nThus, a central conclusion of Keynesian economics is that, in some situations, no strong automatic mechanism moves output and employment towards full employment levels. John Hicks' IS/LM model has been the most influential interpretation of \"The General Theory\".\n\nOver the years, understanding of the business cycle has branched into various research programmes, mostly related to or distinct from Keynesianism. The neoclassical synthesis refers to the reconciliation of Keynesian economics with neoclassical economics, stating that Keynesianism is correct in the short run but qualified by neoclassical-like considerations in the intermediate and long run.\n\nNew classical macroeconomics, as distinct from the Keynesian view of the business cycle, posits market clearing with imperfect information. It includes Friedman's permanent income hypothesis on consumption and \"rational expectations\" theory, led by Robert Lucas, and real business cycle theory.\n\nIn contrast, the new Keynesian approach retains the rational expectations assumption, however it assumes a variety of market failures. In particular, New Keynesians assume prices and wages are \"sticky\", which means they do not adjust instantaneously to changes in economic conditions.\n\nThus, the new classicals assume that prices and wages adjust automatically to attain full employment, whereas the new Keynesians see full employment as being automatically achieved only in the long run, and hence government and central-bank policies are needed because the \"long run\" may be very long.\n\nThe amount of unemployment in an economy is measured by the unemployment rate, the percentage of workers without jobs in the labour force. The labour force only includes workers actively looking for jobs. People who are retired, pursuing education, or discouraged from seeking work by a lack of job prospects are excluded from the labour force. Unemployment can be generally broken down into several types that are related to different causes.\n\nClassical models of unemployment occurs when wages are too high for employers to be willing to hire more workers. Consistent with classical unemployment, frictional unemployment occurs when appropriate job vacancies exist for a worker, but the length of time needed to search for and find the job leads to a period of unemployment.\n\nStructural unemployment covers a variety of possible causes of unemployment including a mismatch between workers' skills and the skills required for open jobs. Large amounts of structural unemployment can occur when an economy is transitioning industries and workers find their previous set of skills are no longer in demand. Structural unemployment is similar to frictional unemployment since both reflect the problem of matching workers with job vacancies, but structural unemployment covers the time needed to acquire new skills not just the short term search process.\n\nWhile some types of unemployment may occur regardless of the condition of the economy, cyclical unemployment occurs when growth stagnates. Okun's law represents the empirical relationship between unemployment and economic growth. The original version of Okun's law states that a 3% increase in output would lead to a 1% decrease in unemployment.\n\nMoney is a \"means of final payment\" for goods in most price system economies, and is the unit of account in which prices are typically stated. Money has general acceptability, relative consistency in value, divisibility, durability, portability, elasticity in supply, and longevity with mass public confidence. It includes currency held by the nonbank public and checkable deposits. It has been described as a social convention, like language, useful to one largely because it is useful to others. In the words of Francis Amasa Walker, a well-known 19th-century economist, \"Money is what money does\" (\"Money is \"that\" money does\" in the original).\n\nAs a medium of exchange, money facilitates trade. It is essentially a measure of value and more importantly, a store of value being a basis for credit creation. Its economic function can be contrasted with barter (non-monetary exchange). Given a diverse array of produced goods and specialized producers, barter may entail a hard-to-locate double coincidence of wants as to what is exchanged, say apples and a book. Money can reduce the transaction cost of exchange because of its ready acceptability. Then it is less costly for the seller to accept money in exchange, rather than what the buyer produces.\n\nAt the level of an economy, theory and evidence are consistent with a positive relationship running from the total money supply to the nominal value of total output and to the general price level. For this reason, management of the money supply is a key aspect of monetary policy.\n\nGovernments implement fiscal policy to influence macroeconomic conditions by adjusting spending and taxation policies to alter aggregate demand. When aggregate demand falls below the potential output of the economy, there is an output gap where some productive capacity is left unemployed. Governments increase spending and cut taxes to boost aggregate demand. Resources that have been idled can be used by the government.\n\nFor example, unemployed home builders can be hired to expand highways. Tax cuts allow consumers to increase their spending, which boosts aggregate demand. Both tax cuts and spending have multiplier effects where the initial increase in demand from the policy percolates through the economy and generates additional economic activity.\n\nThe effects of fiscal policy can be limited by crowding out. When there is no output gap, the economy is producing at full capacity and there are no excess productive resources. If the government increases spending in this situation, the government uses resources that otherwise would have been used by the private sector, so there is no increase in overall output. Some economists think that crowding out is always an issue while others do not think it is a major issue when output is depressed.\n\nSceptics of fiscal policy also make the argument of Ricardian equivalence. They argue that an increase in debt will have to be paid for with future tax increases, which will cause people to reduce their consumption and save money to pay for the future tax increase. Under Ricardian equivalence, any boost in demand from tax cuts will be offset by the increased saving intended to pay for future higher taxes.\n\nInternational trade studies determinants of goods-and-services flows across international boundaries. It also concerns the size and distribution of gains from trade. Policy applications include estimating the effects of changing tariff rates and trade quotas. International finance is a macroeconomic field which examines the flow of capital across international borders, and the effects of these movements on exchange rates. Increased trade in goods, services and capital between countries is a major effect of contemporary globalization.\n\nDevelopment economics examines economic aspects of the economic development process in relatively low-income countries focusing on structural change, poverty, and economic growth. Approaches in development economics frequently incorporate social and political factors.\n\nLabor economics seeks to understand the functioning and dynamics of the markets for wage labor. Labor markets function through the interaction of workers and employers. Labor economics looks at the suppliers of labor services (workers), the demands of labor services (employers), and attempts to understand the resulting pattern of wages, employment, and income. In economics, labor is a measure of the work done by human beings. It is conventionally contrasted with such other factors of production as land and capital. There are theories which have developed a concept called human capital (referring to the skills that workers possess, not necessarily their actual work), although there are also counter posing macro-economic system theories that think human capital is a contradiction in terms.\n\nWelfare economics uses microeconomics techniques to evaluate well-being from allocation of productive factors as to desirability and economic efficiency within an economy, often relative to competitive general equilibrium. It analyzes \"social welfare\", however measured, in terms of economic activities of the individuals that compose the theoretical society considered. Accordingly, individuals, with associated economic activities, are the basic units for aggregating to social welfare, whether of a group, a community, or a society, and there is no \"social welfare\" apart from the \"welfare\" associated with its individual units.\n\nAccording to various random and anonymous surveys of members of the American Economic Association, economists have agreement about the following propositions by percentage:\n\n\n\"The dismal science\" is a derogatory alternative name for economics devised by the Victorian historian Thomas Carlyle in the 19th century. It is often stated that Carlyle gave economics the nickname \"the dismal science\" as a response to the late 18th century writings of The Reverend Thomas Robert Malthus, who grimly predicted that starvation would result, as projected population growth exceeded the rate of increase in the food supply. However, the actual phrase was coined by Carlyle in the context of a debate with John Stuart Mill on slavery, in which Carlyle argued for slavery, while Mill opposed it.\n\nSome economists, like John Stuart Mill or Léon Walras, have maintained that the production of wealth should not be tied to its distribution.\n\nIn \"The Wealth of Nations\", Adam Smith addressed many issues that are currently also the subject of debate and dispute. Smith repeatedly attacks groups of politically aligned individuals who attempt to use their collective influence to manipulate a government into doing their bidding. In Smith's day, these were referred to as factions, but are now more commonly called special interests, a term which can comprise international bankers, corporate conglomerations, outright oligopolies, monopolies, trade unions and other groups.\n\nEconomics \"per se\", as a social science, is independent of the political acts of any government or other decision-making organization; however, many policymakers or individuals holding highly ranked positions that can influence other people's lives are known for arbitrarily using a plethora of economic concepts and rhetoric as vehicles to legitimize agendas and value systems, and do not limit their remarks to matters relevant to their responsibilities. The close relation of economic theory and practice with politics is a focus of contention that may shade or distort the most unpretentious original tenets of economics, and is often confused with specific social agendas and value systems.\n\nNotwithstanding, economics legitimately has a role in informing government policy. It is, indeed, in some ways an outgrowth of the older field of political economy. Some academic economic journals have increased their efforts to gauge the consensus of economists regarding certain policy issues in hopes of effecting a more informed political environment. Often there exists a low approval rate from professional economists regarding many public policies. Policy issues featured in one survey of American Economic Association economists include trade restrictions, social insurance for those put out of work by international competition, genetically modified foods, curbside recycling, health insurance (several questions), medical malpractice, barriers to entering the medical profession, organ donations, unhealthy foods, mortgage deductions, taxing internet sales, Wal-Mart, casinos, ethanol subsidies, and inflation targeting.\n\nIn \"Steady State Economics\" 1977, leading ecological economist and steady-state theorist Herman Daly argues that there exist logical inconsistencies between the emphasis placed on economic growth and the limited availability of natural resources.\n\nIssues like central bank independence, central bank policies and rhetoric in central bank governors discourse or the premises of macroeconomic policies (monetary and fiscal policy) of the state, are focus of contention and criticism.\n\nDeirdre McCloskey has argued that many empirical economic studies are poorly reported, and she and Stephen Ziliak argue that although her critique has been well-received, practice has not improved. This latter contention is controversial.\n\nA 2002 International Monetary Fund study assessed the national economic growth predictions from \"Consensus Forecasts\" in the 1990s. Of the 60 different national recessions that occurred, only 2 (3%) were predicted a year in advance.\n\nEconomics has been subject to criticism that it relies on unrealistic, unverifiable, or highly simplified assumptions, in some cases because these assumptions simplify the proofs of desired conclusions. Examples of such assumptions include perfect information, profit maximization and rational choices. The field of information economics includes both mathematical-economical research and also behavioural economics, akin to studies in behavioural psychology.\n\nNevertheless, prominent mainstream economists such as Keynes and Joskow have observed that much of economics is conceptual rather than quantitative, and difficult to model and formalize quantitatively. In a discussion on oligopoly research, Paul Joskow pointed out in 1975 that in practice, serious students of actual economies tended to use \"informal models\" based upon qualitative factors specific to particular industries. Joskow had a strong feeling that the important work in oligopoly was done through informal observations while formal models were \"trotted out \"ex post\"\". He argued that formal models were largely not important in the empirical work, either, and that the fundamental factor behind the theory of the firm, behaviour, was neglected.\n\nIn recent years, feminist critiques of neoclassical economic models gained prominence, leading to the formation of feminist economics. Contrary to common conceptions of economics as a positive and objective science, feminist economists call attention to the social construction of economics and highlight the ways in which its models and methods reflect masculine preferences. Primary criticisms focus on failures to account for: the selfish nature of actors (homo economicus); exogenous tastes; the impossibility of utility comparisons; the exclusion of unpaid work; and the exclusion of class and gender considerations. Feminist economics developed to address these concerns, and the field now includes critical examinations of many areas of economics including paid and unpaid work, economic epistemology and history, globalization, household economics and the care economy. In 1988, Marilyn Waring published the book \"If Women Counted\", in which she argues that the discipline of economics ignores women's unpaid work and the value of nature; according to Julie A. Nelson, \"If Women Counted\" \"showed exactly how the unpaid work traditionally done by women has been made invisible within national accounting systems\" and \"issued a wake-up call to issues of ecological sustainability.\" Bjørnholt and McKay argue that the financial crisis of 2007–08 and the response to it revealed a crisis of ideas in mainstream economics and within the economics profession, and call for a reshaping of both the economy, economic theory and the economics profession. They argue that such a reshaping should include new advances within feminist economics that take as their starting point the socially responsible, sensible and accountable subject in creating an economy and economic theories that fully acknowledge care for each other as well as the planet.\n\nPhilip Mirowski observes that:\n\nIn a series of peer-reviewed journal and conference papers and books published over a period of several decades, John McMurtry has provided extensive criticism of what he terms the \"unexamined assumptions and implications [of economics], and their consequent cost to people's lives.\"\n\nNassim Nicholas Taleb and Michael Perelman are two additional scholars who criticized conventional or mainstream economics. Taleb opposes most economic theorizing, which in his view suffers acutely from the problem of overuse of Plato's Theory of Forms, and calls for cancellation of the Nobel Memorial Prize in Economics, saying that the damage from economic theories can be devastating. Michael Perelman provides extensive criticism of economics and its assumptions in all his books (and especially his books published from 2000 to date), papers and interviews.\n\nDespite these concerns, mainstream graduate programs have become increasingly technical and mathematical.\n\nEconomics is one social science among several and has fields bordering on other areas, including economic geography, economic history, public choice, energy economics, , family economics and institutional economics.\n\nLaw and economics, or economic analysis of law, is an approach to legal theory that applies methods of economics to law. It includes the use of economic concepts to explain the effects of legal rules, to assess which legal rules are economically efficient, and to predict what the legal rules will be. A seminal article by Ronald Coase published in 1961 suggested that well-defined property rights could overcome the problems of externalities.\n\nPolitical economy is the interdisciplinary study that combines economics, law, and political science in explaining how political institutions, the political environment, and the economic system (capitalist, socialist, mixed) influence each other. It studies questions such as how monopoly, rent-seeking behaviour, and externalities should impact government policy. Historians have employed \"political economy\" to explore the ways in the past that persons and groups with common economic interests have used politics to effect changes beneficial to their interests.\n\nEnergy economics is a broad scientific subject area which includes topics related to energy supply and energy demand. Georgescu-Roegen reintroduced the concept of entropy in relation to economics and energy from thermodynamics, as distinguished from what he viewed as the mechanistic foundation of neoclassical economics drawn from Newtonian physics. His work contributed significantly to thermoeconomics and to ecological economics. He also did foundational work which later developed into evolutionary economics.\n\nThe sociological subfield of economic sociology arose, primarily through the work of Émile Durkheim, Max Weber and Georg Simmel, as an approach to analysing the effects of economic phenomena in relation to the overarching social paradigm (i.e. modernity). Classic works include Max Weber's \"The Protestant Ethic and the Spirit of Capitalism\" (1905) and Georg Simmel's \"The Philosophy of Money\" (1900). More recently, the works of Mark Granovetter, Peter Hedstrom and Richard Swedberg have been influential in this field.\n\nContemporary economics uses mathematics. Economists draw on the tools of calculus, linear algebra, statistics, game theory, and computer science. Professional economists are expected to be familiar with these tools, while a minority specialize in econometrics and mathematical methods.\n\nEconomic theories are frequently tested empirically, largely through the use of econometrics using economic data. The controlled experiments common to the physical sciences are difficult and uncommon in economics, and instead broad data is observationally studied; this type of testing is typically regarded as less rigorous than controlled experimentation, and the conclusions typically more tentative. However, the field of experimental economics is growing, and increasing use is being made of natural experiments.\n\nStatistical methods such as regression analysis are common. Practitioners use such methods to estimate the size, economic significance, and statistical significance (\"signal strength\") of the hypothesized relation(s) and to adjust for noise from other variables. By such means, a hypothesis may gain acceptance, although in a probabilistic, rather than certain, sense. Acceptance is dependent upon the falsifiable hypothesis surviving tests. Use of commonly accepted methods need not produce a final conclusion or even a consensus on a particular question, given different tests, data sets, and prior beliefs.\n\nCriticisms based on professional standards and non-replicability of results serve as further checks against bias, errors, and over-generalization, although much economic research has been accused of being non-replicable, and prestigious journals have been accused of not facilitating replication through the provision of the code and data. Like theories, uses of test statistics are themselves open to critical analysis, although critical commentary on papers in economics in prestigious journals such as the \"American Economic Review\" has declined precipitously in the past 40 years. This has been attributed to journals' incentives to maximize citations in order to rank higher on the Social Science Citation Index (SSCI).\n\nIn applied economics, input-output models employing linear programming methods are quite common. Large amounts of data are run through computer programs to analyse the impact of certain policies; IMPLAN is one well-known example.\n\nExperimental economics has promoted the use of scientifically controlled experiments. This has reduced the long-noted distinction of economics from natural sciences because it allows direct tests of what were previously taken as axioms. In some cases these have found that the axioms are not entirely correct; for example, the ultimatum game has revealed that people reject unequal offers.\n\nIn behavioural economics, psychologist Daniel Kahneman won the Nobel Prize in economics in 2002 for his and Amos Tversky's empirical discovery of several cognitive biases and heuristics. Similar empirical testing occurs in neuroeconomics. Another example is the assumption of narrowly selfish preferences versus a model that tests for selfish, altruistic, and cooperative preferences. These techniques have led some to argue that economics is a \"genuine science\".\n\nThe professionalization of economics, reflected in the growth of graduate programmes on the subject, has been described as \"the main change in economics since around 1900\". Most major universities and many colleges have a major, school, or department in which academic degrees are awarded in the subject, whether in the liberal arts, business, or for professional study.\n\nIn the private sector, professional economists are employed as consultants and in industry, including banking and finance. Economists also work for various government departments and agencies, for example, the national treasury, central bank or bureau of statistics.\n\nThere are dozens of prizes awarded to economists each year for outstanding intellectual contributions to the field, the most prominent of which is the Nobel Memorial Prize in Economic Sciences, though it is not a Nobel Prize.\n\n\n\n\n"}
{"id": "18820", "url": "https://en.wikipedia.org/wiki?curid=18820", "title": "Macroeconomics", "text": "Macroeconomics\n\nMacroeconomics (from the Greek prefix \"makro-\" meaning \"large\" + \"economics\") is a branch of economics dealing with the performance, structure, behavior, and decision-making of an economy as a whole. This includes regional, national, and global economies. \n\nWhile macroeconomics is a broad field of study, there are two areas of research that are emblematic of the discipline: the attempt to understand the causes and consequences of short-run fluctuations in national income (the business cycle), and the attempt to understand the determinants of long-run economic growth (increases in national income).\n\nMacroeconomic models and their forecasts are used by governments to assist in the development and evaluation of economic policy.\n\nMacroeconomists study aggregated indicators such as GDP, unemployment rates, national income, price indices, and the interrelations among the different sectors of the economy to better understand how the whole economy functions. They also develop models that explain the relationship between such factors as national income, output, consumption, unemployment, inflation, saving, investment, energy, international trade, and international finance.\n\nMacroeconomics and microeconomics, a pair of terms coined by Ragnar Frisch, are the two most general fields in economics. In contrast to macroeconomics, microeconomics is the branch of economics that studies the behavior of individuals and firms in making decisions and the interactions among these individuals and firms in narrowly-defined markets. The central problems of an economy are 1. What to produce ? 2. How to produce ? 3. For whom to produce ?\n\nMacroeconomics descended from the once divided fields of business cycle theory and monetary theory. The quantity theory of money was particularly influential prior to World War II. It took many forms, including the version based on the work of Irving Fisher:\n\nIn the typical view of the quantity theory, money velocity (V) and the quantity of goods produced (Q) would be constant, so any increase in money supply (M) would lead to a direct increase in price level (P). The quantity theory of money was a central part of the classical theory of the economy that prevailed in the early twentieth century.\n\nLudwig Von Mises's work \"Theory of Money and Credit\", published in 1912, was one of the first books from the Austrian School to deal with macroeconomic topics.\n\nMacroeconomics, at least in its modern form, began with the publication of John Maynard Keynes's \"General Theory of Employment, Interest and Money\". When the Great Depression struck, classical economists had difficulty explaining how goods could go unsold and workers could be left unemployed. In classical theory, prices and wages would drop until the market cleared, and all goods and labor were sold. Keynes offered a new theory of economics that explained why markets might not clear, which would evolve (later in the 20th century) into a group of macroeconomic schools of thought known as Keynesian economics – also called Keynesianism or Keynesian theory.\n\nIn Keynes's theory, the quantity theory broke down because people and businesses tend to hold on to their cash in tough economic times – a phenomenon he described in terms of liquidity preferences. Keynes also explained how the multiplier effect would magnify a small decrease in consumption or investment and cause declines throughout the economy. Keynes also noted the role uncertainty and animal spirits can play in the economy.\n\nThe generation following Keynes combined the macroeconomics of the \"General Theory\" with neoclassical microeconomics to create the neoclassical synthesis. By the 1950s, most economists had accepted the synthesis view of the macroeconomy. Economists like Paul Samuelson, Franco Modigliani, James Tobin, and Robert Solow developed formal Keynesian models and contributed formal theories of consumption, investment, and money demand that fleshed out the Keynesian framework.\n\nMilton Friedman updated the quantity theory of money to include a role for money demand. He argued that the role of money in the economy was sufficient to explain the Great Depression, and that aggregate demand oriented explanations were not necessary. Friedman also argued that monetary policy was more effective than fiscal policy; however, Friedman doubted the government's ability to \"fine-tune\" the economy with monetary policy. He generally favored a policy of steady growth in money supply instead of frequent intervention.\n\nFriedman also challenged the Phillips curve relationship between inflation and unemployment. Friedman and Edmund Phelps (who was not a monetarist) proposed an \"augmented\" version of the Phillips curve that excluded the possibility of a stable, long-run tradeoff between inflation and unemployment. When the oil shocks of the 1970s created a high unemployment and high inflation, Friedman and Phelps were vindicated. Monetarism was particularly influential in the early 1980s. Monetarism fell out of favor when central banks found it difficult to target money supply instead of interest rates as monetarists recommended. Monetarism also became politically unpopular when the central banks created recessions in order to slow inflation.\n\nNew classical macroeconomics further challenged the Keynesian school. A central development in new classical thought came when Robert Lucas introduced rational expectations to macroeconomics. Prior to Lucas, economists had generally used adaptive expectations where agents were assumed to look at the recent past to make expectations about the future. Under rational expectations, agents are assumed to be more sophisticated. A consumer will not simply assume a 2% inflation rate just because that has been the average the past few years; she will look at current monetary policy and economic conditions to make an informed forecast. When new classical economists introduced rational expectations into their models, they showed that monetary policy could only have a limited impact.\n\nLucas also made an influential critique of Keynesian empirical models. He argued that forecasting models based on empirical relationships would keep producing the same predictions even as the underlying model generating the data changed. He advocated models based on fundamental economic theory that would, in principle, be structurally accurate as economies changed. Following Lucas's critique, new classical economists, led by Edward C. Prescott and Finn E. Kydland, created real business cycle (RB C) models of the macro economy.\n\nRB C models were created by combining fundamental equations from neo-classical microeconomics. In order to generate macroeconomic fluctuations, RB C models explained recessions and unemployment with changes in technology instead of changes in the markets for goods or money. Critics of RB C models argue that money clearly plays an important role in the economy, and the idea that technological regress can explain recent recessions is implausible. However, technological shocks are only the more prominent of a myriad of possible shocks to the system that can be modeled. Despite questions about the theory behind RB C models, they have clearly been influential in economic methodology.\n\nNew Keynesian economists responded to the new classical school by adopting rational expectations and focusing on developing micro-founded models that are immune to the Lucas critique. Stanley Fischer and John B. Taylor produced early work in this area by showing that monetary policy could be effective even in models with rational expectations when contracts locked in wages for workers. Other new Keynesian economists, including Olivier Blanchard, Julio Rotemberg, Greg Mankiw, David Romer, and Michael Woodford, expanded on this work and demonstrated other cases where inflexible prices and wages led to monetary and fiscal policy having real effects.\n\nLike classical models, new classical models had assumed that prices would be able to adjust perfectly and monetary policy would only lead to price changes. New Keynesian models investigated sources of sticky prices and wages due to imperfect competition, which would not adjust, allowing monetary policy to impact quantities instead of prices.\n\nBy the late 1990s economists had reached a rough consensus. The nominal rigidity of new Keynesian theory was combined with rational expectations and the RBC methodology to produce dynamic stochastic general equilibrium (DSGE) models. The fusion of elements from different schools of thought has been dubbed the new neoclassical synthesis. These models are now used by many central banks and are a core part of contemporary macroeconomics.\n\nNew Keynesian economics, which developed partly in response to new classical economics, strives to provide microeconomic foundations to Keynesian economics by showing how imperfect markets can justify demand management.\n\nThe AD-AS model has become the standard textbook model for explaining the macroeconomy. This model shows the price level and level of real output given the equilibrium in aggregate demand and aggregate supply. The aggregate demand curve's downward slope means that more output is demanded at lower price levels. The downward slope is the result of three effects: the Pigou or real balance effect, which states that as real prices fall, real wealth increases, resulting in higher consumer demand of goods; the Keynes or interest rate effect, which states that as prices fall, the demand for money decreases, causing interest rates to decline and borrowing for investment and consumption to increase; and the net export effect, which states that as prices rise, domestic goods become comparatively more expensive to foreign consumers, leading to a decline in exports.\n\nIn the conventional Keynesian use of the AS-AD model, the aggregate supply curve is horizontal at low levels of output and becomes inelastic near the point of potential output, which corresponds with full employment. Since the economy cannot produce beyond the potential output, any AD expansion will lead to higher price levels instead of higher output.\n\nThe AD–AS diagram can model a variety of macroeconomic phenomena, including inflation. Changes in the non-price level factors or determinants cause changes in aggregate demand and shifts of the entire aggregate demand (AD) curve. When demand for goods exceeds supply there is an inflationary gap where demand-pull inflation occurs and the AD curve shifts upward to a higher price level. When the economy faces higher costs, cost-push inflation occurs and the AS curve shifts upward to higher price levels. The AS–AD diagram is also widely used as a pedagogical tool to model the effects of various macroeconomic policies.\n\nThe IS–LM model gives the underpinnings of aggregate demand (itself discussed above). It answers the question “At any given price level, what is the quantity of goods demanded?” This model shows represents what combination of interest rates and output will ensure equilibrium in both the goods and money markets. The goods market is modeled as giving equality between investment and public and private saving (IS), and the money market is modeled as giving equilibrium between the money supply and liquidity preference. \n\nThe IS curve consists of the points (combinations of income and interest rate) where investment, given the interest rate, is equal to public and private saving, given output The IS curve is downward sloping because output and the interest rate have an inverse relationship in the goods market: as output increases, more income is saved, which means interest rates must be lower to spur enough investment to match saving. \n\nThe LM curve is upward sloping because the interest rate and output have a positive relationship in the money market: as income (identically equal to output) increases, the demand for money increases, resulting in a rise in the interest rate in order to just offset the insipient rise in money demand.\n\nThe IS-LM model is often used to demonstrate the effects of monetary and fiscal policy. Textbooks frequently use the IS-LM model, but it does not feature the complexities of most modern macroeconomic models. Nevertheless, these models still feature similar relationships to those in IS-LM.\n\nThe neoclassical growth model of Robert Solow has become a common textbook model for explaining economic growth in the long-run. The model begins with a production function where national output is the product of two inputs: capital and labor. The Solow model assumes that labor and capital are used at constant rates without the fluctuations in unemployment and capital utilization commonly seen in business cycles.\n\nAn increase in output, or economic growth, can only occur because of an increase in the capital stock, a larger population, or technological advancements that lead to higher productivity (total factor productivity). An increase in the savings rate leads to a temporary increase as the economy creates more capital, which adds to output. However, eventually the depreciation rate will limit the expansion of capital: savings will be used up replacing depreciated capital, and no savings will remain to pay for an additional expansion in capital. Solow's model suggests that economic growth in terms of output per capita depends solely on technological advances that enhance productivity.\n\nIn the 1980s and 1990s endogenous growth theory arose to challenge neoclassical growth theory. This group of models explains economic growth through other factors, such as increasing returns to scale for capital and learning-by-doing, that are endogenously determined instead of the exogenous technological improvement used to explain growth in Solow's model.\n\nMacroeconomics encompasses a variety of concepts and variables, but there are three central topics for macroeconomic research. Macroeconomic theories usually relate the phenomena of output, unemployment, and inflation. Outside of macroeconomic theory, these topics are also important to all economic agents including workers, consumers, and producers.\n\nNational output is the total amount of everything a country produces in a given period of time. Everything that is produced and sold generates an equal amount of income. The total output of the economy is measured GDP per person. The output and income are usually considered equivalent and the two terms are often used interchangeably, output changes into income. Output can be measured or it can be viewed from the production side and measured as the total value of final goods and services or the sum of all value added in the economy.\n\nMacroeconomic output is usually measured by gross domestic product (GDP) or one of the other national accounts. Economists interested in long-run increases in output study economic growth. Advances in technology, accumulation of machinery and other capital, and better education and human capital are all factors that lead to increase economic output over time. However, output does not always increase consistently over time. Business cycles can cause short-term drops in output called recessions. Economists look for macroeconomic policies that prevent economies from slipping into recessions and that lead to faster long-term growth.\n\nThe amount of unemployment in an economy is measured by the unemployment rate, i.e. the percentage of workers without jobs in the labor force. The unemployment rate in the labor force only includes workers actively looking for jobs. People who are retired, pursuing education, or discouraged from seeking work by a lack of job prospects are excluded.\n\nUnemployment can be generally broken down into several types that are related to different causes.\n\nA general price increase across the entire economy is called inflation. When prices decrease, there is deflation. Economists measure these changes in prices with price indexes. Inflation can occur when an economy becomes overheated and grows too quickly. Similarly, a declining economy can lead to deflation.\n\nCentral bankers, who manage a country's money supply, try to avoid changes in price level by using monetary policy. Raising interest rates or reducing the supply of money in an economy will reduce inflation. Inflation can lead to increased uncertainty and other negative consequences. Deflation can lower economic output. Central bankers try to stabilize prices to protect economies from the negative consequences of price changes.\n\nChanges in price level may be the result of several factors. The quantity theory of money holds that changes in price level are directly related to changes in the money supply. Most economists believe that this relationship explains long-run changes in the price level. Short-run fluctuations may also be related to monetary factors, but changes in aggregate demand and aggregate supply can also influence price level. For example, a decrease in demand due to a recession can lead to lower price levels and deflation. A negative supply shock, such as an oil crisis, lowers aggregate supply and can cause inflation.\n\nMacroeconomic policy is usually implemented through two sets of tools: fiscal and monetary policy. Both forms of policy are used to stabilize the economy, which can mean boosting the economy to the level of GDP consistent with full employment. Macroeconomic policy focuses on limiting the effects of the business cycle to achieve the economic goals of price stability, full employment, and growth.\n\nCentral banks implement monetary policy by controlling the money supply through several mechanisms. Typically, central banks take action by issuing money to buy bonds (or other assets), which boosts the supply of money and lowers interest rates, or, in the case of contractionary monetary policy, banks sell bonds and take money out of circulation. Usually policy is not implemented by directly targeting the supply of money.\n\nCentral banks continuously shift the money supply to maintain a targeted fixed interest rate. Some of them allow the interest rate to fluctuate and focus on targeting inflation rates instead. Central banks generally try to achieve high output without letting loose monetary policy that create large amounts of inflation.\n\nConventional monetary policy can be ineffective in situations such as a liquidity trap. When interest rates and inflation are near zero, the central bank cannot loosen monetary policy through conventional means.\n\nCentral banks can use unconventional monetary policy such as quantitative easing to help increase output. Instead of buying government bonds, central banks can implement quantitative easing by buying not only government bonds, but also other assets such as corporate bonds, stocks, and other securities. This allows lower interest rates for a broader class of assets beyond government bonds. In another example of unconventional monetary policy, the United States Federal Reserve recently made an attempt at such a policy with Operation Twist. Unable to lower current interest rates, the Federal Reserve lowered long-term interest rates by buying long-term bonds and selling short-term bonds to create a flat yield curve.\n\nFiscal policy is the use of government's revenue and expenditure as instruments to influence the economy. Examples of such tools are expenditure, taxes, debt.\n\nFor example, if the economy is producing less than potential output, government spending can be used to employ idle resources and boost output. Government spending does not have to make up for the entire output gap. There is a multiplier effect that boosts the impact of government spending. For instance, when the government pays for a bridge, the project not only adds the value of the bridge to output, but also allows the bridge workers to increase their consumption and investment, which helps to close the output gap.\n\nThe effects of fiscal policy can be limited by crowding out. When the government takes on spending projects, it limits the amount of resources available for the private sector to use. Crowding out occurs when government spending simply replaces private sector output instead of adding additional output to the economy. Crowding out also occurs when government spending raises interest rates, which limits investment. Defenders of fiscal stimulus argue that crowding out is not a concern when the economy is depressed, plenty of resources are left idle, and interest rates are low.\n\nFiscal policy can be implemented through automatic stabilizers. Automatic stabilizers do not suffer from the policy lags of discretionary fiscal policy. Automatic stabilizers use conventional fiscal mechanisms but take effect as soon as the economy takes a downturn: spending on unemployment benefits automatically increases when unemployment rises and, in a progressive income tax system, the effective tax rate automatically falls when incomes decline.\n\nEconomists usually favor monetary over fiscal policy because it has two major advantages. First, monetary policy is generally implemented by independent central banks instead of the political institutions that control fiscal policy. Independent central banks are less likely to make decisions based on political motives. Second, monetary policy suffers shorter inside lags and outside lags than fiscal policy. Central banks can quickly make and implement decisions while discretionary fiscal policy may take time to pass and even longer to carry out.\n\n\n"}
{"id": "18819", "url": "https://en.wikipedia.org/wiki?curid=18819", "title": "Microeconomics", "text": "Microeconomics\n\nMicroeconomics (from Greek prefix \"mikro-\" meaning \"small\" + \"economics\") is a branch of economics that studies the behaviour of individuals and firms in making decisions regarding the allocation of scarce resources and the interactions among these individuals and firms.\n\nOne goal of microeconomics is to analyze the market mechanisms that establish relative prices among goods and services and allocate limited resources among alternative uses. Microeconomics shows conditions under which free markets lead to desirable allocations. It also analyzes market failure, where markets fail to produce efficient results.\n\nWhile microeconomics focuses on firms and individuals, macroeconomics focuses on the sum total of economic activity, dealing with the issues of growth, inflation, and unemployment and with national policies relating to these issues. Microeconomics also deals with the effects of economic policies (such as changing taxation levels) on microeconomic behavior and thus on the aforementioned aspects of the economy. Particularly in the wake of the Lucas critique, much of modern macroeconomic theories has been built upon microfoundations—i.e. based upon basic assumptions about micro-level behavior.\n\nMicroeconomic theory typically begins with the study of a single rational and utility maximizing individual. To economists, rationality means an individual possesses stable preferences that are both complete and transitive.\n\nThe technical assumption that preference relations are continuous is needed to ensure the existence of a utility function. Although microeconomic theory can continue without this assumption, it would make comparative statics impossible since there is no guarantee that the resulting utility function would be differentiable.\n\nMicroeconomic theory progresses by defining a competitive budget set which is a subset of the consumption set. It is at this point that economists make the technical assumption that preferences are locally non-satiated. Without the assumption of LNS (local non-satiation) there is no 100% guarantee but there would be a rational rise \nin individual utility. With the necessary tools and assumptions in place the utility maximization problem (UMP) is developed.\n\nThe utility maximization problem is the heart of consumer theory. The utility maximization problem attempts to explain the action axiom by imposing rationality axioms on consumer preferences and then mathematically modeling and analyzing the consequences. The utility maximization problem serves not only as the mathematical foundation of consumer theory but as a metaphysical explanation of it as well. That is, the utility maximization problem is used by economists to not only explain \"what\" or \"how\" individuals make choices but \"why\" individuals make choices as well.\n\nThe utility maximization problem is a constrained optimization problem in which an individual seeks to maximize utility subject to a budget constraint. Economists use the extreme value theorem to guarantee that a solution to the utility maximization problem exists. That is, since the budget constraint is both bounded and closed, a solution to the utility maximization problem exists. Economists call the solution to the utility maximization problem a Walrasian demand function or correspondence.\n\nThe utility maximization problem has so far been developed by taking consumer tastes (i.e. consumer utility) as the primitive. However, an alternative way to develop microeconomic theory is by taking consumer choice as the primitive. This model of microeconomic theory is referred to as revealed preference theory.\n\nThe theory of supply and demand usually assumes that markets are perfectly competitive. This implies that there are many buyers and sellers in the market and none of them have the capacity to significantly influence prices of goods and services. In many real-life transactions, the assumption fails because some individual buyers or sellers have the ability to influence prices. Quite often, a sophisticated analysis is required to understand the demand-supply equation of a good model. However, the theory works well in situations meeting these assumptions.\n\nMainstream economics does not assume \"a priori\" that markets are preferable to other forms of social organization. In fact, much analysis is devoted to cases where market failures lead to resource allocation that is suboptimal and creates deadweight loss. A classic example of suboptimal resource allocation is that of a public good. In such cases, economists may attempt to find policies that avoid waste, either directly by government control, indirectly by regulation that induces market participants to act in a manner consistent with optimal welfare, or by creating \"missing markets\" to enable efficient trading where none had previously existed.\n\nThis is studied in the field of collective action and public choice theory. \"Optimal welfare\" usually takes on a Paretian norm, which is a mathematical application of the Kaldor–Hicks method. This can diverge from the Utilitarian goal of maximizing utility because it does not consider the distribution of goods between people. Market failure in positive economics (microeconomics) is limited in implications without mixing the belief of the economist and their theory.\n\nThe demand for various commodities by individuals is generally thought of as the outcome of a utility-maximizing process, with each individual trying to maximize their own utility under a budget constraint and a given consumption set.\n\nEconomists commonly consider themselves microeconomists or macroeconomists. The difference between microeconomics and macroeconomics was introduced in 1933 by the Norwegian economist Ragnar Frisch, the co-recipient of the first Nobel Memorial Prize in Economic Sciences in 1969.\n\nConsumer demand theory relates preferences for the consumption of both goods and services to the consumption expenditures; ultimately, this relationship between preferences and consumption expenditures is used to relate preferences to consumer demand curves. The link between personal preferences, consumption and the demand curve is one of the most closely studied relations in economics. It is a way of analyzing how consumers may achieve equilibrium between preferences and expenditures by maximizing utility subject to consumer budget constraints.\n\nProduction theory is the study of production, or the economic process of converting inputs into outputs. Production uses resources to create a good or service that is suitable for use, gift-giving in a gift economy, or exchange in a market economy. This can include manufacturing, storing, shipping, and packaging. Some economists define production broadly as all economic activity other than consumption. They see every commercial activity other than the final purchase as some form of production.\n\nThe cost-of-production theory of value states that the price of an object or condition is determined by the sum of the cost of the resources that went into making it. The cost can comprise any of the factors of production (including labor, capital, or land) and taxation. Technology can be viewed either as a form of fixed capital (e.g. an industrial plant) or circulating capital (e.g. intermediate goods).\n\nIn the mathematical model for the cost of production, the short-run total cost is equal to fixed cost plus total variable cost. The fixed cost refers to the cost that is incurred regardless of how much the firm produces. The variable cost is a function of the quantity of an object being produced. The cost function can be used to characterize production through the duality theory in economics, developed mainly by Ronald Shephard (1953, 1970) and other scholars (Sickles & Zelenyuk, 2019, ch.2).\n\nOpportunity cost is closely related to the idea of time constraints. One can do only one thing at a time, which means that, inevitably, one is always giving up other things. The opportunity cost of any activity is the value of the next-best alternative thing one may have done instead. Opportunity cost depends only on the value of the next-best alternative. It doesn't matter whether one has five alternatives or 5,000.\n\nOpportunity costs can tell when \"not\" to do something as well as when to do something. For example, one may like waffles, but like chocolate even more. If someone offers only waffles, one would take it. But if offered waffles or chocolate, one would take the chocolate. The opportunity cost of eating waffles is sacrificing the chance to eat chocolate. Because the cost of not eating the chocolate is higher than the benefits of eating the waffles, it makes no sense to choose waffles. Of course, if one chooses chocolate, they are still faced with the opportunity cost of giving up having waffles. But one is willing to do that because the waffle's opportunity cost is lower than the benefits of the chocolate. Opportunity costs are unavoidable constraints on behaviour because one has to decide what's best and give up the next-best alternative.\n\nSupply and demand is an economic model of price determination in a perfectly competitive market. It concludes that in a perfectly competitive market with no externalities, per unit taxes, or price controls, the unit price for a particular good is the price at which the quantity demanded by consumers equals the quantity supplied by producers. This price results in a stable economic equilibrium.\n\nPrices and quantities have been described as the most directly observable attributes of goods produced and exchanged in a market economy. The theory of supply and demand is an organizing principle for explaining how prices coordinate the amounts produced and consumed. In microeconomics, it applies to price and output determination for a market with perfect competition, which includes the condition of no buyers or sellers large enough to have price-setting power.\n\nFor a given market of a commodity, demand is the relation of the quantity that all buyers would be prepared to purchase at each unit price of the good. Demand is often represented by a table or a graph showing price and quantity demanded (as in the figure). Demand theory describes individual consumers as rationally choosing the most preferred quantity of each good, given income, prices, tastes, etc. A term for this is \"constrained utility maximization\" (with income and wealth as the constraints on demand). Here, utility refers to the hypothesized relation of each individual consumer for ranking different commodity bundles as more or less preferred.\n\nThe law of demand states that, in general, price and quantity demanded in a given market are inversely related. That is, the higher the price of a product, the less of it people would be prepared to buy (other things unchanged). As the price of a commodity falls, consumers move toward it from relatively more expensive goods (the substitution effect). In addition, purchasing power from the price decline increases ability to buy (the income effect). Other factors can change demand; for example an increase in income will shift the demand curve for a normal good outward relative to the origin, as in the figure. All determinants are predominantly taken as constant factors of demand and supply.\n\n\"Supply\" is the relation between the price of a good and the quantity available for sale at that price. It may be represented as a table or graph relating price and quantity supplied. Producers, for example business firms, are hypothesized to be \"profit maximizers\", meaning that they attempt to produce and supply the amount of goods that will bring them the highest profit. Supply is typically represented as a function relating price and quantity, if other factors are unchanged.\n\nThat is, the higher the price at which the good can be sold, the more of it producers will supply, as in the figure. The higher price makes it profitable to increase production. Just as on the demand side, the position of the supply can shift, say from a change in the price of a productive input or a technical improvement. The \"Law of Supply\" states that, in general, a rise in price leads to an expansion in supply and a fall in price leads to a contraction in supply. Here as well, the determinants of supply, such as price of substitutes, cost of production, technology applied and various factors inputs of production are all taken to be constant for a specific time period of evaluation of supply.\n\nMarket equilibrium occurs where quantity supplied equals quantity demanded, the intersection of the supply and demand curves in the figure above. At a price below equilibrium, there is a shortage of quantity supplied compared to quantity demanded. This is posited to bid the price up. At a price above equilibrium, there is a surplus of quantity supplied compared to quantity demanded. This pushes the price down. The model of supply and demand predicts that for given supply and demand curves, price and quantity will stabilize at the price that makes quantity supplied equal to quantity demanded. Similarly, demand-and-supply theory predicts a new price-quantity combination from a shift in demand (as to the figure), or in supply.\n\nFor a given quantity of a consumer good, the point on the demand curve indicates the value, or marginal utility, to consumers for that unit. It measures what the consumer would be prepared to pay for that unit. The corresponding point on the supply curve measures marginal cost, the increase in total cost to the supplier for the corresponding unit of the good. The price in equilibrium is determined by supply and demand. In a perfectly competitive market, supply and demand equate marginal cost and marginal utility at equilibrium.\n\nOn the supply side of the market, some factors of production are described as (relatively) \"variable\" in the short run, which affects the cost of changing output levels. Their usage rates can be changed easily, such as electrical power, raw-material inputs, and over-time and temp work. Other inputs are relatively \"fixed\", such as plant and equipment and key personnel. In the long run, all inputs may be adjusted by management. These distinctions translate to differences in the elasticity (responsiveness) of the supply curve in the short and long runs and corresponding differences in the price-quantity change from a shift on the supply or demand side of the market.\n\nMarginalist theory, such as above, describes the consumers as attempting to reach most-preferred positions, subject to income and wealth constraints while producers attempt to maximize profits subject to their own constraints, including demand for goods produced, technology, and the price of inputs. For the consumer, that point comes where marginal utility of a good, net of price, reaches zero, leaving no net gain from further consumption increases. Analogously, the producer compares marginal revenue (identical to price for the perfect competitor) against the marginal cost of a good, with \"marginal profit\" the difference. At the point where marginal profit reaches zero, further increases in production of the good stop. For movement to market equilibrium and for changes in equilibrium, price and quantity also change \"at the margin\": more-or-less of something, rather than necessarily all-or-nothing.\n\nOther applications of demand and supply include the distribution of income among the factors of production, including labour and capital, through factor markets. In a competitive labour market for example the quantity of labour employed and the price of labour (the wage rate) depends on the demand for labour (from employers for production) and supply of labour (from potential workers). Labour economics examines the interaction of workers and employers through such markets to explain patterns and changes of wages and other labour income, labour mobility, and (un)employment, productivity through human capital, and related public-policy issues.\n\nDemand-and-supply analysis is used to explain the behaviour of perfectly competitive markets, but as a standard of comparison it can be extended to any type of market. It can also be generalized to explain variables across the economy, for example, total output (estimated as real GDP) and the general price level, as studied in macroeconomics. Tracing the qualitative and quantitative effects of variables that change supply and demand, whether in the short or long run, is a standard exercise in applied economics. Economic theory may also specify conditions such that supply and demand through the market is an efficient mechanism for allocating resources.\n\nMarket structure refers to features of a market, including the number of firms in the market, the distribution of market shares between them, product uniformity across firms, how easy it is for firms to enter and exit the market, and forms of competition in the market. A market structure can have several types of interacting market systems. \nDifferent forms of markets are a feature of capitalism and market socialism, with advocates of state socialism often criticizing markets and aiming to substitute or replace markets with varying degrees of government-directed economic planning.\n\nCompetition acts as a regulatory mechanism for market systems, with government providing regulations where the market cannot be expected to regulate itself. One example of this is with regards to building codes, which if absent in a purely competition regulated market system, might result in several horrific injuries or deaths to be required before companies would begin improving structural safety, as consumers may at first not be as concerned or aware of safety issues to begin putting pressure on companies to provide them, and companies would be motivated not to provide proper safety features due to how it would cut into their profits.\n\nThe concept of \"market type\" is different from the concept of \"market structure.\" Nevertheless, it is worth noting here that there are a variety of types of markets.\n\nPerfect competition is a situation in which numerous small firms producing identical products compete against each other in a given industry. Perfect competition leads to firms producing the socially optimal output level at the minimum possible cost per unit. Firms in perfect competition are \"price takers\" (they do not have enough market power to profitably increase the price of their goods or services). A good example would be that of digital marketplaces, such as eBay, on which many different sellers sell similar products to many different buyers. Consumers in a perfect competitive market have perfect knowledge about the products that are being sold in this market.\n\nImperfect competition is a type of market structure showing some but not all features of competitive markets.\n\nMonopolistic competition is a situation in which many firms with slightly different products compete. Production costs are above what may be achieved by perfectly competitive firms, but society benefits from the product differentiation. Examples of industries with market structures similar to monopolistic competition include restaurants, cereal, clothing, shoes, and service industries in large cities.\n\nA monopoly is a market structure in which a market or industry is dominated by a single supplier of a particular good or service. Because monopolies have no competition they tend to sell goods and services at a higher price and produce below the socially optimal output level. However, not all monopolies are a bad thing, especially in industries where multiple firms would result in more costs than benefits (i.e. natural monopolies).\n\n\nAn oligopoly is a market structure in which a market or industry is dominated by a small number of firms (oligopolists). Oligopolies can create the incentive for firms to engage in collusion and form cartels that reduce competition leading to higher prices for consumers and less overall market output. Alternatively, oligopolies can be fiercely competitive and engage in flamboyant advertising campaigns.\n\n\nA monopsony is a market where there is only one buyer and many sellers.\n\nA bilateral monopoly is a market consisting of both a monopoly (a single seller) and a monopsony (a single buyer).\n\nAn oligopsony is a market where there are a few buyers and many sellers.\n\nGame theory is a major method used in mathematical economics and business for modeling competing behaviors of interacting agents. The term \"game\" here implies the study of any strategic interaction between people. Applications include a wide array of economic phenomena and approaches, such as auctions, bargaining, mergers & acquisitions pricing, fair division, duopolies, oligopolies, social network formation, agent-based computational economics, general equilibrium, mechanism design, and voting systems, and across such broad areas as experimental economics, behavioral economics, information economics, industrial organization, and political economy.\n\nInformation economics is a branch of microeconomic theory that studies how information and information systems affect an economy and economic decisions. Information has special characteristics. It is easy to create but hard to trust. It is easy to spread but hard to control. It influences many decisions. These special characteristics (as compared with other types of goods) complicate many standard economic theories. The economics of information has recently become of great interest to many - possibly due to the rise of information based companies inside the technology industry. From a game theory approach, we can loosen the usual constraints that agents have complete information to further examine the consequences of having incomplete information. This gives rise to many results which are applicable to real life situations. For example, if one does loosen this assumption, then it is possible to scrutinize the actions of agents in situations of uncertainty. It is also possible to more fully understand the impacts – both positive and negative – of agents seeking out or acquiring information.\n\nApplied microeconomics includes a range of specialized areas of study, many of which draw on methods from other fields.\n\n\n\n\n"}
{"id": "580039", "url": "https://en.wikipedia.org/wiki?curid=580039", "title": "Goods", "text": "Goods\n\nIn economics, goods are materials that satisfy human wants and provide utility, for example, to a consumer making a purchase of a satisfying product. A common distinction is made between goods that are tangible property, and services, which are non-physical. \n\nA good may be a consumable item that is useful to people but scarce in relation to its demand, so that human effort is required to obtain it. In contrast, free goods, such as air, are naturally in abundant supply and need no conscious effort to obtain them. Private goods are things owned by people, such as televisions, living room furniture, wallets, cellular telephones, almost anything owned or used on a daily basis that is not food related. \n\nA consumer good or \"final good\" is any commodity that is produced or consumed by the consumer to satisfy current wants or needs. Consumer goods are ultimately consumed, rather than used in the production of another good. For example, a microwave oven or a bicycle that is sold to a consumer is a final good or consumer good, but the components that are sold to be used in those goods are intermediate goods. For example, textiles or transistors can be used to make some further goods.\n\nCommercial goods are construed as any tangible product that is manufactured and then made available for supply to be used in an industry of commerce. Commercial goods could be tractors, commercial vehicles, mobile structures, airplanes and even roofing materials. Commercial and personal goods as categories are very broad and cover almost everything a person sees from the time they wake up in their home, on their commute to work to their arrival at the workplace.\n\nCommodities may be used as a synonym for economic goods but often refer to marketable raw materials and primary products.\n\nAlthough in economic theory all goods are considered tangible, in reality certain classes of goods, such as information, only take intangible forms. For example, among other goods an apple is a tangible object, while news belongs to an intangible class of goods and can be perceived only by means of an instrument such as print or television.\n\nGoods may increase or decrease their utility directly or indirectly and may be described as having marginal utility. Some things are useful, but not scarce enough to have monetary value, such as the Earth's atmosphere, these are referred to as 'free goods'.\n\nIn normal parlance, \"goods\" is always a plural word, but economists have long termed a single item of goods \"a good\".\n\nIn economics, a bad is the opposite of a good. Ultimately, whether an object is a good or a bad depends on each individual consumer and therefore, it is important to realize that not all goods are good all the time and not all goods are goods to all people.\n\nGoods' diversity allows for their classification into different categories based on distinctive characteristics, such as tangibility and (ordinal) relative elasticity. A tangible good like an apple differs from an intangible good like information due to the impossibility of a person to physically hold the latter, whereas the former occupies physical space. Intangible goods differ from services in that final (intangible) goods are transferable and can be traded, whereas a service cannot.\n\nPrice elasticity also differentiates types of goods. An elastic good is one for which there is a relatively large change in quantity due to a relatively small change in price, and therefore is likely to be part of a family of substitute goods; for example, as pen prices rise, consumers might buy more pencils instead. An inelastic good is one for which there are few or no substitutes, such as tickets to major sporting events, original works by famous artists, and prescription medicine such as insulin. Complementary goods are generally more inelastic than goods in a family of substitutes. For example, if a rise in the price of beef results in a decrease in the quantity of beef demanded, it is likely that the quantity of hamburger buns demanded will also drop, despite no change in buns' prices. This is because hamburger buns and beef (in Western culture) are complementary goods. It is important to note that goods considered complements or substitutes are relative associations and should not be understood in a vacuum. The degree to which a good is a substitute or a complement depends on its relationship to other goods, rather than an intrinsic characteristic, and can be measured as cross elasticity of demand by employing statistical techniques such as covariance and correlation.\n\nThe following chart illustrates the classification of goods according to their exclusivity and competitiveness.\n\nGoods are capable of being physically delivered to a consumer. Goods that are economic intangibles can only be stored, delivered, and consumed by means of media.\n\nGoods, both tangibles and intangibles, may involve the transfer of product ownership to the consumer. Services do not normally involve transfer of ownership of the service itself, but may involve transfer of ownership of goods developed or marketed by a service provider in the course of the service. For example, sale of storage related goods, which could consist of storage sheds, storage containers, storage buildings as tangibles or storage supplies such as boxes, bubble wrap, tape, bags and the like which are consumables, or distributing electricity among consumers is a service provided by an electric utility company. This service can only be experienced through the consumption of electrical energy, which is available in a variety of voltages and, in this case, is the \"economic goods\" produced by the electric utility company. While the service (namely, distribution of electrical energy) is a process that remains in its entirety in the ownership of the electric service provider, the goods (namely, electric energy) is the object of ownership transfer. The consumer becomes electric energy owner by purchase and may use it for any lawful purposes just like any other goods.\n\n"}
{"id": "181586", "url": "https://en.wikipedia.org/wiki?curid=181586", "title": "Service (economics)", "text": "Service (economics)\n\nIn economics, a service is a transaction in which no physical goods are transferred from the seller to the buyer. The benefits of such a service are held to be demonstrated by the buyer's willingness to make the exchange. Public services are those that society (nation state, fiscal union, region) as a whole pays for. Using resources, skill, ingenuity, and experience, service providers benefit service consumers. Service is intangible in nature.\n\nIts titled a Victor 393684727\n\nServices can be described in terms of I's.\n\nServices are by definition intangible. They are not manufactured, transported or stocked.\n\nServices cannot be stored for a future use. They are produced and consumed simultaneously.\n\nServices are perishable in two regards:\nThe service provider must deliver the service at the exact time of service consumption. The service is not manifested in a physical object that is independent of the provider. The service consumer is also inseparable from service delivery. Examples: The service consumer must sit in the hairdresser's chair, or in the airplane seat. Correspondingly, the hairdresser or the pilot must be in the shop or plane, respectively, to deliver the service.\n\nEach service is unique. It can never be exactly repeated as the time, location, circumstances, conditions, current configurations and/or as signed resources are different for the next delivery, even if the same service is requested by the consumer. Many services are regarded as heterogeneous and are typically modified for each service consumer or each service contextual. Example: The taxi service which transports the service consumer from home to work is different from the taxi service which transports the same service consumer from work to home – another point in time, the other direction, possibly another route, probably another taxi driver and cab. Another and more common term for this is heterogeneity.\n\nMass generation and delivery of services must be mastered for a service provider to expand. This can be seen as a problem of service quality. Both inputs and outputs to the processes involved providing services are highly variable, as are the relationships between these processes, making it difficult to maintain consistent service quality. Many services involve variable human activity, rather than a precisely determined process; exceptions include utilities. The human factor is often the key success factor in service provision. Demand can vary by season, time of day, business cycle, etc. Consistency is necessary to create enduring business relationships.\n\nAny service can be clearly and completely, consistently and concisely specified by means of standard attributes that conform to the MECE principle (Mutually Exclusive, Collectively Exhaustive).\n\n\nThe delivery of a service typically involves six factors:\n\nThe service encounter is defined as all activities involved in the service delivery process. Some service managers use the term \"moment of truth\" to indicate that point in a service encounter where interactions are most intense.\n\nMany business theorists view service provision as a performance or act (sometimes humorously referred to as \"dramalurgy\", perhaps in reference to dramaturgy). The location of the service delivery is referred to as the stage and the objects that facilitate the service process are called props. A script is a sequence of behaviors followed by those involved, including the client(s). Some service dramas are tightly scripted, others are more ad lib. Role congruence occurs when each actor follows a script that harmonizes with the roles played by the other actors.\n\nIn some service industries, especially health care, dispute resolution and social services, a popular concept is the idea of the caseload, which refers to the total number of patients, clients, litigants, or claimants for which a given employee is responsible. Employees must balance the needs of each individual case against the needs of all other current cases as well as their own needs.\n\nUnder English law, if a service provider is induced to deliver services to a dishonest client by a deception, this is an offence under the Theft Act 1978.\n\nLovelock used the number of delivery sites (whether single or multiple) and the method of delivery to classify services in a 2 x 3 matrix. Then implications are that the convenience of receiving the service is the lowest when the customer has to come to the service and must use a single or specific outlet. Convenience increases (to a point) as the number of service points increase.\n\nThe distinction between a good and a service remains disputed. The perspective in the late-eighteenth and early-nineteenth centuries focused on creation and possession of wealth. Classical economists contended that goods were objects of value over which ownership rights could be established and exchanged. Ownership implied tangible possession of an object that had been acquired through purchase, barter or gift from the producer or previous owner and was legally identifiable as the property of the current owner.\n\nAdam Smith’s famous book, \"The Wealth of Nations\", published in 1776, distinguished between the outputs of what he termed \"productive\" and \"unproductive\" labor. The former, he stated, produced goods that could be stored after production and subsequently exchanged for money or other items of value. The latter, however useful or necessary, created services that perished at the time of production and therefore did not contribute to wealth. Building on this theme, French economist Jean-Baptiste Say argued that production and consumption were inseparable in services, coining the term \"immaterial products\" to describe them.\n\nMost modern business theorists describe a continuum with pure service on one terminal point and pure commodity good on the other. Most products fall between these two extremes. For example, a restaurant provides a physical good (the food), but also provides services in the form of ambience, the setting and clearing of the table, etc. And although some utilities actually deliver physical goods — like water utilities that deliver water — utilities are usually treated as services.\n\nIn a narrower sense, service refers to quality of customer service: the measured appropriateness of assistance and support provided to a customer. This particular usage occurs frequently in retailing.\n\nThe following is a list of service industries, grouped into sectors. Parenthetical notations indicate how specific occupations and organizations can be regarded as service industries to the extent they provide an intangible service, as opposed to a tangible good.\n\n\nBelow is a list of countries by service output at market exchange rates at peak level as of.\n\n"}
{"id": "29664", "url": "https://en.wikipedia.org/wiki?curid=29664", "title": "Supply and demand", "text": "Supply and demand\n\nIn microeconomics, supply and demand is an economic model of price determination in a market. It postulates that, holding all else equal, in a competitive market, the unit price for a particular good, or other traded item such as labor or liquid financial assets, will vary until it settles at a point where the quantity demanded (at the current price) will equal the quantity supplied (at the current price), resulting in an economic equilibrium for price and quantity transacted.\n\nAlthough it is normal to regard the quantity demanded and the quantity supplied as functions of the price of the goods, the standard graphical representation, usually attributed to Alfred Marshall, has price on the vertical axis and quantity on the horizontal axis.\n\nSince determinants of supply and demand other than the price of the goods in question are not explicitly represented in the supply-demand diagram, changes in the values of these variables are represented by moving the supply and demand curves (often described as \"shifts\" in the curves). By contrast, responses to changes in the price of the good are represented as movements along unchanged supply and demand curves.\n\nA supply schedule is a table that shows the relationship between the price of a good and the quantity supplied by producers, depicted graphically as a supply curve. Under the assumption of perfect competition, supply is determined by marginal cost: firms will produce additional output as long as the cost of producing an extra unit is less than the market price they receive.\n\nA hike in the cost of raw goods would decrease supply, shifting the supply curve up, while a production cost discount would increase supply, shifting costs down and hurting producers as producer surplus decreases.\n\nThe concept of a supply curve assumes that firms are \"perfect competitors\", having no influence over the market price. This is because each point on the supply curve answers the question \"If this firm is \"faced with\" this potential price, how much output will it be willing and able to sell?\" If a firm has market power, its decision of how much output to provide to the market influences the market price, and the firm is not \"faced with\" any fixed price, so the relevant model must become more complex.\n\nEconomists distinguish between the supply curve of an individual firm and the market supply curve. The market supply curve is the sum of the quantities supplied by all suppliers at each potential price: individual firms' supply curves are added horizontally to obtain the market supply curve.\n\nEconomists also distinguish the short-run and the long-run market supply curve. Here \"short run\" means a constant availability of one or more fixed inputs (typically physical capital), and a fixed number of firms in the industry. In the \"long run\", firms have a chance to adjust their producing capital, enabling them to better adjust their quantity supplied at any given price. Furthermore, in the long run competitors can enter or exit the industry in response to market conditions. For both of these reasons, long-run market supply curves are generally flatter than their short-run counterparts.\n\nThe determinants of supply are:\n\n\nA demand schedule, depicted graphically as a demand curve, represents the amount of certain\ngoods that buyers are willing and able to purchase at various prices, assuming constant all other determinants of demand, such as income, tastes and preferences, the price of substitute goods, and the price of complementary goods. According to the law of demand, the demand curve is always downward-sloping, meaning that as price decreases, consumers will buy more of the good.\n\nJust as the supply curve parallels the marginal cost curve, demand curves are parallel marginal utility. Consumers will be willing to buy a given quantity of a good, at a given price, if the marginal utility of additional consumption is equal to the opportunity cost determined by the price, that is, the marginal utility of alternative consumption choices. The demand schedule is defined as the \"willingness\" and \"ability\" of a consumer to purchase a given product at a certain time.\n\nThe demand curve is generally downward-sloping, but some goods have upward-sloping demand curves. Two different types of goods with upward-sloping demand curves are Giffen goods (an inferior but staple good) and Veblen goods (goods made more fashionable by a higher price).\n\nBy its very nature, conceptualizing a demand curve requires that the purchaser be a perfect competitor—that is, that the purchaser has no influence over the market price. This is true because each point on the demand curve is the answer to the question \"If this buyer is \"faced with\" this potential price, how much of the product will it purchase?\" If a buyer has market power, so its decision of how much to buy influences the market price, then the buyer is not \"faced with\" any price, and the question is meaningless.\n\nLike with supply curves, economists distinguish between the demand curve of an individual and the market demand curve. The market demand curve is obtained by summing the quantities demanded by all consumers at each potential price. Thus, in the graph of the demand curve, individuals' demand curves are added horizontally to obtain the market demand curve.\n\nThe determinants of demand are:\n\nGenerally speaking, an equilibrium is defined to be the price-quantity pair where the quantity demanded is equal to the quantity supplied. It is represented by the intersection of the demand and supply curves. The analysis of various equilibria is a fundamental aspect of microeconomics:\n\nMarket equilibrium: A situation in a market when the price is such that the quantity demanded by consumers is correctly balanced by the quantity that firms wish to supply. In this situation, the market clears.\n\nChanges in market equilibrium:\nPractical uses of supply and demand analysis often center on the different variables that change equilibrium price and quantity, represented as shifts in the respective curves. Comparative statics of such a shift traces the effects from the initial equilibrium to the new equilibrium.\n\nDemand curve shifts:\n\nWhen consumers increase the quantity demanded \"at a given price\", it is referred to as an \"increase in demand\". Increased demand can be represented on the graph as the curve being shifted to the right. At each price point, a greater quantity is demanded, as from the initial curve to the new curve . In the diagram, this raises the equilibrium price from to the higher . This raises the equilibrium quantity from to the higher . (A movement along the curve is described as a \"change in the quantity demanded\" to distinguish it from a \"change in demand,\" that is, a shift of the curve.) The \"increase\" in demand has caused an increase in (equilibrium) quantity. The increase in demand could come from changing tastes and fashions, incomes, price changes in complementary and substitute goods, market expectations, and number of buyers. This would cause the entire demand curve to shift changing the equilibrium price and quantity. Note in the diagram that the shift of the demand curve, by causing a new equilibrium price to emerge, resulted in \"movement along\" the supply curve from the point to the point .\n\nIf the \"demand decreases\", then the opposite happens: a shift of the curve to the left. If the demand starts at , and \"decreases\" to , the equilibrium price will decrease, and the equilibrium quantity will also decrease. The quantity supplied at each price is the same as before the demand shift, reflecting the fact that the supply curve has not shifted; but the equilibrium quantity and price are different as a result of the change (shift) in demand.\n\nSupply curve shifts:\n\nWhen technological progress occurs, the supply curve shifts. For example, assume that someone invents a better way of growing wheat so that the cost of growing a given quantity of wheat decreases. Otherwise stated, producers will be willing to supply more wheat at every price and this shifts the supply curve outward, to —an \"increase in supply\". This increase in supply causes the equilibrium price to decrease from to . The equilibrium quantity increases from to as consumers move along the demand curve to the new lower price. As a result of a supply curve shift, the price and the quantity move in opposite directions. If the quantity supplied \"decreases\", the opposite happens. If the supply curve starts at , and shifts leftward to , the equilibrium price will increase and the equilibrium quantity will decrease as consumers move along the demand curve to the new higher price and associated lower quantity demanded. The quantity demanded at each price is the same as before the supply shift, reflecting the fact that the demand curve has not shifted. But due to the change (shift) in supply, the equilibrium quantity and price have changed.\n\nThe movement of the supply curve in response to a change in a non-price determinant of supply is caused by a change in the y-intercept, the constant term of the supply equation. The supply curve shifts up and down the y axis as non-price determinants of demand change.\n\nPartial equilibrium, as the name suggests, takes into consideration only a part of the market to attain equilibrium.\n\nJain proposes (attributed to George Stigler): \"A partial equilibrium is one which is based on only a restricted range of data, a standard example is price of a single product, the prices of all other products being held fixed during the analysis.\"\n\nThe supply-and-demand model is a partial equilibrium model of economic equilibrium, where the clearance on the market of some specific goods is obtained independently from prices and quantities in other markets. In other words, the prices of all substitutes and complements, as well as income levels of consumers are constant. This makes analysis much simpler than in a general equilibrium model which includes an entire economy.\n\nHere the dynamic process is that prices adjust until supply equals demand. It is a powerfully simple technique that allows one to study equilibrium, efficiency and comparative statics. The stringency of the simplifying assumptions inherent in this approach makes the model considerably more tractable, but may produce results which, while seemingly precise, do not effectively model real world economic\nphenomena.\n\nPartial equilibrium analysis examines the effects of policy action in creating equilibrium only in that particular sector or market which is directly affected, ignoring its effect in any other market or industry assuming that they being small will have little impact if any.\n\nHence this analysis is considered to be useful in constricted markets.\n\nLéon Walras first formalized the idea of a one-period economic equilibrium of the general economic system, but it was French economist Antoine Augustin Cournot and English political economist Alfred Marshall who developed tractable models to analyze an economic system.\n\nThe model of supply and demand also applies to various specialty markets.\n\nThe model is commonly applied to wages, in the market for labor. The typical roles of supplier and demander are reversed. The suppliers are individuals, who try to sell their labor for the highest price. The demanders of labor are businesses, which try to buy the type of labor they need at the lowest price. The equilibrium price for a certain type of labor is the wage rate. However, economist Steve Fleetwood revisited the empirical reality of supply and demand curves in labor markets and concluded that the evidence is \"at best inconclusive and at worst casts doubt on their existence.\" For instance, he cites Kaufman and Hotchkiss (2006): \"For adult men, nearly all studies find the labour supply curve to be negatively sloped or backward bending.\" \n\nIn both classical and Keynesian economics, the money market is analyzed as a supply-and-demand system with interest rates being the price. The money supply may be a vertical supply curve, if the central bank of a country chooses to use monetary policy to fix its value regardless of the interest rate; in this case the money supply is totally inelastic. On the other hand, the money supply curve is a horizontal line if the central bank is targeting a fixed interest rate and ignoring the value of the money supply; in this case the money supply curve is perfectly elastic. The demand for money intersects with the money supply to determine the interest rate.\n\nDemand and supply relations in a market can be statistically estimated from price, quantity, and other data with sufficient information in the model. This can be done with \"simultaneous-equation methods of estimation\" in econometrics. Such methods allow solving for the model-relevant \"structural coefficients,\" the estimated algebraic counterparts of the theory. The \"Parameter identification problem\" is a common issue in \"structural estimation.\" Typically, data on exogenous variables (that is, variables other than price and quantity, both of which are endogenous variables) are needed to perform such an estimation. An alternative to \"structural estimation\" is reduced-form estimation, which regresses each of the endogenous variables on the respective exogenous variables.\n\nDemand and supply have also been generalized to explain macroeconomic variables in a market economy, including the quantity of total output and the general price level. The aggregate demand-aggregate supply model may be the most direct application of supply and demand to macroeconomics, but other macroeconomic models also use supply and demand. Compared to microeconomic uses of demand and supply, different (and more controversial) theoretical considerations apply to such macroeconomic counterparts as aggregate demand and aggregate supply. Demand and supply are also used in macroeconomic theory to relate money supply and money demand to interest rates, and to relate labor supply and labor demand to wage rates.\n\nThe 256th couplet of Tirukkural, which was composed at least 2000 years ago, says that \"if people do not consume a product or service, then there will not be anybody to supply that product or service for the sake of price\".\n\nAccording to Hamid S. Hosseini, the power of supply and demand was understood to some extent by several early Muslim scholars, such as fourteenth-century Syrian scholar Ibn Taymiyyah, who wrote: \"If desire for goods increases while its availability decreases, its price rises. On the other hand, if availability of the good increases and the desire for it decreases, the price comes down.\"\nJohn Locke's 1691 work \"Some Considerations on the Consequences of the Lowering of Interest and the Raising of the Value of Money\". includes an early and clear description of supply and demand and their relationship. In this description demand is rent: “The price of any commodity rises or falls by the proportion of the number of buyer and sellers” and “that which regulates the price... [of goods] is nothing else but their quantity in proportion to their rent.”\n\nThe phrase \"supply and demand\" was first used by James Denham-Steuart in his \"Inquiry into the Principles of Political Economy\", published in 1767. Adam Smith used the phrase in his 1776 book \"The Wealth of Nations\", and David Ricardo titled one chapter of his 1817 work \"Principles of Political Economy and Taxation\" \"On the Influence of Demand and Supply on Price\". Thomas Robert Malthus used the phrase \"supply and demand\" twenty times in the second edition of the \"Essay on Population\" in 1803.\n\nIn \"The Wealth of Nations\", Smith generally assumed that the supply price was fixed but that its \"merit\" (value) would decrease as its \"scarcity\" increased, in effect what was later called the law of demand also. Ricardo, in \"Principles of Political Economy and Taxation\", more rigorously laid down the idea of the assumptions that were used to build his ideas of supply and demand. Antoine Augustin Cournot first developed a mathematical model of supply and demand in his 1838 \"Researches into the Mathematical Principles of Wealth\", including diagrams.\n\nDuring the late 19th century the marginalist school of thought emerged. The main innovators of this approach where Stanley Jevons, Carl Menger, and Léon Walras. The key idea was that the price was set by the subjective value of a good at the margin. This was a substantial change from Adam Smith's thoughts on determining the supply price.\n\nIn his 1870 essay \"On the Graphical Representation of Supply and Demand\", Fleeming Jenkin in the course of \"introduc[ing] the diagrammatic method into the English economic literature\" published the first drawing of supply and demand curves in English, including comparative statics from a shift of supply or demand and application to the labor market. The model was further developed and popularized by Alfred Marshall in the 1890 textbook \"Principles of Economics\".\n\nMuch of the buying and selling are now conducted online using platforms such as Amazon and eBay, where the profiles of the customers are captured and analyzed. Tshilidzi Marwala and Evan Hurwitz in their book observed that the advent of artificial intelligence and related technologies such as flexible manufacturing offers the opportunity for individualized demand and supply curves to be generated. This has been found to reduce the degree of arbitrage in the market, allow for individualized pricing for the same product and brings fairness and efficiency into the market.\n\nThe philosopher Hans Albert has argued that the ceteris paribus conditions of the marginalist theory rendered the theory itself an empty tautology and completely closed to experimental testing. In essence, he argues, the supply and demand curves (theoretical functions which express the quantity of a product which would be offered or requested for a given price) are purely ontological.\n\nCambridge economist Joan Robinson attacked the theory in similar line, arguing that the concept is circular: \"Utility is the quality in commodities that makes individuals want to buy them, and the fact that individuals want to buy commodities shows that they have utility\" Robinson also pointed out that if we take changes in peoples' behavior in relation to a change in prices or a change in the underlying budget constraint, then we can never be sure to what extent the change in behavior was due to the change in price or budget constraint and how much was due to a change in preferences.\n\nPiero Sraffa's critique focused on the inconsistency (except in implausible circumstances) of partial equilibrium analysis and the rationale for the upward slope of the supply curve in a market for a produced consumption good. The notability of Sraffa's critique is also demonstrated by Paul Samuelson's comments and engagements with it over many years, for example:\n\nSome economists criticize the conventional supply and demand theory for failing to explain or anticipate asset bubbles that can arise from a positive feedback loop. Conventional supply and demand theory assumes that expectations of consumers do not change as a consequence of price changes. In scenarios such as the United States housing bubble, an initial price change of an asset can increase the expectations of investors, making the asset more lucrative and contributing to further price increases until market sentiment changes, which creates a positive feedback loop and an asset bubble. Asset bubbles cannot be understood in the conventional supply and demand framework because the conventional system assumes a price change will be self-correcting and the system will snap back to equilibrium.\n\n\n"}
{"id": "6639133", "url": "https://en.wikipedia.org/wiki?curid=6639133", "title": "Economy", "text": "Economy\n\nAn economy (from Greek οίκος – \"household\" and νέμoμαι – \"manage\") is an area of the production, distribution and trade, as well as consumption of goods and services by different agents. Understood in its broadest sense, 'The economy is defined as a social domain that emphasize the practices, discourses, and material expressions associated with the production, use, and management of resources'. Economic agents can be individuals, businesses, organizations, or governments. Economic transactions occur when two groups or parties agree to the value or price of the transacted good or service, commonly expressed in a certain currency. However, monetary transactions only account for a small part of the economic domain. Economic activity is spurred by production which uses natural resources, labor and capital. It has changed over time due to technology (automation, accelerator of process, reduction of cost functions), innovation (new products, services, processes, expanding markets, diversification of markets, niche markets, increases revenue functions) such as, that which produces intellectual property and changes in industrial relations (most notably child labor being replaced in some parts of the world with universal access to education). A given economy is the result of a set of processes that involves its culture, values, education, technological evolution, history, social organization, political structure and legal systems, as well as its geography, natural resource endowment, and ecology, as main factors. These factors give context, content, and set the conditions and parameters in which an economy functions. In other words, the economic domain is a social domain of human practices and transactions. It does not stand alone.\n\nA market-based economy is one where goods and services are produced and exchanged according to demand and supply between participants (economic agents) by barter or a medium of exchange with a credit or debit value accepted within the network, such as a unit of currency. A command-based economy is one where political agents directly control what is produced and how it is sold and distributed. A green economy is low-carbon, resource efficient and socially inclusive. In a green economy, growth in income and employment is driven by public and private investments that reduce carbon emissions and pollution, enhance energy and resource efficiency, and prevent the loss of biodiversity and ecosystem services. A gig economy is one in which short-term jobs are assigned or chosen via online platforms. New economy is a term referred to the whole emerging ecosystem where new standards and practices were introduced, usually as a result of technological innovations.\n\nToday the range of fields of study examining the economy revolves around the social science of economics, but may include sociology (economic sociology), history (economic history), anthropology (economic anthropology), and geography (economic geography). Practical fields directly related to the human activities involving production, distribution, exchange, and consumption of goods and services as a whole are engineering, management, business administration, applied science, and finance.\n\nAll professions, occupations, economic agents or economic activities, contribute to the economy. Consumption, saving, and investment are variable components in the economy that determine macroeconomic equilibrium. There are three main sectors of economic activity: primary, secondary, and tertiary.\n\nDue to the growing importance of the economical sector in modern times, the term \"real economy\" is used by analysts as well as politicians to denote the part of the economy that is concerned with the actual production of goods and services, as ostensibly contrasted with the \"paper economy\", or the financial side of the economy, which is concerned with buying and selling on the financial markets. Alternate and long-standing terminology distinguishes measures of an economy expressed in real values (adjusted for inflation), such as real GDP, or in nominal values (unadjusted for inflation).\n\nThe English words \"economy\" and \"economics\" can be traced back to the Greek word (i.e. \"household management\"), a composite word derived from (\"house;household;home\") and νέμω (\"manage; distribute;to deal out;dispense\") by way of (\"household management\").\n\nThe first recorded sense of the word \"economy\" is in the phrase \"the management of œconomic affairs\", found in a work possibly composed in a monastery in 1440. \"Economy\" is later recorded in more general senses, including \"thrift\" and \"administration\".\n\nThe most frequently used current sense, denoting \"the economic system of a country or an area\", seems not to have developed until the 1650s.\n\nAs long as someone has been making, supplying and distributing goods or services, there has been some sort of economy; economies grew larger as societies grew and became more complex. Sumer developed a large-scale economy based on commodity money, while the Babylonians and their neighboring city states later developed the earliest system of economics as we think of, in terms of rules/laws on debt, legal contracts and law codes relating to business practices, and private property.\n\nThe Babylonians and their city state neighbors developed forms of economics comparable to currently used civil society (law) concepts. They developed the first known codified legal and administrative systems, complete with courts, jails, and government records.\n\nThe ancient economy was mainly based on subsistence farming. The Shekel referred to an ancient unit of weight and currency. The first usage of the term came from Mesopotamia circa 3000 BC., and referred to a specific mass of barley which related other values in a metric such as silver, bronze, copper etc. A barley/shekel was originally both a unit of currency and a unit of weight, just as the British Pound was originally a unit denominating a one-pound mass of silver.\n\nFor most people, the exchange of goods occurred through social relationships. There were also traders who bartered in the marketplaces. In Ancient Greece, where the present English word 'economy' originated, many people were bond slaves of the freeholders. The economic discussion was driven by scarcity.\n\nIn Medieval times, what we now call economy was not far from the subsistence level. Most exchange occurred within social groups. On top of this, the great conquerors raised what we now call venture capital (from \"ventura\", ital.; \"risk\") to finance their captures. The capital should be refunded by the goods they would bring up in the New World. The discoveries of Marco Polo (1254–1324), Christopher Columbus (1451–1506) and Vasco da Gama (1469–1524) led to a first global economy. The first enterprises were trading establishments. In 1513, the first stock exchange was founded in Antwerpen. Economy at the time meant primarily trade.\n\nThe European captures became branches of the European states, the so-called colonies. The rising nation-states Spain, Portugal, France, Great Britain and the Netherlands tried to control the trade through custom duties and (from \"mercator\", lat.: merchant) was a first approach to intermediate between private wealth and public interest.\nThe secularization in Europe allowed states to use the immense property of the church for the development of towns. The influence of the nobles decreased. The first Secretaries of State for economy started their work. Bankers like Amschel Mayer Rothschild (1773–1855) started to finance national projects such as wars and infrastructure. Economy from then on meant national economy as a topic for the economic activities of the citizens of a state.\n\nThe first economist in the true modern meaning of the word was the Scotsman Adam Smith (1723–1790) who was inspired partly by the ideas of physiocracy, a reaction to mercantilism and also later Economics student, Adam Mari. He defined the elements of a national economy: products are offered at a natural price generated by the use of competition - supply and demand - and the division of labor. He maintained that the basic motive for free trade is human self-interest. The so-called self-interest hypothesis became the anthropological basis for economics. Thomas Malthus (1766–1834) transferred the idea of supply and demand to the problem of overpopulation.\n\nThe Industrial Revolution was a period from the 18th to the 19th century where major changes in agriculture, manufacturing, mining, and transport had a profound effect on the socioeconomic and cultural conditions starting in the United Kingdom, then subsequently spreading throughout Europe, North America, and eventually the world. The onset of the Industrial Revolution marked a major turning point in human history; almost every aspect of daily life was eventually influenced in some way.\nIn Europe wild capitalism started to replace the system of mercantilism (today: protectionism) and led to economic growth. The period today is called industrial revolution because the system of Production, production and division of labor enabled the mass production of goods.\n\nThe contemporary concept of \"the economy\" wasn't popularly known until the American Great Depression in the 1930s.\n\nAfter the chaos of two World Wars and the devastating Great Depression, policymakers searched for new ways of controlling the course of the economy. This was explored and discussed by Friedrich August von Hayek (1899–1992) and Milton Friedman (1912–2006) who pleaded for a global free trade and are supposed to be the fathers of the so-called neoliberalism. However, the prevailing view was that held by John Maynard Keynes (1883–1946), who argued for a stronger control of the markets by the state. The theory that the state can alleviate economic problems and instigate economic growth through state manipulation of aggregate demand is called Keynesianism in his honor. In the late 1950s, the economic growth in America and Europe—often called Wirtschaftswunder (ger: \"economic miracle\") —brought up a new form of economy: mass consumption economy. In 1958, John Kenneth Galbraith (1908–2006) was the first to speak of an affluent society. In most of the countries the economic system is called a social market economy.\n\nWith the fall of the Iron Curtain and the transition of the countries of the Eastern Bloc towards democratic government and market economies, the idea of the post-industrial society is brought into importance as its role is to mark together the significance that the service sector receives instead of industrialization. Some attribute the first use of this term to Daniel Bell's 1973 book, \"The Coming of Post-Industrial Society\", while others attribute it to social philosopher Ivan Illich's book, \"Tools for Conviviality\". The term is also applied in philosophy to designate the fading of postmodernism in the late 90s and especially in the beginning of the 21st century.\n\nWith the spread of Internet as a mass media and communication medium especially after 2000-2001, the idea for the Internet and information economy is given place because of the growing importance of e-commerce and electronic businesses, also the term for a global information society as understanding of a new type of \"all-connected\" society is created. In the late 2000s, the new type of economies and economic expansions of countries like China, Brazil, and India bring attention and interest to different from the usually dominating Western type economies and economic models.\n\nThe economy may be considered as having developed through the following phases or degrees of precedence.\n\nIn modern economies, these phase precedences are somewhat differently expressed by the three-sector theory. \n\nOther sectors of the developed community include :\n\n\nThere are a number of concepts associated with the economy, such as these:\n\nThe GDP (gross domestic product) of a country is a measure of the size of its economy. The most conventional economic analysis of a country relies heavily on economic indicators like the GDP and GDP per capita. While often useful, GDP only includes economic activity for which money is exchanged.\n\nAn informal economy is economic activity that is neither taxed nor monitored by a government, contrasted with a formal economy. The informal economy is thus not included in that government's gross national product (GNP). Although the informal economy is often associated with developing countries, all economic systems contain an informal economy in some proportion.\n\nInformal economic activity is a dynamic process which includes many aspects of economic and social theory including exchange, regulation, and enforcement. By its nature, it is necessarily difficult to observe, study, define, and measure. No single source readily or authoritatively defines informal economy as a unit of study.\n\nThe terms \"underground\", \"under the table\" and \"off the books\" typically refer to this type of economy. The term black market refers to a specific subset of the informal economy. The term \"informal sector\" was used in many earlier studies, and has been mostly replaced in more recent studies which use the newer term.\n\nThe informal sector makes up a significant portion of the economies in developing countries but it is often stigmatized as troublesome and unmanageable. However the informal sector provides critical economic opportunities for the poor and has been expanding rapidly since the 1960s. As such, integrating the informal economy into the formal sector is an important policy challenge.\n\nEconomic research is conducted in fields as different as economics, economic sociology, economic anthropology, and economic history.\n\n\n"}
{"id": "2593", "url": "https://en.wikipedia.org/wiki?curid=2593", "title": "Accounting", "text": "Accounting\n\nAccounting or accountancy is the measurement, processing, and communication of financial and non financial information about economic entities such as businesses and corporations. Accounting, which has been called the \"language of business\", measures the results of an organization's economic activities and conveys this information to a variety of users, including investors, creditors, management, and regulators. Practitioners of accounting are known as accountants. The terms \"accounting\" and \"financial reporting\" are often used as synonyms.\n\nAccounting can be divided into several fields including financial accounting, management accounting, external auditing, tax accounting and cost accounting. Accounting information systems are designed to support accounting functions and related activities. Financial accounting focuses on the reporting of an organization's financial information, including the preparation of financial statements, to the external users of the information, such as investors, regulators and suppliers; and management accounting focuses on the measurement, analysis and reporting of information for internal use by management. The recording of financial transactions, so that summaries of the financials may be presented in financial reports, is known as bookkeeping, of which double-entry bookkeeping is the most common system.\n\nAlthough accounting has existed in various forms and levels sophistication throughout many human societies, the double-entry accounting system in use today was developed in medieval Europe, particularly in Venice, and is usually attributed to the Italian mathematician and Franciscan friar Luca Pacioli. Today, accounting is facilitated by such as standard-setters, accounting firms and professional bodies. Financial statements are usually audited by accounting firms, and are prepared in accordance with generally accepted accounting principles (GAAP). GAAP is set by various standard-setting organizations such as the Financial Accounting Standards Board (FASB) in the United States and the Financial Reporting Council in the United Kingdom. As of 2012, \"all major economies\" have plans to converge towards or adopt the International Financial Reporting Standards (IFRS).\n\nThe history of accounting is thousands of years old and can be traced to ancient civilizations. The early development of accounting dates back to ancient Mesopotamia, and is closely related to developments in writing, counting and money; there is also evidence of early forms of bookkeeping in ancient Iran, and early auditing systems by the ancient Egyptians and Babylonians. By the time of Emperor Augustus, the Roman government had access to detailed financial information.\n\nDouble-entry bookkeeping was pioneered in the Jewish community of the early-medieval Middle East and was further refined in medieval Europe. With the development of joint-stock companies, accounting split into financial accounting and management accounting. \n\nThe first work on a double-entry bookkeeping system was published in Italy, by Luca Pacioli (\"Father of Accounting\"). Accounting began to transition into an organized profession in the nineteenth century, with local professional bodies in England merging to form the Institute of Chartered Accountants in England and Wales in 1880.\n\nBoth the words accounting and accountancy were in use in Great Britain by the mid-1800s, and are derived from the words \"accompting\" and \"accountantship\" used in the 18th century. In Middle English (used roughly between the 12th and the late 15th century) the verb \"to account\" had the form \"accounten\", which was derived from the Old French word \"aconter\", which is in turn related to the Vulgar Latin word \"computare\", meaning \"to reckon\". The base of \"computare\" is \"putare\", which \"variously meant to prune, to purify, to correct an account, hence, to count or calculate, as well as to think.\"\n\nThe word \"accountant\" is derived from the French word , which is also derived from the Italian and Latin word . The word was formerly written in English as \"accomptant\", but in process of time the word, which was always pronounced by dropping the \"p\", became gradually changed both in pronunciation and in orthography to its present form.\n\nAccounting has variously been defined as the keeping or preparation of the financial records of an entity, the analysis, verification and reporting of such records and \"the principles and procedures of accounting\"; it also refers to the job of being an accountant.\n\nAccountancy refers to the occupation or profession of an accountant, particularly in British English.\n\nAccounting has several subfields or subject areas, including financial accounting, management accounting, auditing, taxation and accounting information systems.\n\nFinancial accounting focuses on the reporting of an organization's financial information to external users of the information, such as investors, potential investors and creditors. It calculates and records business transactions and prepares financial statements for the external users in accordance with generally accepted accounting principles (GAAP). GAAP, in turn, arises from the wide agreement between accounting theory and practice, and change over time to meet the needs of decision-makers.\n\nFinancial accounting produces past-oriented reports—for example the financial statements prepared in 2006 reports on performance in 2005—on an annual or quarterly basis, generally about the organization as a whole.\n\nThis branch of accounting is also studied as part of the board exams for qualifying as an actuary. These two types of professionals, accountants and actuaries, have created a culture of being archrivals.\n\nManagement accounting focuses on the measurement, analysis and reporting of information that can help managers in making decisions to fulfill the goals of an organization. In management accounting, internal measures and reports are based on cost-benefit analysis, and are not required to follow the generally accepted accounting principle (GAAP). In 2014 CIMA created the Global Management Accounting Principles (GMAPs). The result of research from across 20 countries in five continents, the principles aim to guide best practice in the discipline.\n\nManagement accounting produces future-oriented reports—for example the budget for 2006 is prepared in 2005—and the time span of reports varies widely. Such reports may include both financial and non financial information, and may, for example, focus on specific products and departments.\n\nAuditing is the verification of assertions made by others regarding a payoff, and in the context of accounting it is the \"unbiased examination and evaluation of the financial statements of an organization\". Audit is a professional service that is systematic and conventional.\nAn audit of financial statements aims to express or disclaim an opinion on the financial statements. The auditor expresses an opinion on the fairness with which the financial statements presents the financial position, results of operations, and cash flows of an entity, in accordance with the generally acceptable accounting principle (GAAP) and \"in all material respects\". An auditor is also required to identify circumstances in which the generally acceptable accounting principles (GAAP) has not been consistently observed.\n\nAn accounting information system is a part of an organization's information system that focuses on processing accounting data.\nMany corporations use artificial intelligence-based information systems. Banking and finance industry is using AI as fraud detection. Retail industry is using AI for customer services. AI is also used in cybersecurity industry. It involves computer hardware and software systems and using statistics and modeling.\n\nTax accounting in the United States concentrates on the preparation, analysis and presentation of tax payments and tax returns. The U.S. tax system requires the use of specialised accounting principles for tax purposes which can differ from the generally accepted accounting principles (GAAP) for financial reporting. U.S. tax law covers four basic forms of business ownership: sole proprietorship, partnership, corporation, and limited liability company. Corporate and personal income are taxed at different rates, both varying according to income levels and including varying marginal rates (taxed on each additional dollar of income) and average rates (set as a percentage of overall income).\n\nForensic accounting is a specialty practice area of accounting that describes engagements that result from actual or anticipated disputes or litigation. \"Forensic\" means \"suitable for use in a court of law,\" and it is to that standard and potential outcome that forensic accountants generally have to work.\n\nProfessional accounting bodies include the American Institute of Certified Public Accountants (AICPA) and the other 179 members of the International Federation of Accountants (IFAC), including Institute of Chartered Accountants of Scotland (ICAS), CPA Australia, Association of Chartered Certified Accountants (ACCA) and Institute of Chartered Accountants in England and Wales (ICAEW). Professional bodies for subfields of the accounting professions also exist, for example the Chartered Institute of Management Accountants (CIMA) in the UK and Institute of management accountants in the United States. Many of these professional bodies offer education and training including qualification and administration for various accounting designations, such as certified public accountant (AICPA) and chartered accountant.\n\nDepending on its size, a company may be legally required to have their financial statements audited by a qualified auditor, and audits are usually carried out by accounting firms.\n\nAccounting firms grew in the United States and Europe in the late nineteenth and early twentieth century, and through several mergers there were large international accounting firms by the mid-twentieth century. Further large mergers in the late twentieth century led to the dominance of the auditing market by the \"Big Five\" accounting firms: Arthur Andersen, Deloitte, Ernst & Young, KPMG and PricewaterhouseCoopers. The demise of Arthur Andersen following the Enron scandal reduced the Big Five to the Big Four.\n\nGenerally accepted accounting principles (GAAP) are accounting standards issued by national regulatory bodies. In addition, the International Accounting Standards Board (IASB) issues the International Financial Reporting Standards (IFRS) implemented by 147 countries. While standards for international audit and assurance, ethics, education, and public sector accounting are all set by independent standard settings boards supported by IFAC. The International Auditing and Assurance Standards Board sets international standards for auditing, assurance, and quality control; the International Ethics Standards Board for Accountants (IESBA) sets the internationally appropriate principles- based \"Code of Ethics for Professional Accounts\" the International Accounting Education Standards Board (IAESB) sets professional accounting education standards; International Public Sector Accounting Standards Board (IPSASB) sets accrual-based international public sector accounting standards \n\nOrganizations in individual countries may issue accounting standards unique to the countries. For example, in the United States the Financial Accounting Standards Board (FASB) issues the Statements of Financial Accounting Standards, which form the basis of US GAAP, and in the United Kingdom the Financial Reporting Council (FRC) sets accounting standards. However, as of 2012 \"all major economies\" have plans to converge towards or adopt the IFRS.\n\nAt least a bachelor's degree in accounting or a related field is required for most accountant and auditor job positions, and some employers prefer applicants with a master's degree. A degree in accounting may also be required for, or may be used to fulfill the requirements for, membership to professional accounting bodies. For example, the education during an accounting degree can be used to fulfill the American Institute of CPA's (AICPA) 150 semester hour requirement, and associate membership with the Certified Public Accountants Association of the UK is available after gaining a degree in finance or accounting.\n\nA doctorate is required in order to pursue a career in accounting academia, for example to work as a university professor in accounting. The Doctor of Philosophy (PhD) and the Doctor of Business Administration (DBA) are the most popular degrees. The PhD is the most common degree for those wishing to pursue a career in academia, while DBA programs generally focus on equipping business executives for business or public careers requiring research skills and qualifications.\n\nProfessional accounting qualifications include the Chartered Accountant designations and other qualifications including certificates and diplomas. In Scotland, chartered accountants of ICAS undergo Continuous Professional Development and abide by the ICAS code of ethics. In England and Wales, chartered accountants of the ICAEW undergo annual training, and are bound by the ICAEW's code of ethics and subject to its disciplinary procedures. In the United States, the requirements for joining the AICPA as a Certified Public Accountant are set by the Board of Accountancy of each state, and members agree to abide by the AICPA's Code of Professional Conduct and Bylaws. The ACCA is the largest global accountancy body with over 320,000 members and the organisation provides an ‘IFRS stream’ and a ‘UK stream’. Students must pass a total of 14 exams, which are arranged across three papers.\n\nAccounting research is research in the effects of economic events on the process of accounting, the effects of reported information on economic events, and the roles of accounting in organizations and society.. It encompasses a broad range of research areas including financial accounting, management accounting, auditing and taxation.\n\nAccounting research is carried out both by academic researchers and practicing accountants. Methodologies in academic accounting research include archival research, which examines \"objective data collected from repositories\"; experimental research, which examines data \"the researcher gathered by administering treatments to subjects\"; analytical research, which is \"based on the act of formally modeling theories or substantiating ideas in mathematical terms\"; interpretive research, which emphasizes the role of language, interpretation and understanding in accounting practice, \"highlighting the symbolic structures and taken-for-granted themes which pattern the world in distinct ways\"; critical research, which emphasizes the role of power and conflict in accounting practice; case studies; computer simulation; and field research.\n\nEmpirical studies document that leading accounting journals publish in total fewer research articles than comparable journals in economics and other business disciplines, and consequently, accounting scholars are relatively less successful in academic publishing than their business school peers. Due to different publication rates between accounting and other business disciplines, a recent study based on academic author rankings concludes that the competitive value of a single publication in a top-ranked journal is highest in accounting and lowest in marketing.\n\nMany accounting practices have been simplified with the help of accounting computer-based software. An Enterprise resource planning (ERP) system is commonly used for a large organisation and it provides a comprehensive, centralized, integrated source of information that companies can use to manage all major business processes, from purchasing to manufacturing to human resources.\n\nAccounting information systems have reduced the cost of accumulating, storing, and reporting managerial accounting information and have made it possible to produce a more detailed account of all data that is entered into any given system.\n\nThe year 2001 witnessed a series of financial information frauds involving Enron, auditing firm Arthur Andersen, the telecommunications company WorldCom, Qwest and Sunbeam, among other well-known corporations. These problems highlighted the need to review the effectiveness of accounting standards, auditing regulations and corporate governance principles. In some cases, management manipulated the figures shown in financial reports to indicate a better economic performance. In others, tax and regulatory incentives encouraged over-leveraging of companies and decisions to bear extraordinary and unjustified risk.\n\nThe Enron scandal deeply influenced the development of new regulations to improve the reliability of financial reporting, and increased public awareness about the importance of having accounting standards that show the financial reality of companies and the objectivity and independence of auditing firms.\n\nIn addition to being the largest bankruptcy reorganization in American history, the Enron scandal undoubtedly is the biggest audit failure. It involved a financial scandal of Enron Corporation and their auditors Arthur Andersen, which was revealed in late 2001. The scandal caused the dissolution of Arthur Andersen, which at the time was one of the five largest accounting firms in the world. After a series of revelations involving irregular accounting procedures conducted throughout the 1990s, Enron filed for Chapter 11 bankruptcy protection in December 2001.\n\nOne consequence of these events was the passage of Sarbanes–Oxley Act in the United States 2002, as a result of the first admissions of fraudulent behavior made by Enron. The act significantly raises criminal penalties for securities fraud, for destroying, altering or fabricating records in federal investigations or any scheme or attempt to defraud shareholders.\n\nAn accounting error is an unintentional error in an accounting entry, often immediately fixed when spotted. An accounting error should not be confused with fraud, which is an intentional act to hide or alter entries.\n\n\n"}
{"id": "181293", "url": "https://en.wikipedia.org/wiki?curid=181293", "title": "Capital (economics)", "text": "Capital (economics)\n\nIn economics, capital consists of assets that can enhance one's power to perform economically useful work. For example, in a fundamental sense a stone or an arrow is capital for a hunter-gatherer who can use it as a hunting instrument, while roads are capital for inhabitants of a city.\n\nAdam Smith defines capital as \"that part of man's stock which he expects to afford him revenue\".\n\nCapital goods, real capital, or capital assets are already-produced, durable goods or any non-financial asset that is used in production of goods or services.\n\nCapital is distinct from land (or non-renewable resources) in that capital can be increased by human labor. At any given moment in time, total physical capital may be referred to as the capital stock (which is not to be confused with the capital stock of a business entity).\n\nCapital is an input in the production function. Homes and personal autos are not usually defined as capital but as durable goods because they are not used in a production of saleable goods and services.\n\nIn Marxian political economy, capital is money used to buy something only in order to sell it again to realize a profit. For Marx capital only exists within the process of the economic circuit (represented by M-C-M') —it is wealth that grows out of the process of circulation itself, and for Marx it formed the basis of the economic system of capitalism. In more contemporary schools of economics, this form of capital is generally referred to as \"financial capital\" and is distinguished from \"capital goods\".\n\nClassical and neoclassical economics regard capital as one of the factors of production (alongside the other factors: land and labour). All other inputs to production are called intangibles in classical economics. This includes organization, entrepreneurship, knowledge, goodwill, or management (which some characterize as talent, social capital or instructional capital).\n\nThis is what makes it a factor of production:\n\nThese distinctions of convenience have carried over to contemporary economic theory. There was the further clarification that capital is a stock. As such, its value can be estimated at a point in time. By contrast, investment, as production to be added to the capital stock, is described as taking place over time (\"per year\"), thus a flow.\n\nMarxian economics distinguishes between different forms of capital:\n\nEarlier illustrations often described capital as physical items, such as tools, buildings, and vehicles that are used in the production process. Since at least the 1960s economists have increasingly focused on broader forms of capital. For example, investment in skills and education can be viewed as building up human capital or knowledge capital, and investments in intellectual property can be viewed as building up intellectual capital. These terms lead to certain questions and controversies discussed in those articles.\n\nDetailed classifications of capital that have been used in various theoretical or applied uses generally respect the following division:\n\nSeparate literatures have developed to describe both natural capital and social capital. Such terms reflect a wide consensus that nature and society both function in such a similar manner as traditional industrial infrastructural capital, that it is entirely appropriate to refer to them as different types of capital in themselves. In particular, they can be used in the production of other goods, are not used up immediately in the process of production, and can be enhanced (if not created) by human effort.\n\nThere is also a literature of intellectual capital and intellectual property law. However, this increasingly distinguishes means of capital investment, and collection of potential rewards for patent, copyright (creative or individual capital), and trademark (social trust or social capital) instruments.\n\nEconomist Henry George argued that financial instruments like stocks, bonds, mortgages, promissory notes, or other certificates for transferring wealth is not really capital, because \"Their economic value merely represents the power of one class to appropriate the earnings of another\" and \"their increase or decrease does not affect the sum of wealth in the community\".\n\nSome thinkers, such as Werner Sombart and Max Weber, locate the concept of capital as originating in double-entry bookkeeping, which is thus a foundational innovation in capitalism, Sombart writing in \"Medieval and Modern Commercial Enterprise\" that:\n\nWithin classical economics, Adam Smith (\"Wealth of Nations\", Book II, Chapter 1) distinguished fixed capital from circulating capital. The former designated physical assets not consumed in the production of a product (e.g. machines and storage facilities), while the latter referred to physical assets consumed in the process of production (e.g. raw materials and intermediate products). For an enterprise, both were types of capital.\n\nKarl Marx adds a distinction that is often confused with David Ricardo's. In Marxian theory, variable capital refers to a capitalist's investment in labor-power, seen as the only source of surplus-value. It is called \"variable\" since the amount of value it can produce varies from the amount it consumes, \"i.e.\", it creates new value. On the other hand, constant capital refers to investment in non-human factors of production, such as plant and machinery, which Marx takes to contribute only its own replacement value to the commodities it is used to produce.\n\nInvestment or capital accumulation, in classical economic theory, is the production of increased capital. Investment requires that some goods be produced that are not immediately consumed, but instead used to produce other goods as capital goods. Investment is closely related to saving, though it is not the same. As Keynes pointed out, saving involves not spending all of one's income on current goods or services, while investment refers to spending on a specific type of goods, \"i.e.\", capital goods.\n\nAustrian School economist Eugen Boehm von Bawerk maintained that capital intensity was measured by the roundaboutness of production processes. Since capital is defined by him as being goods of higher-order, or goods used to produce consumer goods, and derived their value from them, being future goods.\n\nHuman development theory describes human capital as being composed of distinct social, imitative and creative elements:\nThis theory is the basis of triple bottom line accounting and is further developed in ecological economics, welfare economics and the various theories of green economics. All of which use a particularly abstract notion of capital in which the requirement of capital being produced like durable goods is effectively removed.\n\nThe Cambridge capital controversy was a dispute between economists at Cambridge, Massachusetts based MIT and University of Cambridge in the UK about the measurement of capital. The Cambridge, UK economists, including Joan Robinson and Piero Sraffa claimed that there is no basis for aggregating the heterogeneous objects that constitute 'capital goods.'\n\nPolitical economists Jonathan Nitzan and Shimshon Bichler have suggested that capital is not a productive entity, but solely financial and that capital values measure the relative power of owners over the broad social processes that bear on profits.\n\n\n\n"}
{"id": "4918223", "url": "https://en.wikipedia.org/wiki?curid=4918223", "title": "Company", "text": "Company\n\nA company, abbreviated as co., is a legal entity made up of an association of people, be they natural, legal, or a mixture of both, for carrying on a commercial or industrial enterprise. Company members share a common purpose, and unite to focus their various talents and organize their collectively available skills or resources to achieve specific, declared goals. Companies take various forms, such as:\n\nA company or association of persons can be created at law as a legal person so that the company in itself can accept limited liability for civil responsibility and taxation incurred as members perform (or fail to discharge) their duty within the publicly declared \"\"birth certificate\"\" or published policy.\n\nCompanies as legal persons may associate and register themselves collectively as other companies – often known as a corporate group. When a company closes, it may need a \"\"death certificate\"\" to avoid further legal obligations.\n\nOne can define a company as an \"artificial person\", invisible, intangible, created by or under law,\nwith a discrete legal personality, perpetual succession, and a common seal. Except for some senior positions, companies remain unaffected by the death, insanity, or insolvency of an individual member.\n\nThe English word \"company\" has its origins in the Old French term \"compagnie\" (first recorded in 1150), meaning a \"society, friendship, intimacy; body of soldiers\", which came from the Late Latin word \"companio\" (\"one who eats bread with you\"), first attested in the \" Lex Salica\" ( 500 CE) as a calque of the Germanic expression \"gahlaibo\" (literally, \"with bread\"), related to Old High German \"galeipo\" (\"companion\") and to Gothic \"gahlaiba\" (\"messmate\").\n\nBy 1303, the word referred to trade guilds.\nUsage of the term \"company\" to mean \"business association\" was first recorded in 1553,\nand the abbreviation \"co.\" dates from 1769.\n\nIn English law and in legal jurisdictions based upon it, a company is a body corporate or corporation company registered under the Companies Acts or under similar legislation.\nCommon forms include:\n\nIn the United Kingdom, a partnership is not legally a company, but may sometimes be referred to informally as a company. It may be referred to as a firm.\n\nIn the United States, a company may be a \"corporation, partnership, association, joint-stock company, trust, fund, or organized group of persons, whether incorporated or not, and (in an official capacity) any receiver, trustee in bankruptcy, or similar official, or liquidating agent, for any of the foregoing\". In the US, a company is not necessarily a corporation.\n\nSee also types of business\n\n\"Less common types of companies are:\"\n\nNote that \"Ltd\" after the company's name signifies a limited company, and \"PLC\" (public limited company) indicates that its shares are widely held.\n\nIn the legal context, the owners of a company are normally referred to as the \"members\". In a company limited or unlimited by shares (formed or incorporated with a share capital), this will be the shareholders. In a company limited by guarantee, this will be the guarantors. Some offshore jurisdictions have created special forms of offshore company in a bid to attract business for their jurisdictions. Examples include \"segregated portfolio companies\" and restricted purpose companies.\n\nThere are, however, many, many sub-categories of types of company that can be formed in various jurisdictions in the world.\n\nCompanies are also sometimes distinguished for legal and regulatory purposes between public companies and private companies. Public companies are companies whose shares can be publicly traded, often (although not always) on a stock exchange which imposes listing requirements/Listing Rules as to the issued shares, the trading of shares and future issue of shares to help bolster the reputation of the exchange or particular market of an exchange. Private companies do not have publicly traded shares, and often contain restrictions on transfers of shares. In some jurisdictions, private companies have maximum numbers of shareholders.\n\nA parent company is a company that owns enough voting stock in another firm to control management and operations by influencing or electing its board of directors; the second company being deemed as a subsidiary of the parent company. The definition of a parent company differs by jurisdiction, with the definition normally being defined by way of laws dealing with companies in that jurisdiction.\n\n\n"}
{"id": "7485", "url": "https://en.wikipedia.org/wiki?curid=7485", "title": "Corporation", "text": "Corporation\n\nA corporation is an organization—usually a group of people or a company—authorized by the state to act as a single entity (a legal entity; a legal person in legal context) and recognized as such in law for certain purposes. Early incorporated entities were established by charter (i.e. by an \"ad hoc\" act granted by a monarch or passed by a parliament or legislature). Most jurisdictions now allow the creation of new corporations through registration.\n\nCorporations come in many different types but are usually divided by the law of the jurisdiction where they are chartered based on two aspects: by whether they can issue stock, or by whether they are formed to make a profit . Corporations can be divided by the number of owners: corporation aggregate or corporation sole. The subject of this article is a corporation aggregate. A corporation sole is a legal entity consisting of a single (\"sole\") incorporated office, occupied by a single (\"sole\") natural person.\n\nWhere local law distinguishes corporations by the ability to issue stock, corporations allowed to do so are referred to as \"stock corporations\", ownership of the corporation is through stock, and owners of stock are referred to as \"stockholders\" or \"shareholders\". Corporations not allowed to issue stock are referred to as \"non-stock\" corporations; those who are considered the owners of a non-stock corporation are persons (or other entities) who have obtained membership in the corporation and are referred to as a \"member\" of the corporation.\n\nCorporations chartered in regions where they are distinguished by whether they are allowed to be for profit are referred to as \"for profit\" and \"not-for-profit\" corporations, respectively.\n\nThere is some overlap between stock/non-stock and for-profit/not-for-profit in that not-for-profit corporations are always non-stock as well. A for-profit corporation is almost always a stock corporation, but some for-profit corporations may choose to be non-stock. To simplify the explanation, whenever \"Stockholder\" or \"shareholder\" is used in the rest of this article to refer to a stock corporation, it is presumed to mean the same as \"member\" for a non-profit corporation or for a profit, non-stock corporation.\n\nRegistered corporations have legal personality and their shares are owned by shareholders whose liability is generally limited to their investment. Shareholders do not typically actively manage a corporation; shareholders instead elect or appoint a board of directors to control the corporation in a fiduciary capacity. In most circumstances, a shareholder may also serve as a director or officer of a corporation.\n\nIn American English, the word \"corporation\" is most often used to describe large business corporations. In British English and in the Commonwealth countries, the term \"company\" is more widely used to describe the same sort of entity while the word \"corporation\" encompasses all incorporated entities. In American English, the word \"company\" can include entities such as partnerships that would not be referred to as companies in British English as they are not a separate legal entity.\n\nLate in the 19th century, a new form of company having the limited liability protections of a corporation, and the more favorable tax treatment of either a sole proprietorship or partnership was developed. While not a corporation, this new type of entity became very attractive as an alternative for corporations not needing to issue stock. In Germany, the organization was referred to as \"Gesellschaft mit beschränkter Haftung\" or \"GmbH\". In the last quarter of the 20th Century this new form of non-corporate organization became available in the United States and other countries, and was known as the \"limited liability company\" or \"LLC\". Since the GmbH and LLC forms of organization are technically not corporations (even though they have many of the same features), they will not be discussed in this article.\n\nThe word \"corporation\" derives from \"corpus\", the Latin word for body, or a \"body of people\". By the time of Justinian (reigned 527–565), Roman law recognized a range of corporate entities under the names \"universitas\", \"corpus\" or \"collegium\". These included the state itself (the \"Populus Romanus\"), municipalities, and such private associations as sponsors of a religious cult, burial clubs, political groups, and guilds of craftsmen or traders. Such bodies commonly had the right to own property and make contracts, to receive gifts and legacies, to sue and be sued, and, in general, to perform legal acts through representatives. Private associations were granted designated privileges and liberties by the emperor.\n\nEntities which carried on business and were the subjects of legal rights were found in ancient Rome, and the Maurya Empire in ancient India. In medieval Europe, churches became incorporated, as did local governments, such as the Pope and the City of London Corporation. The point was that the incorporation would survive longer than the lives of any particular member, existing in perpetuity. The alleged oldest commercial corporation in the world, the Stora Kopparberg mining community in Falun, Sweden, obtained a charter from King Magnus Eriksson in 1347.\n\nIn medieval times, traders would do business through common law constructs, such as partnerships. Whenever people acted together with a view to profit, the law deemed that a partnership arose. Early guilds and livery companies were also often involved in the regulation of competition between traders.\n\nDutch and English chartered companies, such as the Dutch East India Company (VOC) and the Hudson's Bay Company, were created to lead the colonial ventures of European nations in the 17th century. Acting under a charter sanctioned by the Dutch government, the Dutch East India Company defeated Portuguese forces and established itself in the Moluccan Islands in order to profit from the European demand for spices. Investors in the VOC were issued paper certificates as proof of share ownership, and were able to trade their shares on the original Amsterdam Stock Exchange. Shareholders were also explicitly granted limited liability in the company's royal charter.\n\nIn England, the government created corporations under a royal charter or an Act of Parliament with the grant of a monopoly over a specified territory. The best-known example, established in 1600, was the East India Company of London. Queen Elizabeth I granted it the exclusive right to trade with all countries to the east of the Cape of Good Hope. Some corporations at this time would act on the government's behalf, bringing in revenue from its exploits abroad. Subsequently, the Company became increasingly integrated with English and later British military and colonial policy, just as most corporations were essentially dependent on the Royal Navy's ability to control trade routes.\n\nLabeled by both contemporaries and historians as \"the grandest society of merchants in the universe\", the English East India Company would come to symbolize the dazzlingly rich potential of the corporation, as well as new methods of business that could be both brutal and exploitative. On 31 December 1600, Queen Elizabeth I granted the company a 15-year monopoly on trade to and from the East Indies and Africa. By 1711, shareholders in the East India Company were earning a return on their investment of almost 150 per cent. Subsequent stock offerings demonstrated just how lucrative the Company had become. Its first stock offering in 1713–1716 raised £418,000, its second in 1717–1722 raised £1.6 million.\n\nA similar chartered company, the South Sea Company, was established in 1711 to trade in the Spanish South American colonies, but met with less success. The South Sea Company's monopoly rights were supposedly backed by the Treaty of Utrecht, signed in 1713 as a settlement following the War of the Spanish Succession, which gave Great Britain an \"asiento\" to trade in the region for thirty years. In fact the Spanish remained hostile and let only one ship a year enter. Unaware of the problems, investors in Britain, enticed by extravagant promises of profit from company promoters bought thousands of shares. By 1717, the South Sea Company was so wealthy (still having done no real business) that it assumed the public debt of the British government. This accelerated the inflation of the share price further, as did the Bubble Act 1720, which (possibly with the motive of protecting the South Sea Company from competition) prohibited the establishment of any companies without a Royal Charter. The share price rose so rapidly that people began buying shares merely in order to sell them at a higher price, which in turn led to higher share prices. This was the first speculative bubble the country had seen, but by the end of 1720, the bubble had \"burst\", and the share price sank from £1000 to under £100. As bankruptcies and recriminations ricocheted through government and high society, the mood against corporations and errant directors was bitter.\nIn the late 18th century, Stewart Kyd, the author of the first treatise on corporate law in English, defined a corporation as:\n\nDue to the late 18th century abandonment of mercantilist economic theory and the rise of classical liberalism and laissez-faire economic theory due to a revolution in economics led by Adam Smith and other economists, corporations transitioned from being government or guild affiliated entities to being public and private economic entities free of governmental directions. Smith wrote in his 1776 work \"The Wealth of Nations\" that mass corporate activity could not match private entrepreneurship, because people in charge of others' money would not exercise as much care as they would with their own.\n\nThe British Bubble Act 1720's prohibition on establishing companies remained in force until its repeal in 1825. By this point, the Industrial Revolution had gathered pace, pressing for legal change to facilitate business activity. The repeal was the beginning of a gradual lifting on restrictions, though business ventures (such as those chronicled by Charles Dickens in \"Martin Chuzzlewit\") under primitive companies legislation were often scams. Without cohesive regulation, proverbial operations like the \"Anglo-Bengalee Disinterested Loan and Life Assurance Company\" were undercapitalised ventures promising no hope of success except for richly paid promoters.\n\nThe process of incorporation was possible only through a royal charter or a private act and was limited, owing to Parliament's jealous protection of the privileges and advantages thereby granted. As a result, many businesses came to be operated as unincorporated associations with possibly thousands of members. Any consequent litigation had to be carried out in the joint names of all the members and was almost impossibly cumbersome. Though Parliament would sometimes grant a private act to allow an individual to represent the whole in legal proceedings, this was a narrow and necessarily costly expedient, allowed only to established companies.\n\nThen, in 1843, William Gladstone became the chairman of a Parliamentary Committee on Joint Stock Companies, which led to the Joint Stock Companies Act 1844, regarded as the first modern piece of company law. The Act created the Registrar of Joint Stock Companies, empowered to register companies by a two-stage process. The first, provisional, stage cost £5 and did not confer corporate status, which arose after completing the second stage for another £5. For the first time in history, it was possible for ordinary people through a simple registration procedure to incorporate. The advantage of establishing a company as a separate legal person was mainly administrative, as a unified entity under which the rights and duties of all investors and managers could be channeled.\n\nHowever, there was still no limited liability and company members could still be held responsible for unlimited losses by the company. The next, crucial development, then, was the Limited Liability Act 1855, passed at the behest of the then Vice President of the Board of Trade, Mr. Robert Lowe. This allowed investors to limit their liability in the event of business failure to the amount they invested in the company – shareholders were still liable directly to creditors, but just for the unpaid portion of their shares. (The principle that shareholders are liable to the corporation had been introduced in the Joint Stock Companies Act 1844).\n\nThe 1855 Act allowed limited liability to companies of more than 25 members (shareholders). Insurance companies were excluded from the act, though it was standard practice for insurance contracts to exclude action against individual members. Limited liability for insurance companies was allowed by the Companies Act 1862.\n\nThis prompted the English periodical \"The Economist\" to write in 1855 that \"never, perhaps, was a change so vehemently and generally demanded, of which the importance was so much overrated.\" The major error of this judgment was recognised by the same magazine more than 70 years later, when it claimed that, \"[t]he economic historian of the future... may be inclined to assign to the nameless inventor of the principle of limited liability, as applied to trading corporations, a place of honour with Watt and Stephenson, and other pioneers of the Industrial Revolution. \"\n\nThese two features – a simple registration procedure and limited liability – were subsequently codified into the landmark 1856 Joint Stock Companies Act. This was subsequently consolidated with a number of other statutes in the Companies Act 1862, which remained in force for the rest of the century, up to and including the time of the decision in \"Salomon v A Salomon & Co Ltd\".\n\nThe legislation shortly gave way to a railway boom, and from then, the numbers of companies formed soared. In the later nineteenth century, depression took hold, and just as company numbers had boomed, many began to implode and fall into insolvency. Much strong academic, legislative and judicial opinion was opposed to the notion that businessmen could escape accountability for their role in the failing businesses.\n\nIn 1892, Germany introduced the Gesellschaft mit beschränkter Haftung with a separate legal personality and limited liability even if all the shares of the company were held by only one person. This inspired other countries to introduce corporations of this kind.\n\nThe last significant development in the history of companies was the 1897 decision of the House of Lords in \"Salomon v. Salomon & Co.\" where the House of Lords confirmed the separate legal personality of the company, and that the liabilities of the company were separate and distinct from those of its owners.\n\nIn the United States, forming a corporation usually required an act of legislation until the late 19th century. Many private firms, such as Carnegie's steel company and Rockefeller's Standard Oil, avoided the corporate model for this reason (as a trust). State governments began to adopt more permissive corporate laws from the early 19th century, although these were all restrictive in design, often with the intention of preventing corporations from gaining too much wealth and power.\n\nNew Jersey was the first state to adopt an \"enabling\" corporate law, with the goal of attracting more business to the state, in 1896. In 1899, Delaware followed New Jersey's lead with the enactment of an enabling corporate statute, but Delaware only became the leading corporate state after the enabling provisions of the 1896 New Jersey corporate law were repealed in 1913.\n\nThe end of the 19th century saw the emergence of holding companies and corporate mergers creating larger corporations with dispersed shareholders. Countries began enacting antitrust laws to prevent anti-competitive practices and corporations were granted more legal rights and protections.\nThe 20th century saw a proliferation of laws allowing for the creation of corporations by registration across the world, which helped to drive economic booms in many countries before and after World War I. Another major post World War I shift was toward the development of conglomerates, in which large corporations purchased smaller corporations to expand their industrial base.\n\nStarting in the 1980s, many countries with large state-owned corporations moved toward privatization, the selling of publicly owned (or 'nationalised') services and enterprises to corporations. Deregulation (reducing the regulation of corporate activity) often accompanied privatization as part of a laissez-faire policy.\n\nA corporation is, at least in theory, owned and controlled by its members. In a joint-stock company the members are known as shareholders and each of their shares in the ownership, control, and profits of the corporation is determined by the portion of shares in the company that they own. Thus a person who owns a quarter of the shares of a joint-stock company owns a quarter of the company, is entitled to a quarter of the profit (or at least a quarter of the profit given to shareholders as dividends) and has a quarter of the votes capable of being cast at general meetings.\n\nIn another kind of corporation, the legal document which established the corporation or which contains its current rules will determine who the corporation's members are. Who a member is depends on what kind of corporation is involved. In a worker cooperative, the members are people who work for the cooperative. In a credit union, the members are people who have accounts with the credit union.\n\nThe day-to-day activities of a corporation are typically controlled by individuals appointed by the members. In some cases, this will be a single individual but more commonly corporations are controlled by a committee or by committees. Broadly speaking, there are two kinds of committee structure.\n\nHistorically, corporations were created by a charter granted by government. Today, corporations are usually registered with the state, province, or national government and regulated by the laws enacted by that government. Registration is the main prerequisite to the corporation's assumption of limited liability. The law sometimes requires the corporation to designate its principal address, as well as a registered agent (a person or company designated to receive legal service of process). It may also be required to designate an agent or other legal representative of the corporation.\n\nGenerally, a corporation files articles of incorporation with the government, laying out the general nature of the corporation, the amount of stock it is authorized to issue, and the names and addresses of directors. Once the articles are approved, the corporation's directors meet to create bylaws that govern the internal functions of the corporation, such as meeting procedures and officer positions.\n\nThe law of the jurisdiction in which a corporation operates will regulate most of its internal activities, as well as its finances. If a corporation operates outside its home state, it is often required to register with other governments as a foreign corporation, and is almost always subject to laws of its host state pertaining to employment, crimes, contracts, civil actions, and the like.\n\nCorporations generally have a distinct name. Historically, some corporations were named after their membership: for instance, \"The President and Fellows of Harvard College\". Nowadays, corporations in most jurisdictions have a distinct name that does not need to make reference to their membership. In Canada, this possibility is taken to its logical extreme: many smaller Canadian corporations have no names at all, merely numbers based on a registration number (for example, \"12345678 Ontario Limited\"), which is assigned by the provincial or territorial government where the corporation incorporates.\n\nIn most countries, corporate names include a term or an abbreviation that denotes the corporate status of the entity (for example, \"Incorporated\" or \"Inc.\" in the United States) or the limited liability of its members (for example, \"Limited\" or \"Ltd.\"). These terms vary by jurisdiction and language. In some jurisdictions, they are mandatory, and in others they are not. Their use puts everybody on constructive notice that they are dealing with an entity whose liability is limited: one can only collect from whatever assets the entity still controls when one obtains a judgment against it.\n\nSome jurisdictions do not allow the use of the word \"company\" alone to denote corporate status, since the word \"company\" may refer to a partnership or some other form of collective ownership (in the United States it can be used by a sole proprietorship but this is not generally the case elsewhere).\n\nDespite not being individual human beings, corporations, as far as US law is concerned, are legal persons, and have many of the same rights and responsibilities as natural persons do. For example, a corporation can own property, and can sue or be sued. Corporations can exercise human rights against real individuals and the state, and they can themselves be responsible for human rights violations. Corporations can be \"dissolved\" either by statutory operation, order of court, or voluntary action on the part of shareholders. Insolvency may result in a form of corporate failure, when creditors force the liquidation and dissolution of the corporation under court order, but it most often results in a restructuring of corporate holdings. Corporations can even be convicted of criminal offenses, such as fraud and manslaughter. However, corporations are not considered living entities in the way that humans are.\n\n\n"}
{"id": "5665", "url": "https://en.wikipedia.org/wiki?curid=5665", "title": "Currency", "text": "Currency\n\nA currency (from , \"in circulation\", from ), in the most specific sense is money in any form when in use or circulation as a medium of exchange, especially circulating banknotes and coins. A more general definition is that a currency is a \"system of money\" (monetary units) in common use, especially for people in a nation. Under this definition, U.S. dollars (US$), euros (€), Japanese yen (¥), and pounds sterling (£) are examples of currencies. These various currencies are recognized as stores of value and are traded between nations in foreign exchange markets, which determine the relative values of the different currencies. Currencies in this sense are defined by governments, and each type has limited boundaries of acceptance.\n\nOther definitions of the term \"currency\" are discussed in their respective synonymous articles banknote, coin, and money. The latter definition, pertaining to the currency systems of nations, is the topic of this article. Currencies can be classified into two monetary systems: fiat money and commodity money, depending on what guarantees the currency's value (the economy at large vs. the government's physical metal reserves). Some currencies are legal tender in certain political jurisdictions. Others are simply traded for their economic value. Digital currency has arisen with the popularity of computers and the Internet.\n\nOriginally money was a form of receipt, representing grain stored in temple granaries in Sumer in ancient Mesopotamia and later in Ancient Egypt.\n\nIn this first stage of currency, metals were used as symbols to represent value stored in the form of commodities. This formed the basis of trade in the Fertile Crescent for over 1500 years. However, the collapse of the Near Eastern trading system pointed to a flaw: in an era where there was no place that was safe to store value, the value of a circulating medium could only be as sound as the forces that defended that store. A trade could only reach as far as the credibility of that military. By the late Bronze Age, however, a series of treaties had established safe passage for merchants around the Eastern Mediterranean, spreading from Minoan Crete and Mycenae in the northwest to Elam and Bahrain in the southeast. It is not known what was used as a currency for these exchanges, but it is thought that ox-hide shaped ingots of copper, produced in Cyprus, may have functioned as a currency.\n\nIt is thought that the increase in piracy and raiding associated with the Bronze Age collapse, possibly produced by the Peoples of the Sea, brought the trading system of oxhide ingots to an end. It was only the recovery of Phoenician trade in the 10th and 9th centuries BC that led to a return to prosperity, and the appearance of real coinage, possibly first in Anatolia with Croesus of Lydia and subsequently with the Greeks and Persians. In Africa, many forms of value store have been used, including beads, ingots, ivory, various forms of weapons, livestock, the manilla currency, and ochre and other earth oxides. The manilla rings of West Africa were one of the currencies used from the 15th century onwards to sell slaves. African currency is still notable for its variety, and in many places, various forms of barter still apply.\n\nThese factors led to the metal itself being the store of value: first silver, then both silver and gold, and at one point also bronze. Now we have copper coins and other non-precious metals as coins. Metals were mined, weighed, and stamped into coins. This was to assure the individual accepting the coin that he was getting a certain known weight of precious metal. Coins could be counterfeited, but the existence of standard coins also created a new unit of account, which helped lead to banking. Archimedes' principle provided the next link: coins could now be easily tested for their fine weight of metal, and thus the value of a coin could be determined, even if it had been shaved, debased or otherwise tampered with (see Numismatics).\n\nMost major economies using coinage had several tiers of coins of different values, made of copper, silver, and gold. Gold coins were the most valuable and were used for large purchases, payment of the military and backing of state activities. Units of account were often defined as the value of a particular type of gold coin. Silver coins were used for midsized transactions, and sometimes also defined a unit of account, while coins of copper or silver, or some mixture of them (see debasement), might be used for everyday transactions. This system had been used in ancient India since the time of the Mahajanapadas. The exact ratios between the values of the three metals varied greatly between different eras and places; for example, the opening of silver mines in the Harz mountains of central Europe made silver relatively less valuable, as did the flood of New World silver after the Spanish conquests. However, the rarity of gold consistently made it more valuable than silver, and likewise silver was consistently worth more than copper.\n\nIn premodern China, the need for credit and for a medium of exchange that was less physically cumbersome than large numbers of copper coins led to the introduction of paper money, i.e. banknotes. Their introduction was a gradual process which lasted from the late Tang dynasty (618–907) into the Song dynasty (960–1279). It began as a means for merchants to exchange heavy coinage for receipts of deposit issued as promissory notes by wholesalers' shops. These notes were valid for temporary use in a small regional territory. In the 10th century, the Song dynasty government began to circulate these notes amongst the traders in its monopolized salt industry. The Song government granted several shops the right to issue banknotes, and in the early 12th century the government finally took over these shops to produce state-issued currency. Yet the banknotes issued were still only locally and temporarily valid: it was not until the mid 13th century that a standard and uniform government issue of paper money became an acceptable nationwide currency. The already widespread methods of woodblock printing and then Bi Sheng's movable type printing by the 11th century were the impetus for the mass production of paper money in premodern China.\nAt around the same time in the medieval Islamic world, a vigorous monetary economy was created during the 7th–12th centuries on the basis of the expanding levels of circulation of a stable high-value currency (the dinar). Innovations introduced by Muslim economists, traders and merchants include the earliest uses of credit, cheques, promissory notes, savings accounts, transaction accounts, loaning, trusts, exchange rates, the transfer of credit and debt, and banking institutions for loans and deposits.\n\nIn Europe, paper money was first introduced on a regular basis in Sweden in 1661 (although Washington Irving records an earlier emergency use of it, by the Spanish in a siege during the Conquest of Granada). As Sweden was rich in copper, many copper coins were in circulation, but its relatively low value necessitated extraordinarily big coins, often weighing several kilograms.\n\nThe advantages of paper currency were numerous: it reduced the need to transport gold and silver, which was risky; it facilitated loans of gold or silver at interest, since the underlying specie (money in the form of gold or silver coins rather than notes) never left the possession of the lender until someone else redeemed the note; and it allowed a division of currency into credit- and specie-backed forms. It enabled the sale of stock in joint-stock companies and the redemption of those shares in a paper.\n\nBut there were also disadvantages. First, since a note has no intrinsic value, there was nothing to stop issuing authorities from printing more notes than they had specie to back them with. Second, because it increased the money supply, it increased inflationary pressures, a fact observed by David Hume in the 18th century. Thus paper money would often lead to an inflationary bubble, which could collapse if people began demanding hard money, causing the demand for paper notes to fall to zero. The printing of paper money was also associated with wars, and financing of wars, and therefore regarded as part of maintaining a standing army. For these reasons, paper currency was held in suspicion and hostility in Europe and America. It was also addictive since the speculative profits of trade and capital creation were quite large. Major nations established mints to print money and mint coins, and branches of their treasury to collect taxes and hold gold and silver stock.\n\nAt that time, both silver and gold were considered a legal tender and accepted by governments for taxes. However, the instability in the exchange rate between the two grew over the course of the 19th century, with the increases both in the supply of these metals, particularly silver, and in trade. The parallel use of both metals is called bimetallism, and the attempt to create a bimetallic standard where both gold and silver backed currency remained in circulation occupied the efforts of inflationists. Governments at this point could use currency as an instrument of policy, printing paper currency such as the United States greenback, to pay for military expenditures. They could also set the terms at which they would redeem notes for specie, by limiting the amount of purchase, or the minimum amount that could be redeemed.\n\nBy 1900, most of the industrializing nations were on some form of gold standard, with paper notes and silver coins constituting the circulating medium. Private banks and governments across the world followed Gresham's law: keeping the gold and silver they received but paying out in notes. This did not happen all around the world at the same time, but occurred sporadically, generally in times of war or financial crisis, beginning in the early 20th century and continuing across the world until the late 20th century, when the regime of floating fiat currencies came into force. One of the last countries to break away from the gold standard was the United States in 1971, an action known as the Nixon shock. No country has an enforceable gold standard or silver standard currency system.\n\nA banknote (more commonly known as a bill in the United States and Canada) is a type of currency and is commonly used as legal tender in many jurisdictions. Together with coins, banknotes make up the cash form of all money. Banknotes are mostly paper, but Australia's Commonwealth Scientific and Industrial Research Organisation developed a polymer currency in the 1980s; it went into circulation on the nation's bicentenary in 1988. Polymer banknotes had already been introduced in the Isle of Man in 1983. As of 2016, polymer currency is used in over 20 countries (over 40 if counting commemorative issues), and dramatically increases the life span of banknotes and reduces counterfeiting.\n\nThe currency usage is based on the concept of lex monetae; that a sovereign state decides which currency it shall use. The International Organization for Standardization has introduced a system of three-letter codes (ISO 4217) to denote currency (as opposed to simple names or currency signs), in order to remove the confusion arising because there are dozens of currencies called the dollar and several called the franc. Even the \"pound\" is used in nearly a dozen different countries; most of these are tied to the Pound Sterling, while the remainder has varying values. In general, the three-letter code uses the ISO 3166-1 country code for the first two letters and the first letter of the name of the currency (D for dollar, for instance) as the third letter. United States currency, for instance, is globally referred to as USD.\n\nThe International Monetary Fund uses a different system when referring to national currencies.\n\nDistinct from centrally controlled government-issued currencies, private decentralized trust networks support alternative currencies such as Bitcoin, Ethereum, Litecoin, Monero, Peercoin or Dogecoin, which are classified as cryptocurrency since payments made and transfers are untrackable, as well as branded currencies, for example 'obligation' based stores of value, such as quasi-regulated BarterCard, Loyalty Points (Credit Cards, Airlines) or Game-Credits (MMO games) that are based on reputation of commercial products, or highly regulated 'asset-backed' 'alternative currencies' such as mobile-money schemes like MPESA (called E-Money Issuance).\n\nThe currency may be Internet-based and digital, for instance, bitcoin is not tied to any specific country, or the IMF's SDR that is based on a basket of currencies (and assets held).\n\nIn most cases, a central bank has a monopoly right to issue of coins and banknotes (fiat money) for its own area of circulation (a country or group of countries); it regulates the production of currency by banks (credit) through monetary policy.\n\nAn exchange rate is a price at which two currencies can be exchanged against each other. This is used for trade between the two currency zones. Exchange rates can be classified as either floating or fixed. In the former, day-to-day movements in exchange rates are determined by the market; in the latter, governments intervene in the market to buy or sell their currency to balance supply and demand at a static exchange rate.\n\nIn cases where a country has control of its own currency, that control is exercised either by a central bank or by a Ministry of Finance. The institution that has control of monetary policy is referred to as the monetary authority. Monetary authorities have varying degrees of autonomy from the governments that create them. A monetary authority is created and supported by its sponsoring government, so independence can be reduced by the legislative or executive authority that creates it.\n\nSeveral countries can use the same name for their own separate currencies (for example, a \"dollar\" in Australia, Canada, and the United States). By contrast, several countries can also use the same currency (for example, the euro or the CFA franc), or one country can declare the currency of another country to be legal tender. For example, Panama and El Salvador have declared US currency to be legal tender, and from 1791 to 1857, Spanish silver coins were legal tender in the United States. At various times countries have either re-stamped foreign coins or used currency boards, issuing one note of currency for each note of a foreign government held, as Ecuador currently does.\n\nEach currency typically has a main currency unit (the dollar, for example, or the euro) and a fractional unit, often defined as of the main unit: 100 cents = 1 dollar, 100 centimes = 1 franc, 100 pence = 1 pound, although units of or occasionally also occur. Some currencies do not have any smaller units at all, such as the Icelandic króna.\n\nMauritania and Madagascar are the only remaining countries that have theoretical fractional units not based on the decimal system; instead, the Mauritanian ouguiya is in theory divided into 5 khoums, while the Malagasy ariary is theoretically divided into 5 iraimbilanja. In these countries, words like \"dollar\" or \"pound\" \"were simply names for given weights of gold.\" Due to inflation khoums and iraimbilanja have in practice fallen into disuse. (See non-decimal currencies for other historic currencies with non-decimal divisions.)\n\nConvertibility of a currency determines the ability of an individual, corporation or government to convert its local currency to another currency or vice versa with or without central bank/government intervention. Based on the above restrictions or free and readily conversion features, currencies are classified as:\n\nIn economics, a local currency is a currency not backed by a national government and intended to trade only in a small area. Advocates such as Jane Jacobs argue that this enables an economically depressed region to pull itself up, by giving the people living there a medium of exchange that they can use to exchange services and locally produced goods (in a broader sense, this is the original purpose of all money). Opponents of this concept argue that local currency creates a barrier which can interfere with economies of scale and comparative advantage and that in some cases they can serve as a means of tax evasion.\n\nLocal currencies can also come into being when there is economic turmoil involving the national currency. An example of this is the Argentinian economic crisis of 2002 in which IOUs issued by local governments quickly took on some of the characteristics of local currencies.\n\nOne of the best examples of a local currency is the original LETS currency, founded on Vancouver Island in the early 1980s. In 1982, the Canadian Central Bank’s lending rates ran up to 14% which drove chartered bank lending rates as high as 19%. The resulting currency and credit scarcity left island residents with few options other than to create a local currency.\n\nThe following table are estimates of the 15 most frequently used currencies in world payments from 2012 to 2018 by SWIFT.\n\nRelated concepts\n\nAccounting units\n\nLists\n"}
{"id": "9472", "url": "https://en.wikipedia.org/wiki?curid=9472", "title": "Euro", "text": "Euro\n\nThe euro (sign: €; code: EUR) is the official currency of 19 of the member states of the European Union. This group of states is known as the eurozone or euro area, and counts about 343 million citizens . The euro, which is divided into 100 cents, is the second-largest and second-most traded currency in the foreign exchange market after the United States dollar.\n\nThe currency is also used officially by the institutions of the European Union, by four European microstates that are not EU members, as well as unilaterally by Montenegro and Kosovo. Outside Europe, a number of special territories of EU members also use the euro as their currency. Additionally, over 200 million people worldwide use currencies pegged to the euro.\n\nThe euro is the second-largest reserve currency as well as the second-most traded currency in the world after the United States dollar.\n, with more than €1.3 trillion in circulation, the euro has one of the highest combined values of banknotes and coins in circulation in the world.\n\nThe name \"euro\" was officially adopted on 16 December 1995 in Madrid. The euro was introduced to world financial markets as an accounting currency on 1 January 1999, replacing the former European Currency Unit (ECU) at a ratio of 1:1 (US$1.1743). Physical euro coins and banknotes entered into circulation on 1 January 2002, making it the day-to-day operating currency of its original members, and by March 2002 it had completely replaced the former currencies. While the euro dropped subsequently to US$0.83 within two years (26 October 2000), it has traded above the U.S. dollar since the end of 2002, peaking at US$1.60 on 18 July 2008. In late 2009, the euro became immersed in the European sovereign-debt crisis, which led to the creation of the European Financial Stability Facility as well as other reforms aimed at stabilising and strengthening the currency.\n\nThe euro is managed and administered by the Frankfurt-based European Central Bank (ECB) and the Eurosystem (composed of the central banks of the eurozone countries). As an independent central bank, the ECB has sole authority to set monetary policy. The Eurosystem participates in the printing, minting and distribution of notes and coins in all member states, and the operation of the eurozone payment systems.\n\nThe 1992 Maastricht Treaty obliges most EU member states to adopt the euro upon meeting certain monetary and budgetary convergence criteria, although not all states have done so. The United Kingdom and Denmark negotiated exemptions, while Sweden (which joined the EU in 1995, after the Maastricht Treaty was signed) turned down the euro in a non-binding referendum in 2003, and has circumvented the obligation to adopt the euro by not meeting the monetary and budgetary requirements. All nations that have joined the EU since 1993 have pledged to adopt the euro in due course.\n\nSince 1 January 2002, the national central banks (NCBs) and the ECB have issued euro banknotes on a joint basis. Eurosystem NCBs are required to accept euro banknotes put into circulation by other Eurosystem members and these banknotes are not repatriated. The ECB issues 8% of the total value of banknotes issued by the Eurosystem. In practice, the ECB's banknotes are put into circulation by the NCBs, thereby incurring matching liabilities vis-à-vis the ECB. These liabilities carry interest at the main refinancing rate of the ECB. The other 92% of euro banknotes are issued by the NCBs in proportion to their respective shares of the ECB capital key, calculated using national share of European Union (EU) population and national share of EU GDP, equally weighted.\n\nThe euro is divided into 100 cents (also referred to as \"euro cents\", especially when distinguishing them from other currencies, and referred to as such on the common side of all cent coins). In Community legislative acts the plural forms of \"euro\" and \"cent\" are spelled without the \"s\", notwithstanding normal English usage. Otherwise, normal English plurals are used, with many local variations such as \"centime\" in France.\n\nAll circulating coins have a \"common side\" showing the denomination or value, and a map in the background. Due to the linguistic plurality in the European Union, the Latin alphabet version of \"euro\" is used (as opposed to the less common Greek or Cyrillic) and Arabic numerals (other text is used on national sides in national languages, but other text on the common side is avoided). For the denominations except the 1-, 2- and 5-cent coins, the map only showed the 15 member states which were members when the euro was introduced. Beginning in 2007 or 2008 (depending on the country), the old map was replaced by a map of Europe also showing countries outside the EU like Norway, Ukraine, Belarus, Russia and Turkey. The 1-, 2- and 5-cent coins, however, keep their old design, showing a geographical map of Europe with the 15 member states of 2002 raised somewhat above the rest of the map. All common sides were designed by Luc Luycx. The coins also have a \"national side\" showing an image specifically chosen by the country that issued the coin. Euro coins from any member state may be freely used in any nation that has adopted the euro.\n\nThe coins are issued in denominations of €2, €1, 50c, 20c, 10c, 5c, 2c, and 1c. To avoid the use of the two smallest coins, some cash transactions are rounded to the nearest five cents in the Netherlands and Ireland (by voluntary agreement) and in Finland (by law). This practice is discouraged by the Commission, as is the practice of certain shops of refusing to accept high-value euro notes.\n\nCommemorative coins with €2 face value have been issued with changes to the design of the national side of the coin. These include both commonly issued coins, such as the €2 commemorative coin for the fiftieth anniversary of the signing of the Treaty of Rome, and nationally issued coins, such as the coin to commemorate the 2004 Summer Olympics issued by Greece. These coins are legal tender throughout the eurozone. Collector coins with various other denominations have been issued as well, but these are not intended for general circulation, and they are legal tender only in the member state that issued them.\n\nThe design for the euro banknotes has common designs on both sides. The design was created by the Austrian designer Robert Kalina. Notes are issued in €500, €200, €100, €50, €20, €10, €5. Each banknote has its own colour and is dedicated to an artistic period of European architecture. The front of the note features windows or gateways while the back has bridges, symbolising links between countries and with the future. While the designs are supposed to be devoid of any identifiable characteristics, the initial designs by Robert Kalina were of specific bridges, including the Rialto and the Pont de Neuilly, and were subsequently rendered more generic; the final designs still bear very close similarities to their specific prototypes; thus they are not truly generic. The monuments looked similar enough to different national monuments to please everyone.\n\nCapital within the EU may be transferred in any amount from one country to another. All intra-EU transfers in euro are treated as domestic transactions and bear the corresponding domestic transfer costs. This includes all member states of the EU, even those outside the eurozone providing the transactions are carried out in euro. Credit/debit card charging and ATM withdrawals within the eurozone are also treated as domestic transactions; however paper-based payment orders, like cheques, have not been standardised so these are still domestic-based. The ECB has also set up a clearing system, TARGET, for large euro transactions.\n\nA special euro currency sign (€) was designed after a public survey had narrowed the original ten proposals down to two. The European Commission then chose the design created by the Belgian Alain Billiet. Of the symbol, the EC stated\n\nThe European Commission also specified a euro logo with exact proportions and foreground and background colour tones. Placement of the currency sign relative to the numeric amount varies from nation to nation, but for texts in English the symbol (or the ISO-standard \"EUR\") should precede the amount.\n\nThe euro was established by the provisions in the 1992 Maastricht Treaty. To participate in the currency, member states are meant to meet strict criteria, such as a budget deficit of less than 3% of their GDP, a debt ratio of less than 60% of GDP (both of which were ultimately widely flouted after introduction), low inflation, and interest rates close to the EU average. In the Maastricht Treaty, the United Kingdom and Denmark were granted exemptions per their request from moving to the stage of monetary union which resulted in the introduction of the euro. (For macroeconomic theory, see below.)\n\nThe name \"euro\" was officially adopted in Madrid on 16 December 1995. Belgian Esperantist Germain Pirlot, a former teacher of French and history is credited with naming the new currency by sending a letter to then President of the European Commission, Jacques Santer, suggesting the name \"euro\" on 4 August 1995.\n\nDue to differences in national conventions for rounding and significant digits, all conversion between the national currencies had to be carried out using the process of triangulation via the euro. The \"definitive\" values of one euro in terms of the exchange rates at which the currency entered the euro are shown on the right.\n\nThe rates were determined by the Council of the European Union, based on a recommendation from the European Commission based on the market rates on 31 December 1998. They were set so that one European Currency Unit (ECU) would equal one euro. The European Currency Unit was an accounting unit used by the EU, based on the currencies of the member states; it was not a currency in its own right. They could not be set earlier, because the ECU depended on the closing exchange rate of the non-euro currencies (principally the pound sterling) that day.\n\nThe procedure used to fix the conversion rate between the Greek drachma and the euro was different since the euro by then was already two years old. While the conversion rates for the initial eleven currencies were determined only hours before the euro was introduced, the conversion rate for the Greek drachma was fixed several months beforehand.\n\nThe currency was introduced in non-physical form (traveller's cheques, electronic transfers, banking, etc.) at midnight on 1 January 1999, when the national currencies of participating countries (the eurozone) ceased to exist independently. Their exchange rates were locked at fixed rates against each other. The euro thus became the successor to the European Currency Unit (ECU). The notes and coins for the old currencies, however, continued to be used as legal tender until new euro notes and coins were introduced on 1 January 2002.\n\nThe changeover period during which the former currencies' notes and coins were exchanged for those of the euro lasted about two months, until 28 February 2002. The official date on which the national currencies ceased to be legal tender varied from member state to member state. The earliest date was in Germany, where the mark officially ceased to be legal tender on 31 December 2001, though the exchange period lasted for two months more. Even after the old currencies ceased to be legal tender, they continued to be accepted by national central banks for periods ranging from several years to indefinitely (the latter for Austria, Germany, Ireland, Estonia and Latvia in banknotes and coins, and for Belgium, Luxembourg, Slovenia and Slovakia in banknotes only). The earliest coins to become non-convertible were the Portuguese escudos, which ceased to have monetary value after 31 December 2002, although banknotes remain exchangeable until 2022.\n\nFollowing the U.S. financial crisis in 2008, fears of a sovereign debt crisis developed in 2009 among investors concerning some European states, with the situation becoming particularly tense in early 2010. Greece was most acutely affected, but fellow Eurozone members Cyprus, Ireland, Italy, Portugal, and Spain were also significantly affected. All these countries utilized EU funds except Italy, which is a major donor to the EFSF. To be included in the eurozone, countries had to fulfil certain convergence criteria, but the meaningfulness of such criteria was diminished by the fact it was not enforced with the same level of strictness among countries.\n\nAccording to the Economist Intelligence Unit in 2011, \"[I]f the [euro area] is treated as a single entity, its [economic and fiscal] position looks no worse and in some respects, rather better than that of the US or the UK\" and the budget deficit for the euro area as a whole is much lower and the euro area's government debt/GDP ratio of 86% in 2010 was about the same level as that of the United States. \"Moreover\", they write, \"private-sector indebtedness across the euro area as a whole is markedly lower than in the highly leveraged Anglo-Saxon economies\". The authors conclude that the crisis \"is as much political as economic\" and the result of the fact that the euro area lacks the support of \"institutional paraphernalia (and mutual bonds of solidarity) of a state\".\n\nThe crisis continued with S&P downgrading the credit rating of nine euro-area countries, including France, then downgrading the entire European Financial Stability Facility (EFSF) fund.\n\nA historical parallel – to 1931 when Germany was burdened with debt, unemployment and austerity while France and the United States were relatively strong creditors – gained attention in summer 2012 even as Germany received a debt-rating warning of its own. In the enduring of this scenario the Euro serves as a mean of quantitative primitive accumulation.\n\nThe euro is the sole currency of 19 EU member states: Austria, Belgium, Cyprus, Estonia, Finland, France, Germany, Greece, Ireland, Italy, Latvia, Lithuania, Luxembourg, Malta, the Netherlands, Portugal, Slovakia, Slovenia, and Spain. These countries constitute the \"eurozone\", some 343 million people in total .\n\nWith all but two of the remaining EU members obliged to join, together with future members of the EU, the enlargement of the eurozone is set to continue. Outside the EU, the euro is also the sole currency of Montenegro and Kosovo and several European microstates (Andorra, Monaco, San Marino and the Vatican City) as well as in five overseas territories of EU members that are not themselves part of the EU (Saint Barthélemy, Saint Martin, Saint Pierre and Miquelon, the French Southern and Antarctic Lands and Akrotiri and Dhekelia). Together this direct usage of the euro outside the EU affects nearly 3 million people.\n\nThe euro has been used as a trading currency in Cuba since 1998, Syria since 2006, and Venezuela since 2018. There are also various currencies pegged to the euro (see below). In 2009, Zimbabwe abandoned its local currency and used major currencies instead, including the euro and the United States dollar.\n\nSince its introduction, the euro has been the second most widely held international reserve currency after the U.S. dollar. The share of the euro as a reserve currency increased from 18% in 1999 to 27% in 2008. Over this period, the share held in U.S. dollar fell from 71% to 64% and that held in RMB fell from 6.4% to 3.3%. The euro inherited and built on the status of the Deutsche Mark as the second most important reserve currency. The euro remains underweight as a reserve currency in advanced economies while overweight in emerging and developing economies: according to the International Monetary Fund the total of euro held as a reserve in the world at the end of 2008 was equal to $1.1 trillion or €850 billion, with a share of 22% of all currency reserves in advanced economies, but a total of 31% of all currency reserves in emerging and developing economies.\n\nThe possibility of the euro becoming the first international reserve currency has been debated among economists. Former US Federal Reserve Chairman Alan Greenspan gave his opinion in September 2007 that it was \"absolutely conceivable that the euro will replace the US dollar as reserve currency, or will be traded as an equally important reserve currency\". In contrast to Greenspan's 2007 assessment, the euro's increase in the share of the worldwide currency reserve basket has slowed considerably since 2007 and since the beginning of the worldwide credit crunch related recession and European sovereign-debt crisis.\n\nOutside the eurozone, a total of 22 countries and territories that do not belong to the EU have currencies that are directly pegged to the euro including 14 countries in mainland Africa (CFA franc), two African island countries (Comorian franc and Cape Verdean escudo), three French Pacific territories (CFP franc) and three Balkan countries, Bosnia and Herzegovina (Bosnia and Herzegovina convertible mark), Bulgaria (Bulgarian lev) and North Macedonia (Macedonian denar). On 28 July 2009, São Tomé and Príncipe signed an agreement with Portugal which will eventually tie its currency to the euro. Additionally, the Moroccan dirham is tied to a basket of currencies, including the euro and the US dollar, with the euro given the highest weighting.\n\nWith the exception of Bosnia, Bulgaria, North Macedonia (which had pegged their currencies against the Deutsche Mark) and Cape Verde (formerly pegged to the Portuguese escudo), all of these non-EU countries had a currency peg to the French Franc before pegging their currencies to the euro. Pegging a country's currency to a major currency is regarded as a safety measure, especially for currencies of areas with weak economies, as the euro is seen as a stable currency, prevents runaway inflation and encourages foreign investment due to its stability.\n\nWithin the EU several currencies are pegged to the euro, mostly as a precondition to joining the eurozone. The Bulgarian lev was formerly pegged to the Deutsche Mark; one other EU currency with a direct peg due to ERM II is the Danish krone.\n\nIn total, , 182 million people in Africa use a currency pegged to the euro, 27 million people outside the eurozone in Europe, and another 545,000 people on Pacific islands.\n\nSince 2005, stamps issued by the Sovereign Military Order of Malta have been denominated in euros, although the Order's official currency remains the Maltese scudo. The Maltese scudo itself is pegged to the euro and is only recognised as legal tender within the Order.\n\nIn economics, an optimum currency area, or region (OCA or OCR), is a geographical region in which it would maximise economic efficiency to have the entire region share a single currency. There are two models, both proposed by Robert Mundell: the stationary expectations model and the international risk sharing model. Mundell himself advocates the international risk sharing model and thus concludes in favour of the euro. However, even before the creation of the single currency, there were concerns over diverging economies. Before the late-2000s recession it was considered unlikely that a state would leave the euro or the whole zone would collapse. However the Greek government-debt crisis led to former British Foreign Secretary Jack Straw claiming the eurozone could not last in its current form. Part of the problem seems to be the rules that were created when the euro was set up. John Lanchester, writing for \"The New Yorker\", explains it: \n\nThe most obvious benefit of adopting a single currency is to remove the cost of exchanging currency, theoretically allowing businesses and individuals to consummate previously unprofitable trades. For consumers, banks in the eurozone must charge the same for intra-member cross-border transactions as purely domestic transactions for electronic payments (e.g., credit cards, debit cards and cash machine withdrawals).\n\nFinancial markets on the continent are expected to be far more liquid and flexible than they were in the past. The reduction in cross-border transaction costs will allow larger banking firms to provide a wider array of banking services that can compete across and beyond the eurozone. However, although transaction costs were reduced, some studies have shown that risk aversion has increased during the last 40 years in the Eurozone.\n\nAnother effect of the common European currency is that differences in prices—in particular in price levels—should decrease because of the law of one price. Differences in prices can trigger arbitrage, i.e., speculative trade in a commodity across borders purely to exploit the price differential. Therefore, prices on commonly traded goods are likely to converge, causing inflation in some regions and deflation in others during the transition. Some evidence of this has been observed in specific eurozone markets.\n\nBefore the introduction of the euro, some countries had successfully contained inflation, which was then seen as a major economic problem, by establishing largely independent central banks. One such bank was the Bundesbank in Germany; the European Central Bank was modelled on the Bundesbank.\n\nThe euro has come under criticism due to its imperialistic style regulation, lack of flexibility and rigidity towards sharing member States on issues such as nominal interest rates.\nMany national and corporate bonds denominated in euro are significantly more liquid and have lower interest rates than was historically the case when denominated in national currencies. While increased liquidity may lower the nominal interest rate on the bond, denominating the bond in a currency with low levels of inflation arguably plays a much larger role. A credible commitment to low levels of inflation and a stable debt reduces the risk that the value of the debt will be eroded by higher levels of inflation or default in the future, allowing debt to be issued at a lower nominal interest rate.\n\nUnfortunately, there is also a cost in structurally keeping inflation lower than in the United States, UK, and China. The result is that seen from those countries, the euro has become expensive, making European products increasingly expensive for its largest importers. Hence export from the eurozone becomes more difficult.\n\nIn general, those in Europe who own large amounts of euros are served by high stability and low inflation.\n\nA monetary union means countries lose the main mechanism of recovery of their international competitiveness by weakening (depreciating) their currency. When wages become too high compared to productivity in exports sector then these exports become more expensive and they are crowded out from the market within a country and abroad. This drive fall of employment and output in the exports sector and fall of trade and current account balances. Fall of output and employment in tradable goods sector may be offset by the growth of non-exports sectors, especially in construction and services. Increased purchases abroad and negative current account balance can be financed without a problem as long as credit is cheap. The need to finance trade deficit weakens currency making exports automatically more attractive in a country and abroad. A country in a monetary union cannot use weakening of currency to recover its international competitiveness. To achieve this a country has to reduce prices, including wages (deflation). This means years of high unemployment and lower incomes as it was during European sovereign-debt crisis.\n\nA 2009 consensus from the studies of the introduction of the euro concluded that it has increased trade within the eurozone by 5% to 10%, although one study suggested an increase of only 3% while another estimated 9 to 14%. However, a meta-analysis of all available studies suggests that the prevalence of positive estimates is caused by publication bias and that the underlying effect may be negligible. Although a more recent meta-analysis shows that publication bias decreases over time and that there are positive trade effects from the introduction of the euro, as long as results from before 2010 are taken into account. This may be because of the inclusion of the Financial crisis of 2007–2008 and ongoing integration within the EU. Furthermore, older studies accounting for time trend reflecting general cohesion policies in Europe that started before, and continue after implementing the common currency find no effect on trade. These results suggest that other policies aimed at European integration might be the source of observed increase in trade.\n\nPhysical investment seems to have increased by 5% in the eurozone due to the introduction. Regarding foreign direct investment, a study found that the intra-eurozone FDI stocks have increased by about 20% during the first four years of the EMU. Concerning the effect on corporate investment, there is evidence that the introduction of the euro has resulted in an increase in investment rates and that it has made it easier for firms to access financing in Europe. The euro has most specifically stimulated investment in companies that come from countries that previously had weak currencies. A study found that the introduction of the euro accounts for 22% of the investment rate after 1998 in countries that previously had a weak currency.\n\nThe introduction of the euro has led to extensive discussion about its possible effect on inflation. In the short term, there was a widespread impression in the population of the eurozone that the introduction of the euro had led to an increase in prices, but this impression was not confirmed by general indices of inflation and other studies. A study of this paradox found that this was due to an asymmetric effect of the introduction of the euro on prices: while it had no effect on most goods, it had an effect on cheap goods which have seen their price round up after the introduction of the euro. The study found that consumers based their beliefs on inflation of those cheap goods which are frequently purchased. It has also been suggested that the jump in small prices may be because prior to the introduction, retailers made fewer upward adjustments and waited for the introduction of the euro to do so.\n\nOne of the advantages of the adoption of a common currency is the reduction of the risk associated with changes in currency exchange rates. It has been found that the introduction of the euro created \"significant reductions in market risk exposures for nonfinancial firms both in and outside Europe\". These reductions in market risk \"were concentrated in firms domiciled in the eurozone and in non-euro firms with a high fraction of foreign sales or assets in Europe\".\n\nThe introduction of the euro seems to have had a strong effect on European financial integration. According to a study on this question, it has \"significantly reshaped the European financial system, especially with respect to the securities markets [...] However, the real and policy barriers to integration in the retail and corporate banking sectors remain significant, even if the wholesale end of banking has been largely integrated.\" Specifically, the euro has significantly decreased the cost of trade in bonds, equity, and banking assets within the eurozone. On a global level, there is evidence that the introduction of the euro has led to an integration in terms of investment in bond portfolios, with eurozone countries lending and borrowing more between each other than with other countries.\n\nAs of January 2014, and since the introduction of the euro, interest rates of most member countries (particularly those with a weak currency) have decreased. Some of these countries had the most serious sovereign financing problems.\n\nThe effect of declining interest rates, combined with excess liquidity continually provided by the ECB, made it easier for banks within the countries in which interest rates fell the most, and their linked sovereigns, to borrow significant amounts (above the 3% of GDP budget deficit imposed on the eurozone initially) and significantly inflate their public and private debt levels. Following the financial crisis of 2007–2008, governments in these countries found it necessary to bail out or nationalise their privately held banks to prevent systemic failure of the banking system when underlying hard or financial asset values were found to be grossly inflated and sometimes so near worthless there was no liquid market for them. This further increased the already high levels of public debt to a level the markets began to consider unsustainable, via increasing government bond interest rates, producing the ongoing European sovereign-debt crisis.\n\nThe evidence on the convergence of prices in the eurozone with the introduction of the euro is mixed. Several studies failed to find any evidence of convergence following the introduction of the euro after a phase of convergence in the early 1990s. Other studies have found evidence of price convergence, in particular for cars. A possible reason for the divergence between the different studies is that the processes of convergence may not have been linear, slowing down substantially between 2000 and 2003, and resurfacing after 2003 as suggested by a recent study (2009).\n\nA study suggests that the introduction of the euro has had a positive effect on the amount of tourist travel within the EMU, with an increase of 6.5%.\n\nThe ECB targets interest rates rather than exchange rates and in general does not intervene on the foreign exchange rate markets. This is because of the implications of the Mundell–Fleming model, which implies a central bank cannot (without capital controls) maintain interest rate and exchange rate targets simultaneously, because increasing the money supply results in a depreciation of the currency. In the years following the Single European Act, the EU has liberalised its capital markets and, as the ECB has inflation targeting as its monetary policy, the exchange-rate regime of the euro is floating.\n\nThe euro is the second-most widely held reserve currency after the U.S. dollar. After its introduction on 4 January 1999 its exchange rate against the other major currencies fell reaching its lowest exchange rates in 2000 (3 May vs Pound sterling, 25 October vs the U.S. dollar, 26 October vs Japanese yen). Afterwards it regained and its exchange rate reached its historical highest point in 2008 (15 July vs U.S. dollar, 23 July vs Japanese yen, 29 December vs Pound sterling). With the advent of the global financial crisis the euro initially fell, to regain later. Despite pressure due to the European sovereign-debt crisis the euro remained stable. In November 2011 the euro's exchange rate index – measured against currencies of the bloc's major trading partners – was trading almost two percent higher on the year, approximately at the same level as it was before the crisis kicked off in 2007.\n\n\nBesides the economic motivations to the introduction of the euro, its creation was also partly justified as a way to foster a closer sense of joint identity between European citizens. Statements about this goal where for instance made by Wim Duisenberg, European Central Bank Governor, in 1998, Laurent Fabius, French Finance Minister, in 2000, Romano Prodi, President of the European Commission, in 2002. However, 15 years after the introduction of the euro, a study found no evidence that it has had a positive influence on a shared sense of European identity (and no evidence that it had a negative effect either).\n\nThe formal titles of the currency are \"euro\" for the major unit and \"cent\" for the minor (one-hundredth) unit and for official use in most eurozone languages; according to the ECB, all languages should use the same spelling for the nominative singular. This may contradict normal rules for word formation in some languages, e.g., those in which there is no \"eu\" diphthong. Bulgaria has negotiated an exception; \"euro\" in the Bulgarian Cyrillic alphabet is spelled as eвро (\"evro\") and not eуро (\"euro\") in all official documents. In the Greek script the term ευρώ (evró) is used; the Greek \"cent\" coins are denominated in λεπτό/ά (leptó/á). Official practice for English-language EU legislation is to use the words euro and cent as both singular and plural, although the European Commission's Directorate-General for Translation states that the plural forms \"euros\" and \"cents\" should be used in English.\n\n\n\n"}
{"id": "34392", "url": "https://en.wikipedia.org/wiki?curid=34392", "title": "Japanese yen", "text": "Japanese yen\n\nThe is the official currency of Japan. It is the third most traded currency in the foreign exchange market after the United States dollar and the euro. It is also widely used as a reserve currency after the U.S. dollar, the euro, and the pound sterling.\n\nThe concept of the yen was a component of the Meiji government's modernization program of Japan's economy, which postulated the pursuit of a uniform currency throughout the country, modelled after the European decimal currency system.\nBefore the Meiji Restoration, Japan's feudal fiefs all issued their own money, \"hansatsu\", in an array of incompatible denominations. The New Currency Act of 1871 did away with these and established the yen, which was defined as of gold, or of silver, as the new decimal currency. The former \"han\" (fiefs) became prefectures and their mints private chartered banks, which initially retained the right to print money. To bring an end to this situation, the Bank of Japan was founded in 1882 and given a monopoly on controlling the money supply.\n\nFollowing World War II the yen lost much of its prewar value. To stabilize the Japanese economy the exchange rate of the yen was fixed at ¥360 per US$1 as part of the Bretton Woods system. When that system was abandoned in 1971, the yen became undervalued and was allowed to float. The yen had appreciated to a peak of ¥271 per US$1 in 1973, then underwent periods of depreciation and appreciation due to the 1973 oil crisis, arriving at a value of ¥227 per US$1 by 1980.\n\nSince 1973, the Japanese government has maintained a policy of currency intervention, and the yen is therefore under a \"dirty float\" regime. The Japanese government focused on a competitive export market, and tried to ensure a low exchange rate for the yen through a trade surplus. The Plaza Accord of 1985 temporarily changed this situation: the exchange rate fell from its average of ¥239 per US$1 in 1985 to ¥128 in 1988 and led to a peak rate of ¥80 against the U.S. dollar in 1995, effectively increasing the value of Japan’s GDP in US dollar terms to almost that of the United States. Since that time, however, the world price of the yen has greatly decreased. The Bank of Japan maintains a policy of zero to near-zero interest rates and the Japanese government has previously had a strict anti-inflation policy.\n\n\"Yen\" derives from the Japanese word , which borrows its phonetic reading from Chinese yuan, similar to North Korean won and South Korean won. Originally, the Chinese had traded silver in mass called sycees and when Spanish and Mexican silver coins arrived, the Chinese called them \"silver rounds\" () for their circular shapes. The coins and the name also appeared in Japan. While the Chinese eventually replaced with , the Japanese continued to use the same word, which was given the shinjitai form in reforms at the end of World War II.\n\nThe spelling and pronunciation \"yen\" is standard in English because when Japan was first encountered by Europeans around the 16th century, Japanese () and () both had been pronounced and Portuguese missionaries had spelled them \"ye\". By the middle of the 18th century, and came to be pronounced as in modern Japanese, although some regions retain the pronunciation. Walter Henry Medhurst, who had neither been to Japan nor met any Japanese, having consulted mainly a Japanese-Dutch dictionary, spelled some \"e\"s as \"ye\" in his \"An English and Japanese, and Japanese and English Vocabulary\" (1830). In the early Meiji era, James Curtis Hepburn, following Medhurst, spelled all \"e\"s as \"ye\" in his \"A Japanese and English dictionary\" (1867); in Japanese, \"e\" and \"i\" are slightly palatalized, somewhat as in Russian. That was the first full-scale Japanese-English/English-Japanese dictionary, which had a strong influence on Westerners in Japan and probably prompted the spelling \"yen\". Hepburn revised most \"ye\"s to \"e\" in the 3rd edition (1886) to mirror the contemporary pronunciation, except \"yen\". This was probably already fixed and has remained so ever since.\n\nIn the 19th century, silver Spanish dollar coins were common throughout Southeast Asia, the China coast, and Japan. These coins had been introduced through Manila over a period of two hundred and fifty years, arriving on ships from Acapulco in Mexico. These ships were known as the Manila galleons. Until the 19th century, these silver dollar coins were actual Spanish dollars minted in the new world, mostly at Mexico City. But from the 1840s, they were increasingly replaced by silver dollars of the new Latin American republics. In the later half of the 19th century, some local coins in the region were made in the resemblance of the Mexican peso. The first of these local silver coins was the Hong Kong silver dollar coin that was minted in Hong Kong between the years 1866 and 1869. The Chinese were slow to accept unfamiliar coinage and preferred the familiar Mexican dollars, and so the Hong Kong government ceased minting these coins and sold the mint machinery to Japan.\nThe Japanese then decided to adopt a silver dollar coinage under the name of 'yen', meaning 'a round object'. The yen was officially adopted by the Meiji government in an Act signed on June 27, 1871. The new currency was gradually introduced beginning from July of that year. The yen was therefore basically a dollar unit, like all dollars, descended from the Spanish Pieces of eight, and up until the year 1873, all the dollars in the world had more or less the same value. The yen replaced Tokugawa coinage, a complex monetary system of the Edo period based on the mon. The \"New Currency Act\" of 1871, stipulated the adoption of the decimal accounting system of \"yen\" (1, ), ' (, ), and ' (, ), with the coins being round and manufactured using Western machinery. The yen was legally defined as 0.78 troy ounces (24.26 g) of pure silver, or 1.5 grams of pure gold (as recommended by the European Congress of Economists in Paris in 1867; the 5-yen coin was equivalent to the Argentine 5 peso fuerte coin),\nhence putting it on a bimetallic standard.\nFollowing the silver devaluation of 1873, the yen devalued against the U.S. dollar and the Canadian dollar (since those two countries adhered to a gold standard), and by the year 1897, the yen was worth only about US$0.50. In that year, Japan adopted a gold exchange standard and hence froze the value of the yen at $0.50. This exchange rate remained in place until Japan left the gold standard in December 1931, after which the yen fell to $0.30 by July 1932 and to $0.20 by 1933. It remained steady at around $0.30 until the start of the Pacific War on December 7, 1941, at which time it fell to $0.23.\n\nThe sen and the rin were eventually taken out of circulation at the end of 1953.\n\nNo true exchange rate existed for the yen between December 7, 1941, and April 25, 1949; wartime inflation reduced the yen to a fraction of its pre-war value. After a period of instability, on April 25, 1949, the U.S. occupation government fixed the value of the yen at ¥360 per US$1 through a United States plan, which was part of the Bretton Woods System, to stabilize prices in the Japanese economy. That exchange rate was maintained until 1971, when the United States abandoned the gold standard, which had been a key element of the Bretton Woods System, and imposed a 10 percent surcharge on imports, setting in motion changes that eventually led to floating exchange rates in 1973.\n\nBy 1971, the yen had become undervalued. Japanese exports were costing too little in international markets, and imports from abroad were costing the Japanese too much. This undervaluation was reflected in the current account balance, which had risen from the deficits of the early 1960s, to a then-large surplus of US$5.8 billion in 1971. The belief that the yen, and several other major currencies, were undervalued motivated the United States' actions in 1971.\n\nFollowing the United States' measures to devalue the dollar in the summer of 1971, the Japanese government agreed to a new, fixed exchange rate as part of the Smithsonian Agreement, signed at the end of the year. This agreement set the exchange rate at ¥308 per US$1. However, the new fixed rates of the Smithsonian Agreement were difficult to maintain in the face of supply and demand pressures in the foreign-exchange market. In early 1973, the rates were abandoned, and the major nations of the world allowed their currencies to float.\n\nIn the 1970s, Japanese government and business people were very concerned that a rise in the value of the yen would hurt export growth by making Japanese products less competitive and would damage the industrial base. The government therefore continued to intervene heavily in foreign-exchange marketing (buying or selling dollars), even after the 1973 decision to allow the yen to float.\n\nDespite intervention, market pressures caused the yen to continue climbing in value, peaking temporarily at an average of ¥271 per US$1 in 1973, before the impact of the 1973 oil crisis was felt. The increased costs of imported oil caused the yen to depreciate to a range of ¥290 to ¥300 between 1974 and 1976. The re-emergence of trade surpluses drove the yen back up to ¥211 in 1978. This currency strengthening was again reversed by the second oil shock in 1979, with the yen dropping to ¥227 by 1980.\n\nDuring the first half of the 1980s, the yen failed to rise in value even though current account surpluses returned and grew quickly. From ¥221 per US$1 in 1981, the average value of the yen actually dropped to ¥239 per US$1 in 1985. The rise in the current account surplus generated stronger demand for yen in foreign-exchange markets, but this trade-related demand for yen was offset by other factors. A wide differential in interest rates, with United States interest rates much higher than those in Japan, and the continuing moves to deregulate the international flow of capital, led to a large net outflow of capital from Japan. This capital flow increased the supply of yen in foreign-exchange markets, as Japanese investors changed their yen for other currencies (mainly dollars) to invest overseas. This kept the yen weak relative to the dollar and fostered the rapid rise in the Japanese trade surplus that took place in the 1980s.\n\nIn 1985, a dramatic change began. Finance officials from major nations signed an agreement (the Plaza Accord) affirming that the dollar was overvalued (and, therefore, the yen undervalued). This agreement, and shifting supply and demand pressures in the markets, led to a rapid rise in the value of the yen. From its average of ¥239 per US$1 in 1985, the yen rose to a peak of ¥128 in 1988, virtually doubling its value relative to the dollar. After declining somewhat in 1989 and 1990, it reached a new high of ¥123 to US$1 in December 1992. In April 1995, the yen hit a peak of under 80 yen per dollar, temporarily making Japan's economy nearly the size of that of the US.\n\nThe yen declined during the Japanese asset price bubble and continued to do so afterwards, reaching a low of ¥134 to US$1 in February 2002. The Bank of Japan's policy of zero interest rates has discouraged yen investments, with the carry trade of investors borrowing yen and investing in better-paying currencies (thus further pushing down the yen) estimated to be as large as $1 trillion. In February 2007, \"The Economist\" estimated that the yen was 15% undervalued against the dollar, and as much as 40% undervalued against the euro.\n\nHowever, this trend of depreciation reversed after the global economic crisis of 2008. Other major currencies, except the Swiss franc, have been declining relative to the yen.\n\nOn April 4, 2013, the Bank of Japan announced that they would expand their Asset Purchase Program by $1.4 trillion in two years. The Bank of Japan hopes to bring Japan from deflation to inflation, aiming for 2% inflation. The amount of purchases is so large that it is expected to double the money supply. But this move has sparked concerns that the authorities in Japan are deliberately devaluing the yen in order to boost exports. However, the commercial sector in Japan worried that the devaluation would trigger an increase in import prices, especially for energy and raw materials.\n\nCoins were introduced in 1870. There were silver 5-, 10-, 20- and 50-sen and 1-yen, and gold 2-, 5-, 10- and 20-yen. Gold 1-yen were introduced in 1871, followed by copper 1-rin, -, 1- and 2-sen in 1873.\nCupronickel 5-sen coins were introduced in 1889. In 1897, the silver 1-yen coin was demonetized and the sizes of the gold coins were reduced by 50%, with 5-, 10- and 20-yen coins issued. In 1920, cupro-nickel 10-sen coins were introduced.\n\nProduction of silver coins ceased in 1938, after which a variety of base metals were used to produce 1-, 5- and 10-sen coins during the Second World War. Clay 5- and 10-sen coins were produced in 1945, but not issued for circulation.\n\nAfter the war, brass 50-sen, 1- and 5-yen were introduced between 1946 and 1948. In 1949, the current type of holed 5-yen was introduced, followed by bronze 10-yen (of the type still in circulation) in 1951.\n\nCoins in denominations of less than 1-yen became invalid on December 31, 1953, following enforcement of the .\n\nIn 1955, the current type of aluminium 1-yen was introduced, along with unholed, nickel 50-yen. In 1957, silver 100-yen pieces were introduced, followed by the holed 50-yen coin in 1959. These were replaced in 1967 by the current cupro-nickel type, along with a smaller 50-yen coin. In 1982, the first 500-yen coins were introduced.\n\nThe date (expressed as the year in the reign of the emperor at the time the coin was stamped) is on the reverse of all coins, and, in most cases, country name (through 1945, ; after 1945, and the value in kanji is on the obverse, except for the present 5-yen coin where the country name is on the reverse.\n\nAlongside with the 5-Swiss franc coin and the rarely used 5-Cuban convertible peso coin, the 500-yen coin is one of the highest-valued coin to be used regularly in the world, with value of US$4.5 . Because of this high face value, the 500-yen coin has been a favorite target for counterfeiters; it was counterfeited to such an extent, that in 2000, a new series of coins was issued with various security features, but counterfeiting continued.\n\nThe 1-yen coin is made out of 100% aluminum and can float on water if placed correctly.\n\nOn various occasions, commemorative coins are minted, often in gold and silver with face values up to 100,000 yen. The first of these were silver ¥100 and ¥1000 Summer Olympic coins issued on the occasion of the 1964 games. Recently this practice is undertaken with the 500-yen coin, the first two types were issued in 1985, in commemoration of the science and technology exposition in Tsukuba and the 100th anniversary of the Governmental Cabinet system. The current commemorative 500- and 1000-yen coin series honouring the 47 prefectures of Japan commenced in 2008, with 47 unique designs planned for each denomination. Only one coin per customer is available from banks in each prefecture. 100,000 of each 1000-yen silver coin have been minted. Even though all commemorative coins can be spent like ordinary (non-commemorative) coins, they are not seen often in typical daily use and normally do not circulate.\n\nInstead of displaying the Gregorian calendar year of mintage like most nations' coins, yen coins instead display the year of the current emperor's reign. For example, a coin minted in 2009, would bear the date Heisei 21 (the 21st year of Emperor Akihito's reign).\n\nDue to the great differences in style, size, weight and the pattern present on the edge of the coin they are very easy for people with visual impairments to tell apart from one another.\nThe issuance of the yen banknotes began in 1872, two years after the currency was introduced. Throughout its history, the denominations have ranged from 10 yen to 10,000 yen; since 1984, the lowest-valued banknote is the 1,000 yen note.\n\nBefore and during World War II, various bodies issued banknotes in yen, such as the Ministry of Finance and the Imperial Japanese National Bank. The Allied forces also issued some notes shortly after the war. Since then, the Bank of Japan has been the exclusive note issuing authority. The bank has issued five series after World War II. Series E, the current series introduced in 2004, consists of ¥1000, ¥5000, and ¥10,000 notes. The EURion constellation pattern is present in the designs.\n\nJapan is generally considered a cash-based society, with 38% of payments in Japan made by cash in 2014. Possible explanations are that cash payments protect one's privacy, merchants do not have to wait for payment, and it does not carry any negative connotation like credit.\n\nOn April 9, 2019, Finance Minister Tarō Asō announced new designs for the ¥1000, ¥5000, and ¥10,000 notes, for use beginning in 2024. The ¥1000 bill will feature Kitasato Shibasaburō and The Great Wave off Kanagawa, the ¥5000 bill will feature Tsuda Umeko and wisteria flowers, and the ¥10,000 bill will feature Shibusawa Eiichi and Tokyo Station.\n\nBeginning in December 1931, Japan gradually shifted from the gold standard system to the managed currency system.\n\nThe relative value of the yen is determined in foreign exchange markets by the economic forces of supply and demand. The supply of the yen in the market is governed by the desire of yen holders to exchange their yen for other currencies to purchase goods, services, or assets. The demand for the yen is governed by the desire of foreigners to buy goods and services in Japan and by their interest in investing in Japan (buying yen-denominated real and financial assets).\n\nSince the 1990s, the Bank of Japan, the country's central bank, has kept interest rates low in order to spur economic growth. Short-term lending rates have responded to this monetary relaxation and fell from 3.7% to 1.3% between 1993 and 2008. Low interest rates combined with a ready liquidity for the yen prompted investors to borrow money in Japan and invest it in other countries (a practice known as carry trade). This has helped to keep the value of the yen low compared to other currencies.\n\nThe special drawing rights (SDR) valuation is an IMF basket of currencies, including the Japanese yen. The SDR is linked to a basket of five different currencies, with 41.73% for the U.S. dollar, 30.93% for the Euro, 10.92% for the Chinese renminbi, 8.33% for the Japanese yen, and 8.09% for the pound sterling (as of 2016). The percentage for the yen has, however, declined from 18% in 2000. The exchange rate for the Japanese yen is expressed in terms of currency units per U.S. dollar; other rates are expressed as U.S. dollars per currency unit. The SDR currency value is calculated daily and the valuation basket is reviewed and adjusted every five years. The SDR was created in 1969, to support the fixed exchange system.\n\nBefore the war commenced, the yen traded on an average of 3.6 yen to the dollar. And then during the war, because of overprinting and inflation as the Empire occupied more territory: the yen went as low as 600 yen to the USD.\n\nWhen McArthur and the US forces entered Japan in 1945, they decreed an official conversion rate of 15 yen to the USD. \n\nWithin 1945-1946: the rate tanked to 50 yen to the USD because of the ongoing inflation. During the first half of 1946, the rate fluctuated to 66 yen to the USD and eventually plummeting to 600 yen to the dollar by 1947 because of the failure of the economic remedies.\n\nEventually, the peg was officially moved to 270 yen to the dollar in 1948 before being adjusted again from 1949-1971 to 360 yen to the dollar.\n\nThe table below shows the monthly average of the U.S. dollar–yen spot rate (JPY per USD) at 17:00 JST:\n\n\n\n\n"}
{"id": "270673", "url": "https://en.wikipedia.org/wiki?curid=270673", "title": "Pound sterling", "text": "Pound sterling\n\nPound sterling (symbol: £; ISO code: GBP), commonly known as the pound and less commonly referred to as sterling, is the official currency of the United Kingdom, Jersey, Guernsey, the Isle of Man, Gibraltar, South Georgia and the South Sandwich Islands, the British Antarctic Territory, and Tristan da Cunha. It is subdivided into 100 \"pence\" (singular: \"penny\", abbreviated: \"p\"). A number of nations that do not use sterling also have currencies called the \"pound\".\n\nSterling is the fourth most-traded currency in the foreign exchange market, after the United States dollar, the euro, and the Japanese yen. Together with those three currencies and the Chinese yuan, it forms the basket of currencies which calculate the value of IMF special drawing rights. , sterling is also the fifth most-held reserve currency in global reserves.\n\nThe British Crown dependencies of Guernsey, Jersey and the Isle of Man produce their own local issues of sterling (the Guernsey pound, the Jersey pound and the Manx pound) which are considered fully equivalent to UK sterling in their respective regions. The pound sterling is also used in Gibraltar (alongside the Gibraltar pound), the Falkland Islands (alongside the Falkland Islands pound), Saint Helena and Ascension Island in Saint Helena, Ascension and Tristan da Cunha (alongside the Saint Helena pound). The Bank of England is the central bank for the pound sterling, issuing its own banknotes, and regulating issuance of banknotes by private banks in Scotland and Northern Ireland. Sterling banknotes issued by other jurisdictions are not regulated by the Bank of England; their governments guarantee convertibility at par.\n\nThe full official name \"pound sterling\" (plural: \"pounds sterling\"), is used mainly in formal contexts and also when it is necessary to distinguish the United Kingdom currency from other currencies with the same name. Otherwise the term \"pound\" is normally used. The currency name is sometimes abbreviated to just \"sterling\", particularly in the wholesale financial markets, but not when referring to specific amounts; for example, \"Payment is accepted in sterling\" but never \"These cost five sterling\". The abbreviations \"ster.\" and \"stg.\" are sometimes used. The term \"British pound\" is sometimes used in less formal contexts, but it is not an official name of the currency.\n\nThere is a variety of theories regarding the origin of the term \"pound sterling\". The Oxford English Dictionary (and sources derived therefrom) state that the \"most plausible\" etymology is derivation from the Old English \"steorra\" for \"star\" with the added diminutive suffix \"-ling\", to mean \"little star\" and to refer to a silver penny of the English Normans.\n\nAnother argument that the Hanseatic League was the origin for both the origin of its definition and manufacture, and in its name is that the German name for the Baltic is \"Ostsee\", or \"East Sea\", and from this the Baltic merchants were called \"Osterlings\", or \"Easterlings\". In 1260, Henry III granted them a charter of protection and land for their Kontor, the Steelyard of London, which by the 1340s was also called \"Easterlings Hall\", or Esterlingeshalle. Because the League's money was not frequently debased like that of England, English traders stipulated to be paid in pounds of the \"Easterlings\", which was contracted to \"'sterling\".\n\nEncyclopedia Britannica states the (pre-Norman) Anglo-Saxon kingdoms had silver coins called 'sterlings' and that the compound noun 'pound sterling' was derived from a pound (weight) of these sterlings.\n\nThe currency sign for the pound is , which is usually written with a single cross-bar (as on modern banknotes exclusively since 1975). A variation with a double cross-bar () has been used intermittently with since the earliest banknotes of 1725 when both were used. Historically, a simple capital L was used in newspapers, books and letters. The symbol derives from medieval Latin documents: the black-letter \"L\" (formula_1) was the abbreviation for \"libra\", the basic Roman unit of weight, taken (incorrectly) as equivalent to a latter-day pound in weight. In the British pre-decimal (duodecimal) currency system, the term £sd (or Lsd) for pounds, shillings and pence referred to the Roman words \"libra\", \"solidus\", and \"denarius\".\n\nThe ISO 4217 currency code is GBP, formed from \"GB\", the ISO 3166-1 alpha-2 code for the United Kingdom, and the first letter of \"pound\". Occasionally, the abbreviation \"UKP\" is used but this is non-standard because the ISO 3166 country code for the United Kingdom is GB (see Terminology of the British Isles). The Crown dependencies use their own (non-ISO) codes: GGP (Guernsey pound), JEP (Jersey pound) and IMP (Isle of Man pound). Stock prices are often quoted in pence, so traders may refer to pence sterling, GBX (sometimes GBp), when listing stock prices.\n\nThe exchange rate of the pound sterling against the US dollar is referred to as \"cable\" in the wholesale foreign exchange markets. The origins of this term are attributed to the fact that in the 1800s, the GBP/USD exchange rate was transmitted via transatlantic cable. Forex traders of GBP/USD are sometimes referred to as \"cable dealers\". GBP/USD is the only currency pair with its own name in the foreign exchange markets.\n\nA common slang term for the pound sterling or pound is \"quid\", which is singular and plural, except in the common phrase \"quids in!\". The term may have come via Italian immigrants from \"scudo\", the name for a number of coins used in Italy until the 19th century; or from Latin 'quid' via the common phrase \"quid pro quo\", literally, \"what for what\", or, figuratively, \"An equal exchange or substitution\".\n\nSince decimalisation on Decimal Day in 1971, the pound has been divided into 100 pence (denoted on coinage, until 1981, as \"new pence\"). The symbol for the penny is \"p\"; hence an amount such as 50p (£0.50) properly pronounced \"fifty pence\" is more colloquially, quite often, pronounced \"fifty pee\" /fɪfti pi/. This also helped to distinguish between new and old pence amounts during the changeover to the decimal system. A decimal halfpenny was issued until 1984 but was removed due to having a higher cost to manufacture than its face value.\n\nBefore decimalisation in 1971, the pound was divided into 20 shillings and each shilling into 12 pence, making 240 pence to the pound. The symbol for the shilling was \"\"s\".\"—not from the first letter of \"shilling\", but from the Latin \"solidus\". The symbol for the penny was \"\"d\".\", from the French \"denier\", from the Latin \"denarius\" (the solidus and denarius were Roman coins). A mixed sum of shillings and pence, such as 3 shillings and 6 pence, was written as \"3/6\" or \"3\"s\". 6\"d\".\" and spoken as \"three and six\" or \"three and sixpence\" except for \"1/1,\" \"2/1\" etc., which were spoken as \"one and a penny\", \"two and a penny\", etc. 5 shillings, for example, was written as \"5\"s\".\" or, more commonly, \"5/–\".\nVarious coin denominations had, and in some cases continue to have, special names—such as crown, farthing, sovereign and guinea. See Coins of the pound sterling and List of British coins and banknotes for details.\n\nBy the 1950s, coins of Kings George III, George IV and William IV had disappeared from circulation, but coins (at least the penny) bearing the head of every British king or queen from Queen Victoria onwards could be found in circulation. Silver coins were replaced by those in cupro-nickel in 1947, and by the 1960s the silver coins were rarely seen. Silver/cupro-nickel shillings (from any period after 1816) and florins (2 shillings) remained legal tender after decimalisation (as 5p and 10p respectively) until 1990 and 1993 respectively, but are now officially demonetised.\n\nAt various times, the pound sterling was commodity money or bank notes backed by silver or gold, but it is currently fiat money, backed only by the economy in the areas where it is accepted. The pound sterling is the world's oldest currency still in use and which has been in continuous use since its inception.\n\nThe \"pound\" was a unit of account in Anglo-Saxon England, equal to 240 silver pennies and equivalent to one pound weight of silver. It evolved into the modern British currency, the pound sterling.\n\nThe accounting system of 4 farthings = 1 penny, 12 pence = 1 shilling, 20 shillings = 1 pound was adopted from that introduced by Charlemagne to the Frankish Empire (see French livre).\n\nThe origins of sterling lie in the reign of King Offa of Mercia (757–796), who introduced the silver penny. It copied the \"denarius\" of the new currency system of Charlemagne's Frankish Empire. As in the Carolingian system, 240 pennies weighed 1 pound (corresponding to Charlemagne's \"libra\"), with the shilling corresponding to Charlemagne's \"solidus\" and equal to 12d. At the time of the penny's introduction, it weighed 22.5 troy grains of fine silver (32 tower grains; about 1.5 g), indicating that the Mercian pound weighed 5,400 troy grains (the Mercian pound became the basis of the tower pound, which also weighed 5,400 troy grains, equivalent to 7,680 tower grains, about 350g).\n\nThe early pennies were struck from fine silver (as pure as was available). However, in 1158, a new coinage was introduced by King Henry II (known as the \"Tealby penny\") which was struck from 0.925 (92.5%) silver. This became the standard until the 20th century and is today known as sterling silver, named after its association with the currency. Sterling silver is harder than the 0.999 (99.9%) fine silver that was traditionally used and so sterling silver coins did not wear down as rapidly as fine silver coins. The English currency was almost exclusively silver until 1344 when the gold noble was successfully introduced into circulation. However, silver remained the legal basis for the pound sterling until 1816.\n\nDuring the time of Henry III, the pound sterling equalled the tower (weight) pound. In the 28th year of Edward I (around 1300), the tale (money) pound, or pound sterling, first began to differ from (weigh less than) the tower pound, from which it originated, for by indenture of that year the pound weight was to contain 20s. 3d. in tale pound. In the 27th year of Edward III (around 1354), the pound sterling was now only 80% of the pound weight, or 9 oz 12 dwt (or 9.6 oz) tower. By an Act of the 13th year of Henry IV's reign (around 1412), the pound weight of standard silver was to contain thirty shillings in \"tale\", or one and a half pounds sterling; thus the pound sterling reduced to two-thirds of a pound weight, or 8 oz tower. The pound sterling was adjusted in weight several more times subsequently.\n\nIn the reign of Henry IV (1399–1413), the penny was reduced in weight to of silver, with a further reduction to in 1464.\n\nDuring the reigns of Henry VIII and Edward VI, the silver coinage was drastically debased, although the pound was redefined to the troy pound of in 1526. In 1544, a silver coinage was issued containing just one-third silver and two-thirds copper—equating to 0.333 silver, or 33.3 per cent pure. The result was a coin copper in appearance but relatively pale in colour. In 1552, a new silver coinage was introduced, struck in sterling silver. However, the penny's weight was reduced to , so 1 troy pound of sterling silver produced 60 shillings of coins. This silver standard was known as the \"60-shilling standard\" and lasted until 1601 when a \"62-shilling standard\" was introduced, reducing the penny's weight to grains (0.50 g).\n\nThroughout this period, the size and value of the gold coinage fluctuated considerably.\n\nIn 1663, a new gold coinage was introduced based on the 22 carat fine guinea. Fixed in weight at to the troy pound from 1670, this coin's value varied considerably until 1717, when it was fixed at 21 shillings (21/-, 1.05 pounds). However, despite the efforts of Sir Isaac Newton, Master of the Mint, to reduce the guinea's value, this valuation overvalued gold relative to silver when compared to the valuations in other European countries. In line with Gresham's Law, British merchants sent silver abroad in payments while goods for export were paid for with gold. As a consequence of these flows of silver out and gold in, Great Britain was effectively on a gold standard. Trade with China aggravated this outflow, as the Chinese refused to accept anything but silver in payment for exports. From the mid-17th century, around 28,000 metric tons (27,600 imperial tons) of silver were received by China, principally from European powers, in exchange for Chinese tea and other goods. In order to trade with China, Great Britain had first to trade with the other European nations to receive silver, which led to the East India Company redressing this trade imbalance through the indirect sale of opium to the Chinese.\n\nDomestic offtake further reduced silver in circulation, as the improving fortunes of the merchant class led to increased demand for tableware. Silversmiths had always regarded coinage as a source of raw material, already verified for fineness by the government. As a result, sterling coins were being melted and fashioned into sterling silverware at an accelerating rate. A 1697 Act of Parliament tried to stem this tide by raising the minimum acceptable fineness on wrought plate from sterling's 92.5% to a new Britannia silver standard of 95.83%. Silverware made purely from melted coins would be found wanting when the silversmith took his wares to the Assay Office, thus discouraging the melting of coins.\n\nThe Bank of England was founded in 1694, followed by the Bank of Scotland a year later. Both began to issue paper money.\n\nThe pound Scots once had much the same value as the pound sterling, but it suffered far higher devaluation until in the 17th century it was pegged to sterling at a value of 12 pounds Scots = 1 pound sterling.\n\nIn 1707, the Kingdom of England and the Kingdom of Scotland merged to form the Kingdom of Great Britain. In accordance with the Treaty of Union, the currency of Great Britain was sterling, with the pound Scots soon being replaced by sterling at the pegged value.\n\nIn 1801, Great Britain and the Kingdom of Ireland were united to form the United Kingdom of Great Britain and Ireland. However, the Irish pound continued to exist and was not replaced by sterling until January 1826. The conversion rate had long been 13 Irish pounds to 12 pounds sterling. The Irish pound was readopted in 1928, six years after the Anglo-Irish Treaty restored Irish independence.\n\nSterling circulated in much of the British Empire. In some parts, it was used alongside local currencies. For example, the gold sovereign was legal tender in Canada despite the use of the Canadian dollar. Several colonies and dominions adopted the pound as their own currency. These included Australia, Barbados, British West Africa, Cyprus, Fiji, British India, the Irish Free State, Jamaica, New Zealand, South Africa and Southern Rhodesia. Some of these retained parity with sterling throughout their existence (e.g. the South African pound), while others deviated from parity after the end of the gold standard (e.g. the Australian pound). These currencies and others tied to sterling constituted the sterling area.\n\nThe original English colonies on mainland North America were not party to the sterling area because the above-mentioned silver shortage in England coincided with these colonies' formative years. As a result of equitable trade (and rather less equitable piracy), the Spanish milled dollar became the most common coin within the English colonies.\n\nDuring the American war of independence and the Napoleonic wars, Bank of England notes were legal tender, and their value floated relative to gold. The Bank also issued silver tokens to alleviate the shortage of silver coins. In 1816, the gold standard was adopted officially, with silver coins minted at a rate of 66 shillings to a troy pound of sterling silver, thus rendering them as \"token\" issues (i.e. not containing their value in precious metal). In 1817, the sovereign was introduced, valued at 20 shillings. Struck in 22‑carat gold, it contained of gold and replaced the guinea as the standard British gold coin without changing the gold standard. In 1825, the Irish pound, which had been pegged to sterling since 1801 at a rate of 13 Irish pounds = 12 pounds sterling, was replaced, at the same rate, with sterling.\n\nBy the 19th century, the pound sterling was widely accepted outside Britain. The American Nellie Bly carried Bank of England notes on her 1889–1890 trip around the world in 72 days. During the late 19th and early 20th centuries, many other countries adopted the gold standard. As a consequence, conversion rates between different currencies could be determined simply from the respective gold standards. The pound sterling was equal to 4.87 United States dollars, 4.87 Canadian dollars, 12.11 Dutch guilders, 25.22 French francs (or equivalent currencies in the Latin Monetary Union), 20.43 German marks or 24.02 Austro-Hungarian krone. After the International Monetary Conference of 1867 in Paris, the possibility of the UK joining the Latin Monetary Union was discussed, and a Royal Commission on International Coinage examined the issues, resulting in a decision against joining monetary union.\n\nThe gold standard was suspended at the outbreak of the war in 1914, with Bank of England and Treasury notes becoming legal tender. Before World War I, the United Kingdom had one of the world's strongest economies, holding 40% of the world's overseas investments. But after the end of the war, the country was indebted: Britain owed £850 million (£ as of 2015) with interest costing the country some 40% of all government spending. To try to resume stability, a version of the gold standard was reintroduced in 1925, under which the currency was fixed to gold at its pre-war peg, but one could only exchange currency for gold bullion, not for coins. This was abandoned on 21 September 1931, during the Great Depression, and sterling suffered an initial devaluation of some 25%.\n\nIn 1940, an agreement with the US pegged the pound to the U.S. dollar at a rate of £1 = $4.03. (Only the year before, it had been $4.86.) This rate was maintained through the Second World War and became part of the Bretton Woods system which governed post-war exchange rates. Under continuing economic pressure, and despite months of denials that it would do so, on 19 September 1949 the government devalued the pound by 30.5 per cent to $2.80. The move prompted several other currencies to be devalued against the dollar.\n\nOperation Bernhard was the codename of a secret Nazi plan devised during the Second World War by the RSHA and the SS to destabilise the British economy via economic warfare by flooding the global economy and the British Empire with forged Bank of England £5, £10, £20, and £50 notes.\n\nIn 1961, 1964, and 1966, the pound came under renewed pressure, as speculators were selling pounds for dollars. In summer 1966, with the value of the pound falling in the currency markets, exchange controls were tightened by the Wilson government. Among the measures, tourists were banned from taking more than £50 out of the country in travellers' cheques and remittances, plus £15 in cash; this restriction was not lifted until 1979. The pound was devalued by 14.3 per cent to $2.40 on 18 November 1967.\n\nUntil decimalisation, amounts were stated in pounds, shillings, and pence, with various widely understood notations. The same amount could be stated as 32s 6d, 32/6, £1 12s 6d, or £1/12/6. It was customary to specify some prices (for example professional fees and auction prices for works of art) in guineas (one guinea was 21 shillings) although guinea coins were no longer in use.\n\nFormal parliamentary proposals to decimalise sterling were first made in 1824 when Sir John Wrottesley, MP for Staffordshire, asked in the British House of Commons whether consideration had been given to decimalising the currency. Wrottesley raised the issue in the House of Commons again in 1833, and it was again raised by John Bowring, MP for Kilmarnock Burghs, in 1847 whose efforts led to the introduction in 1848 of what was in effect the first decimal coin in the United Kingdom, the florin, valued at one-tenth of a pound sterling. However, full decimalisation was resisted, although the florin coin, re-designated as \"ten new pence\", survived the transfer to a full decimal system in 1971, with examples surviving in British coinage until 1993.\n\nJohn Benjamin Smith, MP for Stirling Burghs, raised the issue of full decimalisation again in Parliament in 1853, resulting in the Chancellor of the Exchequer, William Gladstone, announcing soon afterwards that \"the great question of a decimal coinage\" was \"now under serious consideration\". A full proposal for the decimalisation of sterling was then tabled in the House of Commons in June 1855, by William Brown, MP for Lancashire Southern, with the suggestion that the pound sterling be divided into one thousand parts, each called a \"mil\", or alternatively a farthing, as the pound was then equivalent to 960 farthings which could easily be rounded up to one thousand farthings in the new system. This did not result in the conversion of the pound sterling into a decimal system, but it was agreed to establish a Royal Commission to look into the issue. However, largely due to the hostility to decimalisation of two of the appointed commissioners, Lord Overstone (a banker) and John Hubbard (Governor of the Bank of England), decimalisation in Britain was effectively quashed for over a hundred years.\n\nHowever, the pound sterling was decimalised in various British colonial territories before the United Kingdom (and in several cases in line with William Brown's proposal that the pound be divided into 1,000 parts, called mils). These included Hong Kong from 1863 to 1866; Cyprus from 1955 until 1960 (and continued on the island as the division of the Cypriot pound until 1983); and the Palestine Mandate from 1926 until 1948.\n\nTowards the end of the Second World War, various attempts to decimalise the pound sterling in the United Kingdom were made. Later, in 1966, the British government decided to include in the Queen's Speech a plan to convert the pound into a decimal currency. As a result of this, on 15 February 1971, the UK decimalised the pound sterling, replacing the shilling and the penny with a single subdivision, the new penny. For example, a price tag of £1 12s 6d became . The word \"new\" was omitted from coins minted after 1981.\n\nWith the breakdown of the Bretton Woods system, the pound floated from August 1971 onwards. At first, it appreciated a little, rising to almost $2.65 in March 1972 from $2.42, the upper bound of the band in which it had been fixed. The sterling area effectively ended at this time, when the majority of its members also chose to float freely against the pound and the dollar.\n\nJames Callaghan became Prime Minister in 1976. He was immediately told the economy was facing huge problems, according to documents released in 2006 by the National Archives. The effects of the 1973 oil crisis were still being felt, with inflation rising to nearly 27 per cent in 1975. Financial markets were beginning to believe the pound was overvalued, and in April that year \"The Wall Street Journal\" advised the sale of sterling investments in the face of high taxes, in a story that ended with \"goodbye, Great Britain. It was nice knowing you\". At the time the UK government was running a budget deficit, and Labour's strategy emphasised high public spending. Callaghan was told there were three possible outcomes: a disastrous free fall in sterling, an internationally unacceptable siege economy, or a deal with key allies to prop up the pound while painful economic reforms were put in place. The US government feared the crisis could endanger NATO and the European Economic Community (EEC), and in light of this the US Treasury set out to force domestic policy changes. In November 1976 the International Monetary Fund (IMF) announced the conditions for a loan, including deep cuts in public expenditure.\n\nThe Conservative Party was elected to office in 1979, on a programme of fiscal austerity. Initially, the pound rocketed, moving above US$2.40, as interest rates rose in response to the monetarist policy of targeting money supply. The high exchange rate was widely blamed for the deep recession of 1981. Sterling fell sharply after 1980; at its lowest, the pound stood at just $1.03 in March 1985, before rising to $1.70 in December 1989.\n\nIn 1988, Margaret Thatcher's Chancellor of the Exchequer, Nigel Lawson, decided that the pound should \"shadow\" the West German Deutsche Mark (DM), with the unintended result of a rapid rise in inflation as the economy boomed due to low-interest rates. (For ideological reasons, the Conservative Government declined to use alternative mechanisms to control the explosion of credit. For this reason, former Prime Minister Edward Heath referred to Lawson as a \"one club golfer\".)\n\nFollowing German reunification in 1990, the reverse held true, as high German borrowing costs to fund Eastern reconstruction, exacerbated by the political decision to convert the Ostmark to the DM on a 1:1 basis, meant that interest rates in other countries shadowing the DM, especially the UK, were far too high relative to domestic circumstances, leading to a housing decline and recession.\n\nOn 8 October 1990 the Conservative government (Third Thatcher ministry) decided to join the European Exchange Rate Mechanism (ERM), with the pound set at DM2.95. However, the country was forced to withdraw from the system on \"Black Wednesday\" (16 September 1992) as Britain's economic performance made the exchange rate unsustainable.\n\n'Black Wednesday' saw interest rates jump from 10% to 15% in an unsuccessful attempt to stop the pound from falling below the ERM limits. The exchange rate fell to DM2.20. Those who had argued for a lower GBP/DM exchange rate were vindicated since the cheaper pound encouraged exports and contributed to the economic prosperity of the 1990s.\n\nIn 1997, the newly-elected Labour government handed over day-to-day control of interest rates to the Bank of England (a policy that had originally been advocated by the Liberal Democrats). The Bank is now responsible for setting its base rate of interest so as to keep inflation (as measured by the Consumer Price Index (CPI)) very close to 2% per annum. Should CPI inflation be more than one percentage point above or below the target, the governor of the Bank of England is required to write an open letter to the Chancellor of the Exchequer explaining the reasons for this and the measures which will be taken to bring this measure of inflation back in line with the 2% target. On 17 April 2007, annual CPI inflation was reported at 3.1% (inflation of the Retail Prices Index was 4.8%). Accordingly, and for the first time, the Governor had to write publicly to the government explaining why inflation was more than one percentage point higher than its target.\n\nAs a member of the European Union, the United Kingdom could have adopted the euro as its currency. However, the subject was always politically controversial, and the UK negotiated an opt-out on this issue.\n\nIn 2007, Gordon Brown, then Chancellor of the Exchequer, ruled out membership for the foreseeable future, saying that the decision not to join had been right for Britain and for Europe.\n\nOn 1 January 2008, with the Republic of Cyprus switching its currency from the Cypriot pound to the euro, the British sovereign bases on Cyprus (Akrotiri and Dhekelia) followed suit, making the Sovereign Base Areas the only territory under British sovereignty to officially use the euro.\n\nThe 2016 referendum which started the process of United Kingdom's withdrawal from the European Union makes adoption of the euro extremely unlikely.\n\nThe government of former Prime Minister Tony Blair had pledged to hold a public referendum to decide on the adoption of the Euro should \"five economic tests\" be met, to increase the likelihood that any adoption of the euro would be in the national interest. In addition to these internal (national) criteria, the UK would have to meet the European Union's economic convergence criteria (Maastricht criteria) before being allowed to adopt the euro. The Conservative and Liberal Democrat coalition government (2010–2015) ruled out joining the euro for that parliamentary term. \n\nThe idea of replacing the pound with the euro was always controversial with the British public, partly because of the pound's identity as a symbol of British sovereignty and because it would, according to many critics, have led to suboptimal interest rates, harming the British economy. In December 2008, the results of a BBC poll of 1000 people suggested that 71% would vote no to the euro, 23% would vote yes, while 6% said they were unsure. The pound did not join the Second European Exchange Rate Mechanism (ERM II) after the euro was created. Denmark and the UK have opt-outs from entry to the euro. Theoretically, every other EU nation must eventually sign up.\n\nThe Scottish Conservative Party claimed that there was an issue for Scotland in that the adoption of the euro would mean the end of nationally distinctive banknotes, as the euro banknotes do not have national designs. Before the 'No' vote in the Scottish independence referendum in 2014, the Scottish National Party affirmed that the euro would not be the national currency of an independent Scotland.\n\nThe pound and the euro fluctuate in value against one another, although there may be correlation between movements in their respective exchange rates with other currencies such as the US dollar. Inflation concerns in the UK led the Bank of England to raise interest rates in late 2006 and 2007. This caused the pound to appreciate against other major currencies and, with the US dollar depreciating at the same time, the pound hit a 15-year high against the US dollar on 18 April 2007, reaching US$2 the day before, for the first time since 1992. The pound and many other currencies continued to appreciate against the dollar; sterling hit a 26-year high of US$2.1161 on 7 November 2007 as the dollar fell worldwide. From mid-2003 to mid-2007, the pound/euro rate remained within a narrow range (€1.45 ± 5%).\n\nFollowing the global financial crisis in late 2008, the pound depreciated sharply, reaching $1.38 (US) on 23 January 2009 and falling below €1.25 against the euro in April 2008. There was a further decline during the remainder of 2008, most dramatically on 29 December when its euro rate hit an all-time low at €1.0219, while its US dollar rate depreciated. The pound appreciated in early 2009, reaching a peak against the euro of €1.17 in mid-July. In the following months the pound remained broadly steady against the euro, with the pound's valued on 27 May 2011 at €1.15 and US$1.65.\n\nOn 5 March 2009, the Bank of England announced that it would pump £75 billion of new capital into the British economy, through a process known as quantitative easing (QE). This was the first time in the United Kingdom's history that this measure had been used, although the Bank's Governor Mervyn King suggested it was not an experiment.\n\nThe process saw the Bank of England creating new money for itself, which it then used to purchase assets such as government bonds, secured commercial paper, or corporate bonds. The initial amount stated to be created through this method was £75 billion, although Chancellor of the Exchequer Alistair Darling had given permission for up to £150 billion to be created if necessary. It was expected that the process would continue for three months, with results only likely in the long term. By 5 November 2009, some £175 billion had been injected using QE, and the process remained less effective in the long term. In July 2012, the final increase in QE meant it had peaked at £375 billion, then holding solely UK Government bonds, representing one third of the UK national debt.\n\nThe result of the 2016 UK referendum on EU membership caused a major decline in the pound against other world currencies as the future of international trade relationships and domestic political leadership became unclear. The referendum result weakened sterling against the euro by 5% overnight. The night before the vote, the pound was trading at €1.30; the next day, this had fallen to €1.23. By October 2016, the exchange rate was €1.12 to the pound, a fall of 14% since the referendum. By the end of August 2017 the pound was even lower, at €1.08. Against the US dollar, meanwhile, the pound fell from $1.466 to $1.3694 when the referendum result was first revealed, and down to $1.2232 by October 2016, a fall of 16%.\n\nThe Bank of England had stated in 2009 that the decision had been taken to prevent the rate of inflation falling below the 2% target rate. Mervyn King, the Governor of the Bank of England, had also suggested there were no other monetary options left, as interest rates had already been cut to their lowest level ever (0.5%) and it was unlikely that they would be cut further.\n\nThe inflation rate rose in following years, reaching 5.2% per year (based on the Consumer Price Index) in September 2011, then decreased to around 2.5% the following year.\n\nThe silver penny (plural: \"pence\"; abbreviation: \"d\") was the principal and often the only coin in circulation from the 8th century until the 13th century. Although some fractions of the penny were struck (see farthing and halfpenny), it was more common to find pennies cut into halves and quarters to provide smaller change. Very few gold coins were struck, with the gold penny (worth 20 silver pence) a rare example. However, in 1279, the \"groat\", worth 4d, was introduced, with the half groat following in 1344. 1344 also saw the establishment of a gold coinage with the introduction (after the failed gold florin) of the \"noble\" worth six shillings and eight pence (6/8) (i.e. 3 nobles to the pound), together with the half and quarter noble. Reforms in 1464 saw a reduction in value of the coinage in both silver and gold, with the noble renamed the \"ryal\" and worth 10/- (i.e. 2 to the pound) and the \"angel\" introduced at the noble's old value of 6/8.\n\nThe reign of Henry VII saw the introduction of two important coins: the shilling (abbr.: \"s\"; known as the \"testoon\") in 1487 and the pound (known as the \"sovereign\", abbr.: \"£\" or \"L\") in 1489. In 1526, several new denominations of gold coins were added, including the \"crown\" and \"half crown\" worth five shillings (\"5/-\"), and two shillings and six pence (\"2/6\", \"two and six\") respectively. Henry VIII's reign (1509–1547) saw a high level of debasement which continued into the reign of Edward VI (1547–1553). This debasement was halted in 1552, and new silver coinage was introduced, including coins for 1d, 2d, 3d, 4d and 6d, 1/-, 2/6 and 5/-. In the reign of Elizabeth I (1558–1603), silver d and d coins were added, but these denominations did not last. Gold coins included the half-crown, crown, angel, half-sovereign and sovereign. Elizabeth's reign also saw the introduction of the horse-drawn screw press to produce the first \"milled\" coins.\n\nFollowing the succession of the Scottish King James VI to the English throne, a new gold coinage was introduced, including the \"spur ryal\" (15/-), the \"unite\" (20/-) and the \"rose ryal\" (30/-). The \"laurel\", worth 20/-, followed in 1619. The first base metal coins were also introduced: tin and copper farthings. Copper halfpenny coins followed in the reign of Charles I. During the English Civil War, a number of siege coinages were produced, often in unusual denominations.\n\nFollowing the restoration of the monarchy in 1660, the coinage was reformed, with the ending of production of hammered coins in 1662. The \"guinea\" was introduced in 1663, soon followed by the , 2 and 5 guinea coins. The silver coinage consisted of denominations of 1d, 2d, 3d, 4d and 6d, 1/-, 2/6 and 5/-. Due to the widespread export of silver in the 18th century, the production of silver coins gradually came to a halt, with the half crown and crown not issued after the 1750s, the 6d and 1/- stopping production in the 1780s. In response, copper 1d and 2d coins and a gold guinea (7/-) were introduced in 1797. The copper penny was the only one of these coins to survive long.\n\nTo alleviate the shortage of silver coins, between 1797 and 1804, the Bank of England counterstamped Spanish dollars (8 reales) and other Spanish and Spanish colonial coins for circulation. A small counterstamp of the King's head was used. Until 1800, these circulated at a rate of 4/9 for 8 reales. After 1800, a rate of 5/- for 8 reales was used. The Bank then issued silver tokens for 5/- (struck over Spanish dollars) in 1804, followed by tokens for 1/6 and 3/- between 1811 and 1816.\n\nIn 1816, a new silver coinage was introduced in denominations of 6d, 1/-, 2/6 (half-crown) and 5/- (crown). The crown was only issued intermittently until 1900. It was followed by a new gold coinage in 1817 consisting of 10/- and £1 coins, known as the half sovereign and sovereign. The silver 4d coin was reintroduced in 1836, followed by the 3d in 1838, with the 4d coin issued only for colonial use after 1855. In 1848, the 2/- \"florin\" was introduced, followed by the short-lived double florin in 1887. In 1860, copper was replaced by bronze in the farthing (quarter penny, d), halfpenny and penny.\n\nDuring the First World War, production of the sovereign and half-sovereign was suspended, and although the gold standard was later restored, the coins saw little circulation thereafter. In 1920, the silver standard, maintained at .925 since 1552, was reduced to .500. In 1937, a nickel-brass 3d coin was introduced; the last silver 3d coins were issued seven years later. In 1947, the remaining silver coins were replaced with cupro-nickel, with the exception of Maundy coinage which was then restored to .925. Inflation caused the farthing to cease production in 1956 and be demonetised in 1960. In the run-up to decimalisation, the halfpenny and half-crown were demonetised in 1969.\n\nBritish coinage timeline:\n\nAt present, the oldest circulating coins in the UK are the 1p and 2p copper coins introduced in 1971. No other coins from before 1982 are in circulation. Prior to the withdrawal from circulation of the larger 10p in 1993, the oldest circulating coins had usually dated from 1947: although older coins (shilling; florin, sixpence to 1980) were still legal tender, inflation meant that their silver content was worth more than their face value, which meant that they tended to be removed from circulation. Before decimalisation in 1971, a handful of change might have contained coins 100 or more years old, bearing any of five monarchs' heads, especially in the copper coins.\n\nThe first sterling notes were issued by the Bank of England shortly after its foundation in 1694. Denominations were initially handwritten on the notes at the time of issue. From 1745, the notes were printed in denominations between £20 and £1000, with any odd shillings added by hand. £10 notes were added in 1759, followed by £5 in 1793 and £1 and £2 in 1797. The lowest two denominations were withdrawn after the end of the Napoleonic wars. In 1855, the notes were converted to being entirely printed, with denominations of £5, £10, £20, £50, £100, £200, £300, £500 and £1000 issued.\n\nThe Bank of Scotland began issuing notes in 1695. Although the pound Scots was still the currency of Scotland, these notes were denominated in sterling in values up to £100. From 1727, the Royal Bank of Scotland also issued notes. Both banks issued some notes denominated in guineas as well as pounds. In the 19th century, regulations limited the smallest note issued by Scottish banks to be the £1 denomination, a note not permitted in England.\n\nWith the extension of sterling to Ireland in 1825, the Bank of Ireland began issuing sterling notes, later followed by other Irish banks. These notes included the unusual denominations of 30/- and £3. The highest denomination issued by the Irish banks was £100.\n\nIn 1826, banks at least from London were given permission to issue their own paper money. From 1844, new banks were excluded from issuing notes in England and Wales but not in Scotland and Ireland. Consequently, the number of private banknotes dwindled in England and Wales but proliferated in Scotland and Ireland. The last English private banknotes were issued in 1921.\n\nIn 1914, the Treasury introduced notes for 10/- and £1 to replace gold coins. These circulated until 1928 when they were replaced by Bank of England notes. Irish independence reduced the number of Irish banks issuing sterling notes to five operating in Northern Ireland. The Second World War had a drastic effect on the note production of the Bank of England. Fearful of mass forgery by the Nazis (see Operation Bernhard), all notes for £10 and above ceased production, leaving the bank to issue only 10/-, £1 and £5 notes. Scottish and Northern Irish issues were unaffected, with issues in denominations of £1, £5, £10, £20, £50 and £100.\n\nThe Bank of England reintroduced £10 notes in 1964. In 1969, the 10/- note was replaced by the 50p coin to prepare for decimalisation. £20 Bank of England notes were reintroduced in 1970, followed by £50 in 1981. A £1 coin was introduced in 1983, and Bank of England £1 notes were withdrawn in 1988. Scottish and Northern Irish banks followed, with only the Royal Bank of Scotland continuing to issue this denomination.\n\nUK notes include raised print (e.g. on the words \"Bank of England\"); watermarks; embedded metallic thread; holograms; and fluorescent ink visible only under UV lamps. Three printing techniques are involved: offset litho, intaglio and letterpress; and the notes incorporate a total of 85 specialized inks.\n\nThe Bank of England produces notes named \"giant\" and \"titan\". A giant is a one million pound note, and a titan is a one hundred million pound bank note, of which there are about 40. Giants and titans are used only within the banking system.\n\nThe Northern Bank £5 note, issued by (Northern Ireland's) Northern Bank (now Danske Bank) in 2000, was the only polymer banknote in circulation until 2016. The Bank of England introduced £5 polymer banknotes in September 2016, and the paper £5 notes were withdrawn on 5 May 2017. A polymer £10 banknote was introduced on 14 September 2017, and the paper note was withdrawn on 1 March 2018. A polymer £20 banknote will be introduced on 20 February 2020, followed by a £50 in 2021.\n\nAs the central bank of the United Kingdom which has been delegated authority by the government, the Bank of England sets the monetary policy for the British pound by controlling the amount of money in circulation. It has a monopoly on the issuance of banknotes in England and Wales and regulates the amount of banknotes issued by seven authorized banks in Scotland and Northern Ireland. HM Treasury has reserve powers to give orders to the committee \"if they are required in the public interest and by extreme economic circumstances\" but such orders must be endorsed by Parliament within 28 days.\n\nUnlike banknotes which have separate issuers in Scotland and Northern Ireland, all UK coins are issued by the Royal Mint, which is an independent enterprise (wholly owned by the Treasury) which also mints coins for other countries.\n\nIn Britain's Crown Dependencies, the Manx pound, Jersey pound, and Guernsey pound are unregulated by the Bank of England and are issued independently. However, they are maintained at a fixed exchange rate by their respective governments, and Bank of England notes have been made legal tender on the islands, forming a sort of one-way de facto currency union. These currencies do not have ISO 4217 codes, so \"GBP\" is usually used to represent all of them; informal codes are used where the difference is important.\n\nBritish Overseas Territories are responsible for the monetary policy of their own currencies (where they exist), and have their own ISO 4217 codes. The Falkland Islands pound, Gibraltar pound, and Saint Helena pound are set at a fixed 1:1 exchange rate with the British pound by local governments.\n\nLegal tender in the United Kingdom is defined such that \"a debtor cannot successfully be sued for non-payment if he pays into court in legal tender.\" Parties can alternatively settle a debt by other means with mutual consent. Strictly speaking, it is necessary for the debtor to offer the exact amount due as there is no obligation for the other party to provide change.\n\nThroughout the UK, £1 and £2 coins are legal tender for any amount, with the other coins being legal tender only for limited amounts. Bank of England notes are legal tender for any amount in England and Wales, but not in Scotland or Northern Ireland. (Bank of England 10/- and £1 notes were legal tender, as were Scottish banknotes, during World War II under the Currency (Defence) Act 1939, which was repealed on 1 January 1946.) Channel Islands and Isle of Man banknotes are legal tender only in their respective jurisdictions.\n\nBank of England, Scottish, Northern Irish, Channel Islands, Isle of Man, Gibraltar, and Falkland banknotes may be offered anywhere in the UK, although there is no obligation to accept them as a means of payment, and acceptance varies. For example, merchants in England generally accept Scottish and Northern Irish bills, but some unfamiliar with them may reject them. However, Scottish and Northern Irish bills both tend to be accepted in Scotland and Northern Ireland, respectively. Merchants in England generally do not accept Jersey, Guernsey, Isle of Man, Gibraltar, and Falkland notes but Isle of Man notes are generally accepted in Northern Ireland. Bank of England notes are generally accepted in the Falklands and Gibraltar, but for example, Scottish and Northern Irish notes are not. Since all of the bills are denominated in pounds sterling, banks will exchange them for locally issued bills at face value, though some in the UK have had trouble exchanging Falkland Islands pounds.\n\nCommemorative £5 and 25p (crown) coins, rarely seen in circulation, are legal tender, as are the bullion coins issued by the Mint.\n\nIn 2006, the House of Commons Library published a research paper which included an index of prices in pounds for each year between 1750 and 2005, where 1974 was indexed at 100.\n\nRegarding the period 1750–1914 the document states: \"Although there was considerable year on year fluctuation in price levels prior to 1914 (reflecting the quality of the harvest, wars, etc.) there was not the long-term steady increase in prices associated with the period since 1945\". It goes on to say that \"Since 1945 prices have risen in every year with an aggregate rise of over 27 times\".\n\nThe value of the index in 1751 was 5.1, increasing to a peak of 16.3 in 1813 before declining very soon after the end of the Napoleonic Wars to around 10.0 and remaining in the range 8.5–10.0 at the end of the 19th century. The index was 9.8 in 1914 and peaked at 25.3 in 1920, before declining to 15.8 in 1933 and 1934—prices were only about three times as high as they had been 180 years earlier.\n\nInflation has had a dramatic effect during and after World War II: the index was 20.2 in 1940, 33.0 in 1950, 49.1 in 1960, 73.1 in 1970, 263.7 in 1980, 497.5 in 1990, 671.8 in 2000 and 757.3 in 2005.\n\nThe following table shows the equivalent amount of goods and services that, in a particular year, could be purchased with £1.\n\nThe table shows that from 1971 to 2015 the British pound lost about 92 per cent of its buying power.\n\nThe smallest coin in 1971 was the p, worth about 6.4p in 2015 prices.\n\nThe pound is freely bought and sold on the foreign exchange markets around the world, and its value relative to other currencies therefore fluctuates.\n\nSterling is used as a reserve currency around the world and is currently ranked fourth in value held as reserves.\n\n\n\n"}
{"id": "66958", "url": "https://en.wikipedia.org/wiki?curid=66958", "title": "Renminbi", "text": "Renminbi\n\nThe renminbi (abbreviated RMB; ; symbol: 元/¥; code: CNY) is the official currency of the People's Republic of China, and one of the world's major reserve currencies. The yuan () is the basic unit of the renminbi, but is also used to refer to the Chinese currency generally, especially in international contexts where \"Chinese yuan\" is widely used to refer to the renminbi. The distinction between renminbi and yuan is that renminbi is the name of the currency and yuan refers to its primary unit. One yuan is subdivided into 10 \"jiao\" (), and a \"jiao\" in turn is subdivided into 10 \"fen\" (). The renminbi is issued by the People's Bank of China, the monetary authority of China.\n\nThe renminbi is sometimes referred to as the redback in the US financial press.\n\nUntil 2005, the value of the renminbi was pegged to the US dollar. As China pursued its transition from central planning to a market economy and increased its participation in foreign trade, the renminbi was devalued to increase the competitiveness of Chinese industry. It has previously been claimed that the renminbi's official exchange rate was undervalued by as much as 37.5% against its purchasing power parity. However more recently, appreciation actions by the Chinese government, as well as quantitative easing measures taken by the American Federal Reserve and other major central banks, have caused the renminbi to be within as little as 8% of its equilibrium value by the second half of 2012. Since 2006, the renminbi exchange rate has been allowed to float in a narrow margin around a fixed base rate determined with reference to a basket of world currencies. The Chinese government has announced that it will gradually increase the flexibility of the exchange rate. As a result of the rapid internationalization of the renminbi, it became the world's 8th most traded currency in 2013, 5th by 2015, but 8th in 2019.\n\nOn 1 October 2016, the RMB became the first emerging market currency to be included in the IMF's special drawing rights basket, the basket of currencies used by the IMF (reserve currency).\n\nThe ISO code for yuan renminbi is CNY, an abbreviation of \"Chinese yuan\" as it's often referred to in international finance. Hong Kong markets that trade renminbi at free-floating rates use the unofficial code CNH. This is to distinguish the rates from those fixed by Chinese central banks on the mainland. RMB is not a currency code but is sometimes used like one in China.\n\nThe currency symbol is ¥, but because that's ambiguously shared with the Japanese yen, CN¥ is sometimes used. However, in written Chinese contexts the Chinese character for yuan () or, in formal contexts, () usually follows the number in lieu of a currency symbol.\n\n\"Renminbi\" is the name of the currency while \"yuan\" is the name of the primary unit of renminbi. This is analogous to the difference between \"sterling\" and \"pound\" when discussing the official currency of the United Kingdom, the pound sterling. \"Jiao\" and \"fen\" are also units of renminbi.\n\nIn everyday Mandarin, kuai () is usually used when discussing money and renminbi or yuan are rarely heard. Similarly, Mandarin speakers typically use mao () instead of jiao.\n\nA variety of currencies circulated in China during the Republic of China (ROC) era, most of which were denominated in the unit \"yuán\" (Mandarin pronunciation in IPA: ). Each was distinguished by a currency name, such as the \"fabi\" (\"legal tender\"), the \"gold yuan\", and the \"silver yuan\".\n\nThe renminbi was introduced by the People's Bank of China in December 1948, about a year before the establishment of the People's Republic of China. It was issued only in paper money form at first, and replaced the various currencies circulating in the areas controlled by the Communists. One of the first tasks of the new government was to end the hyperinflation that had plagued China in the final years of the Kuomintang (KMT) era. That achieved, a revaluation occurred in 1955 at the rate of 1 new yuan = 10,000 old yuan.\n\nAs the Communist Party of China took control of ever larger territories in the latter part of the Chinese Civil War, its People's Bank of China began in 1948 to issue a unified currency for use in Communist-controlled territories. Also denominated in \"yuan\", this currency was identified by different names, including \"People's Bank of China banknotes\" (; from November 1948), \"New Currency\" (; from December 1948), \"People's Bank of China notes\" (; from January 1949), \"People's Notes\" (人民券, as an abbreviation of the last name), and finally \"People's Currency\", or \"renminbi\", from June 1949.\n\nFrom 1949 until the late 1970s, the state fixed China's exchange rate at a highly overvalued level as part of the country's import-substitution strategy. During this time frame, the focus of the state's central planning was to accelerate industrial development and reduce China's dependence on imported manufactured goods. The overvaluation allowed the government to provide imported machinery and equipment to priority industries at a relatively lower domestic currency cost than otherwise would have been possible.\n\nChina's transition by the mid-1990s to a system in which the value of its currency was determined by supply and demand in a foreign exchange market was a gradual process spanning 15 years that involved changes in the official exchange rate, the use of a dual exchange rate system, and the introduction and gradual expansion of markets for foreign exchange.\n\nThe most important move to a market-oriented exchange rate was an easing of controls on trade and other current account transactions, as occurred in several very early steps. In 1979 the State Council approved a system allowing exporters and their provincial and local government owners to retain a share of their foreign exchange earnings, referred to as foreign exchange quotas. At the same time, the government introduced measures to allow retention of part of the foreign exchange earnings from non-trade sources, such as overseas remittances, port fees paid by foreign vessels, and tourism.\n\nAs early as October 1980, exporting firms that retained foreign exchange above their own import needs were allowed to sell the excess through the state agency responsible for the management of China's exchange controls and its foreign exchange reserves, the State Administration of Exchange Control. Beginning in the mid-1980s, the government sanctioned foreign exchange markets, known as swap centers eventually in most large cities.\n\nThe government also gradually allowed market force to take the dominant role by introducing an \"internal settlement rate\" of RMB 2.8 to 1 US dollar which was a devaluation of almost 100 percent.\n\nIn November 1993 the Third Plenum of the Fourteenth CPC Central Committee approved a comprehensive reform strategy in which foreign exchange management reforms were highlighted as a key element for a market-oriented economy. A floating exchange rate regime and convertibility for RMB were seen as the ultimate goal of the reform. Conditional convertibility under current account was achieved by allowing firms to surrender their foreign exchange earning from current account transactions and purchase foreign exchange as needed. Restrictions on Foreign Direct Investment (FDI) was also loosened and capital inflows to China surged.\n\nDuring the era of the command economy, the value of the renminbi was set to unrealistic values in exchange with western currency and severe currency exchange rules were put in place. With the opening of the Chinese economy in 1978, a dual-track currency system was instituted, with renminbi usable only domestically, and with foreign visitors to China forced to use foreign exchange certificates. The unrealistic levels at which exchange rates were pegged led to a strong black market in currency transactions.\n\nIn the late 1980s and early 1990s, China worked to make the RMB more convertible. Through the use of swap centres, the exchange rate was brought to realistic levels and the dual track currency system was abolished.\n\nAs of 2013, the renminbi is convertible on current accounts but not capital accounts. The ultimate goal has been to make the RMB fully convertible. However, partly in response to the Asian financial crisis in 1998, China has been concerned that the Chinese financial system would not be able to handle the potential rapid cross-border movements of hot money, and as a result, as of 2012, the currency trades within a narrow band specified by the Chinese central government.\n\nFollowing the Internationalization of the renminbi, on 30 November 2015, the IMF voted to designate the renminbi as one of several main world currencies, thus including it in the basket of special drawing rights. The RMB became the first emerging market currency to be included in the IMF's SDR basket on 1 October 2016. The other main world currencies are the United States dollar, euro, British pound, and Japanese yen.\n\nOn October 31, 2019, China's central bank, PBOC, announced that a digital reminbi is going to be release after years of research. The version of the currency, also called DCEP (Digital Currency Electronic Payment), is based on cryptocurrency which can be “decoupled” from the banking system to give visiting tourists a taste of the nation’s burgeoning cashless society. The announcement received various of responses: some regard it's an circumvention of China government from US Dollars, others believe it's more on domestic control.\n\nAs of 2019, renminbi banknotes are available in denominations from ¥0.1, ¥0.5 (1 and 5 jiao), ¥1, ¥5, ¥10, ¥20, ¥50 and ¥100. These denominations have been available since 1955, except for the 20, 50 and 100 yuan notes (added in 1999). Coins are available in denominations from 1 fen to 1 yuan (¥0.01–1). Thus some denominations exist in both coins and banknotes. On rare occasions larger yuan coin denominations such as ¥5 have been issued to commemorate events but use of these outside of collecting has never been widespread.\n\nThe denomination of each banknote is printed in Chinese language. The numbers themselves are printed in financial Chinese numeral characters, as well as Arabic numerals. The denomination and the words \"People's Bank of China\" are also printed in Mongolian, Tibetan, Uyghur and Zhuang on the back of each banknote, in addition to the boldface Hanyu Pinyin \"Zhongguo Renmin Yinhang\" (without tones). The right front of the note has a tactile representation of the denomination in Chinese Braille starting from the fourth series. See corresponding section for detailed information.\n\nThe fen and jiao denominations have become increasingly unnecessary as prices have increased. Coins under ¥0.1 are used infrequently. Chinese retailers tend to avoid decimal values (such as ¥9.99), opting instead for integer values of yuan (such as ¥9 or ¥10).\n\nIn 1953, aluminium 1-, 2-, and 5-fen coins began being struck for circulation, and were first introduced in 1955. These depict the national emblem on the obverse (front) and the name and denomination framed by wheat stocks on the reverse (back). In 1980, brass 1-, 2-, and 5-jiao and cupro-nickel 1-yuan coins were added, although the 1 and 2 jiao were only produced until 1981, with the last 5 jiao and 1 yuan issued in 1985. All jiao coins depicted similar designs to the fen coins while the yuan depicted the Great Wall of China. In 1991, a new coinage was introduced, consisting of an aluminium 1 jiao, brass 5 jiao and nickel-clad-steel 1 yuan. These were smaller than the previous jiao and yuan coins and depicted flowers on the obverse and the national emblem on the reverse. Issuance of the aluminum 1- and 2-fen coins ceased in 1991, with that of the 5 fen halting in 1994. The small coins were still made for annual uncirculated mint sets in limited quantities, and from the beginning of 2005 the 1-fen coin got a new lease on life by being issued again every year since then up to present. New designs of the 1 and 5 jiao and 1 yuan were again introduced in between 1999 and 2002, with the 1 jiao being significantly reduced in size. In 2005, the metallic composition of the 1 jiao was changed from aluminum to more durable nickel-plated steel. The frequency of usage of coins varies between different parts of China, with coins typically being more popular in urban areas, and small notes being more popular in rural areas. Older fen and large jiao coins are uncommonly still seen in circulation but are still valid in exchange.\n\nAs of 2019, there have been five series of renminbi banknotes issued by the People's Republic of China:\n\nIn 1999, a commemorative red ¥50 note was issued in honor of the 50th anniversary of the establishment of the People's Republic of China. This note features Mao Zedong on the front and various animals on the back.\n\nAn orange polymer note, and so far, China's only polymer note, commemorating the new millennium was issued in 2000 with a face value of ¥100. This features a dragon on the obverse and the reverse features the China Millennium monument (at the Center for Cultural and Scientific Fairs).\n\nFor the 2008 Beijing Olympics, a green ¥10 note was issued featuring the Bird's Nest Stadium on the front with the back showing a classical Olympic discus thrower and various other athletes.\n\nOn 26 November 2015, the People's Bank of China issued a blue ¥100 commemorative note to commemorate aerospace science and technology.\n\nIn commemoration of the 70th Anniversary of the issuance of the Renminbi, the People's Bank of China issued 120 million ¥50 banknotes on December 28, 2018.\n\nThe renminbi yuan has different names when used in minority regions. \n\nRenminbi currency production is carried out by a state owned corporation, China Banknote Printing and Minting Corporation (CBPMC; ) headquartered in Beijing. CBPMC uses several printing, engraving and minting facilities around the country to produce banknotes and coins for subsequent distribution. Banknote printing facilities are based in Beijing, Shanghai, Chengdu, Xi'an, Shijiazhuang, and Nanchang. Mints are located in Nanjing, Shanghai, and Shenyang. Also, high grade paper for the banknotes is produced at two facilities in Baoding and Kunshan. The Baoding facility is the largest facility in the world dedicated to developing banknote material according to its website. In addition, the People's Bank of China has its own printing technology research division that researches new techniques for creating banknotes and making counterfeiting more difficult.\n\nOn 13 March 2006, some delegates to an advisory body at the National People's Congress proposed to include Sun Yat-sen and Deng Xiaoping on the renminbi banknotes. However, the proposal was not adopted.\n\nFor most of its early history, the RMB was pegged to the U.S. dollar at ¥2.46 per USD. During the 1970s, it was revalued until it reached ¥1.50 per USD in 1980. When China's economy gradually opened in the 1980s, the RMB was devalued in order to improve the competitiveness of Chinese exports. Thus, the official exchange rate increased from ¥1.50 in 1980 to ¥8.62 by 1994 (the lowest rate on record). Improving current account balance during the latter half of the 1990s enabled the Chinese government to maintain a peg of ¥8.27 per USD from 1997 to 2005.\n\nThe RMB reached a record high exchange value of ¥6.0395 to the U.S. dollar on 14 January 2014. Chinese leadership have been raising the yuan to tame inflation, a step U.S. officials have pushed for years to lower the massive trade deficit with China. Strengthening the value of the RMB also fits with the Chinese transition to a more consumer-led economic growth model. \nIn 2015 the People's Bank of China again devalued their country's currency. , the exchange rate for US$1 is ¥6.38.\n\nOn 21 July 2005, the peg was finally lifted, which saw an immediate one-time RMB revaluation to ¥8.11 per USD. The exchange rate against the euro stood at ¥10.07060 per euro.\n\nHowever the peg was reinstituted unofficially when the financial crisis hit: \"Under intense pressure from Washington, China took small steps to allow its currency to strengthen for three years starting in July 2005. But China 're-pegged' its currency to the dollar as the financial crisis intensified in July 2008.\"\n\nOn 19 June 2010, the People's Bank of China released a statement simultaneously in Chinese and English claiming that they would \"proceed further with reform of the RMB exchange rate regime and increase the RMB exchange rate flexibility\". The news was greeted with praise by world leaders including Barack Obama, Nicolas Sarkozy and Stephen Harper. The PBoC maintained there would be no \"large swings\" in the currency. The RMB rose to its highest level in five years and markets worldwide surged on Monday, 21 June following China's announcement.\n\nIn August 2015, Joseph Adinolfi, a reporter for MarketWatch, reported that China had re-pegged the RMB. In his article, he narrated that \"Weak trade data out of China, released over the weekend, weighed on the currencies of Australia and New Zealand on Monday. But the yuan didn’t budge. Indeed, the Chinese currency, also known as the renminbi, has been remarkably steady over the past month despite the huge selloff in China’s stock market and a spate of disappointing economic data. Market strategists, including Simon Derrick, chief currency strategist at BNY Mellon, and Marc Chandler, head currency strategist at Brown Brothers Harriman, said that is because China's policy makers have effectively re-pegged the yuan. “When I look at the dollar-renminbi right now, that looks like a fixed exchange rate again. They’ve re-pegged it,” Chandler said.\"\n\nThe RMB has now moved to a managed floating exchange rate based on market supply and demand with reference to a basket of foreign currencies. In July 2005, the daily trading price of the U.S. dollar against the RMB in the inter-bank foreign exchange market was allowed to float within a narrow band of 0.3% around the central parity published by the People's Bank of China; in a later announcement published on 18 May 2007, the band was extended to 0.5%. On 14 April 2012, the band was extended to 1.0%. On 17 March 2014, the band was extended to 2%. China has stated that the basket is dominated by the United States dollar, euro, Japanese yen and South Korean won, with a smaller proportion made up of the British pound, Thai baht, Russian ruble, Australian dollar, Canadian dollar and Singapore dollar.\n\nOn 10 April 2008, it traded at ¥6.9920 per US dollar, which was the first time in more than a decade that a dollar had bought less than seven yuan, and at 11.03630 yuan per euro.\n\nBeginning in January 2010, Chinese and non-Chinese citizens have an annual exchange limit of a maximum of US$50,000. Currency exchange will only proceed if the applicant appears in person at the relevant bank and presents their passport or Chinese ID. Currency exchange transactions are centrally registered. The maximum dollar withdrawal is $10,000 per day, the maximum purchase limit of USD is $500 per day. This stringent management of the currency leads to a bottled-up demand for exchange in both directions. It is viewed as a major tool to keep the currency peg, preventing inflows of \"hot money\".\n\nA shift of Chinese reserves into the currencies of their other trading partners has caused these nations to shift more of their reserves into dollars, leading to no great change in the value of the renminbi against the dollar.\n\nRenminbi futures are traded at the Chicago Mercantile Exchange. The futures are cash-settled at the exchange rate published by the People's Bank of China.\n\nScholarly studies suggest that the yuan is undervalued on the basis of purchasing power parity analysis. One 2011 study suggests a 37.5% undervaluation.\n\n\nThe People's Bank of China lowered the renminbi's daily fix to the US dollar by 1.9 per cent to ¥6.2298 on 11 August 2015. The People's Bank of China again lowered the renminbi's daily fix to the US dollar from ¥6.620 to ¥6.6375 after the Brexit on 27 June 2016. It had not been this low since December 2010.\n\nBefore 2009, the Chinese renminbi had little to no exposure in the international markets because of strict government controls by the central Chinese government that prohibited almost all export of the currency, or use of it in international transactions. Transactions between Chinese companies and a foreign entity were generally denominated in US dollars. With Chinese companies unable to hold US dollars and foreign companies unable to hold Chinese yuan, all transactions would go through the People's Bank of China. Once the sum was paid by the foreign party in dollars, the central bank would pass the settlement in renminbi to the Chinese company at the state-controlled exchange rate.\n\nIn June 2009 the Chinese officials announced a pilot scheme where business and trade transactions were allowed between limited businesses in Guangdong province and Shanghai, and only counterparties in Hong Kong, Macau, and select ASEAN nations. Proving a success, the program was further extended to 20 Chinese provinces and counterparties internationally in July 2010, and in September 2011 it was announced that the remaining 11 Chinese provinces would be included.\n\nIn steps intended to establish the renminbi as an international reserve currency, China has agreements with Russia, Vietnam, Sri Lanka, Thailand, and Japan, allowing trade with those countries to be settled directly in renminbi instead of requiring conversion to US dollars, with Australia and South Africa to follow soon.\n\nCurrency restrictions regarding renminbi-denominated bank deposits and financial products were greatly liberalized in July 2010. In 2010 renminbi-denominated bonds were reported to have been purchased by Malaysia's central bank and that McDonald's had issued renminbi denominated corporate bonds through Standard Chartered Bank of Hong Kong. Such liberalization allows the yuan to look more attractive as it can be held with higher return on investment yields, whereas previously that yield was virtually none. Nevertheless, some national banks such as Bank of Thailand (BOT) have expressed a serious concern about RMB since BOT cannot substitute the deprecated US dollars in its US$200 billion foreign exchange reserves for renminbi as much as it wishes because:\n\nTo meet IMF requirements, China gave up some of its tight control over the currency.\n\nCountries that are left-leaning in the political spectrum had already begun to use the renminbi as an alternative reserve currency to the United States dollar; the Central Bank of Chile reported in 2011 to have US$91 million worth of renminbi in reserves, and the president of the Central Bank of Venezuela, Nelson Merentes, made statements in favour of the renminbi following the announcement of reserve withdrawals from Europe and the United States. In Africa, the central banks of Ghana, Nigeria, and South Africa either hold RMB as a reserve currency or have taken steps to purchase bonds denominated in RMB.\n\nThe two special administrative regions, Hong Kong and Macau, have their own respective currencies, according to the \"one country, two systems\" principle and the basic laws of the two territories. Therefore, the Hong Kong dollar and the Macanese pataca remain the legal tenders in the two territories, and renminbi, although sometimes accepted, is not legal tender. Banks in Hong Kong allow people to maintain accounts in RMB. Because of changes in legislation in July 2010, many banks around the world are now slowly offering individuals the chance to hold deposits in Chinese renminbi.\n\nThe RMB had a presence in Macau even before the 1999 return to the People's Republic of China from Portugal. Banks in Macau can issue credit cards based on the renminbi, but not loans. Renminbi-based credit cards cannot be used in Macau's casinos.\n\nThe Republic of China, which governs Taiwan, believes wide usage of the renminbi would create an underground economy and undermine its sovereignty. Tourists are allowed to bring in up to ¥20,000 when visiting Taiwan. These renminbi must be converted to the New Taiwan dollar at trial exchange sites in Matsu and Kinmen. The Chen Shui-bian administration insisted that it would not allow full convertibility until the mainland signs a bilateral foreign exchange settlement agreement, though president Ma Ying-jeou has pledged to allow full convertibility as soon as possible.\n\nThe renminbi circulates in some of China's neighbors, such as Pakistan, Mongolia and northern Thailand. Cambodia welcomes the renminbi as an official currency and Laos and Myanmar allow it in border provinces such as Wa and Kokang and economic zones like Mandalay. Though unofficial, Vietnam recognizes the exchange of the renminbi to the đồng.\n\nSince 2007, RMB-nominated bonds are issued outside mainland China; these are colloquially called \"dim sum bonds\". In April 2011, the first initial public offering denominated in renminbi occurred in Hong Kong, when the Chinese property investment trust Hui Xian REIT raised ¥10.48 billion ($1.6 billion) in its IPO. Beijing has allowed renminbi-denominated financial markets to develop in Hong Kong as part of the effort to internationalise the renminbi.\n\nSince currency flows in and out of mainland China are still restricted, RMB traded in off-shore markets, such as the Hong Kong market, can have a different value to RMB traded on the mainland. The offshore RMB market is usually denoted as CNH, but there is another RMB interbank and spot market in Taiwan for domestic trading known as CNT.\n\nOther RMB markets include the dollar-settled non-deliverable forward (NDF), and the trade-settlement exchange rate (CNT).\n\nNote that the two CNTs mentioned above are different from each other.\n\n"}
{"id": "228246", "url": "https://en.wikipedia.org/wiki?curid=228246", "title": "Rupee", "text": "Rupee\n\nRupee is the common name for the currencies of India, Pakistan, Indonesia, the Maldives, Mauritius, Nepal, Seychelles, and Sri Lanka, and of former currencies of Afghanistan, Tibet, Burma, British East Africa, German East Africa, the Trucial States, and all Arab states of the Persian Gulf (as the Gulf rupee). In Indonesia and the Maldives the unit of currency is known as \"rupiah\" and \"rufiyaa\" respectively. \n\nThe Indian rupees () and Pakistani rupees () are subdivided into one hundred paise (singular \"paisa\") or pice. The Mauritian, Seychellois, and Sri Lankan rupees subdivide into 100 cents. The Nepalese rupee subdivides into one hundred paisa (singular and plural) or four Sukaas.\n\nThe immediate precursor of the Rupee is the \"Rūpiya\"—the silver coin weighing 178 grains (11.53 grams) minted in northern India by first Sher Shah Suri during his brief rule between 1540 and 1545 and adopted and standardized later by the Mughal Empire. The weight remained unchanged well beyond the end of the Mughals till the 20th century.\n\nThe Hindi-Urdu word \"rūpaya\" is derived from the Sanskrit word \"rūpya\", which means \"wrought silver, a coin of silver\", in origin an adjective meaning \"shapely\", with a more specific meaning of \"stamped, impressed\", whence \"coin\". It is derived from the noun \"rūpa\" \"shape, likeness, image\". The word \"rūpa\" is further identified as related to the Dravidian root \"uruppu\", which means \"a member of the body\". Also, the word \"rūpam\" is rooted in Tamil as \"uru\" (shape) derived from \"ur\" (form) which itself is rooted in \"ul\" meaning \"appear\".\n\nThe history of the rupee traces back to Ancient India circa 3rd century BC. Ancient India was one of the earliest issuers of coins in the world, along with the Lydian staters, several other Middle Eastern coinages and the Chinese wen.\nThe term is from \"rūpya\", a Sanskrit term for silver coin, from Sanskrit \"rūpa\", beautiful form.\n\n\"Arthashastra\", written by Chanakya, prime minister to the first Maurya emperor Chandragupta Maurya (c. 340–290 BCE), mentions silver coins as \"rūpyarūpa\", other types including gold coins (\"suvarṇarūpa\"), copper coins (\"tāmrarūpa\") and lead coins (\"sīsarūpa\") are mentioned. \"Rūpa\" means form or shape, example, \"rūpyarūpa\", \"rūpya\" – wrought silver, \"rūpa\" – form.\n\nIn the intermediate times there was no fixed monetary system as reported by the \"Da Tang Xi Yu Ji\".\n\nSher Shah Suri (1540–1545), re-introduced the silver coin \"rupiya\", weighing 178 grains. Its use was continued by the Mughal rulers. Suri also introduced copper coins called \"dam\" and gold coins called \"mohur\" that weighed 169 grains (10.95 g).\n\nBoth the Kabuli rupee and the Kandahari rupee were used as currency in Afghanistan prior to 1891, when they were standardized as the Afghan rupee. The Afghan rupee, which was subdivided into 60 paisas, was replaced by the Afghan afghani in 1925.\n\nUntil the middle of the 20th century, Tibet's official currency was also known as the Tibetan rupee.\n\nEarly 19th-century East India Company rupees were used in Australia for a limited period.\n\nThe Indian rupee was the official currency of Dubai and Qatar until 1959, when India created a new Gulf rupee (also known as the \"external rupee\") to hinder the smuggling of gold. The Gulf rupee was legal tender until 1966, when India significantly devalued the Indian rupee and a new Qatar-Dubai riyal was established to provide economic stability.\n\nIn East Africa, Arabia, and Mesopotamia, the rupee and its subsidiary coinage was current at various times. The usage of the rupee in East Africa extended from Somalia in the north to as far south as Natal. In Mozambique, the British India rupees were overstamped, and in Kenya, the British East Africa Company minted the rupee and its fractions, as well as pice.\n\nThe rise in the price of silver immediately after the First World War caused the rupee to rise in value to two shillings sterling. In 1920 in British East Africa, the opportunity was then taken to introduce a new florin coin, hence bringing the currency into line with sterling. Shortly after that, the florin was split into two East African shillings. This assimilation to sterling did not, however, happen in British India itself. In Somalia, the Italian colonial authority minted 'rupia' to exactly the same standard and called the \"pice\" 'besa'.\n\nThe Straits Settlements were originally an outlier of the British East India Company. The Spanish dollar had already taken hold in the Straits Settlements by the time the British arrived in the 19th century. The East India Company tried to introduce the rupee in its place. These attempts were resisted by the locals, and by 1867 when the British government took over direct control of the Straits Settlements from the East India Company, attempts to introduce the rupee were finally abandoned.\n\nFormerly, the rupee (11.66 g, .917 fine silver) was divided into 16 annas, 64 paise, or 192 pies. Each circulating coin of British India, until the rupee was decimalised, had a different name in practice. A paisa was equal to two \"dhelas\", three \"pies\", or six \"damaris\". Other coins for half anna (\"adhanni\", or two paisas), two annas (\"duanni\"), four annas (a \"chawanni\", or a quarter of a rupee), and eight annas (an \"athanni\", or half a rupee) were widely in use until decimalization in 1961. (The numbers \"adha\", \"do\", \"chār\", \"ātha\" mean respectively half, two, four, eight in Hindi and Urdu.) Two \"paisa\" was also called a \"taka\", see below. \n\nIn India presently (from 2010 onwards), the 50 paise coin (half a rupee) is the lowest valued legal tender. Coins of 1, 2, 5, and 10 rupees and banknotes of 5, 10, 20, 50, 100, 200, 500, and 2000 rupees are commonly in use for cash transaction. \n\nDecimalisation occurred in Ceylon (Sri Lanka) in 1969, in India in 1957, and in Pakistan in 1961. Since 1957 an Indian rupee is divided into 100 paise. The decimalized paisa was originally officially named \"naya paisa\" meaning the \"new paisa\" to distinguish it from the erstwhile paisa which had a higher value of rupee. The word \"naya\" was dropped in 1964 and since then it is simply known as \"paisa\" (plural \"paise\"). The issuance of the Indian currency is controlled by the Reserve Bank of India, whereas in Pakistan it is controlled by State Bank of Pakistan. The most commonly used symbol for the rupee is \"Rs\". India adopted a new symbol () for the Indian rupee on 15 July 2010.\n\nIn most parts of India, the rupee is known as rupaya, rupaye, or one of several other terms derived from the Sanskrit \"rūpya\", meaning silver. \n\n\"Ṭaṅka\" is an ancient Sanskrit word for money. While the two-paise coin was called a \"taka\" in West Pakistan, the word \"taka\" was commonly used in East Pakistan (now Bangladesh), alternatively for rupee. In the Bengali and Assamese languages, spoken in Assam, Tripura, and West Bengal, the rupee is known as a \"taka\", and is written as such on Indian banknotes. In Odisha it is known as \"tanka\". After its independence, Bangladesh started to officially call its currency \"taka\" (BDT) in 1971.\n\nLarge denominations of rupees are often counted in lac/lakh (100,000 = 1 lac/lakh, 100 lac/lakh = 1 crore/karor, 100 crore/karor = 1 arab, 100 arab = 1 kharab/khrab, 100 Kharab/khrab = 1 nil/neel, 100 nil/neel = 1 padma, 100 padma = 1 shankh, 100 shankh = 1 udpadha, 100 udpadha = 1 ank). Terms beyond a crore are not generally used in the context of money, e.g. an amount would be called Rs 1 lakh crore (equivalent to 1 trillion) instead of Rs 10 kharab.\n\nThe rupee sign “₨” is a currency sign used to represent the monetary unit of account in Pakistan, Sri Lanka, Nepal, Mauritius, Seychelles, and formerly in India. It resembles, and is often written as, the Latin character sequence “Rs” or “Rs.”. Currency signs exist for other countries that use the rupee but not this sign: their usage is also described at the main article.\n\nIn latin script, \"rupee\" (singular) is abbreviated as Re. and \"rupees\" (plural) as Rs. The Indonesian \"rupiah\" is abbreviated Rp. In 19th century typography, abbreviations are often superscripted: formula_1 or formula_2. In Brahmic scripts, rupee is often abbreviated with the grapheme for the first syllable, optionally followed by a circular abbreviation mark or a latin abbreviation point: रु૰ (Devanagari \"ru.\"), રૂ૰ (Gujarati \"ru.\"), රු (Sinhala \"ru\"), రూ (Telugu \"rū\").\n\nThe history of the rupees can be traced back to Ancient India around the 6th century BC. Ancient India had some of the earliest coins in the world, along with the Chinese wen and Lydian staters.\nThe rupee coin has been used since then, even during British India, when it contained 11.66 g (1 tola) of 91.7% silver with an ASW of 0.3437 of a troy ounce (that is, silver worth about US$10 at modern prices). At the end of the 19th century, the Indian silver rupee went onto a gold exchange standard at a fixed rate of one rupee to one shilling and fourpence in British currency, i.e. 15 rupees to 1 pound sterling.\n\nValuation of the rupee based on its silver content had severe consequences in the 19th century, when the strongest economies in the world were on the gold standard. The discovery of vast quantities of silver in the United States and various European colonies resulted in a decline in the value of silver relative to gold.\n\n"}
{"id": "18717338", "url": "https://en.wikipedia.org/wiki?curid=18717338", "title": "United States dollar", "text": "United States dollar\n\nThe United States dollar (sign: $; code: USD; also abbreviated US$ and referred to as the dollar, U.S. dollar, or American dollar) is the official currency of the United States and its territories per the Coinage Act of 1792. One dollar is divided into 100 cents (Symbol: ¢) or 1000 mills (for accounting purposes and for taxing. Symbol: ₥). The Coinage Act of 1792 created a decimal currency by creating the following coins: tenth dollar, one-twentieth dollar, one-hundredth dollar. In addition the act created the dollar, half dollar, and quarter dollar coins. All of these coins are still minted in 2020.\n\nIn addition, several forms of paper money were introduced by Congress over the years. The latest of these, the Federal Reserve Note, was authorized by the Federal Reserve Act of 1913, while all existing U.S. currency remains legal tender.\nIssuance of the previous form of the currency (U.S. notes) was discontinued in January 1971. As a result, currently circulating paper money consists primarily of Federal Reserve Notes that are denominated in United States dollars (). \n\nSince the suspension in 1971 of convertibility of paper U.S. currency into any precious metal, the U.S. dollar is \"de facto\" fiat money. As it is the most used in international transactions, the U.S. dollar is the world's primary reserve currency. Several countries use it as their official currency, and in many others it is the \"de facto\" currency. Besides the United States, it is also used as the sole currency in two British Overseas Territories in the Caribbean: the British Virgin Islands and Turks and Caicos Islands. A few countries use the Federal Reserve Notes for paper money, while still minting their own coins, or also accept U.S. dollar coins (such as the Sacagawea or presidential dollar). As of January 31, 2019, there are approximately $1.7 trillion in circulation, of which $1.65 trillion is in Federal Reserve Notes (the remaining $50 billion is in the form of U.S. notes and coins).\n\nThe U.S. dollar as a currency is often referred to as the greenback by foreign exchange traders and the financial press in other countries, such as Australia, New Zealand, South Africa, and India.\n\nArticle I, of the U.S. Constitution provides that the Congress has the power \"To coin money\". Laws implementing this power are currently codified at . Section 5112 prescribes the forms in which the United States dollars should be issued. These coins are both designated in Section 5112 as \"legal tender\" in payment of debts. The Sacagawea dollar is one example of the copper alloy dollar. The pure silver dollar is known as the American Silver Eagle. Section 5112 also provides for the minting and issuance of other coins, which have values ranging from one cent to 100 dollars. These other coins are more fully described in Coins of the United States dollar.\n\nThe Constitution provides that \"a regular Statement and Account of the Receipts and Expenditures of all public Money shall be published from time to time\". That provision of the Constitution is made specific by Section 331 of Title 31 of the United States Code. The sums of money reported in the \"Statements\" are currently being expressed in U.S. dollars (for example, see the \"2009 Financial Report of the United States Government\"). The U.S. dollar may therefore be described as the unit of account of the United States.\n\nThe word \"dollar\" is one of the words in the first paragraph of Section 9 of Article I of the Constitution. There, \"dollars\" is a reference to the Spanish milled dollar, a coin that had a monetary value of 8 Spanish units of currency, or reales. In 1792 the U.S. Congress passed a Coinage Act. Section 9 of that act authorized the production of various coins, including \"DOLLARS OR UNITS—each to be of the value of a Spanish milled dollar as the same is now current, and to contain three hundred and seventy-one grains and four sixteenth parts of a grain of pure, or four hundred and sixteen grains of standard silver\". Section 20 of the act provided, \"That the money of account of the United States shall be expressed in dollars, or units... and that all accounts in the public offices and all proceedings in the courts of the United States shall be kept and had in conformity to this regulation\". In other words, this act designated the United States dollar as the \"unit of currency\" of the United States.\n\nUnlike the Spanish milled dollar, the U.S. dollar has been based upon a decimal system of values since the time of the Continental Congress. This decimal system was again described in the Coinage Act of 1792: in addition to the dollar, the Act officially established monetary units of \"mill\" or one-thousandth of a dollar (symbol ₥), \"cent\" or one-hundredth of a dollar (symbol ¢), \"dime\" or one-tenth of a dollar, and \"eagle\" or ten dollars, with prescribed weights and composition of gold, silver, or copper for each. It was proposed in the mid-1800s that one hundred dollars be known as a \"union\", but no union coins were ever struck and only patterns for the $50 half union exist. However, only cents are in everyday use as divisions of the dollar; \"dime\" is used solely as the name of the coin with the value of 10¢, while \"eagle\" and \"mill\" are largely unknown to the general public, though mills are sometimes used in matters of tax levies, and gasoline prices are usually in the form of $X.XX9 per gallon, e.g., $3.599, more commonly written as $3.59. When currently issued in circulating form, denominations equal to or less than a dollar are emitted as U.S. coins while denominations equal to or greater than a dollar are emitted as Federal Reserve Notes (with the exception of gold, silver, platinum and palladium coins valued up to $100 as legal tender, but worth far more as bullion). Both one-dollar coins and notes are produced today, although the note form is significantly more common. In the past, \"paper money\" was occasionally issued in denominations less than a dollar (fractional currency) and gold coins were issued for circulation up to the value of $20 (known as the \"double eagle\", discontinued in the 1930s). The term \"eagle\" was used in the Coinage Act of 1792 for the denomination of ten dollars, and subsequently was used in naming gold coins. Paper currency less than one dollar in denomination, known as \"fractional currency\", was also sometimes pejoratively referred to as \"shinplasters\". In 1854, James Guthrie, then Secretary of the Treasury, proposed creating $100, $50 and $25 gold coins, which were referred to as a \"Union\", \"Half Union\", and \"Quarter Union\", thus implying a denomination of 1 Union = $100.\n\nToday, USD notes are made from cotton fiber paper, unlike most common paper, which is made of wood fiber. U.S. coins are produced by the United States Mint. U.S. dollar banknotes are printed by the Bureau of Engraving and Printing and, since 1914, have been issued by the Federal Reserve. The \"large-sized notes\" issued before 1928 measured ; small-sized notes, introduced that year, measure . When the current, smaller sized U.S. currency was introduced it was referred to as \"Philippine-sized currency\" because the Philippines had previously adopted the same size for its legal currency, the Philippine peso.\n\nIn the 16th century, Count Hieronymus Schlick of Bohemia began minting coins known as \"Joachimstalers\", named for Joachimstal, the valley where the silver was mined. The German word for valley is \"thal\", or nowadays usually \"Tal\" (cognate with \"dale\" in English). St. Joachim's Valley is now known as Jáchymov, in the Czech Republic (then part of the Kingdom of Bohemia). Joachimstaler was later shortened to the German \"Taler\", a word that eventually found its way into many languages, including Danish and Swedish as \"daler\", Norwegian as \"dalar\" and \"daler\", Dutch as \"daler\" or \"daalder\", Ethiopian as \"talari\", Hungarian as \"tallér\", Italian as \"tallero\", and English as \"dollar\". Alternatively, \"thaler\" is said to come from the German coin \"Guldengroschen\" (\"great guilder\", being of silver but equal in value to a gold guilder), minted from the silver from Joachimsthal.\n\nThe coins minted at Joachimsthal soon lent their name to other coins of similar size and weight from other places. One such example, was a Dutch coin depicting a lion, hence its Dutch name \"leeuwendaler\" (in English: \"lion dollar\").\n\nThe \"leeuwendaler\" was authorized to contain 427.16 grains of .75 fine silver and passed locally for between 36 and 42 stuivers. It was lighter than the large-denomination coins then in circulation, thus it was more advantageous for a Dutch merchant to pay a foreign debt in leeuwendalers and it became the coin of choice for foreign trade.\n\nThe \"leeuwendaler\" was popular in the Dutch East Indies and in the Dutch North American New Netherland Colony (today the New York metropolitan area), and circulated throughout the Thirteen Colonies during the 17th and early 18th centuries. It was also separately popular throughout Eastern Europe, where it led to the current Romanian and Moldovan currency being called leu (literally \"lion\").\n\nAmong the English-speaking community, the Dutch coin came to be popularly known as lion dollar – and is the origin of the English \"dollar\". The modern American-English pronunciation of \"dollar\" is still remarkably close to the 17th-century Dutch pronunciation of \"daler\".\n\nBy analogy with this lion dollar, Spanish pesos – with the same weight and shape as the lion dollar – came to be known as \"Spanish\" dollars. By the mid-18th century, the lion dollar had been replaced by the Spanish dollar, the famous \"piece of eight\", which was distributed widely in the Spanish colonies in the New World and in the Philippines.\nEventually, dollar became the name of the official American currency.\n\nThe colloquialism \"\"\"(s) (much like the British word \"quid\"\"(s, pl) for the pound sterling) is often used to refer to dollars of various nations, including the U.S. dollar. This term, dating to the 18th century, may have originated with the colonial leather trade. It may also have originated from a poker term.\n\n\"\"Greenback\"\" is another nickname originally applied specifically to the 19th-century Demand Note dollars created by Abraham Lincoln to finance the costs of the Civil War for the North. The original note was printed in black and green on the back side. It is still used to refer to the U.S. dollar (but not to the dollars of other countries). Other well-known names of the dollar as a whole in denominations include \"\"greenmail\", \"green\" and \"dead presidents\" (the last because deceased presidents are pictured on most bills).\n\nThe term \"greenback\" is also used by foreign exchange traders with reference to the U.S. dollar as a currency, and by the financial press in other countries, such as Australia, New Zealand, South Africa, and India.\n\nA \"grand\", sometimes shortened to simply \"G\", is a common term for the amount of $1,000. The suffix \"K\" or \"k\"\" (from \"kilo-\") is also commonly used to denote this amount (such as \"$10k\" to mean $10,000). However, the $1,000 note is no longer in general use. A \"\"large\" or \"stack\", it is usually a reference to a multiple of $1,000 (such as \"fifty large\" meaning $50,000). The $100 note is nicknamed \"Benjamin\", \"Benji\", \"Ben\", or \"Franklin\" (after Benjamin Franklin), \"C-note\" (C being the Roman numeral for 100), \"Century note\" or \"bill\" (e.g. \"two bills\" being $200). The $50 note is occasionally called a \"yardstick\" or a \"grant\" (after President Ulysses S. Grant, pictured on the obverse). The $20 note is referred to as a \"double sawbuck\", \"Jackson\"\" (after Andrew Jackson), or \"double eagle\". The $10 note is referred to as a \"\"sawbuck\", \"ten-spot\" or \"Hamilton\" (after Alexander Hamilton). The $5 note as \"Lincoln\", \"fin\", \"fiver\" or \"five-spot\". The infrequently-used $2 note is sometimes called \"deuce\", \"Tom\", or \"Jefferson\" (after Thomas Jefferson). The $1 note as a \"single\" or \"buck\". The dollar has also been referred to as a \"bone\" and \"bones\" in plural (e.g. \"twenty bones\" is equal to $20). The newer designs, with portraits displayed in the main body of the obverse (rather than in cameo insets), upon paper color-coded by denomination, are sometimes referred to as \"bigface\"\" notes or \"Monopoly money\".\n\n\"Piastre\" was the original French word for the U.S. dollar, used for example in the French text of the Louisiana Purchase. Calling the dollar a piastre is still common among the speakers of Cajun French and New England French. Modern French uses \"dollar\" for this unit of currency as well. The term is still used as slang for U.S. dollars in the French-speaking Caribbean islands, most notably Haiti.\n\nThe symbol $, usually written before the numerical amount, is used for the U.S. dollar (as well as for many other currencies). The sign was the result of a late 18th-century evolution of the scribal abbreviation \"p\" for the peso, the common name for the Spanish dollars that were in wide circulation in the New World from the 16th to the 19th centuries. These Spanish pesos or dollars were minted in Spanish America, namely in Mexico City; Potosí, Bolivia; and Lima, Peru. The \"p\" and the \"s\" eventually came to be written over each other giving rise to \"$\".\n\nAnother popular explanation is that it is derived from the Pillars of Hercules on the Spanish Coat of arms of the Spanish dollar. These Pillars of Hercules on the silver Spanish dollar coins take the form of two vertical bars (||) and a swinging cloth band in the shape of an \"S\".\n\nYet another explanation suggests that the dollar sign was formed from the capital letters U and S written or printed one on top of the other. This theory, popularized by novelist Ayn Rand in \"Atlas Shrugged\", does not consider the fact that the symbol was already in use before the formation of the United States.\n\nThe American dollar coin was initially based on the value and look of the Spanish dollar or \"piece of eight\", used widely in Spanish America from the 16th to the 19th centuries. The first dollar coins issued by the United States Mint (founded 1792) were similar in size and composition to the Spanish dollar, minted in Mexico and Peru. The Spanish, U.S. silver dollars, and later, Mexican silver pesos circulated side by side in the United States, and the Spanish dollar and Mexican peso remained legal tender until the Coinage Act of 1857. The coinage of various English colonies also circulated. The lion dollar was popular in the Dutch New Netherland Colony (New York), but the lion dollar also circulated throughout the English colonies during the 17th century and early 18th century. Examples circulating in the colonies were usually worn so that the design was not fully distinguishable, thus they were sometimes referred to as \"dog dollars\".\n\nOn the 6th of July 1785, the Continental Congress resolved that the money unit of the United States, the dollar, would contain 375.64 grains of fine silver; on the 8th of August 1786, the Continental Congress continued that definition and further resolved that the money of account, corresponding with the division of coins, would proceed in a decimal ratio, with the sub-units being mills at 0.001 of a dollar, cents at 0.010 of a dollar, and dimes at 0.100 of a dollar.\n\nAfter the adoption of the United States Constitution, the U.S. dollar was defined by the Coinage Act of 1792, which specified a \"dollar\" to be based in the Spanish milled dollar and of 371 grains and 4 sixteenths part of a grain of pure or of standard silver and an \"eagle\" to be 247 and 4 eighths of a grain or of gold (again depending on purity). The choice of the value 371 grains arose from Alexander Hamilton's decision to base the new American unit on the average weight of a selection of worn Spanish dollars. Hamilton got the treasury to weigh a sample of Spanish dollars and the average weight came out to be 371 grains. A new Spanish dollar was usually about 377 grains in weight, and so the new U.S. dollar was at a slight discount in relation to the Spanish dollar.\n\nThe same coinage act also set the value of an eagle at 10 dollars, and the dollar at eagle. It called for 90% silver alloy coins in denominations of 1, , , , and dollars; it called for 90% gold alloy coins in denominations of 1, , , and eagles. The value of gold or silver contained in the dollar was then converted into relative value in the economy for the buying and selling of goods. This allowed the value of things to remain fairly constant over time, except for the influx and outflux of gold and silver in the nation's economy.\n\nThe early currency of the United States did not exhibit faces of presidents, as is the custom now; although today, by law, only the portrait of a deceased individual may appear on United States currency. In fact, the newly formed government was against having portraits of leaders on the currency, a practice compared to the policies of European monarchs. The currency as we know it today did not get the faces they currently have until after the early 20th century; before that \"heads\" side of coinage used profile faces and striding, seated, and standing figures from Greek and Roman mythology and composite Native Americans. The last coins to be converted to profiles of historic Americans were the dime (1946) and the Dollar (1971).\n\nFor articles on the currencies of the colonies and states, see Connecticut pound, Delaware pound, Georgia pound, Maryland pound, Massachusetts pound, New Hampshire pound, New Jersey pound, New York pound, North Carolina pound, Pennsylvania pound, Rhode Island pound, South Carolina pound, and Virginia pound.\n\nDuring the American Revolution the thirteen colonies became independent states. Freed from British monetary regulations, they each issued £sd paper money to pay for military expenses. The Continental Congress also began issuing \"Continental Currency\" denominated in Spanish dollars. The dollar was valued relative to the states' currencies at the following rates:\n\nContinental currency depreciated badly during the war, giving rise to the famous phrase \"not worth a continental\". A primary problem was that monetary policy was not coordinated between Congress and the states, which continued to issue bills of credit. Additionally, neither Congress nor the governments of the several states had the will or the means to retire the bills from circulation through taxation or the sale of bonds. The currency was ultimately replaced by the silver dollar at the rate of 1 silver dollar to 1000 continental dollars.\n\nFrom 1792, when the Mint Act was passed, the dollar was defined as 371.25 grains (24.056 g) of silver. The gold coins that were minted were not given any denomination and traded for a market value relative to the Congressional standard of the silver dollar. 1834 saw a shift in the gold standard to , followed by a slight adjustment to in 1837 (16:1 ratio).\n\nIn 1862, paper money was issued without the backing of precious metals, due to the Civil War. Silver and gold coins continued to be issued and in 1878 the link between paper money and coins was reinstated. This disconnection from gold and silver backing also occurred during the War of 1812. The use of paper money not backed by precious metals had also occurred under the Articles of Confederation from 1777 to 1788. With no solid backing and being easily counterfeited, the continentals quickly lost their value, giving rise to the phrase \"not worth a continental\". This was a primary reason for the \"No state shall... make any thing but gold and silver coin a tender in payment of debts\" clause in of the United States Constitution.\n\nIn order to finance the War of 1812, Congress authorized the issuance of Treasury Notes, interest-bearing short-term debt that could be used to pay public dues. While they were intended to serve as debt, they did function \"to a limited extent\" as money. Treasury Notes were again printed to help resolve the reduction in public revenues resulting from the Panic of 1837 and the Panic of 1857, as well as to help finance the Mexican–American War and the Civil War.\n\nIn addition to Treasury Notes, in 1861, Congress authorized the Treasury to borrow $50 million in the form of Demand Notes, which did not bear interest but could be redeemed on demand for precious metals. However, by December 1861, the Union government's supply of specie was outstripped by demand for redemption and they were forced to suspend redemption temporarily. The following February, Congress passed the Legal Tender Act of 1862, issuing United States Notes, which were not redeemable on demand and bore no interest, but were legal tender, meaning that creditors had to accept them at face value for any payment except for public debts and import tariffs. However, silver and gold coins continued to be issued, resulting in the depreciation of the newly printed notes through Gresham's Law. In 1869, Supreme Court ruled in Hepburn v. Griswold that Congress could not require creditors to accept United States Notes, but overturned that ruling the next year in the Legal Tender Cases. In 1875, Congress passed the Specie Payment Resumption Act, requiring the Treasury to allow US Notes to be redeemed for gold after January 1, 1879. The Treasury ceased to issue United States Notes in 1971.\n\nThe Gold Standard Act of 1900 abandoned the bimetallic standard and defined the dollar as of gold, equivalent to setting the price of 1 troy ounce of gold at $20.67. Silver coins continued to be issued for circulation until 1964, when all silver was removed from dimes and quarters, and the half dollar was reduced to 40% silver. Silver half dollars were last issued for circulation in 1970. Gold coins were confiscated by Executive Order 6102 issued in 1933 by Franklin Roosevelt. The gold standard was changed to , equivalent to setting the price of 1 troy ounce of gold at $35. This standard persisted until 1968.\n\nBetween 1968 and 1975, a variety of pegs to gold were put in place, eventually culminating in a sudden end, on August 15, 1971, to the convertibility of dollars to gold later dubbed the Nixon Shock. The last peg was $42.22 per ounce before the U.S. dollar was allowed to freely float on currency markets.\n\nAccording to the Bureau of Engraving and Printing, the largest note it ever printed was the $100,000 Gold Certificate, Series 1934. These notes were printed from December 18, 1934, through January 9, 1935, and were issued by the Treasurer of the United States to Federal Reserve Banks only against an equal amount of gold bullion held by the Treasury. These notes were used for transactions between Federal Reserve Banks and were not circulated among the general public.\n\nOfficial United States coins have been produced every year from 1792 to the present.\n\nDiscontinued and canceled coin denominations include:\n\n\nCollector coins for which everyday transactions are non-existent.\n\n\nTechnically, all these coins are still legal tender at face value, though some are far more valuable today for their numismatic value, and for gold and silver coins, their precious metal value. From 1965 to 1970 the Kennedy half dollar was the only \"circulating\" coin with any silver content, which was removed in 1971 and replaced with cupronickel. However, since 1992, the U.S. Mint has produced special Silver Proof Sets in addition to the regular yearly proof sets with silver dimes, quarters, and half dollars in place of the standard copper-nickel versions.\nIn addition, an experimental $4.00 (Stella) coin was also minted in 1879, but never placed into circulation, and is properly considered to be a pattern rather than an actual coin denomination.\n\nThe $50 coin mentioned was only produced in 1915 for the Panama-Pacific International Exposition (1915) celebrating the opening of the Panama Canal. Only 1,128 were made, 645 of which were octagonal; this remains the only U.S. coin that was not round as well as the largest and heaviest U.S. coin ever produced.\n\nA $100 gold coin was produced in High relief during 2015, although it was primarily produced for collectors, not for general circulation.\n\nFrom 1934 to present, the only denominations produced for circulation have been the familiar penny, nickel, dime, quarter, half dollar and dollar. The nickel is the only coin still in use today that is essentially unchanged (except in its design) from its original version. Every year since 1866, the nickel has been 75% copper and 25% nickel, except for 4 years during World War II when nickel was needed for the war.\n\nDue to the penny's low value, some efforts have been made to eliminate the penny as circulating coinage.\n\nThe United States Mint produces Proof Sets specifically for collectors and speculators. \"Silver Proofs\" tend to be the standard designs but with the dime, quarter, and half dollar containing 90% silver. Starting in 1983 and ending in 1997, the Mint also produced proof sets containing the year's commemorative coins alongside the regular coins. Another type of proof set is the Presidential Dollar Proof Set where four special $1 coins are minted each year featuring a president. Because of budget constraints and increasing stockpiles of these relatively unpopular coins, the production of new Presidential dollar coins for circulation was suspended on December 13, 2011, by U.S. Treasury Secretary Timothy F. Geithner. Presidential dollars (along with all other dollar coin series) minted from 2012 onward were made solely for collectors.\n\n\nThe first United States dollar was minted in 1794. Known as the Flowing Hair Dollar, it contained 416 grains of \"standard silver\" (89.25% silver and 10.75% copper), as specified by Section 13 of the Coinage Act of 1792. It was designated by Section 9 of that Act as having \"the value of a Spanish milled dollar\".\n\nDollar coins have not been very popular in the United States. Silver dollars were minted intermittently from 1794 through 1935; a copper-nickel dollar of the same large size, featuring President Dwight D. Eisenhower, was minted from 1971 through 1978. Gold dollars were also minted in the 19th century. The Susan B. Anthony dollar coin was introduced in 1979; these proved to be unpopular because they were often mistaken for quarters, due to their nearly equal size, their milled edge, and their similar color. Minting of these dollars for circulation was suspended in 1980 (collectors' pieces were struck in 1981), but, as with all past U.S. coins, they remain legal tender. As the number of Anthony dollars held by the Federal Reserve and dispensed primarily to make change in postal and transit vending machines had been virtually exhausted, additional Anthony dollars were struck in 1999. In 2000, a new dollar coin featuring Sacagawea was introduced, which corrected some of the problems of the Anthony dollar by having a smooth edge and a gold color, without requiring changes to vending machines that accept the Anthony dollar. However, this new coin has failed to achieve the popularity of the still-existing dollar bill and is rarely used in daily transactions. The failure to simultaneously withdraw the dollar bill and weak publicity efforts have been cited by coin proponents as primary reasons for the failure of the dollar coin to gain popular support.\n\nIn February 2007, the U.S. Mint, under the Presidential $1 Coin Act of 2005, introduced a new $1 U.S. Presidential dollar coin. Based on the success of the \"50 State Quarters\" series, the new coin features a sequence of presidents in order of their inaugurations, starting with George Washington, on the obverse side. The reverse side features the Statue of Liberty. To allow for larger, more detailed portraits, the traditional inscriptions of \"E Pluribus Unum\", \"In God We Trust\", the year of minting or issuance, and the mint mark will be inscribed on the edge of the coin instead of the face. This feature, similar to the edge inscriptions seen on the British £1 coin, is not usually associated with U.S. coin designs. The inscription \"Liberty\" has been eliminated, with the Statue of Liberty serving as a sufficient replacement. In addition, due to the nature of U.S. coins, this will be the first time there will be circulating U.S. coins of different denominations with the same president featured on the obverse (heads) side (Lincoln/penny, Jefferson/nickel, Franklin D. Roosevelt/dime, Washington/quarter, Kennedy/half dollar, and Eisenhower/dollar). Another unusual fact about the new $1 coin is Grover Cleveland will have two coins with two different portraits issued due to the fact he was the only U.S. President to be elected to two non-consecutive terms.\n\nEarly releases of the Washington coin included error coins shipped primarily from the Philadelphia mint to Florida and Tennessee banks. Highly sought after by collectors, and trading for as much as $850 each within a week of discovery, the error coins were identified by the absence of the edge impressions \"E PLURIBUS UNUM IN GOD WE TRUST 2007 P\". The mint of origin is generally accepted to be mostly Philadelphia, although identifying the source mint is impossible without opening a mint pack also containing marked units. Edge lettering is minted in both orientations with respect to \"heads\", some amateur collectors were initially duped into buying \"upside down lettering error\" coins. Some cynics also erroneously point out that the Federal Reserve makes more profit from dollar bills than dollar coins because they wear out in a few years, whereas coins are more permanent. The fallacy of this argument arises because new notes printed to replace worn out notes, which have been withdrawn from circulation, bring in no net revenue to the government to offset the costs of printing new notes and destroying the old ones. As most vending machines are incapable of making change in banknotes, they commonly accept only $1 bills, though a few will give change in dollar coins.\n\nThe U.S. Constitution provides that Congress shall have the power to \"borrow money on the credit of the United States\". Congress has exercised that power by authorizing Federal Reserve Banks to issue Federal Reserve Notes. Those notes are \"obligations of the United States\" and \"shall be redeemed in lawful money on demand at the Treasury Department of the United States, in the city of Washington, District of Columbia, or at any Federal Reserve bank\". Federal Reserve Notes are designated by law as \"legal tender\" for the payment of debts. Congress has also authorized the issuance of more than 10 other types of banknotes, including the United States Note and the Federal Reserve Bank Note. The Federal Reserve Note is the only type that remains in circulation since the 1970s.\n\nCurrently printed denominations are $1, $2, $5, $10, $20, $50, and $100. Notes above the $100 denomination stopped being printed in 1946 and were officially withdrawn from circulation in 1969. These notes were used primarily in inter-bank transactions or by organized crime; it was the latter usage that prompted President Richard Nixon to issue an executive order in 1969 halting their use. With the advent of electronic banking, they became less necessary. Notes in denominations of $500, $1,000, $5,000, $10,000, and $100,000 were all produced at one time; see large denomination bills in U.S. currency for details. With the exception of the $100,000 bill (which was only issued as a Series 1934 Gold Certificate and was never publicly circulated; thus it is illegal to own), these notes are now collectors' items and are worth more than their face value to collectors.\n\nThough still predominantly green, post-2004 series incorporate other colors to better distinguish different denominations. As a result of a 2008 decision in an accessibility lawsuit filed by the American Council of the Blind, the Bureau of Engraving and Printing is planning to implement a raised tactile feature in the next redesign of each note, except the $1 and the current version of the $100 bill. It also plans larger, higher-contrast numerals, more color differences, and distribution of currency readers to assist the visually impaired during the transition period.\n\nThe monetary base consists of coins and Federal Reserve Notes in circulation outside the Federal Reserve Banks and the U.S. Treasury, plus deposits held by depository institutions at Federal Reserve Banks. The adjusted monetary base has increased from approximately 400 billion dollars in 1994, to 800 billion in 2005, over 3000 billion in 2013. The amount of cash in circulation is increased (or decreased) by the actions of the Federal Reserve System. Eight times a year, the 12-person Federal Open Market Committee meets to determine U.S. monetary policy. Every business day, the Federal Reserve System engages in Open market operations to carry out that monetary policy. If the Federal Reserve desires to increase the money supply, it will buy securities (such as U.S. Treasury Bonds) anonymously from banks in exchange for dollars. Conversely, it will sell securities to the banks in exchange for dollars, to take dollars out of circulation.\n\nWhen the Federal Reserve makes a purchase, it credits the seller's reserve account (with the Federal Reserve). This money is not transferred from any existing funds—it is at this point that the Federal Reserve has created new high-powered money. Commercial banks can freely withdraw in cash any excess reserves from their reserve account at the Federal Reserve. To fulfill those requests, the Federal Reserve places an order for printed money from the U.S. Treasury Department. The Treasury Department in turn sends these requests to the Bureau of Engraving and Printing (to print new dollar bills) and the Bureau of the Mint (to stamp the coins).\n\nUsually, the short-term goal of open market operations is to achieve a specific short-term interest rate target. In other instances, monetary policy might instead entail the targeting of a specific exchange rate relative to some foreign currency or else relative to gold. For example, in the case of the United States the Federal Reserve targets the federal funds rate, the rate at which member banks lend to one another overnight. The other primary means of conducting monetary policy include: (i) Discount window lending (as lender of last resort); (ii) Fractional deposit lending (changes in the reserve requirement); (iii) Moral suasion (cajoling certain market players to achieve specified outcomes); (iv) \"Open mouth operations\" (talking monetary policy with the market).\n\nThe 6th paragraph of Section 8 of Article 1 of the U.S. Constitution provides that the U.S. Congress shall have the power to \"coin money\" and to \"regulate the value\" of domestic and foreign coins. Congress exercised those powers when it enacted the Coinage Act of 1792. That Act provided for the minting of the first U.S. dollar and it declared that the U.S. dollar shall have \"the value of a Spanish milled dollar as the same is now current\".\n\nThe table to the right shows the equivalent amount of goods that, in a particular year, could be purchased with $1. The table shows that from 1774 through 2012 the U.S. dollar has lost about 97.0% of its buying power.\n\nThe decline in the value of the U.S. dollar corresponds to price inflation, which is a rise in the general level of prices of goods and services in an economy over a period of time. A consumer price index (CPI) is a measure estimating the average price of consumer goods and services purchased by households. The United States Consumer Price Index, published by the Bureau of Labor Statistics, is a measure estimating the average price of consumer goods and services in the United States. It reflects inflation as experienced by consumers in their day-to-day living expenses. A graph showing the U.S. CPI relative to 1982–1984 and the annual year-over-year change in CPI is shown at right.\n\nThe value of the U.S. dollar declined significantly during wartime, especially during the American Civil War, World War I, and World War II. The Federal Reserve, which was established in 1913, was designed to furnish an \"elastic\" currency subject to \"substantial changes of quantity over short periods\", which differed significantly from previous forms of high-powered money such as gold, national bank notes, and silver coins. Over the very long run, the prior gold standard kept prices stable—for instance, the price level and the value of the U.S. dollar in 1914 was not very different from the price level in the 1880s. The Federal Reserve initially succeeded in maintaining the value of the U.S. dollar and price stability, reversing the inflation caused by the First World War and stabilizing the value of the dollar during the 1920s, before presiding over a 30% deflation in U.S. prices in the 1930s.\n\nUnder the Bretton Woods system established after World War II, the value of gold was fixed to $35 per ounce, and the value of the U.S. dollar was thus anchored to the value of gold. Rising government spending in the 1960s, however, led to doubts about the ability of the United States to maintain this convertibility, gold stocks dwindled as banks and international investors began to convert dollars to gold, and as a result the value of the dollar began to decline. Facing an emerging currency crisis and the imminent danger that the United States would no longer be able to redeem dollars for gold, gold convertibility was finally terminated in 1971 by President Nixon, resulting in the \"Nixon shock\".\n\nThe value of the U.S. dollar was therefore no longer anchored to gold, and it fell upon the Federal Reserve to maintain the value of the U.S. currency. The Federal Reserve, however, continued to increase the money supply, resulting in stagflation and a rapidly declining value of the U.S. dollar in the 1970s. This was largely due to the prevailing economic view at the time that inflation and real economic growth were linked (the Phillips curve), and so inflation was regarded as relatively benign. Between 1965 and 1981, the U.S. dollar lost two thirds of its value.\n\nIn 1979, President Carter appointed Paul Volcker Chairman of the Federal Reserve. The Federal Reserve tightened the money supply and inflation was substantially lower in the 1980s, and hence the value of the U.S. dollar stabilized.\n\nOver the thirty-year period from 1981 to 2009, the U.S. dollar lost over half its value. This is because the Federal Reserve has targeted not zero inflation, but a low, stable rate of inflation—between 1987 and 1997, the rate of inflation was approximately 3.5%, and between 1997 and 2007 it was approximately 2%. The so-called \"Great Moderation\" of economic conditions since the 1970s is credited to monetary policy targeting price stability.\n\nThere is ongoing debate about whether central banks should target zero inflation (which would mean a constant value for the U.S. dollar over time) or low, stable inflation (which would mean a continuously but slowly declining value of the dollar over time, as is the case now). Although some economists are in favor of a zero inflation policy and therefore a constant value for the U.S. dollar, others contend that such a policy limits the ability of the central bank to control interest rates and stimulate the economy when needed.\n\nNotes:\n1. Mexican peso values prior to 1993 revaluation \n2. Value at the start of the year\n\nSources:\n\n\n\n\n"}
{"id": "7558", "url": "https://en.wikipedia.org/wiki?curid=7558", "title": "Coin", "text": "Coin\n\nA coin is a small, flat, (usually, depending on the country or value) round piece of metal or plastic used primarily as a medium of exchange or legal tender. They are standardized in weight, and produced in large quantities at a mint in order to facilitate trade. They are most often issued by a government. Coins often have images, numerals, or text on them.\n\nCoins are usually metal or an alloy, or sometimes made of manmade materials. They are usually disc shaped. Coins made of valuable metal are stored in large quantities as bullion coins. Other coins are used as money in everyday transactions, circulating alongside banknotes. Usually the highest value coin in circulation (excluding bullion coins) is worth less than the lowest-value note. In the last hundred years, the face value of circulation coins has occasionally been lower than the value of the metal they contain, for example due to inflation. If the difference becomes significant, the issuing authority may decide to withdraw these coins from circulation, possibly issuing new equivalents with a different composition, or the public may decide to melt the coins down or hoard them (see Gresham's law).\n\nExceptions to the rule of face value being higher than content value also occur for some bullion coins made of copper, silver, or gold (and, rarely, other metals, such as platinum or palladium), intended for collectors or investors in precious metals. Examples of modern gold collector/investor coins include the British sovereign minted by the United Kingdom, the American Gold Eagle minted by the United States, the Canadian Gold Maple Leaf minted by Canada, and the Krugerrand, minted by South Africa. While the Eagle, Maple Leaf, and Sovereign coins have nominal (purely symbolic) face values, the Krugerrand does not.\n\nHistorically, a great quantity of coinage metals (including alloys) and other materials (e.g. porcelain) have been used to produce coins for circulation, collection, and metal investment: bullion coins often serve as more convenient stores of assured metal quantity and purity than other bullion.\n\nMetal ingots, silver bullion or unmarked bars were probably in use for exchange among many of the civilizations that mastered metallurgy. The weight and purity of bullion would be the key determinant of value. In the Achaemenid Empire in the early 6th century BC, coinage was yet unknown, and barter and to some extent silver bullion was used instead for trade. The practice of using silver bars for currency also seems to have been current in Central Asia from the 6th century BC.\n\nCoins were an evolution of \"currency\" systems of the Late Bronze Age, where standard-sized ingots, and tokens such as knife money, were used to store and transfer value. In the late Chinese Bronze Age, standardized cast tokens were made, such as those discovered in a tomb near Anyang. These were replicas in bronze of earlier Chinese currency, cowrie shells, so they were named Bronze Shell.\n\nThe earliest coins are mostly associated with Iron Age Anatolia of the late 7th century BC, and especially with the kingdom of Lydia. Early electrum coins (a variable mix of gold and silver, typically with a ratio of about 54% gold to 44% silver) were not standardized in weight, and in their earliest stage may have been ritual objects, such as badges or medals, issued by priests. The unpredictability of the composition of naturally occurring electrum implied that it had a variable value, which greatly hampered its development.\n\nMost of the early Lydian coins include no writing (\"legend\" or \"inscription\"), only an image of a symbolic animal. Therefore, the dating of these coins relies primarily on archaeological evidence, with the most commonly cited evidence coming from excavations at the Temple of Artemis at Ephesus, also called the Ephesian Artemision (which would later evolve into one of the Seven Wonders of the Ancient World), site of the earliest known deposit of electrum coins. Because the oldest lion head \"coins\" were discovered in that temple, and they do not appear to have been used in commerce , these objects may not have been coins but badges or medals issued by the priests of that temple. Anatolian Artemis was the Πὀτνια Θηρῶν (\"Potnia Thêrôn\", \"Mistress of Animals\"), whose symbol was the stag. It took some time before ancient coins were used for commerce and trade. Even the smallest-denomination electrum coins, perhaps worth about a day's subsistence, would have been too valuable for buying a loaf of bread. Maybe the first coins to be used for retailing on a large-scale basis were likely small silver fractions, Hemiobol, Ancient Greek coinage minted by the Ionian Greeks in the late sixth century BC.\nIn contrast Herodotus mentioned the innovation made by the Lydians:\n\nMany early Lydian and Greek coins were minted under the authority of private individuals and are thus more akin to tokens or badges than to modern coins, though due to their numbers it is evident that some were official state issues. The earliest inscribed coins are those of Phanes, dated to 625–600 BC from Ephesus in Ionia, with the legend ΦΑΝΕΟΣ ΕΜΙ ΣΗΜΑ (or similar) (“I am the badge of Phanes”), or just bearing the name ΦΑΝΕΟΣ (“of Phanes”).\n\nThe first electrum coins issued by a monarch are those minted by king Alyattes of Lydia (died c. 560 BC), for which reason this king is sometimes mentioned as the originator of coinage.\n\nThe successor of Alyattes, king Croesus (r. c. 560–546 BC), became associated with great wealth in Greek historiography. He is credited with issuing the \"Croeseid\", the first true gold coins with a standardized purity for general circulation. and the world's first bimetallic monetary system circa 550 BCE.\n\nCoins spread rapidly in the 6th and 5th centuries BC, leading to the development of Ancient Greek coinage and Achaemenid coinage, and further to Illyrian coinage.\n\nStandardized Roman currency was used throughout the Roman Empire. Important Roman gold and silver coins were continued into the Middle Ages (see Gold dinar, Solidus, Aureus, Denarius). Ancient and early medieval coins in theory had the value of their metal content, although there have been many instances throughout history of governments inflating their currencies by debasing the metal content of their coinage, so that the inferior coins were worth less in metal than their face value. Fiat money first arose in medieval China, with the jiaozi paper money. Early paper money was introduced in Europe in the later Middle Ages, but some coins continued to have the value of the gold or silver they contained throughout the Early Modern period. The penny was minted as a silver coin until the 17th century.\n\nWhen Cyrus the Great (550–530 BC) came to power, coinage was unfamiliar in his realm. Barter and to some extent silver bullion was used instead for trade. The practice of using silver bars for currency also seems to have been current in Central Asia from the 6th century.\n\nCyrus the Great introduced coins to the Persian Empire after 546 BC, following his conquest of Lydia and the defeat of its king Croesus, who had put in place the first coinage in history. With his conquest of Lydia, Cyrus acquired a region in which coinage was invented, developed through advanced metallurgy, and had already been in circulation for about 50 years, making the Lydian Kingdom one of the leading trade powers of the time. It seems Cyrus initially adopted the Lydian coinage as such, and continued to strike Lydia's lion-and-bull coinage.\n\nOriginal coins of the Achaemenid Empire were issued from 520 BCE – 450 BCE to 330 BCE. The Persian Daric was the first truly Achaemenid gold coin which, along with a similar silver coin, the Siglos, represented the bimetallic monetary standard of the Achaemenid Persian Empire.\n\nThe Achaemenid Empire already reached the doors of India during the original expansion of Cyrus the Great, and the Achaemenid conquest of the Indus Valley is dated to circa 515 BC under Darius I. An Achaemenid administration was established in the area. The Kabul hoard, also called the Chaman Hazouri hoard, is a coin hoard discovered in the vicinity of Kabul, Afghanistan, containing numerous Achaemenid coins as well as many Greek coins from the 5th and 4th centuries BCE. The deposit of the hoard is dated to the Achaemenid period, in approximately 380 BCE. The hoard also contained many locally produced silver coins, minted by local authorities under Achaemenid rule. Several of these issues follow the \"western designs\" of the facing bull heads, a stag, or Persian column capitals on the obverse, and incuse punch on the reverse.\n\nAccording to numismatist Joe Cribb, these finds suggest that the idea of coinage and the use of punch-marked techniques was introduced to India from the Achaemenid Empire during the 4th century BCE. More Achaemenid coins were also found in Pushkalavati and in Bhir Mound.\n\nThe Karshapana is the earliest punch-marked coin found in India, produced from at least the mid-4th century BC, and possibly as early as 575 BC, influenced by similar coins produced in Gandhara under the Achaemenid empire, such as those of the Kabul hoard, or other examples found at Pushkalavati and in Bhir Mound.\n\nAccording to Aristotle (fr. 611,37, ed. V. Rose) and Pollux (Onamastikon IX.83), the first issuer of Greek coinage was Hermodike of Kyme.\n\nA small percentage of early Lydian/Greek coins have a legend. A famous early electrum coin, the most ancient inscribed coin at present known, is from nearby Caria. This coin has a Greek legend reading \"phaenos emi sema\" interpreted variously as \"I am the badge of Phanes\", or \"I am the sign of light\", or \"I am the tomb of light\", or \"I am the tomb of Phanes\". The coins of Phanes are known to be among the earliest of Greek coins, a hemihekte of the issue was found in the foundation deposit of the temple of Artemis at Ephesos (the oldest deposit of electrum coins discovered). One assumption is that Phanes was a wealthy merchant, another that this coin is associated with Apollo-Phanes and, due to the Deer, with Artemis (twin sister of the god of light Apollo-Phaneos). Although only seven Phanes type coins were discovered, it is also notable that 20% of all early electrum coins also have the lion of Artemis and the sun burst of Apollo-Phaneos.\n\nAlternatively, Phanes may have been the Halicarnassian mercenary of Amasis mentioned by Herodotus, who escaped to the court of Cambyses, and became his guide in the invasion of Egypt in 527 or 525 BC. According to Herodotus, this Phanes was buried alive by a sandstorm, together with 50,000 Persian soldiers, while trying to conquer the temple of Amun–Zeus in Egypt. The fact that the Greek word \"Phanes\" also means light (or lamp), and the word \"sema\" also means tomb makes this coin a famous and controversial one.\n\nAnother candidate for the site of the earliest coins is Aegina, where Chelone (\"turtle\") coins were first minted circa 700 BC. Coins from Athens and Corinth appeared shortly thereafter, known to exist at least since the late 6th century BC.\n\nThe Classical period saw Greek coinage reach a high level of technical and aesthetic quality. Larger cities now produced a range of fine silver and gold coins, most bearing a portrait of their patron god or goddess or a legendary hero on one side, and a symbol of the city on the other. Some coins employed a visual pun: some coins from Rhodes featured a rose, since the Greek word for rose is \"rhodon\". The use of inscriptions on coins also began, usually the name of the issuing city.\n\nThe wealthy cities of Sicily produced some especially fine coins. The large silver \"decadrachm\" (10-drachm) coin from Syracuse is regarded by many collectors as the finest coin produced in the ancient world, perhaps ever. Syracusan issues were rather standard in their imprints, one side bearing the head of the nymph Arethusa and the other usually a victorious quadriga. The tyrants of Syracuse were fabulously rich, and part of their public relations policy was to fund quadrigas for the Olympic chariot race, a very expensive undertaking. As they were often able to finance more than one quadriga at a time, they were frequent victors in this highly prestigious event. Syracuse was one of the epicenters of numismatic art during the classical period. Led by the engravers Kimon and Euainetos, Syracuse produced some of the finest coin designs of antiquity.\n\nAmongst the first centers to produce coins during the Greek colonization of mainland Southern Italy (Magna Graecia) were Paestum, Crotone, Sybaris, Caulonia, Metapontum, and Taranto. These ancient cities started producing coins from 550BC to 510BC.\n\nAmisano, in a general publication, including the Etruscan coinage, attributing it the beginning to about 560 BC in Populonia, a chronology that would leave out the contribution of the Greeks of Magna Graecia and attribute to the Etruscans the burden of introducing the coin in Italy. In this work, constant reference is made to classical sources, and credit is given to the origin of the Etruscan Lydia, a source supported by Herodotus, and also to the invention of coin in Lydia.\n\nAlthough many of the first coins illustrated the images of various gods, the first portraiture of actual rulers appears with the coinage of Lycia in the 5th century BC. No ruler had dared illustrating his own portrait on coinage until that time. The Achaemenids had been the first to illustrate the person of their king or a hero in a stereotypical manner, showing a bust or the full body but never an actual portrait, on their Sigloi and Daric coinage from circa 500 BC. A slightly earlier candidate for the first portrait is Themistocles, the Athenian general, who became a Governor of Magnesia on the Meander circa 465–459 BC for the Achaemenid Empire, although there is some doubt that his coins may have represented Zeus rather than himself. Themistocles may have been in a unique position in which he could transfer the notion of individual portraiture, already current in the Greek world, and at the same time wield the dynastic power of an Achaemenid dynasty who could issue his own coins and illustrate them as he wished. From the time of Alexander the Great, portraiture of the issuing ruler would then become a standard, generalized, feature of coinage.\nIn China, early round coins appeared in the 4th century BC and were adopted for all China by Emperor Qin Shi Huang Di at the end of 3rd century BC. The round coin, the precursor of the familiar cash coin, circulated in both the spade and knife money areas in the Zhou period, from around 350 BC. Apart from two small and presumably late coins from the State of Qin, coins from the spade money area have a round hole and refer to the \"jin\" and \"liang\" units. Those from the knife money area have a square hole and are denominated in \"hua\" (化).\n\nAlthough for discussion purposes the Zhou coins are divided up into categories of knives, spades, and round coins, it is apparent from archaeological finds that most of the various kinds circulated together. A hoard found in 1981, near Hebi in north Henan province, consisted of: 3,537 Gong spades, 3 Anyi arched foot spades, 8 Liang \"Dang Lie\" spades, 18 Liang square foot spades and 1,180 Yuan round coins, all contained in three clay jars.\n\nThe Hellenistic period was characterized by the spread of Greek culture across a large part of the known world. Greek-speaking kingdoms were established in Egypt and Syria, and for a time also in Iran and as far east as what is now Afghanistan and northwestern India. Greek traders spread Greek coins across this vast area, and the new kingdoms soon began to produce their own coins. Because these kingdoms were much larger and wealthier than the Greek city states of the classical period, their coins tended to be more mass-produced, as well as larger, and more frequently in gold. They often lacked the aesthetic delicacy of coins of the earlier period.\n\nStill, some of the Greco-Bactrian coins, and those of their successors in India, the Indo-Greeks, are considered the finest examples of Greek numismatic art with \"a nice blend of realism and idealization\", including the largest coins to be minted in the Hellenistic world: the largest gold coin was minted by Eucratides (reigned 171–145 BC), the largest silver coin by the Indo-Greek king Amyntas Nikator (reigned c. 95–90 BC). The portraits \"show a degree of individuality never matched by the often bland depictions of their royal contemporaries further West\" (Roger Ling, \"Greece and the Hellenistic World\").\nCoinage followed Greek colonization and influence first around the Mediterranean and soon after to North Africa (including Egypt), Syria, Persia, and the Balkans. Coins came late to the Roman Republic compared with the rest of the Mediterranean, especially Greece and Asia Minor where coins were invented in the 7th century BC. The currency of central Italy was influenced by its natural resources, with bronze being abundant (the Etruscans were famous metal workers in bronze and iron) and silver ore being scarce. The coinage of the Roman Republic started with a few silver coins apparently devised for trade with Celtic in northern Italy and the Greek colonies in Southern Italy, and heavy cast bronze pieces for use in Central Italy. The first Roman coins, which were crude, heavy cast bronzes, were issued c. 289 BC.\nAmisano, in a general publication, including the Etruscan coinage, attributing it the beginning to about 550 BC in Populonia, a chronology that would leave out the contribution of the Greeks of Magna Graecia and attribute to the Etruscans the burden of introducing the coin in Italy. In this work, constant reference is made to classical sources, and credit is given to the origin of the Etruscan Lydia, a source supported by Herodotus, and also to the invention of coin in Lydia.\n\nThe first European coin to use Arabic numerals to date the year in which the coin was minted was the St. Gall silver \"Plappart\" of 1424.\n\nMost coins presently are made of a base metal, and their value comes from their status as fiat money. This means that the value of the coin is decreed by government fiat (law), and thus is determined by the free market only in as much as national currencies are used in domestic trade and also traded internationally on foreign exchange markets. Thus, these coins are monetary tokens, just as paper currency is: they are usually not backed by metal, but rather by some form of government guarantee. Some have suggested that such coins not be considered to be \"true coins\" (see below). Thus, there is very little economic difference between notes and coins of equivalent face value.\n\nCoins may be in circulation with fiat values lower than the value of their component metals, but they are never initially issued with such value, and the shortfall only arises over time due to inflation, as market values for the metal overtake the fiat declared face value of the coin. Examples are the pre-1965 US dime, quarter, half dollar, and dollar (nominally containing slightly less than a tenth, quarter, half, and full ounce of silver, respectively), US nickel, and pre-1982 US penny. As a result of the increase in the value of copper, the United States greatly reduced the amount of copper in each penny. Since mid-1982, United States pennies are made of 97.5% zinc, with the remaining 2.5% being a coating of copper. Extreme differences between fiat values and metal values of coins cause coins to be hoarded or removed from circulation by illicit smelters in order to realize the value of their metal content. This is an example of Gresham's law. The United States Mint, in an attempt to avoid this, implemented new interim rules on December 14, 2006, subject to public comment for 30 days, which criminalized the melting and export of pennies and nickels. Violators can be fined up to $10,000 and/or imprisoned for up to five years.\n\nA coin's value as a collector's item or as an investment generally depends on its condition, specific historical significance, rarity, quality, beauty of the design and general popularity with collectors. If a coin is greatly lacking in all of these, it is unlikely to be worth much. The value of bullion coins is also influenced to some extent by those factors, but is largely based on the value of their gold, silver, or platinum content. Sometimes non-monetized bullion coins such as the Canadian Maple Leaf and the American Gold Eagle are minted with nominal face values less than the value of the metal in them, but as such coins are never intended for circulation, these face values have no relevance.\n\nCollector catalogs often include information about coins to assists collectors with identifying and grading. Additional resources can be found online for collectors These are collector clubs, collection management tools, marketplaces, trading platforms, and forums,\n\nCoins can be used as creative medium of expression – from fine art sculpture to the penny machines that can be found in most amusement parks. In the Code of Federal Regulations (CFR) in the United States there are some regulations specific to nickels and pennies that are informative on this topic. 31 CFR § 82.1 forbids unauthorized persons from exporting, melting, or treating any 5 or 1 cent coins.\n\nThis has been a particular problem with nickels and dimes (and with some comparable coins in other currencies) because of their relatively low face value and unstable commodity prices. For a while, the copper in US pennies was worth more than one cent, so people would hoard pennies and then melt them down for their metal value. It cost more than face value to manufacture pennies or nickels, so any widespread loss of the coins in circulation could be expensive for the US Treasury. This was more of a problem when coins were still made of precious metals like silver and gold, \n\n31 CFR § 82.2(b) goes on to state that: \"The prohibition contained in § 82.1 against the treatment of 5-cent coins and one-cent coins shall not apply to the treatment of these coins for educational, amusement, novelty, jewelry, and similar purposes as long as the volumes treated and the nature of the treatment makes it clear that such treatment is not intended as a means by which to profit solely from the value of the metal content of the coins.\"\n\nThroughout history, monarchs and governments have often created more coinage than their supply of precious metals would allow if the coins were pure metal. By replacing some fraction of a coin's precious metal content with a base metal (often copper or nickel), the intrinsic value of each individual coin was reduced (thereby \"debasing\" the money), allowing the coining authority to produce more coins than would otherwise be possible. Debasement occasionally occurs in order to make the coin physically harder and therefore less likely to be worn down as quickly, but the more usual reason is to profit from the difference between face value and metal value. Debasement of money almost always leads to price inflation. Sometimes price controls are at the same time also instituted by the governing authority, but historically these have generally proved unworkable.\n\nThe United States is unusual in that it has only slightly modified its coinage system (except for the images and symbols on the coins, which have changed a number of times) to accommodate two centuries of inflation. The one-cent coin has changed little since 1856 (though its composition was changed in 1982 to remove virtually all copper from the coin) and still remains in circulation, despite a greatly reduced purchasing power. On the other end of the spectrum, the largest coin in common circulation is valued at 25 cents, a very low value for the largest denomination coin compared to many other countries. Increases in the prices of copper, nickel, and zinc meant that both the US one- and five-cent coins became worth more for their raw metal content than their face (fiat) value. In particular, copper one-cent pieces (those dated prior to 1982 and some 1982-dated coins) contained about two cents' worth of copper.\n\nSome denominations of circulating coins that were formerly minted in the United States are no longer made. These include coins with a face value of a half cent, two cents, three cents, and twenty cents. (The half dollar and dollar coins are still produced, but mostly for vending machines and collectors.) In the past, the US also coined the following denominations for circulation in gold: One dollar, $2.50, three dollars, five dollars, ten dollars, and twenty dollars. In addition, cents were originally slightly larger than the modern quarter and weighed nearly half an ounce, while five-cent coins (known then as \"half dimes\") were smaller than a dime and made of a silver alloy. Dollar coins were also much larger, and weighed approximately an ounce. One-dollar gold coins are no longer produced and rarely used. The US also issues bullion and commemorative coins with the following denominations: 50¢, $1, $5, $10, $25, $50, and $100.\n\nCirculating coins commonly suffered from \"shaving\" or \"clipping\": the public would cut off small amounts of precious metal from their edges to sell it and then pass on the mutilated coins at full value. Unmilled British sterling silver coins were sometimes reduced to almost half their minted weight. This form of debasement in Tudor England was commented on by Sir Thomas Gresham, whose name was later attached to Gresham's law. The monarch would have to periodically recall circulating coins, paying only the bullion value of the silver, and reminting them. This, also known as recoinage, is a long and difficult process that was done only occasionally. Many coins have milled or reeded edges, originally designed to make it easier to detect clipping.\n\nSome convicted criminals from the British Isles who were sentenced to transportation to Australia in the 18th and 19th centuries used coins to leave messages of remembrance to loved ones left behind in Britain. The coins were defaced, smoothed and inscribed, either by stippling or engraving, with sometimes touching words of loss. These coins were called \"convict love tokens\" or \"leaden hearts\". A number of these tokens are in the collection of the National Museum of Australia.\n\nThe side of a coin carrying an image of a monarch, other authority (\"see List of people on coins\"), or a national emblem is called the \"obverse\" (colloquially, \"heads\"); the other side, carrying various types of information, is called the \"reverse\" (colloquially, \"tails\"). The year of minting is usually shown on the obverse, although some Chinese coins, most Canadian coins, the pre-2008 British 20p coin, the post-1999 American quarter, and all Japanese coins are exceptions.\n\nThe relation of the images on the obverse and reverse of a coin is the coin's orientation. If the image on the obverse of the coin is right side up and turning the coin left or right on its vertical axis reveals that the reverse of the coin is also right side up, then the coin is said to have medallic orientation—typical of the Euro and pound sterling; if, however, turning the coin left or right shows that the reverse image is upside down, then the coin is said to have coin orientation, characteristic of the United States dollar coin.\n\nBimetallic coins are sometimes used for higher values and for commemorative purposes. In the 1990s, France used a tri-metallic coin. Common circulating bimetallic examples include the €1, €2, British £1, £2 and Canadian $2 and several peso coins in Mexico.\n\nThe \"exergue\" is the space on a coin beneath the main design, often used to show the coin's date, although it is sometimes left blank or contains a mint mark, privy mark, or some other decorative or informative design feature. Many coins do not have an exergue at all, especially those with few or no legends, such as the Victorian bun penny.\nNot all coins are round; they come in a variety of shapes. The Australian 50-cent coin, for example, has twelve flat sides. Some coins have wavy edges, e.g. the $2 and 20-cent coins of Hong Kong and the 10-cent coins of Bahamas. Some are square-shaped, such as the 15-cent coin of the Bahamas and the 50-cent coin from Aruba. During the 1970s, Swazi coins were minted in several shapes, including squares, polygons, and wavy edged circles with 8 and 12 waves.\n\nSome other coins, like the British 20 and 50 pence coins and the Canadian Loonie, have an odd number of sides, with the edges rounded off. This way the coin has a constant diameter, recognizable by vending machines whichever direction it is inserted.\n\nA triangular coin with a face value of £5 (produced to commemorate the 2007/2008 Tutankhamun exhibition at The O2 Arena) was commissioned by the Isle of Man: it became legal tender on 6 December 2007. Other triangular coins issued earlier include: Cabinda coin, Bermuda coin, 2 Dollar Cook Islands 1992 triangular coin, Uganda Millennium Coin and Polish Sterling-Silver 10-Zloty Coin.\n\nSome medieval coins, called bracteates, were so thin they were struck on only one side.\n\nMany coins over the years have been manufactured with integrated holes such as Chinese \"cash\" coins, Japanese coins, Colonial French coins, etc. This may have been done to permit their being strung on cords, to facilitate storage and being carried. Nowadays, holes help to differentiate coins of similar size and metal, such as the Japanese 50 yen and 100 yen coin.\n\nThe Royal Canadian Mint is now able to produce holographic-effect gold and silver coinage. However, this procedure is not limited to only bullion or commemorative coinage. The 500 yen coin from Japan was subject to a massive amount of counterfeiting. The Japanese government in response produced a circulatory coin with a holographic image.\n\nThe Royal Canadian Mint has also released several coins that are colored, the first of which was in commemoration of Remembrance Day. The subject was a colored poppy on the reverse of a 25-cent piece minted through a patented process.\n\nAn example of non-metallic composite coins (sometimes incorrectly called plastic coins) was introduced into circulation in Transnistria on 22 August 2014. Most of these coins are also non-circular, with different shapes corresponding to different coin values.\n\nFor a list of many pure metallic elements and their alloys which have been used in actual circulation coins and for trial experiments, see coinage metals.\n\nTo flip a coin to see whether it lands \"heads\" or \"tails\" is to use it as a two-sided dice in what is known in mathematics as a Bernoulli trial: if the probability of heads (in the parlance of Bernoulli trials, a \"success\") is exactly 0.5, the coin is fair.\n\nCoins can also be spun on a flat surface such as a table. This results in the following phenomenon: as the coin falls over and rolls on its edge, it spins faster and faster (formally, the precession rate of the symmetry axis of the coin, i.e., the axis passing from one face of the coin to the other) before coming to an abrupt stop. This is mathematically modeled as a finite-time singularity – the precession rate is accelerating to infinity, before it suddenly stops, and has been studied using high speed photography and devices such as Euler's Disk. The slowing down is predominantly caused by rolling friction (air resistance is minor), and the singularity (divergence of the precession rate) can be modeled as a power law with exponent approximately −1/3.\n\nIron and copper coins have a characteristic metallic smell that is produced upon contact with oils in the skin. Perspiration is chemically reduced upon contact with these metals, which causes the skin oils to decompose, forming with iron the volatile molecule 1-octen-3-one.\n\nPiloncitos are small engraved gold coins found in the Philippines. Some piloncitos are of the size of a corn kernel and weigh from 0.09 to 2.65 grams of fine gold. Piloncitos have been excavated from Mandaluyong, Bataan, the banks of the Pasig River, Batangas, Marinduque, Samar, Leyte and some areas in Mindanao. They have been found in large numbers in Indonesian archaeological sites leading to questions of origin such as whether they were made in the Philippines or imported. However. many Spanish accounts state that the gold coins are mined and labored in the Philippines, such as the following in 1586:\n\n"}
{"id": "208286", "url": "https://en.wikipedia.org/wiki?curid=208286", "title": "Banknote", "text": "Banknote\n\nA banknote (often known as a bill, paper money, or simply a note) is a type of negotiable promissory note, made by a bank, payable to the bearer on demand.\nBanknotes were originally issued by commercial banks, which were legally required to redeem the notes for legal tender (usually gold or silver coin) when presented to the chief cashier of the originating bank. These commercial banknotes only traded at face value in the market served by the issuing bank. Commercial banknotes have primarily been replaced by national banknotes issued by central banks.\n\nNational banknotes are generally legal tender, meaning that medium of payment is allowed by law or recognized by a legal system to be valid for meeting a financial obligation. Historically, banks sought to ensure that they could always pay customers in coins when they presented banknotes for payment. This practice of \"backing\" notes with something of substance is the basis for the history of central banks backing their currencies in gold or silver. Today, most national currencies have no backing in precious metals or commodities and have value only by fiat. With the exception of non-circulating high-value or precious metal issues, coins are used for lower valued monetary units, while banknotes are used for higher values.\n\nIn China during the Han dynasty promissory notes appeared in 118 BC and were made of leather. Rome may have used a durable lightweight substance as promissory notes in 57 AD which have been found in London. However, Carthage was purported to have issued bank notes on parchment or leather before 146 BC. Hence Carthage may be the oldest user of lightweight promissory notes. The first known banknote was first developed in China during the Tang and Song dynasties, starting in the 7th century. Its roots were in merchant receipts of deposit during the Tang dynasty (618–907), as merchants and wholesalers desired to avoid the heavy bulk of copper coinage in large commercial transactions. During the Yuan dynasty, banknotes were adopted by the Mongol Empire. In Europe, the concept of banknotes was first introduced during the 13th century by travelers such as Marco Polo, with European banknotes appearing in 1661 in Sweden.\n\nCounterfeiting, the forgery of banknotes, is an inherent challenge in issuing currency. It is countered by anticounterfeiting measures in the printing of banknotes. Fighting the counterfeiting of banknotes and cheques has been a principal driver of security printing methods development in recent centuries.\n\nPaper currency first developed in Tang dynasty China during the 7th century, although true paper money did not appear until the 11th century, during the Song dynasty. The usage of paper currency later spread throughout the Mongol Empire or Yuan dynasty China. European explorers like Marco Polo introduced the concept in Europe during the 13th century. Napoleon issued paper banknotes in the early 1800s. Cash paper money originated as receipts for value held on account \"value received\", and should not be conflated with promissory \"sight bills\" which were issued with a promise to convert at a later date.\n\nThe perception of banknotes as money has evolved over time. Originally, money was based on precious metals. Banknotes were seen by some as an I.O.U. or promissory note: a promise to pay someone in precious metal on presentation (see representative money), but were readily accepted - for convenience and security - in the City of London for example from the late 1600s onwards. With the removal of precious metals from the monetary system, banknotes evolved into pure fiat money.\n\nDevelopment of the banknote began in the Tang dynasty during the 7th century, with local issues of paper currency, although true paper money did not appear until the 11th century, during the Song dynasty. Its roots were in merchant receipts of deposit during the Tang Dynasty (618–907), as merchants and wholesalers desired to avoid the heavy bulk of copper coinage in large commercial transactions.\n\nBefore the use of paper, the Chinese used coins that were circular, with a rectangular hole in the middle. Several coins could be strung together on a rope. Merchants in China, if they became rich enough, found that their strings of coins were too heavy to carry around easily. To solve this problem, coins were often left with a trustworthy person, and the merchant was given a slip of paper recording how much money they had with that person. If they showed the paper to that person, they could regain their money. Eventually, the Song Dynasty paper money called \"jiaozi\" originated from these promissory notes.\n\nBy 960 the Song dynasty, short of copper for striking coins, issued the first generally circulating notes. A note is a promise to redeem later for some other object of value, usually specie. The issue of credit notes is often for a limited duration, and at some discount to the promised amount later. The jiaozi nevertheless did not replace coins during the Song Dynasty; paper money was used alongside the coins.\n\nThe central government soon observed the economic advantages of printing paper money, issuing a monopoly right of several of the deposit shops to the issuance of these certificates of deposit. By the early 12th century, the amount of banknotes issued in a single year amounted to an annual rate of 26 million strings of cash coins. By the 1120s the central government officially stepped in and produced their own state-issued paper money (using woodblock printing).\nEven before this point, the Song government was amassing large amounts of paper tribute. It was recorded that each year before 1101 AD, the prefecture of Xin'an (modern Shexian, Anhui) alone would send 1,500,000 sheets of paper in seven different varieties to the capital at Kaifeng. In that year of 1101, the Emperor Huizong of Song decided to lessen the amount of paper taken in the tribute quota, because it was causing detrimental effects and creating heavy burdens on the people of the region. However, the government still needed masses of paper product for the exchange certificates and the state's new issuing of paper money. For the printing of paper money alone, the Song court established several government-run factories in the cities of Huizhou, Chengdu, Hangzhou, and Anqi.\n\nThe size of the workforce employed in these paper money factories were quite large, as it was recorded in 1175 AD, that the factory at Hangzhou alone employed more than a thousand workers a day. However, the government issues of paper money were not yet nationwide standards of currency at that point; issues of banknotes were limited to regional zones of the empire, and were valid for use only in a designated and temporary limit of three years.\n\nThe geographic limitation changed between the years 1265 and 1274, when the late Southern Song government finally produced a nationwide standard currency of paper money, once its widespread circulation was backed by gold or silver. The range of varying values for these banknotes was perhaps from one string of cash to one hundred at the most. Ever since 1107, the government printed money in no less than six ink colors and printed notes with intricate designs and sometimes even with mixture of unique fiber in the paper to avoid counterfeiting.\n\nThe founder of the Yuan dynasty, Kublai Khan, issued paper money known as Jiaochao in his reign. The original notes during the Yuan dynasty were restricted in area and duration as in the Song dynasty, but in the later course of the dynasty, facing massive shortages of specie to fund their ruling in China, they began printing paper money without restrictions on duration. The Venetian merchants were impressed by the fact that the Chinese paper money was guaranteed by the State.\n\nAccording to a travelogue of a visit to Prague in 960 by Ibrahim ibn Yaqub, small pieces of cloth were used as a means of trade, with these cloths having a set exchange rate versus silver.\n\nAround 1150, the Knights Templar issued bank notes to pilgrims. Pilgrims deposited their valuables with a local Templar preceptory before embarking, received a document indicating the value of their deposit, then used that document upon arrival in the Holy Land to retrieve their funds in an amount of treasure of equal value.\nIn the 13th century, Chinese paper money of Mongol Yuan became known in Europe through the accounts of travelers, such as Marco Polo and William of Rubruck. Marco Polo's account of paper money during the Yuan Dynasty is the subject of a chapter of his book, \"The Travels of Marco Polo\", titled \".\"\n\nIn medieval Italy and Flanders, because of the insecurity and impracticality of transporting large sums of cash over long distances, money traders started using promissory notes. In the beginning these were personally registered, but they soon became a written order to pay the amount to whomever had it in their possession. These notes are seen as a predecessor to regular banknotes by some but are mainly thought of as proto bills of exchange and cheques. The term \"bank note\" comes from the notes of the bank (\"nota di banco\") and dates from the 14th century; it originally recognized the right of the holder of the note to collect the precious metal (usually gold or silver) deposited with a banker (via a currency account). In the 14th century, it was used in every part of Europe and in Italian city-state merchants colonies outside of Europe. For international payments, the more efficient and sophisticated bill of exchange (\"lettera di cambio\"), that is, a promissory note based on a virtual currency account (usually a coin no longer physically existing), was used more often. All physical currencies were physically related to this virtual currency; this instrument also served as credit.\n\nThe shift toward the use of these receipts as a means of payment took place in the mid-17th century, as the price revolution, when relatively rapid gold inflation was causing a re-assessment of how money worked. The goldsmith bankers of London began to give out the receipts as payable to the \"bearer\" of the document rather than the original depositor. This meant that the note could be used as currency based on the security of the goldsmith, not the account holder of the goldsmith-banker. The bankers also began issuing a greater value of notes than the total value of their physical reserves in the form of loans, on the assumption that they would not have to redeem all of their issued banknotes at the same time. This pivotal shift changed the simple promissory note into an agency for the expansion of the monetary supply itself. As these receipts were increasingly used in the money circulation system, depositors began to ask for multiple receipts to be made out in smaller, fixed denominations for use as money. The receipts soon became a written order to pay the amount to whoever had possession of the note. These notes are credited as the first modern banknotes.\n\nThe first short-lived attempt at issuing banknotes by a central bank was in 1661 by Stockholms Banco, a predecessor of Sweden's central bank Sveriges Riksbank. These replaced the copper-plates being used instead as a means of payment. This banknote issue was brought about by the peculiar circumstances of the Swedish coin supply. Cheap foreign imports of copper had forced the Crown to steadily increase the size of the copper coinage to maintain its value relative to silver. The heavy weight of the new coins encouraged merchants to deposit it in exchange for receipts. These became banknotes when the manager of the Bank decoupled the rate of note issue from the bank currency reserves. Three years later, the bank went bankrupt, after rapidly increasing the artificial money supply through the large-scale printing of paper money. A new bank, the \"Riksens Ständers Bank\" was established in 1668, but did not issue banknotes until the 19th century.\n\nThe modern banknote rests on the assumption that money is determined by a social and legal consensus. A gold coin's value is simply a reflection of the supply and demand mechanism of a society exchanging goods in a free market, as opposed to stemming from any intrinsic property of the metal. By the late 17th century, this new conceptual outlook helped to stimulate the issue of banknotes. The economist Nicholas Barbon wrote that money \"was an imaginary value made by a law for the convenience of exchange.\" A temporary experiment of banknote issue was carried out by Sir William Phips as the Governor of the Province of Massachusetts Bay in 1690 to help fund the war effort against France.\nThe first bank to initiate the permanent issue of banknotes was the Bank of England. Established in 1694 to raise money for the funding of the war against France, the bank began issuing notes in 1695 with the promise to pay the bearer the value of the note on demand. They were initially handwritten to a precise amount and issued on deposit or as a loan. There was a gradual move toward the issuance of fixed denomination notes, and by 1745, standardized printed notes ranging from £20 to £1,000 were being printed. Fully printed notes that did not require the name of the payee and the cashier's signature first appeared in 1855.\n\nThe Scottish economist John Law helped establish banknotes as a formal currency in France, after the wars waged by Louis XIV left the country with a shortage of precious metals for coinage.\n\nIn the United States there were early attempts at establishing a central bank in 1791 and 1816, but it was only in 1862 that the federal government of the United States began to print banknotes.\n\nOriginally, the banknote was simply a promise to the bearer that they could redeem it for its value in specie, but in 1833 the second in a series of Bank Charter Acts established that banknotes would be considered as legal tender during peacetime.\n\nUntil the mid-nineteenth century, commercial banks were able to issue their own banknotes, and notes issued by provincial banking companies were the common form of currency throughout England, outside London. The Bank Charter Act of 1844, which established the modern central bank, restricted authorisation to issue new banknotes to the Bank of England, which would henceforth have sole control of the money supply in 1921. At the same time, the Bank of England was restricted to issue new banknotes only if they were 100% backed by gold or up to £14 million in government debt. The Act gave the Bank of England an effective monopoly over the note issue from 1928.\n\nGenerally, a central bank or treasury is solely responsible within a state or currency union for the issue of banknotes. However, this is not always the case, and historically the paper currency of countries was often handled entirely by private banks. Thus, many different banks or institutions may have issued banknotes in a given country. Commercial banks in the United States had legally issued banknotes before there was a national currency; however, these became subject to government authorization from 1863 to 1932. In the last of these series, the issuing bank would stamp its name and promise to pay, along with the signatures of its president and cashier on a preprinted note. By this time, the notes were standardized in appearance and not too different from Federal Reserve Notes.\nIn a small number of countries, private banknote issue continues to this day. For example, by virtue of the complex constitutional setup in the United Kingdom, certain commercial banks in two of the state's four constituent countries (Scotland and Northern Ireland) continue to print their own banknotes for domestic circulation, even though they are not fiat money or declared in law as legal tender anywhere. The UK's central bank, the Bank of England, prints notes which are legal tender in England and Wales; these notes are also usable as money (but not legal tender) in the rest of the UK (see Banknotes of the pound sterling).\n\nIn the two Special Administrative Regions of the People's Republic of China, arrangements are similar to those in the UK; in Hong Kong, three commercial banks are licensed to issue Hong Kong dollar notes, and in Macau, banknotes of the Macanese pataca are issued by two different commercial banks. In Luxembourg, the Banque Internationale à Luxembourg was entitled to issue its own Luxembourgish franc notes until the introduction of the Euro in 1999.\n\nAs well as commercial issuers, other organizations may have note-issuing powers; for example, until 2002 the Singapore dollar was issued by the Board of Commissioners of Currency Singapore, a government agency which was later taken over by the Monetary Authority of Singapore.\n\nAs with any printing, there is also a chance for banknotes to have printing errors. For U.S. banknotes, these errors can include board break errors, butterfly fold errors, cutting errors, dual denomination errors, fold over errors, and misalignment errors.\n\nPrior to the introduction of banknotes, precious or semiprecious metals minted into coins to certify their substance were widely used as a medium of exchange. The value that people attributed to coins was originally based upon the value of the metal unless they were token issues or had been debased. Banknotes were originally a claim for the coins held by the bank, but due to the ease with which they could be transferred and the confidence that people had in the capacity of the bank to settle the notes in coin if presented, they became a popular means of exchange in their own right. They now make up a very small proportion of the \"money\" that people think that they have as demand deposit bank accounts and electronic payments have negated the need to carry notes and coins.\n\nBanknotes have a natural advantage over coins in that they are lighter to carry but are also less durable. Banknotes issued by commercial banks had counterparty risk, meaning that the bank may not be able to make payment when the note was presented. Notes issued by central banks had a theoretical risk when they were backed by gold and silver. Both banknotes and coins are subject to inflation. The durability of coins means that even if metal coins melt in a fire or are submerged under the sea for hundreds of years they still have some value when they are recovered. Gold coins salvaged from shipwrecks retain almost all of their original appearance, but silver coins slowly corrode.\n\nOther costs of using bearer money include:\n\n\nThe different disadvantages between coins and banknotes imply that there may be an ongoing role for both forms of bearer money, each being used where its advantages outweigh its disadvantages.\n\nMost banknotes are made from cotton paper with a weight of 80 to 90 grams per square meter. The cotton is sometimes mixed with linen, abaca, or other textile fibres. Generally, the paper used is different from ordinary paper: it is much more resilient, resists wear and tear (the average life of a banknote is two years), and also does not contain the usual agents that make ordinary paper glow slightly under ultraviolet light. Unlike most printing and writing paper, banknote paper is infused with polyvinyl alcohol or gelatin, instead of water, to give it extra strength. Early Chinese banknotes were printed on paper made of mulberry bark. Mitsumata (\"Edgeworthia chrysantha\") and other fibers are used in Japanese banknote paper (a kind of Washi).\n\nMost banknotes are made using the mould made process in which a watermark and thread is incorporated during the paper forming process. The thread is a simple looking security component found in most banknotes. It is however often rather complex in construction comprising fluorescent, magnetic, metallic and micro print elements. By combining it with watermarking technology the thread can be made to surface periodically on one side only. This is known as windowed thread and further increases the counterfeit resistance of the banknote paper. This process was invented by Portals, part of the De La Rue group in the UK. Other related methods include watermarking to reduce the number of corner folds by strengthening this part of the note. Varnishing and coatings reduce the accumulation of dirt on the note for longer durability in circulation.\n\nAnother security feature is based on windows in the paper which are covered by holographic foils to make it very hard to copy. Such technology is applied as a \"portrait window\" for the higher denominations of the Europa series (ES2) of the euro banknotes. Windows are also used with the Hybrid substrate from Giesecke+Devrient which is composed of an inner layer of paper substrate with thin outer layers of plastic film for high durability.\n\nWhen paper bank notes were first introduced in England, they resulted in a dramatic rise in counterfeiting. The attempts by the Bank of England and the Royal Mint to stamp out currency crime led to new policing strategies, including the increased use of entrapment.\n\nThe characteristics of banknotes, their materials and production techniques (as well as their development over history) are topics that normally aren't thoroughly examined by historians, even though now there are a number of works detailing how bank notes were actually constructed. This is mostly due to the fact that historians prioritize the theoretical understanding of how money worked rather than how it was produced. The first great deterrent against counterfeiting was the death penalty for forgers, but this wasn't enough to stop the rise of counterfeiting. Over the eighteenth century, far fewer banknotes were circulating in England compared to the boom of bank notes in the nineteenth century; because of this, improving note-making techniques wasn't considered a compelling issue.\n\nIn the eighteenth century, banknotes were produced mainly through copper-plate engraving and printing and they were single-sided. Notes making technologies remained basically the same during the eighteenth century The first banknotes were produced through the so-called \"intaglio printing\", a technique that consisted of engraving a copper plate by hand and then covering it in ink to print the bank notes. Only with this technique it was possible, at that time, to force the paper into the lines of the engraving and to make suitable banknotes. Another factor that made it harder to counterfeit banknotes was the paper, since the type of paper used for banknotes was rather different from the paper commercially available at that time. Despite this, some forgers managed to successfully forge notes by getting involved with and consulting paper makers, in order to make a similar kind of paper by themselves. Furthermore, watermarked paper was also used since banknotes first appeared; it involved the sewing of a thin wire frame into paper mould. Watermarks for notes were first used in 1697 by a Berkshire paper maker whose name was Rice Watkins. Watermarks, together with a special paper type, were supposed to make it harder and more expensive to forge banknotes, since more complex and expensive paper making machines were needed in order to make them.\n\nAt the beginning of the nineteenth century (the so-called Bank Restriction Period, 1797-1821), the dramatically increased demand of bank notes slowly forced the banks to refine the technologies employed. In 1801, watermarks, which previously were straight lines, became wavy, thanks to the idea of a watermark mould maker whose name was William Brewer. This made even harder the counterfeiting of bank notes, at least in the short term, since in 1803 the number of forged bank notes fell to just 3000, compared to 5000 of the previous year In the same period, bank notes also started to become double-sided and with more complex patterns, and banks asked skilled engravers and artists to help them make their notes harder to counterfeit (episode labelled by historians as \"the search for the inimitable banknote\").\n\nThe ease with which paper money can be created, by both legitimate authorities and counterfeiters, has led both to a temptation in times of crisis such as war or revolution to produce paper money which was not supported by precious metal or other goods, thus leading to Hyperinflation and a loss of faith in the value of paper money, e.g. the Continental Currency produced by the Continental Congress during the American Revolution, the Assignats produced during the French Revolution, the paper currency produced by the Confederate States of America and the individual states of the Confederate States of America, the financing of World War I by the Central Powers (by 1922 1 gold Austro-Hungarian krone of 1914 was worth 14,400 paper Kronen), the devaluation of the Yugoslav Dinar in the 1990s, etc. Banknotes may also be overprinted to reflect political changes that occur faster than new currency can be printed.\n\nIn 1988, Austria produced the 5000 Schilling banknote (Mozart), which is the first foil application (Kinegram) to a paper banknote in the history of banknote printing. The application of optical features is now in common use throughout the world. Many countries' banknotes now have embedded holograms.\n\nIn 1983, Costa Rica and Haiti issued the first Tyvek and the Isle of Man issued the first Bradvek polymer (or plastic) banknotes; these were printed by the American Banknote Company and developed by DuPont. These early plastic notes were plagued with issues such as ink wearing off and were discontinued. In 1988, after significant research and development in Australia by the Commonwealth Scientific and Industrial Research Organisation (CSIRO) and the Reserve Bank of Australia, Australia produced the first polymer banknote made from biaxially-oriented polypropylene (plastic), and in 1996, it became the first country to have a full set of circulating polymer banknotes of all denominations completely replacing its paper banknotes. Since then, other countries to adopt circulating polymer banknotes include Bangladesh, Brazil, Brunei, Canada, Chile, Guatemala, Dominican Republic, Indonesia, Israel, Malaysia, Mexico, Nepal, New Zealand, Papua New Guinea, Paraguay, Romania, Samoa, Singapore, the Solomon Islands, Thailand, Trinidad and Tobago, the United Kingdom, Vietnam, and Zambia, with other countries issuing commemorative polymer notes, including China, Kuwait, the Northern Bank of Northern Ireland, Taiwan and Hong Kong. Another country indicating plans to issue polymer banknotes is Nigeria. In 2005, Bulgaria issued the world's first hybrid paper-polymer banknote.\n\nPolymer banknotes were developed to improve durability and prevent counterfeiting through incorporated security features, such as optically variable devices that are extremely difficult to reproduce.\n\nOver the years, a number of materials other than paper have been used to print banknotes. This includes various textiles, including silk, and materials such as leather.\n\nSilk and other fibers have been commonly used in the manufacture of various banknote papers, intended to provide both additional durability and security. Crane and Company patented banknote paper with embedded silk threads in 1844 and has supplied paper to the United States Treasury since 1879. Banknotes printed on pure silk \"paper\" include \"emergency money\" Notgeld issues from a number of German towns in 1923 during a period of fiscal crisis and hyperinflation. Most notoriously, Bielefeld produced a number of silk, leather, velvet, linen and wood issues. These issues were produced primarily for collectors, rather than for circulation. They are in demand by collectors. Banknotes printed on cloth include a number of Communist Revolutionary issues in China from areas such as Xinjiang, or Sinkiang, in the United Islamic Republic of East Turkestan in 1933. Emergency money was also printed in 1902 on khaki shirt fabric during the Boer War.\n\nCotton fibers together with 25% linen is the material of the banknotes in the United States. Leather banknotes (or coins) were issued in a number of sieges, as well as in other times of emergency. During the Russian administration of Alaska, banknotes were printed on sealskin. A number of 19th century issues are known in Germanic and Baltic states, including the places of Dorpat, Pernau, Reval, Werro and Woiseck. In addition to the Bielefeld issues, other German leather Notgeld from 1923 is known from Borna, Osterwieck, Paderborn and Pößneck.\n\nOther issues from 1923 were printed on wood, which was also used in Canada in 1763–1764 during Pontiac's Rebellion, and by the Hudson's Bay Company. In 1848, in Bohemia, wooden checkerboard pieces were used as money.\n\nEven playing cards were used for currency in France in the early 19th century, and in French Canada from 1685 until 1757, the Colony of Louisiana, Dutch Guiana, and in the Isle of Man in the beginning of the 19th century, and again in Germany after World War I.\n\nMost recently, Bisphenol S (BPS), has been frequently used in the production of banknotes worldwide. BPS is an endocrine disruptor that is subject to human dermal absorption through handling banknotes.\n\nVertical currency is a type of currency in which the orientation has been changed from the conventional horizontal orientation to a vertical orientation. Dowling Duncan, a self-touted multidisciplinary design studio, conducted a study in which they determined people tend to handle and deal with money vertically rather than horizontally, especially when the currency is processed through ATM and other money machines. They also note how money transactions are conducted vertically not horizontally. Bermuda, Cape Verde, Israel, Switzerland, and Venezuela have adopted vertically oriented currency, although Israel and Cape Verde have now reverted to horizontal orientation.\n\nSince 1979, Sri Lanka has printed the reverse of its banknotes vertically. The 2018 Hong Kong dollar banknotes series has the obverse in traditional horizontal layout, while the reverse is in vertical format.\n\nEarly Chinese banknotes were also vertical, due to the direction of Chinese writing.\n\nThe 2018 Canadian $10 bill featuring a portrait of Canadian civil rights pioneer Viola Desmond is presented in a vertical format. The Northern Irish £5 and £10 notes issued by Ulster Bank for 2019 will also be presented in this way.\n\nPeople are not the only economic actors who are required to accept banknotes. In the late 20th century, vending machines were designed to recognize banknotes of the smaller values long after they were designed to recognize coins distinct from slugs. This capability has become inescapable in economies where inflation has not been followed by introduction of progressively larger coin denominations (such as the United States, where several attempts to make dollar coins popular in general circulation have largely failed). The existing infrastructure of such machines presents one of the difficulties in changing the design of these banknotes to make them less counterfeitable, that is, by adding additional features so easily discernible by people that they would immediately reject banknotes of inferior quality, for every machine in the country would have to be updated.\n\nA banknote is removed from circulation because of everyday wear and tear from its handling. Banknotes are passed through a banknote sorting machine for determining authenticity and fitness for circulation, or may be classified unfit for circulation if they are worn, dirty, soiled, damaged, mutilated or torn. Unfit notes are returned to the central bank for secure online destruction by high-speed banknote sorting machines using a cross-cut shredder device similar to a paper shredder with security level P-5 (pieces smaller than 30 mm²) according to the standard DIN 66399-2. This small size decomposes a banknote into typically more than 500 tiny pieces and rules out reconstruction like a jigsaw puzzle because the shreds from many banknotes are commingled.\n\nA subsequent briquettor compresses shredded paper material into a small cylindrical or rectangular form for the disposal (e. g. landfill or burning Before the 1990s, unfit banknotes were destroyed by incineration with a higher risk of manipulations.\n\nWhen a Federal Reserve Bank of the United States receives a cash deposit from a commercial bank or another financial institution, it checks the individual notes to determine whether they are fit for future circulation. About one-third of the notes that the Fed receives are unfit, and the Fed destroys them. In average, US dollar banknotes last an average of more than five years.\n\nContaminated banknotes are also decommissioned and removed from circulation, primarily to prevent the spread of diseases. A Canadian government report indicates:\n\nIn the US, the nickname \"Fed Shreds\" refers to paper money which has been shredded after becoming unfit for circulation. Although these shredded banknotes are generally landfilled, they are sometimes sold or given away in small bags as souvenirs or as briquettes.\n\nPolymer banknotes may be shredded and then melted down and recycled to form plastic products like building components, plumbing fittings, or compost bins.\n\nIntelligent banknote neutralisation systems (IBNS) are security systems which render banknotes unusable by marking them permanently as stolen with a degradation agent. Marked (stained) banknotes cannot be brought back into circulation easily and can be linked to the crime scene. Today's most used degradation agent is a special security ink which cannot be removed from the banknote easily and not without destroying the banknote itself, but other agents also exist. Today IBNSs are used to protect banknotes in automated teller machines, retail machines, and during cash-in-transit operations.\n\nDynamic Intelligent Currency Encryption (DICE) is a security technology introduced in 2014 by British company EDAQS, which devaluates banknotes remotely that are illegal or have been stolen. The technology is based on identifiable banknotes - that could be an RFID chip or a barcode - and connects to a digital security system to verify the validity of the banknote. The company claims that the banknotes are unforgeable and contribute to solve cash-related problems as well as fight crime and terrorism. In another note, the DICE benefits cover and solve almost all cash-related issues that are seen by governments to be a motivation for the progressive abolition of cash.\n\nIn the United States there are many laws that allow the confiscation of cash and other assets from the bearer if there is suspicion that the money came from an illegal activity. Because a significant amount of U.S. currency contains traces of cocaine and other illegal drugs, it is not uncommon for innocent people searched at airports or stopped for traffic violations to have cash in their possession sniffed by dogs for drugs and then have the cash seized because the dog smelled drugs on the money. It is then up to the owner of the money to prove where the cash came from at his own expense. Many people simply forfeit the money. In 1994, the United States Court of Appeals, Ninth Circuit, held in the case of \"UNITED STATES of America v. U.S. CURRENCY, $30,060.00\" (39 F.3d 1039 63 USLW 2351, No. 92-55919) that the widespread presence of illegal substances on paper currency in the Los Angeles area created a situation where the reaction of a drug-sniffing dog would not create probable cause for civil forfeiture.\n\nSince the 1980s, the use of banknotes has increasingly been displaced by credit and debit cards, electronic money transfers and mobile payments, but much slower than expected. The cashless society has been predicted since more than 40 years, but cash remains the most widely used payment instrument in the world and on all continents. In 17 out of 24 studied countries, cash represents more than 50% of all payment transactions, with Austria at 85%, Germany at 80%, France at 68%. The United Kingdom at 42%, Australia at 37%, United States of America at 32%, Sweden at 20%, and South Korea at 14% are among the countries with lower cash usage.\n\nCash is still the primary means of payment (and store of value) for unbanked people with low income and helps avoiding debt traps due to uncontrolled spending of money. It supports anonymity and avoids tracking for economic or political reasons. In addition, cash is the only means for contingency planning in order to mitigate risks in case of natural disasters or failures of the technical infrastructure like a large-scale power blackout or shutdown of the communication network. Therefore central banks and governments are increasingly driving the sufficient availability of cash. The US Federal Reserve has provided guidelines for the continuity of cash services, and the Swedish government is concerned about the consequences in abandoning cash and is considering to pass a law requiring all banks to handle cash.\n\nDigital currency is a generic term for various approaches to support secure transactions of the public or using a distributed ledger, like blockchain, as a new technology for decentralized asset management. It considers establishing an electronic version of the national currency which is backed by the central bank as the issuer. Virtual currency is a digital representation of value that is neither issued by a central bank or a public authority\", such as Bitcoin. Facebook's concept for the libra is based on a token to be backed by financial assets such as a basket of national currencies.\n\nIn 2012 Bank of Canada was considering introducing digital currency. Meanwhile, it rates digital currency a pretty complicated decision and is analyzing the pros and cons and working to determine under which conditions it may make sense to, one day, issue a digital currency. As a threat, a central bank digital currency could increase the risk of a run on the banking system.\n\nAlso in 2012, Sveriges Riksbank, the central bank of Sweden, was reported to analyze technological advances with regard to electronic money and payment methods for digital currency as an alternative to cash. In 2019, it is investigating whether Swedish krona need to be made available in electronic form, the so-called e-krona, and if so, how it would affect Swedish legislation and the Riksbank's task. It has started procuring a technical supplier to develop and test solutions for a potential future e-krona. No decisions have yet been taken on issuing an e-krona.\n\nBanknote collecting, or notaphily, is a slowly growing area of numismatics. Although generally not as widespread as coin and stamp collecting, the hobby is slowly expanding. Prior to the 1990s, currency collecting was a relatively small adjunct to coin collecting, but currency auctions and greater public awareness of paper money have caused more interest in rare banknotes and consequently their increased value. The most valuable banknote is the $1000 bill issued in 1890 that was sold at an auction for $2,255,000.\n\nFor years, the mode of collecting banknotes was through a handful of mail order dealers who issued price lists and catalogs. In the early 1990s, it became more common for rare notes to be sold at various coin and currency shows via auction. The illustrated catalogs and \"event nature\" of the auction practice seemed to fuel a sharp rise in overall awareness of paper money in the numismatic community. The emergence of currency third party grading services (similar to services that grade and \"slab\", or encapsulate, coins) also may have increased collector and investor interest in notes. Entire advanced collections are often sold at one time, and to this day single auctions can generate millions in gross sales. Today, eBay has surpassed auctions in terms of highest volume of sales of banknotes. However, rare banknotes still sell for much less than comparable rare coins. This disparity is diminishing as paper money prices continue to rise. A few rare and historical banknotes have sold for more than a million dollars.\n\nThere are many different organizations and societies around the world for the hobby, including the International Bank Note Society (IBNS), which currently assert to have around 2,000 members in 90 countries.\n\nThe universal appeal and instant recognition of bank notes has resulted in a plethora of novelty merchandise that is designed to have the appearance of paper currency. These items cover nearly every class of product. Cloth material printed with bank note patterns is used for clothing, bed linens, curtains, upholstery and more. Acrylic paperweights and even toilet seats with bank notes embedded inside are also common. Items that resemble stacks of bank notes and can be used as a seat or ottoman are also available.\n\nManufacturers of these items must take into consideration when creating these products whether the product could be construed as counterfeiting. Overlapping note images and/or changing the dimensions of the reproduction to be at least 50% smaller or 50% larger than the original are some ways to avoid the risk of being considered a counterfeit. But in cases where realism is the goal, other steps may be necessary. For example, in the stack of bank notes seat mentioned earlier, the decal used to create the product would be considered counterfeit. However, once the decal has been affixed to the resin stack shell and cannot be peeled off, the final product is no longer at risk of being classified as counterfeit, even though the resulting appearance is realistic.\n\n\n"}
{"id": "19360669", "url": "https://en.wikipedia.org/wiki?curid=19360669", "title": "Bank", "text": "Bank\n\nA bank is a financial institution that accepts deposits from the public and creates credit. Lending activities can be performed either directly or indirectly through capital markets. Due to their importance in the financial stability of a country, banks are highly regulated in most countries. Most nations have institutionalized a system known as fractional reserve banking under which banks hold liquid assets equal to only a portion of their current liabilities. In addition to other regulations intended to ensure liquidity, banks are generally subject to minimum capital requirements based on an international set of capital standards, known as the Basel Accords.\n\nBanking in its modern sense evolved in the fourteenth century in the prosperous cities of Renaissance Italy but in many ways was a continuation of ideas and concepts of credit and lending that had their roots in the ancient world. In the history of banking, a number of banking dynasties – notably, the Medicis, the Fuggers, the Welsers, the Berenbergs, and the Rothschilds – have played a central role over many centuries. The oldest existing retail bank is Banca Monte dei Paschi di Siena, while the oldest existing merchant bank is Berenberg Bank.\n\nThe concept of banking may have begun in ancient Babylonia and Old sangvi, with merchants offering loans of grain as collateral within a barter system. Lenders in ancient Greece and during the Roman Empire added two important innovations: they accepted deposits and changed money. Archaeology from this period in ancient China and India also shows evidence of money lending.\n\nMore modern banking can be traced to medieval and early Renaissance Italy, to the rich cities in the centre and north like Florence, Lucca, Siena, Venice and Genoa. The Bardi and Peruzzi families dominated banking in 14th-century Florence, establishing branches in many other parts of Europe. One of the most famous Italian banks was the Medici Bank, set up by Giovanni di Bicci de' Medici in 1397. The earliest known state deposit bank, Banco di San Giorgio (Bank of St. George), was founded in 1407 at Genoa, Italy.\n\nModern banking practices, including fractional reserve banking and the issue of banknotes, emerged in the 17th and 18th centuries. Merchants started to store their gold with the goldsmiths of London, who possessed private vaults, and charged a fee for that service. In exchange for each deposit of precious metal, the goldsmiths issued receipts certifying the quantity and purity of the metal they held as a bailee; these receipts could not be assigned, only the original depositor could collect the stored goods.\nGradually the goldsmiths began to lend the money out on behalf of the depositor, which led to the development of modern banking practices; promissory notes (which evolved into banknotes) were issued for money deposited as a loan to the goldsmith. The goldsmith paid interest on these deposits. Since the promissory notes were payable on demand, and the advances (loans) to the goldsmith's customers were repayable over a longer time period, this was an early form of fractional reserve banking. The promissory notes developed into an assignable instrument which could circulate as a safe and convenient form of money backed by the goldsmith's promise to pay, allowing goldsmiths to advance loans with little risk of default. Thus, the goldsmiths of London became the forerunners of banking by creating new money based on credit.\n\nThe Bank of England was the first to begin the permanent issue of banknotes, in 1695. The Royal Bank of Scotland established the first overdraft facility in 1728. By the beginning of the 19th century a bankers' clearing house was established in London to allow multiple banks to clear transactions. The Rothschilds pioneered international finance on a large scale, financing the purchase of the Suez canal for the British government.\n\nThe word \" bank\" was taken Middle English from Middle French \"banque\", from Old Italian \"banco\", meaning \"table\", from Old High German \"banc, bank\" \"bench, counter\". Benches were used as makeshift desks or exchange counters during the Renaissance by Jewish Florentine bankers, who used to make their transactions atop desks covered by green tablecloths.\n\nThe definition of a bank varies from country to country. See the relevant country pages for more information.\n\nUnder English common law, a banker is defined as a person who carries on the business of banking by conducting current accounts for his customers, paying cheques drawn on him/her and also collecting cheques for his/her customers.\n\nIn most common law jurisdictions there is a Bills of Exchange Act that codifies the law in relation to negotiable instruments, including cheques, and this Act contains a statutory definition of the term \"banker\": \"banker\" includes a body of persons, whether incorporated or not, who carry on the business of banking' (Section 2, Interpretation). Although this definition seems circular, it is actually functional, because it ensures that the legal basis for bank transactions such as cheques does not depend on how the bank is structured or regulated.\n\nThe business of banking is in many English common law countries not defined by statute but by common law, the definition above. In other English common law jurisdictions there are statutory definitions of the \"business of banking\" or \"banking business\". When looking at these definitions it is important to keep in mind that they are defining the business of banking for the purposes of the legislation, and not necessarily in general. In particular, most of the definitions are from legislation that has the purpose of regulating and supervising banks rather than regulating the actual business of banking. However, in many cases the statutory definition closely mirrors the common law one. Examples of statutory definitions:\n\nSince the advent of EFTPOS (Electronic Funds Transfer at Point Of Sale), direct credit, direct debit and internet banking, the cheque has lost its primacy in most banking systems as a payment instrument. This has led legal theorists to suggest that the cheque based definition should be broadened to include financial institutions that conduct current accounts for customers and enable customers to pay and be paid by third parties, even if they do not pay and collect cheques .\n\nBanks act as payment agents by conducting checking or current accounts for customers, paying cheques drawn by customers in the bank, and collecting cheques deposited to customers' current accounts. Banks also enable customer payments via other payment methods such as Automated Clearing House (ACH), Wire transfers or telegraphic transfer, EFTPOS, and automated teller machines (ATMs).\n\nBanks borrow money by accepting funds deposited on current accounts, by accepting term deposits, and by issuing debt securities such as banknotes and bonds. Banks lend money by making advances to customers on current accounts, by making installment loans, and by investing in marketable debt securities and other forms of money lending.\n\nBanks provide different payment services, and a bank account is considered indispensable by most businesses and individuals. Non-banks that provide payment services such as remittance companies are normally not considered as an adequate substitute for a bank account.\n\nBanks can create new money when they make a loan. New loans throughout the banking system generate new deposits elsewhere in the system. The money supply is usually increased by the act of lending, and reduced when loans are repaid faster than new ones are generated. In the United Kingdom between 1997 and 2007, there was an increase in the money supply, largely caused by much more bank lending, which served to push up property prices and increase private debt. The amount of money in the economy as measured by M4 in the UK went from £750 billion to £1700 billion between 1997 and 2007, much of the increase caused by bank lending. If all the banks increase their lending together, then they can expect new deposits to return to them and the amount of money in the economy will increase. Excessive or risky lending can cause borrowers to default, the banks then become more cautious, so there is less lending and therefore less money so that the economy can go from boom to bust as happened in the UK and many other Western economies after 2007.\nActivities undertaken by banks include personal banking, corporate banking, investment banking, private banking, transaction banking, insurance, consumer finance, foreign exchange trading, commodity trading, trading in equities, futures and options trading and money market trading.\n\nBanks offer many different channels to access their banking and other services:\n\nA bank can generate revenue in a variety of different ways including interest, transaction fees and financial advice. Traditionally, the most significant method is via charging interest on the capital it lends out to customers. The bank profits from the difference between the level of interest it pays for deposits and other sources of funds, and the level of interest it charges in its lending activities.\n\nThis difference is referred to as the spread between the cost of funds and the loan interest rate. Historically, profitability from lending activities has been cyclical and dependent on the needs and strengths of loan customers and the stage of the economic cycle. Fees and financial advice constitute a more stable revenue stream and banks have therefore placed more emphasis on these revenue lines to smooth their financial performance.\n\nIn the past 20 years, American banks have taken many measures to ensure that they remain profitable while responding to increasingly changing market conditions.\n\nThis helps in making a profit and facilitates economic development as a whole.\n\nRecently, as banks have been faced with pressure from fintechs, new and additional business models have been suggested such as freemium, monetization of data, white-labeling of banking and payment applications, or the cross-selling of complementary products.\n\n\n\nBanks face a number of risks in order to conduct their business, and how well these risks are managed and understood is a key driver behind profitability, and how much capital a bank is required to hold. Bank capital consists principally of equity, retained earnings and subordinated debt.\n\nAfter the 2007-2009 financial crisis, regulators force banks to issue \"Contingent convertible bonds\" (CoCos).These are hybrid capital securities that absorb losses in accordance with their contractual terms when the capital of the issuing bank falls below a certain level. Then debt is reduced and bank capitalization gets a boost. Owing to their capacity to absorb losses, CoCos have the potential to satisfy regulatory capital requirement.\n\nSome of the main risks faced by banks include:\n\nThe capital requirement is a bank regulation, which sets a framework within which a bank or depository institution must manage its balance sheet. The categorization of assets and capital is highly standardized so that it can be risk weighted.\n\nThe economic functions of banks include:\n\nBanks are susceptible to many forms of risk which have triggered occasional systemic crises. These include liquidity risk (where many depositors may request withdrawals in excess of available funds), credit risk (the chance that those who owe money to the bank will not repay it), and interest rate risk (the possibility that the bank will become unprofitable, if rising interest rates force it to pay relatively more on its deposits than it receives on its loans).\n\nBanking crises have developed many times throughout history when one or more risks have emerged for a banking sector as a whole. Prominent examples include the bank run that occurred during the Great Depression, the U.S. Savings and Loan crisis in the 1980s and early 1990s, the Japanese banking crisis during the 1990s, and the sub-prime mortgage crisis in the 2000s.\n\nAssets of the largest 1,000 banks in the world grew by 6.8% in the 2008/2009 financial year to a record US$96.4 trillion while profits declined by 85% to US$115 billion. Growth in assets in adverse market conditions was largely a result of recapitalization. EU banks held the largest share of the total, 56% in 2008/2009, down from 61% in the previous year. Asian banks' share increased from 12% to 14% during the year, while the share of US banks increased from 11% to 13%. Fee revenue generated by global investment banking totalled US$66.3 billion in 2009, up 12% on the previous year.\n\nThe United States has the most banks in the world in terms of institutions (5,330 as of 2015) and possibly branches (81,607 as of 2015). This is an indicator of the geography and regulatory structure of the US, resulting in a large number of small to medium-sized institutions in its banking system. As of November 2009, China's top 4 banks have in excess of 67,000 branches (ICBC:18000+, BOC:12000+, CCB:13000+, ABC:24000+) with an additional 140 smaller banks with an undetermined number of branches.\nJapan had 129 banks and 12,000 branches. In 2004, Germany, France, and Italy each had more than 30,000 branches – more than double the 15,000 branches in the UK.\n\nBetween 1985 and 2018 banks engaged in around 28,798 mergers or acquisitions, either as the acquirer or the target company. The overall known value of these deals cumulates to around 5,169 bil. USD. In terms of value, there have been two major waves (1999 and 2007) which both peaked at around 460 bil. USD followed by a steep decline (-82% from 2007 until 2018).\n\nHere is a list of the largest deals in history in terms of value with participation from at least one bank:\nCurrently, commercial banks are regulated in most jurisdictions by government entities and require a special bank license to operate.\n\nUsually, the definition of the business of banking for the purposes of regulation is extended to include acceptance of deposits, even if they are not repayable to the customer's order – although money lending, by itself, is generally not included in the definition.\n\nUnlike most other regulated industries, the regulator is typically also a participant in the market, being either a publicly or privately governed central bank. Central banks also typically have a monopoly on the business of issuing banknotes. However, in some countries this is not the case. In the UK, for example, the Financial Services Authority licenses banks, and some commercial banks (such as the Bank of Scotland) issue their own banknotes in addition to those issued by the Bank of England, the UK government's central bank.\n\nBanking law is based on a contractual analysis of the relationship between the \"bank\" (defined above) and the \"customer\" – defined as any entity for which the bank agrees to conduct an account.\n\nThe law implies rights and obligations into this relationship as follows:\n\nThese implied contractual terms may be modified by express agreement between the customer and the bank. The statutes and regulations in force within a particular jurisdiction may also modify the above terms and/or create new rights, obligations or limitations relevant to the bank-customer relationship.\n\nSome types of financial institution, such as building societies and credit unions, may be partly or wholly exempt from bank license requirements, and therefore regulated under separate rules.\n\nThe requirements for the issue of a bank license vary between jurisdictions but typically include:\n\nBanks' activities can be divided into:\nMost banks are profit-making, private enterprises. However, some are owned by government, or are non-profit organizations.\n\n\n\n\n\nThe United States banking industry is one of the most heavily regulated and guarded in the world, with multiple specialized and focused regulators. All banks with FDIC-insured deposits have the Federal Deposit Insurance Corporation (FDIC) as a regulator. However, for soundness examinations (i.e., whether a bank is operating in a sound manner), the Federal Reserve is the primary federal regulator for Fed-member state banks; the Office of the Comptroller of the Currency (OCC) is the primary federal regulator for national banks. State non-member banks are examined by the state agencies as well as the FDIC. National banks have one primary regulator – the OCC.\n\nEach regulatory agency has their own set of rules and regulations to which banks and thrifts must adhere.\nThe Federal Financial Institutions Examination Council (FFIEC) was established in 1979 as a formal inter-agency body empowered to prescribe uniform principles, standards, and report forms for the federal examination of financial institutions. Although the FFIEC has resulted in a greater degree of regulatory consistency between the agencies, the rules and regulations are constantly changing.\n\nIn addition to changing regulations, changes in the industry have led to consolidations within the Federal Reserve, FDIC, OTS, and OCC. Offices have been closed, supervisory regions have been merged, staff levels have been reduced and budgets have been cut. The remaining regulators face an increased burden with increased workload and more banks per regulator. While banks struggle to keep up with the changes in the regulatory environment, regulators struggle to manage their workload and effectively regulate their banks. The impact of these changes is that banks are receiving less hands-on assessment by the regulators, less time spent with each institution, and the potential for more problems slipping through the cracks, potentially resulting in an overall increase in bank failures across the United States.\n\nThe changing economic environment has a significant impact on banks and thrifts as they struggle to effectively manage their interest rate spread in the face of low rates on loans, rate competition for deposits and the general market changes, industry trends and economic fluctuations. It has been a challenge for banks to effectively set their growth strategies with the recent economic market. A rising interest rate environment may seem to help financial institutions, but the effect of the changes on consumers and businesses is not predictable and the challenge remains for banks to grow and effectively manage the spread to generate a return to their shareholders.\n\nThe management of the banks’ asset portfolios also remains a challenge in today's economic environment. Loans are a bank's primary asset category and when loan quality becomes suspect, the foundation of a bank is shaken to the core. While always an issue for banks, declining asset quality has become a big problem for financial institutions.\n\nThere are several reasons for this, one of which is the lax attitude some banks have adopted because of the years of “good times.” The potential for this is exacerbated by the reduction in the regulatory oversight of banks and in some cases depth of management. Problems are more likely to go undetected, resulting in a significant impact on the bank when they are discovered. In addition, banks, like any business, struggle to cut costs and have consequently eliminated certain expenses, such as adequate employee training programs.\n\nBanks also face a host of other challenges such as ageing ownership groups. Across the country, many banks’ management teams and board of directors are ageing. Banks also face ongoing pressure by shareholders, both public and private, to achieve earnings and growth projections. Regulators place added pressure on banks to manage the various categories of risk. Banking is also an extremely competitive industry. Competing in the financial services industry has become tougher with the entrance of such players as insurance agencies, credit unions, cheque cashing services, credit card companies, etc.\n\nAs a reaction, banks have developed their activities in financial instruments, through financial market operations such as brokerage and have become big players in such activities.\n\nAnother major challenge is the ageing infrastructure, also called legacy IT. Backend systems were built decades ago and are incompatible to new applications. Fixing bugs and creating interfaces costs huge sums, as knowledgeable programmers become scarce.\n\nTo be able to provide home buyers and builders with the funds needed, banks must compete for deposits. The phenomenon of disintermediation had to dollars moving from savings accounts and into direct market instruments such as U.S. Department of Treasury obligations, agency securities, and corporate debt. One of the greatest factors in recent years in the movement of deposits was the tremendous growth of money market funds whose higher interest rates attracted consumer deposits.\n\nTo compete for deposits, US savings institutions offer many different types of plans:\n\nBank statements are accounting records produced by banks under the various accounting standards of the world. Under GAAP there are two kinds of accounts: debit and credit. Credit accounts are Revenue, Equity and Liabilities. Debit Accounts are Assets and Expenses. The bank credits a \"credit account\" to increase its balance, and debits a \"credit account\" to decrease its balance.\n\nThe customer debits his or her savings/bank (asset) account in his ledger when making a deposit (and the account is normally in debit), while the customer credits a credit card (liability) account in his ledger every time he spends money (and the account is normally in credit). When the customer reads his bank statement, the statement will show a credit to the account for deposits, and debits for withdrawals of funds. The customer with a positive balance will see this balance reflected as a credit balance on the bank statement. If the customer is overdrawn, he will have a negative balance, reflected as a debit balance on the bank statement.\n\nOne source of deposits for banks is brokers who deposit large sums of money on behalf of investors through trust corporations. This money will generally go to the banks which offer the most favourable terms, often better than those offered local depositors. It is possible for a bank to engage in business with no local deposits at all, all funds being brokered deposits. Accepting a significant quantity of such deposits, or \"hot money\" as it is sometimes called, puts a bank in a difficult and sometimes risky position, as the funds must be lent or invested in a way that yields a return sufficient to pay the high interest being paid on the brokered deposits. This may result in risky decisions and even in eventual failure of the bank. Banks which failed during 2008 and 2009 in the United States during the global financial crisis had, on average, four times more brokered deposits as a percent of their deposits than the average bank. Such deposits, combined with risky real estate investments, factored into the savings and loan crisis of the 1980s. Regulation of brokered deposits is opposed by banks on the grounds that the practice can be a source of external funding to growing communities with insufficient local deposits. There are different types of accounts: saving, recurring and current accounts.\n\nCustodial accounts are accounts in which assets are held for a third party. For example, businesses that accept custody of funds for clients prior to their conversion, return or transfer may have a custodial account at a bank for this purposes.\n\nIn modern time there has been huge reductions to the barriers of global competition in the banking industry. Increases in telecommunications and other financial technologies, such as Bloomberg, have allowed banks to extend their reach all over the world, since they no longer have to be near customers to manage both their finances and their risk. The growth in cross-border activities has also increased the demand for banks that can provide various services across borders to different nationalities.\nHowever, despite these reductions in barriers and growth in cross-border activities, the banking industry is nowhere near as globalized as some other industries. In the US, for instance, very few banks even worry about the Riegle–Neal Act, which promotes more efficient interstate banking. In the vast majority of nations around the globe the market share for foreign owned banks is currently less than a tenth of all market shares for banks in a particular nation.\nOne reason the banking industry has not been fully globalized is that it is more convenient to have local banks provide loans to small business and individuals. On the other hand, for large corporations, it is not as important in what nation the bank is in, since the corporation's financial information is available around the globe.\n\nTypes of institutions:\nTerms and concepts:\n\nTerms and concepts:\nCrime:\nCyber Crime\n\nLists:\n\nBanking by country\n\n"}
{"id": "1267494", "url": "https://en.wikipedia.org/wiki?curid=1267494", "title": "Cheque", "text": "Cheque\n\nA cheque, or check (American English; see spelling differences), is a document that orders a bank to pay a specific amount of money from a person's account to the person in whose name the cheque has been issued. The person writing the cheque, known as the \"drawer\", has a transaction banking account (often called a current, cheque, chequing or checking account) where their money is held. The drawer writes the various details including the monetary amount, date, and a payee on the cheque, and signs it, ordering their bank, known as the \"drawee\", to pay that person or company the amount of money stated.\n\nCheques are a type of bill of exchange that were developed as a way to make payments without the need to carry large amounts of money. Paper money evolved from promissory notes, another form of negotiable instrument similar to cheques in that they were originally a written order to pay the given amount to whoever had it in their possession (the \"bearer\").\n\nA cheque is a negotiable instrument instructing a financial institution to pay a specific amount of a specific currency from a specified transactional account held in the drawer's name with that institution. Both the drawer and payee may be natural persons or legal entities. Cheques are \"order instruments\", and are not in general payable simply to the bearer as bearer instruments are, but must be paid to the payee. In some countries, such as the US, the payee may endorse the cheque, allowing them to specify a third party to whom it should be paid.\n\nAlthough forms of cheques have been in use since ancient times and at least since the 9th century, it was during the 20th century that cheques became a highly popular non-cash method for making payments and the usage of cheques peaked. By the second half of the 20th century, as cheque processing became automated, billions of cheques were issued annually; these volumes peaked in or around the early 1990s. Since then cheque usage has fallen, being partly replaced by electronic payment systems. In an increasing number of countries cheques have either become a marginal payment system or have been completely phased out.\n\nThe spellings \"check\", \"checque\", and \"cheque\" were used interchangeably from the 17th century until the 20th century. However, since the 19th century, the spelling \"cheque\" (from the French word \"chèque\") has become standard for the financial instrument in the Commonwealth and Ireland, while \"check\" is used only for other meanings, thus distinguishing the two definitions in writing.\n\n\"Check\" is the original spelling. The newer spelling, \"cheque\", is believed to have come into use around 1828, when the switch was made by James William Gilbart in his \"Practical Treatise on Banking\".\n\nIn American English, the usual spelling for both is \"check\".\n\nEtymological dictionaries attribute the financial meaning to come from \"a check against forgery\", with the use of \"check\" to mean \"control\" stemming from a check in chess, a term which came into English through French, Latin, Arabic and ultimately from the Persian word \"shah\", or \"king\".\n\nThe cheque had its origins in the ancient banking system, in which bankers would issue orders at the request of their customers, to pay money to identified payees. Such an order was referred to as a \"bill of exchange\". The use of bills of exchange facilitated trade by eliminating the need for merchants to carry large quantities of currency (for example, gold) to purchase goods and services.\n\nThere is early evidence of using cheques. In India, during the Maurya Empire (from 321 to 185 BC), a commercial instrument called the adesha was in use, which was an order on a banker desiring him to pay the money of the note to a third person.\n\nThe ancient Romans are believed to have used an early form of cheque known as \"praescriptiones\" in the 1st century BCE.\n\nBeginning in the third century CE, banks in Persian territory began to issue letters of credit. These letters were termed \"čak\", meaning \"document\" or \"contract\". The \"čak\" became the \"sakk\" later used by traders in the Abbasid Caliphate and other Arab-ruled lands. Transporting a paper \"sakk\" was more secure than transporting money. In the ninth century, a merchant in one country could cash a \"sakk\" drawn on his bank in another country.\n\nIn the 13th century in Venice the \"bill of exchange\" was developed as a legal device to allow international trade without the need to carry large amounts of gold and silver. Their use subsequently spread to other European countries.\n\nIn the early 1500s in the Dutch Republic, to protect large accumulations of cash, people began depositing their money with \"cashiers\". These cashiers held the money for a fee. Competition drove cashiers to offer additional services including paying money to any person bearing a written order from a depositor to do so. They kept the note as proof of payment. This concept went on to spread to England and elsewhere.\n\nBy the 17th century, bills of exchange were being used for domestic payments in England. Cheques, a type of bill of exchange, then began to evolve. Initially they were called \"drawn notes\", because they enabled a customer to draw on the funds that he or she had in the account with a bank and required immediate payment. These were handwritten, and one of the earliest known still to be in existence was drawn on Messrs Morris and Clayton, scriveners and bankers based in the City of London, and dated 16 February 1659.\n\nIn 1717, the Bank of England pioneered the first use of a pre-printed form. These forms were printed on \"cheque paper\" to prevent fraud, and customers had to attend in person and obtain a numbered form from the cashier. Once written, the cheque was brought back to the bank for settlement. The suppression of banknotes in eighteenth-century England further promoted the use of cheques.\n\nUntil about 1770, an informal exchange of cheques took place between London banks. Clerks of each bank visited all the other banks to exchange cheques, whilst keeping a tally of balances between them until they settled with each other. Daily cheque clearing began around 1770 when the bank clerks met at the Five Bells, a tavern in Lombard Street in the City of London, to exchange all their cheques in one place and settle the balances in cash. This was the first bankers' clearing house.\n\nIn America, the Bank of New York, after its establishment by Alexander Hamilton in 1784, began issuing cheques. The oldest surviving example of a complete American chequebook from the 1790s was discovered by a family in New Jersey. The documents are in some ways similar to modern-day checks, with some data pre-printed on sheets of paper alongside blank spaces for where other information could be hand-written as needed.\n\nIt is thought that the Commercial Bank of Scotland was the first bank to personalize its customers' cheques, in 1811, by printing the name of the account holder vertically along the left-hand edge. In 1830 the Bank of England introduced books of 50, 100, and 200 forms and counterparts, bound or stitched. These \"cheque books\" became a common format for the distribution of cheques to bank customers.\n\nIn the late 19th century, several countries formalized laws regarding cheques. The UK passed the Bills of Exchange Act 1882, and India passed the Negotiable Instruments Act, 1881; which both covered cheques.\n\nIn 1931 an attempt was made to simplify the international use of cheques by the Geneva Convention on the Unification of the Law Relating to Cheques. Many European and South American states as well as Japan joined the convention. However, countries including the US and members of the British Commonwealth did not participate and so it remained very difficult for cheques to be used across country borders.\n\nIn 1959 a standard for machine-readable characters (MICR) was agreed and patented in the US for use with cheques. This opened the way for the first automated reader/sorting machines for clearing cheques. As automation increased, the following years saw a dramatic change in the way in which cheques were handled and processed. Cheque volumes continued to grow; in the late 20th century, cheques were the most popular non-cash method for making payments, with billions of them processed each year. Most countries saw cheque volumes peak in the late 1980s or early 1990s, after which electronic payment methods became more popular and the use of cheques declined.\n\nIn 1969 cheque guarantee cards were introduced in several countries, allowing a retailer to confirm that a cheque would be honoured when used at a point of sale. The drawer would sign the cheque in front of the retailer, who would compare the signature to the signature on the card and then write the cheque-guarantee-card number on the back of the cheque. Such cards were generally phased out and replaced by debit cards, starting in the mid-1990s.\n\nFrom the mid-1990s, many countries enacted laws to allow for cheque truncation, in which a physical cheque is converted into electronic form for transmission to the paying bank or clearing-house. This eliminates the cumbersome physical presentation and saves time and processing costs.\n\nIn 2002, the Eurocheque system was phased out and replaced with domestic clearing systems. Old eurocheques could still be used, but they were now processed by national clearing systems. At that time, a number of countries took the opportunity to phase out the use of cheques altogether. As of 2010, many countries have either phased out the use of cheques altogether or signalled that they would do so in the future.\n\nThe four main items on a cheque are\n\nAs cheque usage increased during the 19th and 20th centuries, additional items were added to increase security or to make processing easier for the bank or financial institution. A signature of the drawer was required to authorize the cheque, and this is the main way to authenticate the cheque. Second, it became customary to write the amount in words as well as in numbers to avoid mistakes and make it harder to fraudulently alter the amount after the cheque had been written. It is not a legal requirement to write down the amount in words, although some banks will refuse to accept cheques that do not have the amount in both numbers and words.\n\nAn issue date was added, and cheques may not be valid a certain amount of time after issue. In the US and Canada a cheque is typically valid for six months after the date of issue, after which it is a \"stale-dated cheque,\" but this depends on where the cheque is drawn; in Australia this is typically fifteen months. A cheque that has an issue date in the future, a post-dated cheque, may not be able to be presented until that date has passed, writing a post dated cheque may simply be ignored or is illegal in some countries. Conversely, an antedated cheque has an issue date in the past.\n\nA cheque number was added and cheque books were issued so that cheque numbers were sequential. This allowed for some basic fraud detection by banks and made sure one cheque was not presented twice.\n\nIn some countries such as the US, cheques contain a memo line where the purpose of the cheque can be indicated as a convenience without affecting the official parts of the cheque. In the United Kingdom this is not available and such notes are sometimes written on the reverse side of the cheque.\n\nIn the US, at the top (when cheque oriented vertically) of the reverse side of the cheque, there are usually one or more blank lines labelled something like \"Endorse here\".\n\nStarting in the 1960s, machine readable routing and account information was added to the bottom of cheques in MICR format. This allowed automated sorting and routing of cheques between banks and led to automated central clearing facilities. The information provided at the bottom of the cheque is country-specific and is driven by each country's cheque clearing system. This means that the payee no longer has to go to the bank that issued the cheque, instead they can deposit it at their own bank or any other banks and the cheque would be routed back to the originating bank, and funds transferred to their own bank account.\n\nIn the US, the bottom 5/8\" of the cheque is a keep out zone reserved for MICR characters only, which should not be intruded upon by handwriting. One must be especially careful of lowercase descenders when filling out the signature and memo lines which are often at the bottom of the cheque in close proximity. It is advisable to treat the signature and memo lines as boundaries rather than baselines and sign above them. Intrusion into the MICR area can cause problems when the cheque runs through the clearinghouse, requiring someone to print an MICR cheque correction strip and glue it to the cheque. Many new ATMs do not use deposit envelopes and actually scan the cheque at the time it is deposited and will reject cheques due to handwriting incursion which interferes with reading the MICR. This can cause considerable inconvenience as the depositor may have to wait days for the bank to be open and may have difficulty getting to the bank even when they are open; this can delay the availability of the portion of a deposit which their bank makes available immediately as well as the balance of the deposit. Terms of service for many mobile (cell phone camera) deposits also require the MICR section to be readable. Not all of the MICR characters have been printed at the time you manually fill in the cheque as additional characters will be printed later to encode the amount; thus your sloppy signature could obscure characters that you didn't realize would later be printed there. Since MICR characters are no longer necessarily printed in magnetic ink and will be scanned by optical rather than magnetic means, the readers will be unable to distinguish pen ink from pre-printed magnetic ink; these changes allow cheques to be printed on ordinary home and office printers without requiring pre-printed cheque forms, allow ATM deposit capture, allow mobile deposits, and facilitate electronic copies of cheques.\n\nFor additional protection, a cheque can be crossed, which restricts the use of the cheque so that the funds must be paid into a bank account. The format and wording varies from country to country, but generally two parallel lines may be placed either vertically across the cheque or in the top left hand corner. In addition the words 'or bearer' must not be used, or if pre-printed on the cheque must be crossed out on the payee line. If the cheque is crossed with the words 'Account Payee' or similar then the cheque can only be paid into the bank account of the person initially named as the payee, thus it cannot be endorsed to a different payee.\n\nCheques sometimes include additional documents. A page in a chequebook may consist of both the cheque itself and a stub or \"\" – when the cheque is written, only the cheque itself is detached, and the stub is retained in the chequebook as a record of the cheque. Alternatively, cheques may be recorded with carbon paper behind each cheque, in ledger sheets between cheques or at the back of a chequebook, or in a completely separate transaction register that comes with a chequebook.\n\nWhen a cheque is mailed, a separate letter or \"remittance advice\" may be attached to inform the recipient of the purpose of the cheque – formally, which account receivable to credit the funds to. This is frequently done formally using a provided slip when paying a bill, or informally via a letter when sending an ad hoc cheque.\n\nParties to regular cheques generally include a \"drawer\", the depositor writing a cheque; a \"drawee,\" the financial institution where the cheque can be presented for payment; and a \"payee,\" the entity to whom the drawer issues the cheque. The drawer \"drafts\" or \"draws\" a cheque, which is also called \"cutting a cheque\", especially in the US. There may also be a \"beneficiary\"—for example, in depositing a cheque with a custodian of a brokerage account, the payee will be the custodian, but the cheque may be marked \"F/B/O\" (\"for the benefit of\") the beneficiary.\n\nUltimately, there is also at least one \"endorsee\" which would typically be the financial institution servicing the payee's account, or in some circumstances may be a third party to whom the payee owes or wishes to give money.\n\nA payee that accepts a cheque will typically deposit it in an account at the payee's bank, and have the bank process the cheque. In some cases, the payee will take the cheque to a branch of the drawee bank, and cash the cheque there. If a cheque is refused at the drawee bank (or the drawee bank returns the cheque to the bank that it was deposited at) because there are insufficient funds for the cheque to clear, it is said that the cheque has been \"dishonoured\". Once a cheque is approved and all appropriate accounts involved have been credited, the cheque is stamped with some kind of cancellation mark, such as a \"paid\" stamp. The cheque is now a \"cancelled cheque\". Cancelled cheques are placed in the account holder's file. The account holder can request a copy of a cancelled cheque as proof of a payment. This is known as the cheque clearing cycle.\n\nCheques can be lost or go astray within the cycle, or be delayed if further verification is needed in the case of suspected fraud. A cheque may thus bounce some time after it has been deposited.\nFollowing concerns about the amount of time it took the Cheque and Credit Clearing Company to clear cheques, the United Kingdom Office of Fair Trading set up a working group in 2006 to look at the cheque clearing cycle. Their report said that clearing times could be improved, but that the costs associated with speeding up the cheque clearing cycle could not be justified considering the use of cheques was declining. However, they concluded the biggest problem was the unlimited time a bank could take to dishonour a cheque. To address this, changes were implemented so that the maximum time after a cheque was deposited that it could be dishonoured was six days, what was known as the \"certainty of fate\" principle.\n\nAn advantage to the drawer of using cheques instead of debit card transactions, is that they know the drawer's bank will not release the money until several days later. Paying with a cheque and making a deposit before it clears the drawer's bank is called \"kiting\" or \"floating\" and is generally illegal in the US, but rarely enforced unless the drawer uses multiple chequing accounts with multiple institutions to increase the delay or to steal the funds.\n\nCheque usage has been declining for some years, both for point of sale transactions (for which credit cards and debit cards are increasingly preferred) and for third party payments (for example, bill payments), where the decline has been accelerated by the emergence of telephone banking and online banking. Being paper-based, cheques are costly for banks to process in comparison to electronic payments, so banks in many countries now discourage the use of cheques, either by charging for cheques or by making the alternatives more attractive to customers. In particular the handling of money transfer requires more effort and is time consuming. The cheque has to be handed over in person or sent through mail. The rise of automated teller machines (ATMs) means that small amounts of cash are often easily accessible, so that it is sometimes unnecessary to write a cheque for such amounts instead.\n\nAlternative payment systems include:\n\n\nIn most European countries, cheques are now rarely used, even for third party payments. In these countries, it is standard practice for businesses to publish their bank details on invoices, to facilitate the receipt of payments by giro. Even before the introduction of online banking, it has been possible in some countries to make payments to third parties using ATMs, which may accurately and rapidly capture invoice amounts, due dates, and payee bank details via a bar code reader to reduce keying. In some countries, entering the bank account number results in the bank revealing the name of the payee as an added safeguard against fraud. In using a cheque, the onus is on the payee to initiate the payment, whereas with a giro transfer, the onus is on the payer to effect the payment (The writer of a paper cheque is pushing on a rope: he cannot force money out of his own account and into the destination's account. By writing the paper cheque, he is handing the far end of the rope to the payee, who will pull in his own good time. In contrast, giro is more akin to wire transfer, in that the payer pushes his money away towards the payee). The process is also procedurally more simple, as no cheques are ever posted, can claim to have been posted, or need banking or clearance.\n\nIn Germany, Austria, the Netherlands, Belgium, and Scandinavia, cheques have almost completely vanished in favour of direct bank transfers and electronic payments. Direct bank transfers, using so-called giro transfers, have been standard procedure since the 1950s to send and receive regular payments like rent and wages and even mail-order invoices. In the Netherlands, Austria, and Germany, all kinds of invoices are commonly accompanied by so-called ' (Netherlands) or ' (German), which are essentially standardized bank transfer order forms preprinted with the payee's account details and the amount payable. The payer fills in his account details and hands the form to a clerk at his bank, which will then transfer the money. It is also very common to allow the payee to automatically withdraw the requested amount from the payer's account (\"Lastschrifteinzug\" (German) or \"Incasso (machtiging)\" (Netherlands)). Though similar to paying by cheque, the payee only needs the payer's bank and account number. Since the early 1990s, this method of payment has also been available to merchants. Due to this, credit cards are rather uncommon in Germany, Austria and the Netherlands, and are mostly used to give access to credit rather than as a payment mechanism. However, debit cards are widespread in these countries, since virtually all Austrian, German and Dutch banks issue debit cards instead of simple ATM cards for use on current accounts. Acceptance of cheques has been further diminished since the late 1990s, because of the abolition of the Eurocheque. Cashing a foreign bank cheque is possible, but usually very expensive.\n\nIn Finland, banks stopped issuing personal cheques in about 1993 in favour of giro systems, which are now almost exclusively electronically initiated either via internet banking or payment machines located at banks and shopping malls. All Nordic countries have used an interconnected international giro system since the 1950s, and in Sweden, cheques are now almost totally abandoned; in Denmark, all banks stopped accepting cheques starting on January 1, 2017. Debit cards are now preferred for direct shop payments when not using cash. For large shop payments, such as car purchases, a type of cheque, a money order (Swedish:postväxel) is still used.\n\nIn Poland cheques were withdrawn from use in 2006, mainly because of lack of popularity due to the widespread adoption of credit and debit cards. Electronic payments across the European Union are now fast and inexpensive—usually free for consumers.\n\nIn the United Kingdom, Ireland, and France, cheques are still popular, partly because cheques remain free of charge to personal customers; however, bank-to-bank transfers are increasing in popularity. Since 2001, businesses in the United Kingdom have made more electronic payments than cheque payments. Automated payments rose from 753 million in 1995 to 1.1 billion in 2001 and cheques declined in that same period of time from 1.14 to 1.1 billion payments. Most utilities in the United Kingdom charge lower prices to customers who pay by direct debit than for other payment methods, including electronic methods. The vast majority of retailers in the United Kingdom and many in France have not accepted cheques as a means of payment for several years, and cheque guarantee cards are no longer issued. For example, Shell announced in September 2005 that it would no longer accept cheques at its UK petrol stations. This was soon followed by other major fuel retailers, such as Texaco, BP, and Total. Asda announced in April 2006 that it would stop accepting cheques, initially as a trial in the London area, and Boots announced in September 2006 that it would stop accepting cheques, initially as a trial in Sussex and Surrey. Currys (and other stores in the DSGi group) and WH Smith also no longer accept cheques. Cheques are now widely predicted to become a thing of the past, or at most, a niche product used to pay private individuals or for the very large number of small service providers who are not willing to provide their bank details to customers to allow electronic payments to be made to them or do not wish to be burdened with checking their bank accounts frequently and reconciling them with amounts due (for example, music teachers, driving instructors, children's sports lessons, small shops, schools). The UK Payments Council announced in December 2009 that cheques would be phased out by October 2018, but only if adequate alternatives were developed. They intended to perform annual checks on the progress of other payments systems and a final review of the decision would have been held in 2016. Concerns were expressed, however, by charities and older people, who are still heavy users of cheques, and replacement plans were criticized as open to fraud. It was therefore announced by the UK Payments Council in July 2011 that the cheque would not be eliminated. 432 million inter-bank cheques and credit-items worth £472 billion were processed in the United Kingdom in 2016 according to Payments UK. In 2017, 405 million cheques worth £356 billion were used for payments and acquiring cash, an average of 1.2 million cheques per day, with more than 10 million being cleared in Northern Ireland alone. The Cheque and Credit Clearing Company noted that cheques continue to be highly valued for paying tradesmen and utility bills, and play a vital role in business, clubs and societies sectors, with nine in 10 business saying that they received or made payment by cheque on a monthly basis.\n\nIn June 2014, following a successful trial in the UK by Barclays, the British government gave the go-ahead for a cheque photo plan allowing people to pay in a cheque by taking a photo of it, rather than physically depositing the paper cheque at a bank.\n\nIn 2002 the US still relied heavily on cheques, due to the convenience it affords payers, and due to the absence of a high volume system for low value electronic payments. Since then the decline in cheque usage seen around the world has also started in the US. The cheque, although not as common as it used to be, is still a long way from disappearing completely in the US.\n\nIn the US, an estimated 18.3 billion cheques were paid in 2012, with a value of $25.9 trillion.\n\nAbout 70 billion cheques were written annually in the US by 2001, though around 17 million adult Americans do not have bank accounts at all. Certain companies whom a person pays with a cheque will turn it into an Automated Clearing House (ACH) or electronic transaction. Banks try to save time processing cheques by sending them electronically between banks. Cheque clearing is usually done through an electronic cheque broker, such as The Clearing House, Viewpointe LLC or the Federal Reserve Banks. Copies of the cheques are stored at a bank or the broker, for periods up to 99 years, and this is why some cheque archives have grown to 20 petabytes. The access to these archives is now worldwide, as most bank programming is now done offshore. Many utilities and most credit cards will also allow customers to pay by providing bank information and having the payee draw payment from the customer's account (direct debit). Many people in the US still use paper money orders to pay bills or transfer money which is a unique type of cheque. They have security advantages over mailing cash, and do not require access to a bank account.\n\nCanada's usage of cheques is less than that of the US and is declining rapidly at the urging of the Canadian Banking Association. The Government of Canada claims it is 6.5 times more expensive to mail a cheque than to make a direct deposit. The Canadian Payments Association reported that in 2012, cheque use in Canada accounted for only 40% of total financial transactions. The Interac system, which allows instant fund transfers via chip or magnetic strip and PIN, is widely used by merchants to the point that few brick and mortar merchants accept cheques. Many merchants accept Interac debit payments but not credit card payments, even though most Interac terminals can support credit card payments. Financial institutions also facilitate transfers between accounts within different institutions with the Email Money Transfer (EMT) service.\n\nCheques are still used for government payments, payroll, rent, and utility bill payments, though direct deposits and online or telephone bill payments are more widely and increasingly used.\n\nThe Canadian government began phasing out all government cheques from April 2016.\n\nIn many Asian countries cheques were never widely used and generally only used by the wealthy, with cash being used for the majority of payments. Where cheques were used they have been declining rapidly, by 2009 there was negligible consumer cheque usage in Japan, South Korea and Taiwan. This declining trend was accelerated by these developed markets advanced financial services infrastructure. Many of the developing countries in Asia have seen an increasing use of electronic payment systems, 'leap-frogging' the less efficient chequeing system altogether.\n\nIndia is one of the few countries in Asia that did have significant cheque usage. It had a long tradition of using cheques and passed laws formalising cheque usage as early as 1881. In 2009 cheques were still widely used as a means of payment in trade, and also by individuals to pay other individuals or utility bills. One of the reasons was that banks usually provided cheques for free to their individual account holders. However, cheques are now rarely accepted at point of sale in retail stores where cash and cards are payment methods of choice. Electronic payment transfer continued to gain popularity in India and like other countries this caused a subsequent reduction in volumes of cheques issued each year. In 2009 the Reserve Bank of India reported there was a five percent decline in cheque usage compared to the previous year.\n\nIn Australia, following global trends, the use of cheques continues to decline. In 1994 the value of daily cheque transactions was A$25 billion; by 2004 this had dropped to only A$5 billion, and by 2018 this had dropped to only A$1 billion, with almost half of this for B2B transactions. Personal cheque use is practically non-existent thanks to the longstanding use of the EFTPOS system, BPAY, electronic transfers, and debit cards.\n\nIn New Zealand, payments by cheque have declined since the mid-1990s in favour of electronic payment methods. In 1993, cheques accounted for over half of transactions through the national banking system, with an annual average of 130 cheques per capita. By 2006 cheques lagged well behind EFTPOS (debit card) transaction and electronic credits, making up only nine per cent of transactions, an annual average of 41 cheque transaction per capita. Most retail stores no longer accept cheques; those that do often require government-issued identification or a store-issued \"cheque identification card\" before they can be accepted as payment.\n\nIn addition to regular cheques, a number of variations were developed to address specific needs or address issues when using a regular cheque.\n\nCashier's cheques and banker's drafts, also known as bank cheques, banker's cheques or treasurer's cheques, are cheques issued against the funds of a financial institution rather than an individual account holder. Typically, the term \"cashier's check\" is used in the US and \"banker's draft\" is used in the UK and most of the Commonwealth. The mechanism differs slightly from country to country but in general the bank issuing the cheque or draft will allocate the funds at the point the cheque is drawn. This provides a guarantee, save for a failure of the bank, that it will be honoured. Cashier's cheques are perceived to be as good as cash but they are still a cheque, a misconception sometimes exploited by scam artists. A lost or stolen cheque can still be stopped like any other cheque, so payment is not completely guaranteed.\n\nWhen a certified cheque is drawn, the bank operating the account verifies there are currently sufficient funds in the drawer's account to honour the cheque. Those funds are then set aside in the bank's internal account until the cheque is cashed or returned by the payee. Thus, a certified cheque cannot \"bounce\", and its liquidity is similar to cash, absent failure of the bank. The bank indicates this fact by making a notation on the face of the cheque (technically called an \"acceptance\").\n\nA cheque used to pay wages may be referred to as a payroll cheque. Even when the use of cheques for paying wages and salaries became rare, the vocabulary \"pay cheque\" still remained commonly used to describe the payment of wages and salaries. Payroll cheques issued by the military to soldiers, or by some other government entities to their employees, beneficiants, and creditors, are referred to as warrants.\n\nWarrants look like cheques and clear through the banking system like cheques, but are not drawn against cleared funds in a deposit account. A cheque differs from a warrant in that the warrant is not necessarily payable on demand and may not be negotiable. They are often issued by government entities such as the military to pay wages or suppliers. In this case they are an instruction to the entity's treasurer department to pay the warrant holder on demand or after a specified maturity date.\n\nA traveller's cheque is designed to allow the person signing it to make an unconditional payment to someone else as a result of paying the issuer for that privilege. Traveller's cheques can usually be replaced if lost or stolen, and people frequently used them on holiday instead of cash as many businesses used to accept traveller's cheques as currency. The use of credit or debit cards has begun to replace the traveller's cheque as the standard for vacation money due to their convenience and additional security for the retailer. As a result, many businesses no longer accept traveller's cheques.\n\nA cheque sold by a post office, bank, or merchant such as a grocery store for payment in favour of a third party is referred to as a money order or postal order. These are paid for in advance when the order is drawn and are guaranteed by the institution that issues them and can only be paid to the named third party. This was a common way to send low value payments to third parties, avoiding the risks associated with sending cash by post, prior to the advent of electronic payment methods.\n\nOversized cheques are often used in public events such as donating money to charity or giving out prizes such as Publishers Clearing House. The cheques are commonly in size; however, according to the Guinness Book of World Records, the largest ever is . Until recently, regardless of the size, such cheques could still be redeemed for their cash value as long as they would have the same parts as a normal cheque, although usually the oversized cheque is kept as a souvenir and a normal cheque is provided. Any bank could levy additional charges for clearing an oversized cheque. Most banks need to have the machine-readable information on the bottom of cheques read electronically, so only very limited dimensions can be allowed due to standardised equipment.\n\nIn the US some public assistance programmes such as the Special Supplemental Nutrition Program for Women, Infants and Children, or Aid to Families with Dependent Children make \"vouchers\" available to their beneficiaries, which are good up to a certain monetary amount for purchase of grocery items deemed eligible under the particular programme. The voucher can be deposited like any other cheque by a participating supermarket or other approved business.\n\nThe Cheques Act 1986 is the body of law governing the issuance of cheques and payment orders in Australia. Procedural and practical issues governing the clearance of cheques and payment orders are handled by Australian Payments Clearing Association (APCA).\n\nIn 1999, banks adopted a system to allow faster clearance of cheques by electronically transmitting information about cheques, this brought clearance times down from five to three days. Prior to that cheques had to be physically transported to the paying bank before processing began. If the cheque was dishonoured, it was physically returned.\n\nAll licensed banks in Australia may issue cheques in their own name. Non-banks are not permitted to issue cheques in their own name but may issue, and have drawn on them, payment orders (which functionally are no different from cheques).\n\nIn Canada, cheque sizes and types, endorsement requirements and MICR tolerances are overseen by Payments Canada.\n\nThe Cheque was introduced in India by the Bank of Hindustan, the first joint stock bank established in 1770. In 1881, the Negotiable Instruments Act (NI Act) was enacted in India, formalising the usage and characteristics of instruments like the cheque, the bill of exchange, and promissory note. The NI Act provided a legal framework for non-cash paper payment instruments in India. In 1938, the Calcutta Clearing Banks' Association, which was the largest bankers' association at that time, adopted clearing house.\n\nUntil 1 April 2012, cheques in India were valid for a period of six months from the date of their issue, before the Reserve Bank of India issued a notification reducing their validity to three months from the date of issue.\n\nIn Japan, cheques are called , and are governed by . \n\nBounced cheques are called . If an account owner bounces two cheques in six months, the bank will suspend the account for two years. If the account belongs to a public company, their stock will also be suspended from trading on the stock exchange, which can lead to bankruptcy.\n\nInstrument-specific legislation includes the Cheques Act 1960, part of the Bills of Exchange Act 1908, which codifies aspects related to the cheque payment instrument, notably the procedures for the endorsement, presentment and payment of cheques. A 1995 amendment provided for the electronic presentment of cheques and removed the previous requirement to deliver cheques physically to the paying bank, opening the way for cheque truncation and imaging. Truncation allows for the transmission of an electronic image of all or part of the cheque to the paying bank's branch, instead of cumbersome physical presentment. This reduced the total cheque clearance time and eliminated the costs of physically moving the cheque.\n\nThe under supervision of Reserve Bank of New Zealand provide the cheque payment services. Once banked, cheques are processed electronically together with other retail payment instruments. \"Homeguard v Kiwi Packaging\" is often cited case law regarding the banking of cheques tendered as full settlement of disputed accounts.\n\nIn the UK all cheques must now conform to an industry standard detailing layout and font (\"Cheque and Credit Clearing Company (C&CCC) Standard 3\"), be printed on a specific weight of paper (CBS1), and contain explicitly defined security features.\n\nSince 1995, all cheque printers must be members of the Cheque Printer Accreditation Scheme (CPAS). The scheme is managed by the Cheque and Credit Clearing Company and requires that all cheques for use in the British clearing process are produced by accredited printers who have adopted stringent security standards.\n\nThe rules concerning crossed cheques are set out in Section 1 of the Cheques Act 1992 and prevent cheques being cashed by or paid into the accounts of third parties. On a crossed cheque the words “account payee only” (or similar) are printed between two parallel vertical lines in the centre of the cheque. This makes the cheque non-transferable and is to avoid cheques being endorsed and paid into an account other than that of the named payee. Crossing cheques basically ensures that the money is paid into an account of the intended beneficiary of the cheque.\n\nFollowing concerns about the amount of time it took banks to clear cheques, the United Kingdom Office of Fair Trading set up a working group in 2006 to look at the cheque clearing cycle. They produced a report recommending maximum times for the cheque clearing which were introduced in UK from November 2007. In the report the date the credit appeared on the recipient's account (usually the day of deposit) was designated \"T\". At \"T + 2\" (two business days afterwards) the value would count for calculation of credit interest or overdraft interest on the recipient's account. At \"T + 4\" clients would be able to withdraw funds on current accounts or at \"T + 6\" on savings accounts (though this will often happen earlier, at the bank's discretion). \"T + 6\" is the last day that a cheque can bounce without the recipient's permission—this is known as \"certainty of fate\". Before the introduction of this standard (also known as 2-4-6 for current accounts and 2-6-6 for savings accounts), the only way to know the \"fate\" of a cheque has been \"Special Presentation\", which would normally involve a fee, where the drawee bank contacts the payee bank to see if the payee has that money at that time. \"Special Presentation\" had been stated at the time of deposit.\n\nCheque volumes peaked in 1990 when four billion cheque payments were made. Of these, 2.5 billion were cleared through the inter-bank clearing managed by the C&CCC, the remaining 1.5 billion being in-house cheques which were either paid into the branch on which they were drawn or processed intra-bank without going through the clearings. As volumes started to fall, the challenges faced by the clearing banks were then of a different nature: how to benefit from technology improvements in a declining business environment.\n\nAlthough the UK did not adopt the euro as its national currency when other European countries did in 1999, many banks began offering euro denominated accounts with chequebooks, principally to business customers. The cheques can be used to pay for certain goods and services in the UK. The same year, the C&CCC set up the euro cheque clearing system to process euro denominated cheques separately from sterling cheques in Great Britain.\n\nThe UK Payments Council from 30 June 2011 withdrew the existing \"Cheque Guarantee Card Scheme\" in the UK. This service allowed cheques to be guaranteed at point of sales up to a certain value, normally £50 or £100, when signed in front of the retailer with the additional cheque guarantee card. This was after a long period of decline in their use in favour of debit cards.\n\nThe Payments Council proposed to close the centralised cheque clearing altogether in the UK and had set a target date of 31 October 2018. However, on 12 July 2011, the Payments Council announced that after opposition from MPs, charity groups and public opinion, the cheque will remain in use and there would no longer be a reason to seek an alternative paper-initiated payment.\n\nIn the United States, cheques are referred to as \"checks\" and are governed by Article 3 of the Uniform Commercial Code, under the rubric of negotiable instruments.\n\nIn the US, the terminology for a cheque historically varied with the type of financial institution on which it is drawn. In the case of a savings and loan association it was a \"negotiable order of withdrawal\" (compare Negotiable Order of Withdrawal account); if a credit union it was a \"share draft.\" \"Checks\" were associated with chartered commercial banks. However, common usage has increasingly conformed to more recent versions of Article 3, where \"check\" means any or all of these negotiable instruments. Certain types of cheques drawn on a government agency, especially payroll cheques, may be called a \"payroll warrant\".\n\nAt the bottom of each cheque there is the routing/account number in MICR format. The ABA routing transit number is a nine-digit number in which the first four digits identifies the US Federal Reserve Bank's cheque-processing centre. This is followed by digits 5 through 8, identifying the specific bank served by that cheque-processing centre. Digit 9 is a verification check digit, computed using a complex algorithm of the previous eight digits.\n\nA \"draft\" in the US Uniform Commercial Code is any bill of exchange, whether payable on demand or at a later date. If payable on demand it is a \"demand draft\", or if drawn on a financial institution, a cheque.\n\nThe electronic cheque or substitute cheque was formally adopted in the US in 2004 with the passing of the \"Check Clearing for the 21st Century Act\" (or Check 21 Act). This allowed the creation of electronic cheques and translation (truncation) of paper cheques into electronic replacements, reducing cost and processing time.\n\nThe specification for US cheques is given by ANSI committee X9 Technical Report 2.\n\nIn Turkey, cheques are usually used for commercial transactions only, and using post-dated cheques is legally permissible.\n\nCheques have been a tempting target for criminals to steal money or goods from the drawer, payee or the banks. A number of measures have been introduced to combat fraud over the years. These range from things like writing a cheque so it is difficult to alter after it is drawn, to mechanisms like crossing a cheque so that it can only be paid into another bank's account providing some traceability. However, the inherent security weaknesses of cheques as a payment method, such as having only the signature as the main authentication method and not knowing if funds will be received until the clearing cycle to complete, have made them vulnerable to a number of different types of fraud.\n\nTaking advantage of the float period (cheque kiting) to delay the notice of non-existent funds. This often involves trying to convince a merchant or other recipient, hoping the recipient will not suspect that the cheque will not clear, giving time for the fraudster to disappear.\n\nSometimes, forgery is the method of choice in defrauding a bank. One form of forgery involves the use of a victim's legitimate cheques, that have either been stolen and then cashed, or altering a cheque that has been legitimately written to the perpetrator, by adding words or digits to inflate the amount.\n\nSince cheques include significant personal information (name, account number, signature and in some countries driver's license number, the address or phone number of the account holder), they can be used for identity theft. The practice was discontinued as identity theft became widespread.\n\nA dishonoured cheque cannot be redeemed for its value and is worthless; they are also known as an \"RDI\" (returned deposit item), or \"NSF\" (non-sufficient funds) cheque. Cheques are usually dishonoured because the drawer's account has been frozen or limited, or because there are insufficient funds in the drawer's account when the cheque was redeemed. A cheque drawn on an account with insufficient funds is said to have \"bounced\" and may be called a \"rubber cheque\". Banks will typically charge customers for issuing a dishonoured cheque, and in some jurisdictions such an act is a criminal action. A drawer may also issue a \"stop\" on a cheque, instructing the financial institution not to honour a particular cheque.\n\nIn England and Wales, they are typically returned marked \"Refer to Drawer\"—an instruction to contact the person issuing the cheque for an explanation as to why the cheque was not honoured. This wording was brought in after a bank was successfully sued for libel after returning a cheque with the phrase \"Insufficient Funds\" after making an error—the court ruled that as there were sufficient funds the statement was demonstrably false and damaging to the reputation of the person issuing the cheque. Despite the use of this revised phrase, successful libel lawsuits brought against banks by individuals remained for similar errors.\n\nIn Scotland, a cheque acts as an assignment of the amount of money to the payee. As such, if a cheque is dishonoured in Scotland, what funds are present in the bank account are \"attached\" and frozen, until either sufficient funds are credited to the account to pay the cheque, the drawer recovers the cheque and hands it into the bank, or the drawer obtains a letter from the payee stating that they have no further interest in the cheque.\n\nA cheque may also be dishonoured because it is stale or not cashed within a \"void after date\". Many cheques have an explicit notice printed on the cheque that it is void after some period of days. In the US, banks are not required by the Uniform Commercial Code to honour a , which is a cheque presented six months after it is dated.\n\nIn the United States some consumer reporting agencies such as ChexSystems, Early Warning Services, and TeleCheck have been providing cheque verification services that track how people manage their checking accounts. Banks use the agencies to screen checking account applicants. Those with low debit scores are denied checking accounts because a bank can not afford an account to be overdrawn.\n\nIn the United Kingdom, in common with other items such as Direct Debits or standing orders, dishonoured cheques can be reported on a customer's credit file, although not individually and this does not happen universally amongst banks. Dishonoured payments from current accounts can be marked in the same manner as missed payments on the customer's credit report.\n\nTypically when customers pay bills with cheques (like gas or water bills), the mail will go to a \"lock box\" at the post office. There a bank will pick up all the mail, sort it, open it, take the cheques and remittance advice out, process it all through electronic machinery, and post the funds to the proper accounts. In modern systems, taking advantage of the Check 21 Act, as in the US, many cheques are transformed into electronic objects and the paper is destroyed.\n\n\n"}
{"id": "152835", "url": "https://en.wikipedia.org/wiki?curid=152835", "title": "Debt", "text": "Debt\n\nDebt is an obligation that requires one party, the debtor, to pay money or other agreed-upon value to another party, the creditor. Debt is a deferred payment, or series of payments, which differentiates it from an immediate purchase. The debt may be owed by sovereign state or country, local government, company, or an individual. Commercial debt is generally subject to contractual terms regarding the amount and timing of repayments of principal and interest. Loans, bonds, notes, and mortgages are all types of debt. The term can also be used metaphorically to cover moral obligations and other interactions not based on economic value. For example, in Western cultures, a person who has been helped by a second person is sometimes said to owe a \"debt of gratitude\" to the second person.\n\nThe English term \"debt\" was first used in the late 13th century. The term \"debt\" comes from \"dette, from Old French dete, from Latin debitum \"thing owed,\" neuter past participle of debere \"to owe,\" originally, \"keep something away from someone,\" from de- \"away\" (see de-) + habere \"to have\" (see habit (n.)). Restored spelling [was used] after c. 1400. The related term \"debtor\" was first used in English also in the early 13th century; the terms \"dettur, dettour, [came] from Old French detour, from Latin debitor \"a debter,\" from past participle stem of debere;...The -b- was restored in later French, and in English c. 1560-c. 1660.\" In the King James Bible, only one spelling, \"debtor\", is used. The word \"debtor\" appears four times and \"debtors\" appears five times in the KJV Bible. (Searches for the previous erroneous claim that the words detter, debter and debtour are all used in the KJV Bible each resulted in 0 words found.)\n\nInterest is the fee paid by the borrower to the lender. Interest is calculated as a percentage of the outstanding principal, which percentage is known as an interest rate, and is generally paid periodically at intervals, such as monthly or semi-annually.\n\nInterest rates may be fixed or floating. In floating-rate structures, the rate of interest that the borrower pays during each time period is tied to a benchmark such as LIBOR or, in the case of inflation-indexed bonds, inflation.\n\nThere are many different conventions for calculating interest. Depending on the terms of the debt, compound interest may accumulate at a specific interval. In addition, different day count conventions exist, for example, sometimes each month is considered to have exactly thirty days, such that the interest payment due is the same in each calendar month. The annual percentage rate (APR) is a standardized way to calculate and compare interest rates on an annual basis. Quoting interest rates using APR is required by regulation for most loans to individuals in the United States and United Kingdom.\n\nFor some loans, the amount actually loaned to the debtor is less than the principal sum to be repaid. This may be because upfront fees or points are charged, or because the loan has been structured to be sharia-compliant. The additional principal due at the end of the term has the same economic effect as a higher interest rate.\n\nRiskier borrowers must generally pay higher rates of interest to compensate lenders for taking on the additional risk of default. Debt investors assess the risk of default prior to making a loan, for example through credit scores and corporate and sovereign ratings.\n\nThere are three main ways repayment may be structured: the entire principal balance may be due at the maturity of the loan; the entire principal balance may be amortized over the term of the loan; or the loan may partially amortized during its term, with the remaining principal due as a \"balloon payment\" at maturity. Amortization structures are common in mortgages and credit cards.\n\nDebtors of every type default on their debt from time to time, with various consequences depending on the terms of the debt and the law governing default in the relevant jurisdiction. \nIf the debt was secured by specific collateral, such as a car or home, the creditor may seek to repossess the collateral. In more serious circumstances, individuals and companies may go into bankruptcy.\n\nCommon types of debt owed by individuals and households include mortgage loans, car loans, credit card debt, and income taxes. For individuals, debt is a means of using anticipated income and future purchasing power in the present before it has actually been earned. Commonly, people in industrialized nations use consumer debt to purchase houses, cars and other things too expensive to buy with cash on hand.\n\nPeople are more likely to spend more and get into debt when they use credit cards vs. cash for buying products and services. This is primarily because of the transparency effect and consumer's \"pain of paying.\" The transparency effect refers to the fact that the further you are from cash (as in a credit card or another form of payment), the less transparent it is and the less you remember how much you spent. The less transparent or further away from cash, the form of payment employed is, the less an individual feels the “pain of paying” and thus is likely to spend more. Furthermore, the differing physical appearance/form that credit cards have from cash may cause them to be viewed as “monopoly” money vs. real money, luring individuals to spend more money than they would if they only had cash available.\n\nBesides these more formal debts, private individuals also lend informally to other people, mostly relatives or friends. One reason for such informal debts is that many people, in particular those who are poor, have no access to affordable credit. Such debts can cause problems when they are not paid back according to expectations of the lending household. In 2011, 8 percent of people in the European Union reported their households has been in arrears, that is, unable to pay as scheduled \"payments related to informal loans from friends or relatives not living in your household\".\n\nA company may use various kinds of debt to finance its operations as a part of its overall corporate finance strategy.\n\nA term loan is the simplest form of corporate debt. It consists of an agreement to lend a fixed amount of money, called the principal sum or principal, for a fixed period of time, with this amount to be repaid by a certain date. In commercial loans interest, calculated as a percentage of the principal sum per year, will also have to be paid by that date, or may be paid periodically in the interval, such as annually or monthly. Such loans are also colloquially called \"bullet loans\", particularly if there is only a single payment at the end – the \"bullet\" – without a \"stream\" of interest payments during the life of the loan.\n\nA revenue-based financing loan comes with a fixed repayment target that is reached over a period of several years. This type of loan generally comes with a repayment amount of 1.5 to 2.5 times the principle loan. Repayment periods are flexible; businesses can pay back the agreed-upon amount sooner, if possible, or later. In addition, business owners do not sell equity or relinquish control when using revenue-based financing. Lenders that provide revenue-based financing work more closely with businesses than bank lenders, but take a more hands-off approach than private equity investors.\n\nA syndicated loan is a loan that is granted to companies that wish to borrow more money than any single lender is prepared to risk in a single loan. A syndicated loan is provided by a group of lenders and is structured, arranged, and administered by one or several commercial banks or investment banks known as arrangers. Loan syndication is a risk management tool that allows the lead banks underwriting the debt to reduce their risk and free up lending capacity.\n\nA company may also issue bonds, which are debt securities. Bonds have a fixed lifetime, usually a number of years; with long-term bonds, lasting over 30 years, being less common. At the end of the bond's life the money should be repaid in full. Interest may be added to the end payment, or can be paid in regular installments (known as coupons) during the life of the bond.\n\nA letter of credit or LC can also be the source of payment for a transaction, meaning that redeeming the letter of credit will pay an exporter. Letters of credit are used primarily in international trade transactions of significant value, for deals between a supplier in one country and a customer in another. They are also used in the land development process to ensure that approved public facilities (streets, sidewalks, stormwater ponds, etc.) will be built. The parties to a letter of credit are usually a beneficiary who is to receive the money, the issuing bank of whom the applicant is a client, and the advising bank of whom the beneficiary is a client. Almost all letters of credit are irrevocable, i.e., cannot be amended or canceled without prior agreement of the beneficiary, the issuing bank and the confirming bank, if any. In executing a transaction, letters of credit incorporate functions common to giros and traveler's cheque. Typically, the documents a beneficiary has to present in order to receive payment include a commercial invoice, bill of lading, and a document proving the shipment was insured against loss or damage in transit. However, the list and form of documents is open to imagination and negotiation and might contain requirements to present documents issued by a neutral third party evidencing the quality of the goods shipped, or their place of origin.\n\nCompanies also use debt in many ways to leverage the investment made in their assets, \"leveraging\" the return on their equity. This leverage, the proportion of debt to equity, is considered important in determining the riskiness of an investment; the more debt per equity, the riskier.\n\nGovernments issue debt to pay for ongoing expenses as well as major capital projects. Government debt may be issued by sovereign states as well as by local governments, sometimes known as municipalities.\n\nDebt issued by the government of the United States, called Treasuries, serves as a reference point for all other debt. There are deep, transparent, liquid, and open capital markets for Treasuries. Furthermore, Treasuries are issued in a wide variety of maturities, from one day to thirty years, which facilitates comparing the interest rates on other debt to a security of comparable maturity. In finance, the theoretical \"risk-free interest rate\" is often approximated by practitioners by using the current yield a Treasury of the same duration.\n\nThe overall level of indebtedness by a government is typically shown as a ratio of debt-to-GDP. This ratio helps to assess the speed of changes in government indebtedness and the size of the debt due.\n\nThe debt service coverage ratio is the ratio of income available to the amount of debt service due (including both interest and principal amortization, if any). The higher the debt service coverage ratio, the more income is available to pay debt service, and the easier and lower-cost it will be for a borrower to obtain financing.\n\nDifferent debt markets have somewhat different conventions in terminology and calculations for income-related metrics. For example, in mortgage lending in the United States, a debt-to-income ratio typically includes the cost of mortgage payments as well as insurance and property tax, divided by a consumer's monthly income. A \"front-end ratio\" of 28% or below, together with a \"back-end ratio\" (including required payments on non-housing debt as well) of 36% or below is also required to be eligible for a conforming loan.\n\nThe loan-to-value ratio is the ratio of the total amount of the loan to the total value of the collateral securing the loan.\n\nFor example, in mortgage lending in the United States, the loan-to-value concept is most commonly expressed as a \"down payment.\" A 20% down payment is equivalent to an 80% loan to value. With home purchases, value may be assessed using the agreed-upon purchase price, and/or an appraisal.\n\nA debt obligation is considered secured if creditors have recourse to specific collateral. Collateral may include claims on tax receipts (in the case of a government), specific assets (in the case of a company) or a home (in the case of a consumer). Unsecured debt comprises financial obligations for which creditors do not have recourse to the assets of the borrower to satisfy their claims.\n\nCredit bureaus collect information about the borrowing and repayment history of consumers. Lenders, such as banks and credit card companies, use credit scores to evaluate the potential risk posed by lending money to consumers. In the United States, the primary credit bureaus are Equifax, Experian, and TransUnion.\n\nDebts owed by governments and private corporations may be rated by rating agencies, such as Moody's, Standard & Poor's, Fitch Ratings, and A. M. Best. The government or company itself will also be given its own separate rating. These agencies assess the ability of the debtor to honor his obligations and accordingly give him or her a credit rating. Moody's uses the letters \"Aaa Aa A Baa Ba B Caa Ca C\", where ratings \"Aa-Caa\" are qualified by numbers 1-3. S&P and other rating agencies have slightly different systems using capital letters and +/- qualifiers. Thus a government or corporation with a high rating would have Aaa rating.\n\nA change in ratings can strongly affect a company, since its cost of refinancing depends on its creditworthiness. Bonds below Baa/BBB (Moody's/S&P) are considered junk or high-risk bonds. Their high risk of default (approximately 1.6 percent for Ba) is compensated by higher interest payments. Bad Debt is a loan that can not (partially or fully) be repaid by the debtor. The debtor is said to default on his debt. These types of debt are frequently repackaged and sold below face value. Buying junk bonds is seen as a risky but potentially profitable investment.\n\nBonds are debt securities, tradeable on a bond market. A country's regulatory structure determines what qualifies as a security. For example, in North America, each security is uniquely identified by a CUSIP for trading and settlement purposes. In contrast, loans are not securities and do not have CUSIPs (or the equivalent). Loans may be sold or acquired in certain circumstances, as when a bank syndicates a loan.\n\nLoans can be turned into securities through the securitization process. In a securitization, a company sells a pool of assets to a securitization trust, and the securitization trust finances its purchase of the assets by selling securities to the market. For example, a trust may own a pool of home mortgages, and be financed by residential mortgage-backed securities. In this case, the asset-backed trust is a debt issuer of residential mortgage-backed securities.\n\nCentral banks, such as the U.S. Federal Reserve System, play a key role in the debt markets. Debt is normally denominated in a particular currency, and so changes in the valuation of that currency can change the effective size of the debt. This can happen due to inflation or deflation, so it can happen even though the borrower and the lender are using the same currency.\n\nSome argue against debt as an instrument and institution, on a personal, family, social, corporate and governmental level. Some Islamic banking forbids lending with interest even today. In hard times, the cost of servicing debt can grow beyond the debtor's ability to pay, due to either external events (income loss) or internal difficulties (poor management of resources).\n\nDebt with an associated interest rate will increase through time if it is not repaid faster than it grows through interest. This effect may be termed usury, while the term \"usury\" in other contexts refers only to an excessive rate of interest, in excess of a reasonable profit for the risk accepted.\n\nIn international legal thought, odious debt is debt that is incurred by a regime for purposes that do not serve the interest of the state. Such debts are thus considered by this doctrine to be personal debts of the regime that incurred them and not debts of the state. International Third World debt has reached the scale that many economists are convinced that debt relief or debt cancellation is the only way to restore global equity in relations with the developing nations.\n\nExcessive debt accumulation has been blamed for exacerbating economic problems. For example, before the Great Depression, the debt-to-GDP ratio was very high. Economic agents were heavily indebted. This excess of debt, equivalent to excessive expectations on future returns, accompanied asset bubbles on the stock markets. When expectations corrected, deflation and a credit crunch followed. Deflation effectively made debt more expensive and, as Fisher explained, this reinforced deflation again, because, in order to reduce their debt level, economic agents reduced their consumption and investment. The reduction in demand reduced business activity and caused further unemployment. In a more direct sense, more bankruptcies also occurred due both to increased debt cost caused by deflation and the reduced demand.\n\nAt the household level, debts can also have detrimental effects — particularly when households make spending decisions assuming income will increase, or remain stable, in years to come. When households take on credit based on this assumption, life events can easily change indebtedness into over-indebtedness. Such life events include unexpected unemployment, relationship break-up, leaving the parental home, business failure, illness, or home repairs. Over-indebtedness has severe social consequences, such as financial hardship, poor physical and mental health, family stress, stigma, difficulty obtaining employment, exclusion from basic financial services (European Commission, 2009), work accidents and industrial disease, a strain on social relations (Carpentier and Van den Bosch, 2008), absenteeism at work and lack of organisational commitment (Kim \"et al.\", 2003), feeling of insecurity, and relational tensions.\n\nGlobal debt underwriting grew 4.3 percent year-over-year to during 2004. It is expected to rise in the coming years if the spending habits of millions of people worldwide continue the way they do.\n\nAccording to historian Paul Johnson, the lending of \"food money\" was commonplace in Middle Eastern civilizations as early as 5000 BC. \n\nTraditions in some cultures demand that debt be forgiven on a regular (often annual) basis, in order to prevent systemic inequities between groups in society, or anyone becoming a specialist in holding debt and coercing repayment. An example is the Biblical Jubilee year, described in the Book of Leviticus.\n\n"}
{"id": "17182301", "url": "https://en.wikipedia.org/wiki?curid=17182301", "title": "Credit card", "text": "Credit card\n\nA credit card is a payment card issued to users (cardholders) to enable the cardholder to pay a merchant for goods and services based on the cardholder's promise to the card issuer to pay them for the amounts plus the other agreed charges. The card issuer (usually a bank) creates a revolving account and grants a line of credit to the cardholder, from which the cardholder can borrow money for payment to a merchant or as a cash advance.\n\nA credit card is different from a charge card, which requires the balance to be repaid in full each month. In contrast, credit cards allow the consumers to build a continuing balance of debt, subject to interest being charged. A credit card also differs from a cash card, which can be used like currency by the owner of the card. A credit card differs from a charge card also in that a credit card typically involves a third-party entity that pays the seller and is reimbursed by the buyer, whereas a charge card simply defers payment by the buyer until a later date.\nThe size of most credit cards is and rounded corners with a radius of conforming to the ISO/IEC 7810 ID-1 standard, the same size as ATM cards and other payment cards, such as debit cards.\n\nCredit cards have a printed or embossed bank card number complying with the ISO/IEC 7812 numbering standard. The card number's \"prefix\", called the Bank Identification Number (known in the industry as a BIN), is the sequence of digits at the beginning of the number that determine the bank to which a credit card number belongs. This is the first six digits for MasterCard and Visa cards. The next nine digits are the individual account number, and the final digit is a validity check code.\n\nBoth of these standards are maintained and further developed by ISO/IEC JTC 1/SC 17/WG 1. Credit cards have a magnetic stripe conforming to the ISO/IEC 7813. Many modern credit cards have a computer chip embedded in them as a security feature.\n\nIn addition to the main credit card number, credit cards also carry issue and expiration dates (given to the nearest month), as well as extra codes such as issue numbers and security codes. Not all credit cards have the same sets of extra codes nor do they use the same number of digits.\n\nCredit card numbers were originally embossed to allow easy transfer of the number to charge slips. With the decline of paper slips, some credit cards are no longer embossed and in fact the card number is no longer in the front.\n\nThe concept of using a card for purchases was described in 1887 by Edward Bellamy in his utopian novel \"Looking Backward\". Bellamy used the term \"credit card\" eleven times in this novel, although this referred to a card for spending a citizen's dividend from the government, rather than borrowing, making it more similar to a debit card.\n\nCharge coins and other similar items were used from the late 19th century to the 1930s. They came in various shapes and sizes; with materials made out of celluloid (an early type of plastic), copper, aluminum, steel, and other types of whitish metals. Each charge coin usually had a little hole, enabling it to be put in a key ring, like a key. These charge coins were usually given to customers who had charge accounts in department stores, hotels, and so on. A charge coin usually had the charge account number along with the merchant's name and logo.\n\nThe charge coin offered a simple and fast way to copy a charge account number to the sales slip, by imprinting the coin onto the sales slip. This sped the process of copying, previously done by handwriting. It also reduced the number of errors, by having a standardized form of numbers on the sales slip, instead of various kind of handwriting style.\n\nBecause the customer's name was not on the charge coin, almost anyone could use it. This sometimes led to a case of mistaken identity, either accidentally or intentionally, by acting on behalf of the charge account owner or out of malice to defraud both the charge account owner and the merchant. Beginning in the 1930s, merchants started to move from charge coins to the newer Charga-Plate.\n\nThe Charga-Plate, developed in 1928, was an early predecessor of the credit card and was used in the U.S. from the 1930s to the late 1950s. It was a rectangle of sheet metal related to Addressograph and military dog tag systems. It was embossed with the customer's name, city, and state. It held a small paper card on its back for a signature. In recording a purchase, the plate was laid into a recess in the imprinter, with a paper \"charge slip\" positioned on top of it. The record of the transaction included an impression of the embossed information, made by the imprinter pressing an inked ribbon against the charge slip. Charga-Plate was a trademark of Farrington Manufacturing Co. Charga-Plates were issued by large-scale merchants to their regular customers, much like department store credit cards of today. In some cases, the plates were kept in the issuing store rather than held by customers. When an authorized user made a purchase, a clerk retrieved the plate from the store's files and then processed the purchase. Charga-Plates speeded back-office bookkeeping and reduced copying errors that were done manually in paper ledgers in each store.\n\nIn 1934, American Airlines and the Air Transport Association simplified the process even more with the advent of the Air Travel Card. They created a numbering scheme that identified the issuer of the card as well as the customer account. This is the reason the modern UATP cards still start with the number 1. With an Air Travel Card, passengers could \"buy now, and pay later\" for a ticket against their credit and receive a fifteen percent discount at any of the accepting airlines. By the 1940s, all of the major U.S. airlines offered Air Travel Cards that could be used on 17 different airlines. By 1941, about half of the airlines' revenues came through the Air Travel Card agreement. The airlines had also started offering installment plans to lure new travelers into the air. In October 1948, the Air Travel Card became the first internationally valid charge card within all members of the International Air Transport Association.\n\nThe concept of customers paying different merchants using the same card was expanded in 1950 by Ralph Schneider and Frank McNamara, founders of Diners Club, to consolidate multiple cards. The Diners Club, which was created partially through a merger with Dine and Sign, produced the first \"general purpose\" charge card and required the entire bill to be paid with each statement. That was followed by Carte Blanche and in 1958 by American Express which created a worldwide credit card network (although these were initially charge cards that later acquired credit card features).\n\nUntil 1958, no one had been able to successfully establish a \"revolving credit\" financial system in which a card issued by a third-party bank was being generally accepted by a large number of merchants, as opposed to merchant-issued revolving cards accepted by only a few merchants. There had been a dozen attempts by small American banks, but none of them were able to last very long. In September 1958, Bank of America launched the \"BankAmericard\" in Fresno, California, which would become the first successful recognizably modern credit card. This card succeeded where others failed by breaking the chicken-and-egg cycle in which consumers did not want to use a card that few merchants would accept and merchants did not want to accept a card that few consumers used. Bank of America chose Fresno because 45% of its residents used the bank, and by sending a card to 60,000 Fresno residents at once, the bank was able to convince merchants to accept the card. It was eventually licensed to other banks around the United States and then around the world, and in 1976, all BankAmericard licensees united themselves under the common brand Visa. In 1966, the ancestor of MasterCard was born when a group of banks established Master Charge to compete with BankAmericard; it received a significant boost when Citibank merged its own Everything Card, launched in 1967, into Master Charge in 1969.\n\nEarly credit cards in the U.S., of which BankAmericard was the most prominent example, were mass-produced and mass mailed unsolicited to bank customers who were thought to be good credit risks. They have been mailed off to unemployable people, drunks, narcotics addicts and to compulsive debtors, a process President Johnson's Special Assistant Betty Furness found very like \"giving sugar to diabetics\". These mass mailings were known as \"drops\" in banking terminology, and were outlawed in 1970 due to the financial chaos they caused. However, by the time the law came into effect, approximately 100 million credit cards had been dropped into the U.S. population. After 1970, only credit card applications could be sent unsolicited in mass mailings.\n\nBefore the computerization of credit card systems in America, using a credit card to pay at a merchant was significantly more complicated than it is today. Each time a consumer wanted to use a credit card, the merchant would have to call their bank, who in turn had to call the credit card company, which then had to have an employee manually look up the customer's name and credit balance. This system was computerized in 1973 under the leadership of Dee Hock, the first CEO of Visa, allowing transaction time to decrease substantially to less than one minute. However, until always-connected payment terminals became ubiquitous at the beginning of the 21st century, it was common for a merchant to accept a charge, especially below a threshold value or from a known and trusted customer, without verifying it by phone. Books with lists of stolen card numbers were distributed to merchants who were supposed in any case to check cards against the list before accepting them, as well as verifying the signature on the charge slip against that on the card. Merchants who failed to take the time to follow the proper verification procedures were liable for fraudulent charges, but because of the cumbersome nature of the procedures, merchants would often simply skip some or all of them and assume the risk for smaller transactions.\n\nThe fractured nature of the U.S. banking system under the Glass–Steagall Act meant that credit cards became an effective way for those who were traveling around the country to move their credit to places where they could not directly use their banking facilities. There are now countless variations on the basic concept of revolving credit for individuals (as issued by banks and honored by a network of financial institutions), including organization-branded credit cards, corporate-user credit cards, store cards and so on.\n\nIn 1966, Barclaycard in the United Kingdom launched the first credit card outside the United States.\n\nAlthough credit cards reached very high adoption levels in the US, Canada and the UK during the latter 20th century, many cultures were more cash-oriented or developed alternative forms of cashless payments, such as Carte bleue or the Eurocard (Germany, France, Switzerland, and others). In these places, adoption of credit cards was initially much slower. Due to strict regulations regarding bank overdrafts, some countries, France in particular, were much quicker to develop and adopt chip-based credit cards which are seen as major anti-fraud credit devices. Debit cards and online banking (using either ATMs or PCs) are used more widely than credit cards in some countries. It took until the 1990s to reach anything like the percentage market penetration levels achieved in the US, Canada, and UK. In some countries, acceptance still remains low as the use of a credit card system depends on the banking system of each country; while in others, a country sometimes had to develop its own credit card network, e.g. UK's Barclaycard and Australia's Bankcard. Japan remains a very cash-oriented society, with credit card adoption being limited mainly to the largest of merchants; although stored value cards (such as telephone cards) are used as alternative currencies, the trend is toward RFID-based systems inside cards, cellphones, and other objects.\n\nThe design of the credit card itself has become a major selling point in recent years. The value of the card to the issuer is often related to the customer's usage of the card, or to the customer's financial worth. This has led to the rise of Co-Brand and Affinity cards, where the card design is related to the \"affinity\" (a university or professional society, for example) leading to higher card usage. In most cases a percentage of the value of the card is returned to the affinity group.\n\nA growing field of numismatics (study of money), or more specifically exonumia (study of money-like objects), credit card collectors seek to collect various embodiments of credit from the now familiar plastic cards to older paper merchant cards, and even metal tokens that were accepted as merchant credit cards. Early credit cards were made of celluloid plastic, then metal and fiber, then paper, and are now mostly polyvinyl chloride (PVC) plastic.\nHowever the chip part of credit cards is not made from plastic but from metals.\n\nA credit card issuing company, such as a bank or credit union, enters into agreements with merchants for them to accept their credit cards. Merchants often advertise which cards they accept by displaying acceptance marks – generally derived from logos – or this may be communicated in signage in the establishment or in company material (e.g., a restaurant's menu may indicate which credit cards are accepted). Merchants may also communicate this orally, as in \"We take (brands X, Y, and Z)\" or \"We don't take credit cards\".\nThe credit card issuer issues a credit card to a customer at the time or after an account has been approved by the credit provider, which need not be the same entity as the card issuer. The cardholders can then use it to make purchases at merchants accepting that card. When a purchase is made, the cardholder agrees to pay the card issuer. The cardholder indicates consent to pay by signing a receipt with a record of the card details and indicating the amount to be paid or by entering a personal identification number (PIN). Also, many merchants now accept verbal authorizations via telephone and electronic authorization using the Internet, known as a card not present transaction (CNP).\n\nElectronic verification systems allow merchants to verify in a few seconds that the card is valid and the cardholder has sufficient credit to cover the purchase, allowing the verification to happen at time of purchase. The verification is performed using a credit card payment terminal or point-of-sale (POS) system with a communications link to the merchant's acquiring bank. Data from the card is obtained from a magnetic stripe or chip on the card; the latter system is called Chip and PIN in the United Kingdom and Ireland, and is implemented as an EMV card.\n\nFor card not present transactions where the card is not shown (e.g., e-commerce, mail order, and telephone sales), merchants additionally verify that the customer is in physical possession of the card and is the authorized user by asking for additional information such as the security code printed on the back of the card, date of expiry, and billing address.\n\nEach month, the cardholder is sent a statement indicating the purchases made with the card, any outstanding fees, the total amount owed and the minimum payment due. In the US, after receiving the statement, the cardholder may dispute any charges that he or she thinks are incorrect (see , which limits cardholder liability for unauthorized use of a credit card to $50). The Fair Credit Billing Act gives details of the U.S. regulations.\n\nMany banks now also offer the option of electronic statements, either in lieu of or in addition to physical statements, which can be viewed at any time by the cardholder via the issuer's online banking website. Notification of the availability of a new statement is generally sent to the cardholder's email address. If the card issuer has chosen to allow it, the cardholder may have other options for payment besides a physical check, such as an electronic transfer of funds from a checking account. Depending on the issuer, the cardholder may also be able to make multiple payments during a single statement period, possibly enabling him or her to utilize the credit limit on the card several times.\n\nThe cardholder must pay a defined minimum portion of the amount owed by a due date, or may choose to pay a higher amount. The credit issuer charges interest on the unpaid balance if the billed amount is not paid in full (typically at a much higher rate than most other forms of debt). In addition, if the cardholder fails to make at least the minimum payment by the due date, the issuer may impose a late fee or other penalties. To help mitigate this, some financial institutions can arrange for automatic payments to be deducted from the cardholder's bank account, thus avoiding such penalties altogether, as long as the cardholder has sufficient funds.\n\nIn cases where the minimum payment is less than the finance charges and fees assessed during the billing cycle, the outstanding balance will increase in what is called negative amortization. This practice tends to increase credit risk and mask the lender's portfolio quality, and consequently has been banned in the U.S. since 2003.\n\nCredit card advertising regulations in the U.S. include the Schumer box disclosure requirements. A large fraction of junk mail consists of credit card offers created from lists provided by the major credit reporting agencies. In the United States, the three major U.S. credit bureaus (Equifax, TransUnion and Experian) allow consumers to opt out from related credit card solicitation offers via its Opt Out Pre Screen program.\n\nCredit card issuers usually waive interest charges if the balance is paid in full each month, but typically will charge full interest on the entire outstanding balance from the date of each purchase if the total balance is not paid.\n\nFor example, if a user had a $1,000 transaction and repaid it in full within this grace period, there would be no interest charged. If, however, even $1.00 of the total amount remained unpaid, interest would be charged on the $1,000 from the date of purchase until the payment is received. The precise manner in which interest is charged is usually detailed in a cardholder agreement which may be summarized on the back of the monthly statement. The general calculation formula most financial institutions use to determine the amount of interest to be charged is (APR/100 x ADB)/365 x number of days revolved. Take the annual percentage rate (APR) and divide by 100 then multiply to the amount of the average daily balance (ADB). Divide the result by 365 and then take this total and multiply by the total number of days the amount revolved before payment was made on the account. Financial institutions refer to interest charged back to the original time of the transaction and up to the time a payment was made, if not in full, as a residual retail finance charge (RRFC). Thus after an amount has revolved and a payment has been made, the user of the card will still receive interest charges on their statement after paying the next statement in full (in fact the statement may only have a charge for interest that collected up until the date the full balance was paid, i.e. when the balance stopped revolving).\n\nThe credit card may simply serve as a form of revolving credit, or it may become a complicated financial instrument with multiple balance segments each at a different interest rate, possibly with a single umbrella credit limit, or with separate credit limits applicable to the various balance segments. Usually this compartmentalization is the result of special incentive offers from the issuing bank, to encourage balance transfers from cards of other issuers. In the event that several interest rates apply to various balance segments, payment allocation is generally at the discretion of the issuing bank, and payments will therefore usually be allocated towards the lowest rate balances until paid in full before any money is paid towards higher rate balances. Interest rates can vary considerably from card to card, and the interest rate on a particular card may jump dramatically if the card user is late with a payment on that card \"or any other credit instrument\", or even if the issuing bank decides to raise its revenue.\n\nA credit card's grace period is the time the cardholder has to pay the balance before interest is assessed on the outstanding balance. Grace periods may vary, but usually range from 20 to 55 days depending on the type of credit card and the issuing bank. Some policies allow for reinstatement after certain conditions are met.\n\nUsually, if a cardholder is late paying the balance, finance charges will be calculated and the grace period does not apply. Finance charges incurred depend on the grace period and balance; with most credit cards there is no grace period if there is any outstanding balance from the previous billing cycle or statement (i.e. interest is applied on both the previous balance and new transactions). However, there are some credit cards that will only apply finance charge on the previous or old balance, excluding new transactions.\n\n\nThe flow of information and money between these parties — always through the card associations — is known as the interchange, and it consists of a few steps.\n\n\nA credit card register is a transaction register used to ensure the increasing balance owed from using a credit card is enough below the credit limit to deal with authorization holds and payments not yet received by the bank and to easily look up past transactions for reconciliation and budgeting.\n\nThe register is a personal record of banking transactions used for credit card purchases as they affect funds in the bank account or the available credit. In addition to check number and so forth the code column indicates the credit card. The balance column shows available funds after purchases. When the credit card payment is made the balance already reflects the funds were spent. In a credit card's entry, the deposit column shows the available credit and the payment column shows total owed, their sum being equal to the credit limit.\n\nEach check written, debit card transaction, cash withdrawal, and credit card charge is entered manually into the paper register daily or several times per week. Credit card register also refers to one transaction record for each credit card. In this case the booklets readily enable the location of a card's current available credit when ten or more cards are in use.\n\nAs well as convenient credit, credit cards offer consumers an easy way to track expenses, which is necessary for both monitoring personal expenditures and the tracking of work-related expenses for taxation and reimbursement purposes. Credit cards are accepted in larger establishments in almost all countries, and are available with a variety of credit limits, repayment arrangements. Some have added perks (such as insurance protection, rewards schemes in which points earned by purchasing goods with the card can be redeemed for further goods and services or cashback).\n\nSome countries, such as the United States, the United Kingdom, and France, limit the amount for which a consumer can be held liable in the event of fraudulent transactions with a lost or stolen credit card.\n\nBusiness credit cards are specialized credit cards issued in the name of a registered business, and typically they can only be used for business purposes. Their use has grown in recent decades. In 1998, for instance, 37% of small businesses reported using a business credit card; by 2009, this number had grown to 64%.\n\nBusiness credit cards offer a number of features specific to businesses. They frequently offer special rewards in areas such as shipping, office supplies, travel, and business technology. Most issuers use the applicant's personal credit score when evaluating these applications. In addition, income from a variety of sources may be used to qualify, which means these cards may be available to businesses that are newly established. In addition, most major issuers of these cards do not report account activity to the owner's personal credit unless there is a default. This may have the effect of protecting the owner's personal credit from the activity of the business.\n\nBusiness credit cards are offered by almost all major card issuers—like American Express, Visa, and MasterCard in addition to local banks and credit unions. Charge cards for businesses, however, are currently only offered by American Express.\n\nA secured credit card is a type of credit card secured by a deposit account owned by the cardholder. Typically, the cardholder must deposit between 100% and 200% of the total amount of credit desired. Thus if the cardholder puts down $1,000, they will be given credit in the range of $500–1,000. In some cases, credit card issuers will offer incentives even on their secured card portfolios. In these cases, the deposit required may be significantly less than the required credit limit, and can be as low as 10% of the desired credit limit. This deposit is held in a special savings account. Credit card issuers offer this because they have noticed that delinquencies were notably reduced when the customer perceives something to lose if the balance is not repaid.\n\nThe cardholder of a secured credit card is still expected to make regular payments, as with a regular credit card, but should they default on a payment, the card issuer has the option of recovering the cost of the purchases paid to the merchants out of the deposit. The advantage of the secured card for an individual with negative or no credit history is that most companies report regularly to the major credit bureaus. This allows building a positive credit history.\n\nAlthough the deposit is in the hands of the credit card issuer as security in the event of default by the consumer, the deposit will not be debited simply for missing one or two payments. Usually the deposit is only used as an offset when the account is closed, either at the request of the customer or due to severe delinquency (150 to 180 days). This means that an account which is less than 150 days delinquent will continue to accrue interest and fees, and could result in a balance which is much higher than the actual credit limit on the card. In these cases the total debt may far exceed the original deposit and the cardholder not only forfeits their deposit but is left with an additional debt.\n\nMost of these conditions are usually described in a cardholder agreement which the cardholder signs when their account is opened.\n\nSecured credit cards are an option to allow a person with a poor credit history or no credit history to have a credit card which might not otherwise be available. They are often offered as a means of rebuilding one's credit. Fees and service charges for secured credit cards often exceed those charged for ordinary non-secured credit cards. For people in certain situations, (for example, after charging off on other credit cards, or people with a long history of delinquency on various forms of debt), secured cards are almost always more expensive than unsecured credit cards.\n\nSometimes a credit card will be secured by the equity in the borrower's home.\n\nA \"prepaid credit card\" is not a true credit card, since no credit is offered by the card issuer: the cardholder spends money which has been \"stored\" via a prior deposit by the cardholder or someone else, such as a parent or employer. However, it carries a credit-card brand (such as Discover, Visa, MasterCard, American Express, or JCB) and can be used in similar ways just as though it were a credit card. Unlike debit cards, prepaid credit cards generally do not require a PIN. An exception are prepaid credit cards with an EMV chip. These cards do require a PIN if the payment is processed via Chip and PIN technology.\n\nAfter purchasing the card, the cardholder loads the account with any amount of money, up to the predetermined card limit and then uses the card to make purchases the same way as a typical credit card. Prepaid cards can be issued to minors (above 13) since there is no credit line involved. The main advantage over secured credit cards (see above section) is that the cardholder is not required to come up with $500 or more to open an account. With prepaid credit cards purchasers are not charged any interest but are often charged a purchasing fee plus monthly fees after an arbitrary time period. Many other fees also usually apply to a prepaid card.\n\nPrepaid credit cards are sometimes marketed to teenagers for shopping online without having their parents complete the transaction. Teenagers can only use funds that are available on the card which helps promote financial management to reduce the risk of debt problems later in life.\n\nPrepaid cards can be used globally. The prepaid card is convenient for payees in developing countries like Brazil, Russia, India, and China, where international wire transfers and bank checks are time consuming, complicated and costly.\n\nBecause of the many fees that apply to obtaining and using credit-card-branded prepaid cards, the Financial Consumer Agency of Canada describes them as \"an expensive way to spend your own money\". The agency publishes a booklet entitled \"Pre-paid Cards\" which explains the advantages and disadvantages of this type of prepaid card.\n\nA digital card is a digital cloud-hosted virtual representation of any kind of identification card or payment card, such as a credit card.\n\nThe main benefit to the cardholder is convenience. Compared to debit cards and checks, a credit card allows small short-term loans to be quickly made to a cardholder who need not calculate a balance remaining before every transaction, provided the total charges do not exceed the maximum credit line for the card.\n\nDifferent countries offer different levels of protection. In the UK, for example, the bank is jointly liable with the merchant for purchases of defective products over £100.\n\nMany credit cards offer rewards and benefits packages, such as enhanced product warranties at no cost, free loss/damage coverage on new purchases, various insurance protections, for example, rental car insurance, common carrier accident protection, and travel medical insurance.\n\nCredit cards can also offer a loyalty program, where each purchase is rewarded with points, which may be redeemed for cash or products. Research has examined whether competition among card networks may potentially make payment rewards too generous, causing higher prices among merchants, thus actually impacting social welfare and its distribution, a situation potentially warranting public policy interventions.\n\nThe table below contains a list of benefits offered in the United States for consumer credit cards. Benefits may vary in other countries or business credit cards.\n\nLow introductory credit card rates are limited to a fixed term, usually between 6 and 12 months, after which a higher rate is charged. As all credit cards charge fees and interest, some customers become so indebted to their credit card provider that they are driven to bankruptcy. Some credit cards often levy a rate of 20 to 30 percent after a payment is missed. In other cases, a fixed charge is levied without change to the interest rate. In some cases universal default may apply: the high default rate is applied to a card in good standing by missing a payment on an unrelated account from the same provider. This can lead to a snowball effect in which the consumer is drowned by unexpectedly high interest rates. Further, most card holder agreements enable the issuer to arbitrarily raise the interest rate for any reason they see fit. First Premier Bank at one point offered a credit card with a 79.9% interest rate; however, they discontinued this card in February 2011 because of persistent defaults.\n\nResearch shows that a substantial fraction of consumers (about 40 percent) choose a sub-optimal credit card agreement, with some incurring hundreds of dollars of avoidable interest costs.\n\nSeveral studies have shown that consumers are likely to spend more money when they pay by credit card. Researchers suggest that when people pay using credit cards, they do not experience the abstract pain of payment. Furthermore, researchers have found that using credit cards can increase consumption of unhealthy food.\n\nMerchants that accept credit cards must pay interchange fees and discount fees on all credit-card transactions. In some cases merchants are barred by their credit agreements from passing these fees directly to credit card customers, or from setting a minimum transaction amount (no longer prohibited in the United States, United Kingdom or Australia). The result is that merchants are induced to charge all customers (including those who do not use credit cards) higher prices to cover the fees on credit card transactions. The inducement can be strong because the merchant's fee is a percentage of the sale price, which has a disproportionate effect on the profitability of businesses that have predominantly credit card transactions, unless compensated for by raising prices generally. In the United States in 2008 credit card companies collected a total of $48 billion in interchange fees, or an average of $427 per family, with an average fee rate of about 2% per transaction.\n\nCredit card rewards result in a total transfer of $1,282 from the average cash payer to the average card payer per year.\n\nFor merchants, a credit card transaction is often more secure than other forms of payment, such as cheques, because the issuing bank commits to pay the merchant the moment the transaction is authorized, regardless of whether the consumer defaults on the credit card payment (except for legitimate disputes, which are discussed below, and can result in charges back to the merchant). In most cases, cards are even more secure than cash, because they discourage theft by the merchant's employees and reduce the amount of cash on the premises. Finally, credit cards reduce the back office expense of processing checks/cash and transporting them to the bank.\n\nPrior to credit cards, each merchant had to evaluate each customer's credit history before extending credit. That task is now performed by the banks which assume the credit risk. Credit cards can also aid in securing a sale especially if the customer does not have enough cash on hand or in a checking account. Extra turnover is generated by the fact that the customer can purchase goods and services immediately and is less inhibited by the amount of cash in pocket and the immediate state of the customer's bank balance. Much of merchants' marketing is based on this immediacy.\n\nFor each purchase, the bank charges the merchant a commission (discount fee) for this service and there may be a certain delay before the agreed payment is received by the merchant. The commission is often a percentage of the transaction amount, plus a fixed fee (interchange rate).\n\nMerchants are charged several fees for accepting credit cards. The merchant is usually charged a commission of around 1 to 4 percent of the value of each transaction paid for by credit card. The merchant may also pay a variable charge, called a merchant discount rate, for each transaction. In some instances of very low-value transactions, use of credit cards will significantly reduce the profit margin or cause the merchant to lose money on the transaction. Merchants with very low average transaction prices or very high average transaction prices are more averse to accepting credit cards. In some cases merchants may charge users a \"credit card supplement\" (or surcharge), either a fixed amount or a percentage, for payment by credit card. This practice was prohibited by most credit card contracts in the United States until 2013, when a major settlement between merchants and credit card companies allowed merchants to levy surcharges. Most retailers have not started using credit card surcharges, however, for fear of losing customers.\n\nMerchants in the United States have been fighting what they consider to be unfairly high fees charged by credit card companies in a series of lawsuits that started in 2005. Merchants charged that the two main credit card processing companies, MasterCard and Visa, used their monopoly power to levy excessive fees in a class-action lawsuit involving the National Retail Federation and major retailers such as Wal-Mart. In December 2013, a federal judge approved a $5.7 billion settlement in the case that offered payouts to merchants who had paid credit card fees, the largest antitrust settlement in U.S. history. Some large retailers, such as Wal-Mart and Amazon, chose to not participate in this settlement, however, and have continued their legal fight against the credit card companies.\n\nMerchants are also required to lease or purchase processing equipment, in some cases this equipment is provided free of charge by the processor. Merchants must also satisfy data security compliance standards which are highly technical and complicated. In many cases, there is a delay of several days before funds are deposited into a merchant's bank account. Because credit card fee structures are very complicated, smaller merchants are at a disadvantage to analyze and predict fees.\n\nFinally, merchants assume the risk of chargebacks by consumers.\n\nCredit card security relies on the physical security of the plastic card as well as the privacy of the credit card number. Therefore, whenever a person other than the card owner has access to the card or its number, security is potentially compromised. Once, merchants would often accept credit card numbers without additional verification for mail order purchases. It is now common practice to only ship to confirmed addresses as a security measure to minimise fraudulent purchases. Some merchants will accept a credit card number for in-store purchases, whereupon access to the number allows easy fraud, but many require the card itself to be present, and require a signature (for magnetic stripe cards). A lost or stolen card can be cancelled, and if this is done quickly, will greatly limit the fraud that can take place in this way. European banks can require a cardholder's security PIN be entered for in-person purchases with the card.\n\nThe Payment Card Industry Data Security Standard (PCI DSS) is the security standard issued by the Payment Card Industry Security Standards Council (PCI SSC). This data security standard is used by acquiring banks to impose cardholder data security measures upon their merchants.\n\nThe goal of the credit card companies is not to eliminate fraud, but to \"reduce it to manageable levels\". This implies that fraud prevention measures will be used only if their cost are lower than the potential gains from fraud reduction, whereas high-cost low-return measures will not be used – as would be expected from organizations whose goal is profit maximization.\n\nInternet fraud may be by claiming a chargeback which is not justified (\"friendly fraud\"), or carried out by the use of credit card information which can be stolen in many ways, the simplest being copying information from retailers, either online or offline. Despite efforts to improve security for remote purchases using credit cards, security breaches are usually the result of poor practice by merchants. For example, a website that safely uses TLS to encrypt card data from a client may then email the data, unencrypted, from the webserver to the merchant; or the merchant may store unencrypted details in a way that allows them to be accessed over the Internet or by a rogue employee; unencrypted card details are always a security risk. Even encrypted data may be cracked.\n\nControlled payment numbers (also known as virtual credit cards or disposable credit cards) are another option for protecting against credit card fraud where presentation of a physical card is not required, as in telephone and online purchasing. These are one-time use numbers that function as a payment card and are linked to the user's real account, but do not reveal details, and cannot be used for subsequent unauthorised transactions. They can be valid for a relatively short time, and limited to the actual amount of the purchase or a limit set by the user. Their use can be limited to one merchant. If the number given to the merchant is compromised, it will be rejected if an attempt is made to use it a second time.\n\nA similar system of controls can be used on physical cards. Technology provides the option for banks to support many other controls too that can be turned on and off and varied by the credit card owner in real time as circumstances change (i.e., they can change temporal, numerical, geographical and many other parameters on their primary and subsidiary cards). Apart from the obvious benefits of such controls: from a security perspective this means that a customer can have a Chip and PIN card secured for the real world, and limited for use in the home country. In this eventuality a thief stealing the details will be prevented from using these overseas in non chip and pin EMV countries. Similarly the real card can be restricted from use on-line so that stolen details will be declined if this tried. Then when card users shop online they can use virtual account numbers. In both circumstances an alert system can be built in notifying a user that a fraudulent attempt has been made which breaches their parameters, and can provide data on this in real time.\n\nAdditionally, there are security features present on the physical card itself in order to prevent counterfeiting. For example, most modern credit cards have a watermark that will fluoresce under ultraviolet light. Most major credit cards have a hologram. A Visa card has a letter V superimposed over the regular Visa logo and a MasterCard has the letters MC across the front of the card. Older Visa cards have a bald eagle or dove across the front. In the aforementioned cases, the security features are only visible under ultraviolet light and are invisible in normal light.\n\nThe United States Department of Justice, United States Secret Service, Federal Bureau of Investigation, U.S. Immigration and Customs Enforcement, and U.S. Postal Inspection Service are responsible for prosecuting criminals who engage in credit card fraud in the United States. However, they do not have the resources to pursue all criminals, and in general they only prosecute cases exceeding $5,000.\n\nThree improvements to card security have been introduced to the more common credit card networks, but none has proven to help reduce credit card fraud so far. First, the cards themselves are being replaced with similar-looking tamper-resistant smart cards which are intended to make forgery more difficult. The majority of smart card (IC card) based credit cards comply with the EMV (Europay MasterCard Visa) standard. Second, an additional 3 or 4 digit card security code (CSC) is now present on the back of most cards, for use in card not present transactions. Stakeholders at all levels in electronic payment have recognized the need to develop consistent global standards for security that account for and integrate both current and emerging security technologies. They have begun to address these needs through organisations such as PCI DSS and the Secure POS Vendor Alliance.\n\nCode 10 calls are made when merchants are suspicious about accepting a credit card.\n\nThe operator then asks the merchant a series of YES or NO questions to find out whether the merchant is suspicious of the card or the cardholder. The merchant may be asked to retain the card if it is safe to do so. The merchant may receive a reward for returning a confiscated card to the issuing bank, especially if an arrest is made.\n\nWhen a cardholder becomes severely delinquent on a debt (often at the point of six months without payment), the creditor may declare the debt to be a charge-off. It will then be listed as such on the debtor's credit bureau reports. (Equifax, for instance, lists \"R9\" in the \"status\" column to denote a charge-off.)\n\nA charge-off is considered to be \"written off as uncollectible\". To banks, bad debts and fraud are part of the cost of doing business.\n\nHowever, the debt is still legally valid, and the creditor can attempt to collect the full amount for the time periods permitted under state law, which is usually three to seven years. This includes contacts from internal collections staff, or more likely, an outside collection agency. If the amount is large (generally over $1,500–2,000), there is the possibility of a lawsuit or arbitration.\n\nIn relative numbers the values lost in bank card fraud are minor, calculated in 2006 at 7 cents per 100 dollars worth of transactions (7 basis points). In 2004, in the UK, the cost of fraud was over £500 million. When a card is stolen, or an unauthorized duplicate made, most card issuers will refund some or all of the charges that the customer has received for things they did not buy. These refunds will, in some cases, be at the expense of the merchant, especially in mail order cases where the merchant cannot claim sight of the card. In several countries, merchants will lose the money if no ID card was asked for, therefore merchants usually require ID card in these countries. Credit card companies generally guarantee the merchant will be paid on legitimate transactions regardless of whether the consumer pays their credit card bill.\n\nMost banking services have their own credit card services that handle fraud cases and monitor for any possible attempt at fraud. Employees that are specialized in doing fraud monitoring and investigation are often placed in Risk Management, Fraud and Authorization, or Cards and Unsecured Business. Fraud monitoring emphasizes minimizing fraud losses while making an attempt to track down those responsible and contain the situation. Credit card fraud is a major white collar crime that has been around for many decades, even with the advent of the chip based card (EMV) that was put into practice in some countries to prevent cases such as these. Even with the implementation of such measures, credit card fraud continues to be a problem.\n\nBanks generally borrow the money they then lend to their customers. As they receive very low-interest loans from other firms, they may borrow as much as their customers require, while lending their capital to other borrowers at higher rates. If the card issuer charges 15% on money lent to users, and it costs 5% to borrow the money to lend, and the balance sits with the cardholder for a year, the issuer earns 10% on the loan. This 10% difference is the \"net interest spread\" and the 5% is the \"interest expense\".\n\nThis is the cost of running the credit card portfolio, including everything from paying the executives who run the company to printing the plastics, to mailing the statements, to running the computers that keep track of every cardholder's balance, to taking the many phone calls which cardholders place to their issuer, to protecting the customers from fraud rings. Depending on the issuer, marketing programs are also a significant portion of expenses.\n\nMany credit card customers receive rewards, such as frequent flyer points, gift certificates, or cash back as an incentive to use the card. Rewards are generally tied to purchasing an item or service on the card, which may or may not include balance transfers, cash advances, or other special uses. Depending on the type of card, rewards will generally cost the issuer between 0.25% and 2.0% of the spread. Networks such as Visa or MasterCard have increased their fees to allow issuers to fund their rewards system. Some issuers discourage redemption by forcing the cardholder to call customer service for rewards. On their servicing website, redeeming awards is usually a feature that is very well hidden by the issuers. With a fractured and competitive environment, rewards points cut dramatically into an issuer's bottom line, and rewards points and related incentives must be carefully managed to ensure a profitable portfolio. Unlike unused gift cards, in whose case the breakage in certain US states goes to the state's treasury, unredeemed credit card points are retained by the issuer.\n\nIn addition to fees paid by the card holder, merchants must also pay interchange fees to the card-issuing bank and the card association. For a typical credit card issuer, interchange fee revenues may represent about a quarter of total revenues.\n\nThese fees are typically from 1 to 6 percent of each sale, but will vary not only from merchant to merchant (large merchants can negotiate lower rates), but also from card to card, with business cards and rewards cards generally costing the merchants more to process. The interchange fee that applies to a particular transaction is also affected by many other variables including: the type of merchant, the merchant's total card sales volume, the merchant's average transaction amount, whether the cards were physically present, how the information required for the transaction was received, the specific type of card, when the transaction was settled, and the authorized and settled transaction amounts. In some cases, merchants add a surcharge to the credit cards to cover the interchange fee, encouraging their customers to instead use cash, debit cards, or even cheques.\n\nInterest charges vary widely from card issuer to card issuer. Often, there are \"teaser\" rates in effect for initial periods of time (as low as zero percent for, say, six months), whereas regular rates can be as high as 40 percent. In the U.S. there is no federal limit on the interest or late fees credit card issuers can charge; the interest rates are set by the states, with some states such as South Dakota, having no ceiling on interest rates and fees, inviting some banks to establish their credit card operations there. Other states, for example Delaware, have very weak usury laws. The teaser rate no longer applies if the customer does not pay their bills on time, and is replaced by a penalty interest rate (for example, 23.99%) that applies retroactively.\n\nThe major credit card fees are for:\n\nIn the U.S., the Credit CARD Act of 2009 specifies that credit card companies must send cardholders a notice 45 days before they can increase or change certain fees. This includes annual fees, cash advance fees, and late fees.\n\nOne controversial area is the trailing interest issue. Trailing interest is the practice of charging interest on the entire bill no matter what percentage of it is paid. U.S. Senator Carl Levin raised the issue of millions of Americans affected by hidden fees, compounding interest and cryptic terms. Their woes were heard in a Senate Permanent Subcommittee on Investigations hearing which was chaired by Senator Levin, who said that he intends to keep the spotlight on credit card companies and that legislative action may be necessary to purge the industry. In 2009, the C.A.R.D. Act was signed into law, enacting protections for many of the issues Levin had raised.\n\nIn the United Kingdom, merchants won the right through The Credit Cards (Price Discrimination) Order 1990 to charge customers different prices according to the payment method; this was later removed by the EU's 2nd Payment Services Directive. As of 2007, the United Kingdom was one of the world's most credit card-intensive countries, with 2.4 credit cards per consumer, according to the UK Payments Administration Ltd.\n\nIn the United States until 1984, federal law prohibited surcharges on card transactions. Although the federal Truth in Lending Act provisions that prohibited surcharges expired that year, a number of states have since enacted laws that continue to outlaw the practice; California, Colorado, Connecticut, Florida, Kansas, Massachusetts, Maine, New York, Oklahoma, and Texas have laws against surcharges. As of 2006, the United States probably had one of the world's highest if not the top ratio of credit cards per capita, with 984 million bank-issued Visa and MasterCard credit card and debit card accounts alone for an adult population of roughly 220 million people. The credit card per U.S. capita ratio was nearly 4:1 as of 2003 and as high as 5:1 as of 2006.\n\nConsumers who keep their account in good order by always staying within their credit limit, and always making at least the minimum monthly payment will see interest as the biggest expense from their card provider. Those who are not so careful and regularly surpass their credit limit or are late in making payments are exposed to multiple charges that were typically as high as £25–35 until a ruling from the Office of Fair Trading that they would presume charges over £12 to be unfair which led the majority of card providers to reduce their fees to £12.\n\nThe higher fees originally charged were claimed to be designed to recoup the card operator's overall business costs and to try to ensure that the credit card business as a whole generated a profit, rather than simply recovering the cost to the provider of the limit breach, which has been estimated as typically between £3–£4. Profiting from a customer's mistakes is arguably not permitted under UK common law, if the charges constitute penalties for breach of contract, or under the Unfair Terms in Consumer Contracts Regulations 1999.\n\nSubsequent rulings in respect of personal current accounts suggest that the argument that these charges are penalties for breach of contract is weak, and given the Office of Fair Trading's ruling it seems unlikely that any further test case will take place.\n\nWhilst the law remains in the balance, many consumers have made claims against their credit card providers for the charges that they have incurred, plus interest that they would have earned had the money not been deducted from their account. It is likely that claims for amounts charged in excess of £12 will succeed, but claims for charges at the OFT's £12 threshold level are more contentious.\n\nThe Credit CARD Act of 2009 requires that consumers opt into over-limit charges. Some card issuers have therefore commenced solicitations requesting customers to opt into over-limit fees, presenting this as a benefit as it may avoid the possibility of a future transaction being declined. Other issuers have simply discontinued the practice of charging over-limit fees. Whether a customer opts into the over-limit fee or not, banks will in practice have discretion as to whether they choose to authorize transactions above the credit limit or not. Of course, any approved over limit transactions will only result in an over-limit fee for those customers who have opted into the fee. This legislation took effect on 22 February 2010. Following this Act, the companies are now required by law to show on a customer's bills how long it would take them to pay off the balance.\n\nThe Government of Canada maintains a database of the fees, features, interest rates and reward programs of nearly 200 credit cards available in Canada. This database is updated on a quarterly basis with information supplied by the credit card issuing companies. Information in the database is published every quarter on the website of the Financial Consumer Agency of Canada (FCAC).\n\nInformation in the database is published in two formats. It is available in PDF comparison tables that break down the information according to type of credit card, allowing the reader to compare the features of, for example, all the student credit cards in the database.\n\nThe database also feeds into an interactive tool on the FCAC website. The interactive tool uses several interview-type questions to build a profile of the user's credit card usage habits and needs, eliminating unsuitable choices based on the profile, so that the user is presented with a small number of credit cards and the ability to carry out detailed comparisons of features, reward programs, interest rates, etc.\n\nMany credit cards can be used in an ATM to withdraw money against the credit limit extended to the card, but many card issuers charge interest on cash advances before they do so on purchases. The interest on cash advances is commonly charged from the date the withdrawal is made, rather than the monthly billing date. Many card issuers levy a commission for cash withdrawals, even if the ATM belongs to the same bank as the card issuer. Merchants do not offer cashback on credit card transactions because they would pay a percentage commission of the additional cash amount to their bank or merchant services provider, thereby making it uneconomical. Discover is a notable exception to the above. A customer with a Discover card may get up to $120 cash back if the merchant allows it. This amount is simply added to the card holder's cost of the transaction and no extra fees are charged as the transaction is not considered a cash advance.\n\nMany credit card companies will also, when applying payments to a card, do so, for the matter at hand, at the end of a billing cycle, and apply those payments to everything before cash advances. For this reason, many consumers have large cash balances, which have no grace period and incur interest at a rate that is (usually) higher than the purchase rate, and will carry those balances for years, even if they pay off their statement balance each month.\n\nAn \"acceptance mark\" is a logo or design that indicates which card schemes an ATM or merchant accepts. Common uses include decals and signs at merchant locations or in merchant advertisements. The purpose of the mark is to provide the card holder with information where his or her card can be used. An acceptance mark differs from the a card product name (such as American Express Black card, Eurocard), as it shows the card scheme (group of cards) accepted. An acceptance mark however corresponds to the card scheme mark shown on a card.\n\nAn acceptance mark is however not an absolute guarantee that all cards belonging to a given card scheme will be accepted. On occasion cards issued in a foreign country may not be accepted by a merchant or ATM due to contractual or legal restrictions.\n\nCredit cards are a risky way for entrepreneurs to acquire capital for their start ups when more conventional financing is unavailable. Len Bosack and Sandy Lerner used personal credit cards to start Cisco Systems. Larry Page and Sergey Brin's start up of Google was financed by credit cards to buy the necessary computers and office equipment, more specifically \"a terabyte of hard disks\". Similarly, filmmaker Robert Townsend financed part of \"Hollywood Shuffle\" using credit cards. Director Kevin Smith funded \"Clerks\" in part by maxing out several credit cards. Actor Richard Hatch also financed his production of \"\" partly through his credit cards. Famed hedge fund manager Bruce Kovner began his career (and, later on, his firm Caxton Associates) in financial markets by borrowing from his credit card. UK entrepreneur James Caan (as seen on \"Dragons' Den\") financed his first business using several credit cards.\n\nTravelers from the U.S. had encountered problems abroad because many countries have introduced smart cards, but the U.S. had not. , the U.S. banking system had not updated the cards and associated readers in the U.S., stating that the costs were prohibitive. As of 2015, the smart cards had been introduced and put into use in the United States.\n\n\n"}
{"id": "208852", "url": "https://en.wikipedia.org/wiki?curid=208852", "title": "Loan", "text": "Loan\n\nIn finance, a loan is the lending of money by one or more individuals, organizations, or other entities to other individuals, organizations etc. The recipient (i.e. the borrower) incurs a debt, and is usually liable to pay interest on that debt until it is repaid, and also to repay the principal amount borrowed.\n\nThe document evidencing the debt, e.g. a promissory note, will normally specify, among other things, the principal amount of money borrowed, the interest rate the lender is charging, and date of repayment. A loan entails the reallocation of the subject asset(s) for a period of time, between the lender and the borrower.\n\nThe interest provides an incentive for the lender to engage in the loan. In a legal loan, each of these obligations and restrictions is enforced by contract, which can also place the borrower under additional restrictions known as loan covenants. Although this article focuses on monetary loans, in practice any material object might be lent.\n\nActing as a provider of loans is one of the main activities of financial institutions such as banks and credit card companies. For other institutions, issuing of debt contracts such as bonds is a typical source of funding.\n\nA secured loan is a loan in which the borrower pledges some asset (e.g. a car or house) as collateral.\n\nA mortgage loan is a very common type of loan, used by many individuals to purchase residential property. The lender, usually a financial institution, is given security a lien on the title to the property until the mortgage is paid off in full. In case of home loans if the borrower defaults on the loan, the bank would have the legal right to repossess the house and sell it, to recover sums owing to it.\n\nSimilarly, a loan taken out to buy a car may be secured by the car. The duration of the loan is much shorter often corresponding to the useful life of the car. There are two types of auto loans, direct and indirect. In a direct auto loan, a bank lends the money directly to a consumer. In an indirect auto loan, a car dealership (or a connected company) acts as an intermediary between the bank or financial institution and the consumer.\n\nOther forms of secured loans include loans against securities - such as shares, mutual funds, bonds, etc. This particular instrument issues customers a line of credit based on the quality of the securities pledged. Gold loans are issued to customers after evaluating the quantity and quality of gold in the items pledged. Corporate entities can also take out secured lending by pledging the company's assets, including the company itself. The interest rates for secured loans are usually lower than that of unsecured loans. Usually, the lending institution employs people (on roll or on contract basis) to evaluate the quality of pledged collateral before sanctioning the loan.\n\nUnsecured loans are monetary loans that are not secured against the borrower's assets. These may be available from financial institutions under many different guises or marketing packages:\n\nThe interest rates applicable to these different forms may vary depending on the lender and the borrower. These may or may not be regulated by law. In the United Kingdom, when applied to individuals, these may come under the Consumer Credit Act 1974.\n\nInterest rates on unsecured loans are nearly always higher than for secured loans because an unsecured lender's options for recourse against the borrower in the event of default are severely limited, subjecting the lender to higher risk compared to that encountered for a secured loan. An unsecured lender must sue the borrower, obtain a money judgment for breach of contract, and then pursue execution of the judgment against the borrower's unencumbered assets (that is, the ones not already pledged to secured lenders). In insolvency proceedings, secured lenders traditionally have priority over unsecured lenders when a court divides up the borrower's assets. Thus, a higher interest rate reflects the additional risk that in the event of insolvency, the debt may be uncollectible.\n\nDemand loans are short-term loans that typically do not have fixed dates for repayment. Instead, demand loans carry a floating interest rate which varies according to the prime lending rate or other defined contract terms. Demand loans can be \"called\" for repayment by the lending institution at any time. Demand loans may be unsecured or secured.\n\nA subsidized loan is a loan on which the interest is reduced by an explicit or hidden subsidy. In the context of college loans in the United States, it refers to a loan on which no interest is accrued while a student remains enrolled in education.\n\nA concessional loan, sometimes called a \"soft loan\", is granted on terms substantially more generous than market loans either through below-market interest rates, by grace periods or a combination of both. Such loans may be made by foreign governments to developing countries or may be offered to employees of lending institutions as an employee benefit (sometimes called a \"perk\").\n\nLoans can also be subcategorized according to whether the debtor is an individual person (consumer) or a business.\n\nCommon personal loans include mortgage loans, car loans, home equity lines of credit, credit cards, installment loans and payday loans. The credit score of the borrower is a major component in and underwriting and interest rates (APR) of these loans. The monthly payments of personal loans can be decreased by selecting longer payment terms, but overall interest paid increases as well.\n\nLoans to businesses are similar to the above, but also include commercial mortgages and corporate bonds. Underwriting is not based upon credit score but rather credit rating.\n\nThe most typical loan payment type is the fully amortizing payment in which each monthly rate has the same value over time.\n\nThe fixed monthly payment \"P\" for a loan of \"L\" for \"n\" months and a monthly interest rate \"c\" is:\n\nFor more information see monthly amortized loan or mortgage payments.\n\nPredatory lending is one form of abuse in the granting of loans. It usually involves granting a loan in order to put the borrower in a position that one can gain advantage over him or her; subprime mortgage-lending and payday-lending are two examples, where the moneylender is not authorized or regulated, the lender could be considered a loan shark.\n\nUsury is a different form of abuse, where the lender charges excessive interest. In different time periods and cultures the acceptable interest rate has varied, from no interest at all to unlimited interest rates. Credit card companies in some countries have been accused by consumer organizations of lending at usurious interest rates and making money out of frivolous \"extra charges\".\n\nAbuses can also take place in the form of the customer abusing the lender by not repaying the loan or with an intent to defraud the lender.\n\nMost of the basic rules governing how loans are handled for tax purposes in the United States are codified by both Congress (the Internal Revenue Code) and the Treasury Department (Treasury Regulations another set of rules that interpret the Internal Revenue Code).\n\n1. A loan is not gross income to the borrower. Since the borrower has the obligation to repay the loan, the borrower has no accession to wealth.\n\n2. The lender may not deduct (from own gross income) the amount of the loan. The rationale here is that one asset (the cash) has been converted into a different asset (a promise of repayment). Deductions are not typically available when an outlay serves to create a new or different asset.\n\n3. The amount paid to satisfy the loan obligation is not deductible (from own gross income) by the borrower.\n\n4. Repayment of the loan is not gross income to the lender. In effect, the promise of repayment is converted back to cash, with no accession to wealth by the lender.\n\n5. Interest paid to the lender is included in the lender's gross income. Interest paid represents compensation for the use of the lender's money or property and thus represents profit or an accession to wealth to the lender. Interest income can be attributed to lenders even if the lender doesn't charge a minimum amount of interest.\n\n6. Interest paid to the lender may be deductible by the borrower. In general, interest paid in connection with the borrower's business activity is deductible, while interest paid on personal loans are not deductible.The major exception here is interest paid on a home mortgage.\n\nAlthough a loan does not start out as income to the borrower, it becomes income to the borrower if the borrower is discharged of indebtedness. Thus, if a debt is discharged, then the borrower essentially has received income equal to the amount of the indebtedness. The Internal Revenue Code lists \"Income from Discharge of Indebtedness\" in Section 61(a)(12) as a source of gross income.\n\nExample: X owes Y $50,000. If Y discharges the indebtedness, then X no longer owes Y $50,000. For purposes of calculating income, this is treated the same way as if Y gave X $50,000.\n\nFor a more detailed description of the \"discharge of indebtedness\", look at Section 108 (Cancellation of Debt (COD) Income) of the Internal Revenue Code.\n\nUS specific:\n"}
{"id": "146738", "url": "https://en.wikipedia.org/wiki?curid=146738", "title": "Interest", "text": "Interest\n\nInterest, in finance and economics, is payment from a borrower or deposit-taking financial institution to a lender or depositor of an amount above repayment of the principal sum (that is, the amount borrowed), at a particular rate. It is distinct from a fee which the borrower may pay the lender or some third party. It is also distinct from dividend which is paid by a company to its shareholders (owners) from its profit or reserve, but not at a particular rate decided beforehand, rather on a pro rata basis as a share in the reward gained by risk taking entrepreneurs when the revenue earned exceeds the total costs.\n\nFor example, a customer would usually pay interest to borrow from a bank, so they pay the bank an amount which is more than the amount they borrowed; or a customer may earn interest on their savings, and so they may withdraw more than they originally deposited. In the case of savings, the customer is the lender, and the bank plays the role of the borrower.\n\nInterest differs from profit, in that interest is received by a lender, whereas profit is received by the owner of an asset, investment or enterprise. (Interest may be part or the whole of the profit on an investment, but the two concepts are distinct from each other from an accounting perspective.)\n\nThe rate of interest is equal to the interest amount paid or received over a particular period divided by the principal sum borrowed or lent (usually expressed as a percentage).\n\nCompound interest means that interest is earned on prior interest in addition to the principal. Due to compounding, the total amount of debt grows exponentially, and its mathematical study led to the discovery of the number \"e\". In practice, interest is most often calculated on a daily, monthly, or yearly basis, and its impact is influenced greatly by its compounding rate.\n\nAccording to historian Paul Johnson, the lending of \"food money\" was commonplace in Middle Eastern civilizations as early as 5000 BC. The argument that acquired seeds and animals could reproduce themselves was used to justify interest, but ancient Jewish religious prohibitions against usury (נשך \"NeSheKh\") represented a \"different view\".\n\nThe first written evidence of compound interest dates roughly 2400 BC. The annual interest rate was roughly 20%. Compound interest was necessary for the development of agriculture and important for urbanization. \n\nWhile the traditional Middle Eastern views on interest was the result of the urbanized, economically developed character of the societies that produced them, the new Jewish prohibition on interest showed a pastoral, tribal influence. In the early 2nd millennium BC, since silver used in exchange for livestock or grain could not multiply of its own, the Laws of Eshnunna instituted a legal interest rate, specifically on deposits of dowry. Early Muslims called this \"riba\", translated today as the charging of interest.\n\nThe First Council of Nicaea, in 325, forbade clergy from engaging in usury which was defined as lending on interest above 1 percent per month (12.7% APR). Ninth century ecumenical councils applied this regulation to the laity. Catholic Church opposition to interest hardened in the era of scholastics, when even defending it was considered a heresy. St. Thomas Aquinas, the leading theologian of the Catholic Church, argued that the charging of interest is wrong because it amounts to \"double charging\", charging for both the thing and the use of the thing.\n\nIn the medieval economy, loans were entirely a consequence of necessity (bad harvests, fire in a workplace) and, under those conditions, it was considered morally reproachable to charge interest. It was also considered morally dubious, since no goods were produced through the lending of money, and thus it should not be compensated, unlike other activities with direct physical output such as blacksmithing or farming. For the same reason, interest has often been looked down upon in Islamic civilization, with almost all scholars agreeing that the Qur'an explicitly forbids charging interest.\n\nMedieval jurists developed several financial instruments to encourage responsible lending and circumvent prohibitions on usury, such as the Contractum trinius.\nIn the Renaissance era, greater mobility of people facilitated an increase in commerce and the appearance of appropriate conditions for entrepreneurs to start new, lucrative businesses. Given that borrowed money was no longer strictly for consumption but for production as well, interest was no longer viewed in the same manner.\n\nThe first attempt to control interest rates through manipulation of the money supply was made by the Banque de France in 1847.\n\nThe latter half of the 20th century saw the rise of interest-free Islamic banking and finance, a movement that applies Islamic law to financial institutions and the economy. Some countries, including Iran, Sudan, and Pakistan, have taken steps to eradicate interest from their financial systems. Rather than charging interest, the interest-free lender shares the risk by investing as a partner in profit loss sharing scheme, because predetermined loan repayment as interest is prohibited, as well as making money out of money is unacceptable. All financial transactions must be asset-backed and it does not charge any interest or fee for the service of lending.\n\nIt is thought that Jacob Bernoulli discovered the mathematical constant e by studying a question about compound interest. He realized that if an account that starts with $1.00 and pays say 100% interest per year, at the end of the year, the value is $2.00; but if the interest is computed and added twice in the year, the $1 is multiplied by 1.5 twice, yielding $1.00×1.5 = $2.25. Compounding quarterly yields $1.00×1.25 = $2.4414..., and so on.\n\nBernoulli noticed that if the frequency of compounding is increased without limit, this sequence can be modeled as follows:\n\nwhere \"n\" is the number of times the interest is to be compounded in a year.\n\nIn economics, the rate of interest is the price of credit, and it plays the role of the cost of capital. In a free market economy, interest rates are subject to the law of supply and demand of the money supply, and one explanation of the tendency of interest rates to be generally greater than zero is the scarcity of loanable funds.\n\nOver centuries, various schools of thought have developed explanations of interest and interest rates. The School of Salamanca justified paying interest in terms of the benefit to the borrower, and interest received by the lender in terms of a premium for the risk of default. In the sixteenth century, Martín de Azpilcueta applied a time preference argument: it is preferable to receive a given good now rather than in the future. Accordingly, interest is compensation for the time the lender forgoes the benefit of spending the money.\n\nOn the question of why interest rates are normally greater than zero, in 1770, French economist Anne-Robert-Jacques Turgot, Baron de Laune proposed the theory of fructification. By applying an opportunity cost argument, comparing the loan rate with the rate of return on agricultural land, and a mathematical argument, applying the formula for the value of a perpetuity to a plantation, he argued that the land value would rise without limit, as the interest rate approached zero. For the land value to remain positive and finite keeps the interest rate above zero.\n\nAdam Smith, Carl Menger, and Frédéric Bastiat also propounded theories of interest rates. In the late 19th century, Swedish economist Knut Wicksell in his 1898 \"Interest and Prices\" elaborated a comprehensive theory of economic crises based upon a distinction between natural and nominal interest rates. In the 1930s, Wicksell's approach was refined by Bertil Ohlin and Dennis Robertson and became known as the loanable funds theory. Other notable interest rate theories of the period are those of Irving Fisher and John Maynard Keynes.\n\nSimple interest is calculated only on the principal amount, or on that portion of the principal amount that remains. It excludes the effect of compounding. Simple interest can be applied over a time period other than a year, for example, every month.\n\nSimple interest is calculated according to the following formula:\n\nwhere\n\nFor example, imagine that a credit card holder has an outstanding balance of $2500 and that the simple annual interest rate is 12.99% \"per annum\", applied monthly, so the frequency of applying interest is 12 per year. Over one month,\n\ninterest is due (rounded to the nearest cent).\n\nSimple interest applied over 3 months would be\n\nIf the card holder pays off only interest at the end of each of the 3 months, the total amount of interest paid would be\n\nwhich is the simple interest applied over 3 months, as calculated above. (The one cent difference arises due to rounding to the nearest cent.)\n\nCompound interest includes interest earned on the interest which was previously accumulated.\n\nCompare for example a bond paying 6 percent biannually (that is, coupons of 3 percent twice a year) with a certificate of deposit (GIC) which pays 6 percent interest once a year. The total interest payment is $6 per $100 par value in both cases, but the holder of the biannual bond receives half the $6 per year after only 6 months (time preference), and so has the opportunity to reinvest the first $3 coupon payment after the first 6 months, and earn additional interest.\n\nFor example, suppose an investor buys $10,000 par value of a US dollar bond, which pays coupons twice a year, and that the bond's simple annual coupon rate is 6 percent per year. This means that every 6 months, the issuer pays the holder of the bond a coupon of 3 dollars per 100 dollars par value. At the end of 6 months, the issuer pays the holder:\n\nAssuming the market price of the bond is 100, so it is trading at par value, suppose further that the holder immediately reinvests the coupon by spending it on another $300 par value of the bond. In total, the investor therefore now holds:\n\nand so earns a coupon at the end of the next 6 months of:\n\nAssuming the bond remains priced at par, the investor accumulates at the end of a full 12 months a total value of:\n\nand the investor earned in total:\n\nThe formula for the annual equivalent compound interest rate is:\n\nwhere\n\nFor example, in the case of a 6% simple annual rate, the annual equivalent compound rate is:\n\nThe outstanding balance \"B\" of a loan after \"n\" regular payments increases each period by a growth factor according to the periodic interest, and then decreases by the amount paid \"p\" at the end of each period:\n\nwhere\n\nBy repeated substitution one obtains expressions for \"B\", which are linearly proportional to \"B\" and p and use of the formula for the partial sum of a geometric series results in\n\nA solution of this expression for \"p\" in terms of \"B\" and \"B\" reduces to\n\nTo find the payment if the loan is to be finished in \"n\" payments one sets \"B\" = 0.\n\nThe PMT function found in spreadsheet programs can be used to calculate the monthly payment of a loan:\n\nAn interest-only payment on the current balance would be\n\nThe total interest, \"I\", paid on the loan is\n\nThe formulas for a regular savings program are similar but the payments are added to the balances instead of being subtracted and the formula for the payment is the negative of the one above. These formulas are only approximate since actual loan balances are affected by rounding. To avoid an underpayment at the end of the loan, the payment must be rounded up to the next cent.\n\nConsider a similar loan but with a new period equal to \"k\" periods of the problem above. If \"r\" and \"p\" are the new rate and payment, we now have\n\nComparing this with the expression for B above we note that\n\nand\n\nThe last equation allows us to define a constant that is the same for both problems,\n\nand \"B\" can be written as\n\nSolving for \"r\" we find a formula for \"r\" involving known quantities and \"B\", the balance after \"k\" periods,\n\nSince B could be any balance in the loan, the formula works for any two balances separate by \"k\" periods and can be used to compute a value for the annual interest rate.\n\n\"B\"* is a scale invariant since it does not change with changes in the length of the period.\n\nRearranging the equation for \"B\" one gets a transformation coefficient (scale factor),\n\nand we see that \"r\" and \"p\" transform in the same manner,\n\nThe change in the balance transforms likewise,\n\nwhich gives an insight into the meaning of some of the coefficients found in the formulas above. The annual rate, \"r\", assumes only one payment per year and is not an \"effective\" rate for monthly payments. With monthly payments the monthly interest is paid out of each payment and so should not be compounded and an annual rate of 12·\"r\" would make more sense. If one just made interest-only payments the amount paid for the year would be 12·\"r\"·\"B\".\n\nSubstituting \"p\" = \"r\" \"B\"* into the equation for the \"B\" we get,\n\nSince \"B\" = 0 we can solve for \"B\"*,\n\nSubstituting back into the formula for the \"B\" shows that they are a linear function of the \"r\" and therefore the \"λ\",\n\nThis is the easiest way of estimating the balances if the \"λ\" are known. Substituting into the first formula for \"B\" above and solving for \"λ\" we get,\n\n\"λ\" and \"λ\" can be found using the formula for \"λ\" above or computing the \"λ\" recursively from \"λ\" = 0 to \"λ\".\n\nSince \"p\" = \"rB\"* the formula for the payment reduces to,\n\nand the average interest rate over the period of the loan is\n\nwhich is less than \"r\" if \"n\" > 1.\n\n\nIn the age before electronic computing power was widely available, flat rate consumer loans in the United States of America would be priced using the Rule of 78s, or \"sum of digits\" method. (The sum of the integers from 1 to 12 is 78.) The technique required only a simple calculation.\n\nPayments remain constant over the life of the loan; however, payments are allocated to interest in progressively smaller amounts. In a one-year loan, in the first month, 12/78 of all interest owed over the life of the loan is due; in the second month, 11/78; progressing to the twelfth month where only 1/78 of all interest is due. The practical effect of the Rule of 78s is to make early pay-offs of term loans more expensive. For a one-year loan, approximately 3/4 of all interest due is collected by the sixth month, and pay-off of the principal then will cause the effective interest rate to be much higher than the APY used to calculate the payments.\n\nIn 1992, the United States outlawed the use of \"Rule of 78s\" interest in connection with mortgage refinancing and other consumer loans over five years in term. Certain other jurisdictions have outlawed application of the Rule of 78s in certain types of loans, particularly consumer loans.\n\nTo approximate how long it takes for money to double at a given interest rate, that is, for accumulated compound interest to reach or exceed the initial deposit, divide 72 by the percentage interest rate. For example, compounding at an annual interest rate of 6 percent, it will take 72/6 = 12 years for the money to double.\n\nThe rule provides a good indication for interest rates up to 10%.\n\nIn the case of an interest rate of 18 percent, the rule of 72 predicts that money will double after 72/18 = 4 years.\n\nIn the case of an interest rate of 24 percent, the rule predicts that money will double after 72/24 = 3 years.\n\nThere are markets for investments (which include the money market, bond market, as well as retail financial institutions like banks) set interest rates. Each specific debt takes into account the following factors in determining its interest rate:\n\nOpportunity cost encompasses any other use to which the money could be put, including lending to others, investing elsewhere, holding cash, or spending the funds.\n\nCharging interest equal to inflation preserves the lender's purchasing power, but does not compensate for the time value of money in real terms. The lender may prefer to invest in another product rather than consume. The return they might obtain from competing investments is a factor in determining the interest rate they demand.\n\nSince the lender is deferring consumption, they will \"wish\", as a bare minimum, to recover enough to pay the increased cost of goods due to inflation. Because future inflation is unknown, there are three ways this might be achieved:\n\nHowever interest rates are set by the market, and it happens frequently that they are insufficient to compensate for inflation: for example at times of high inflation during, for example, the oil crisis; and currently (2011) when real yields on many inflation-linked government stocks are negative.\n\nThere is always the risk the borrower will become bankrupt, abscond or otherwise default on the loan. The risk premium attempts to measure the integrity of the borrower, the risk of his enterprise succeeding and the security of any collateral pledged. For example, loans to developing countries have higher risk premiums than those to the US government due to the difference in creditworthiness. An operating line of credit to a business will have a higher rate than a mortgage loan.\n\nThe creditworthiness of businesses is measured by bond rating services and individual's credit scores by credit bureaus. The risks of an individual debt may have a large standard deviation of possibilities. The lender may want to cover his maximum risk, but lenders with portfolios of debt can lower the risk premium to cover just the most probable outcome.\n\nIn economics, interest is considered the price of credit, therefore, it is also subject to distortions due to inflation. The nominal interest rate, which refers to the price before adjustment to inflation, is the one visible to the consumer (that is, the interest tagged in a loan contract, credit card statement, etc.). Nominal interest is composed of the real interest rate plus inflation, among other factors. An approximate formula for the nominal interest is:\n\nWhere\n\nHowever, not all borrowers and lenders have access to the same interest rate, even if they are subject to the same inflation. Furthermore, expectations of future inflation vary, so a forward-looking interest rate cannot depend on a single real interest rate plus a single expected rate of inflation.\n\nInterest rates also depend on credit quality or risk of default. Governments are normally highly reliable debtors, and the interest rate on government securities is normally lower than the interest rate available to other borrowers.\n\nThe equation:\n\nrelates expectations of inflation and credit risk to nominal and expected real interest rates, over the life of a loan, where\n\nDefault interest is the rate of interest that a borrower must pay after material breach of a loan covenant.\n\nThe default interest is usually much higher than the original interest rate since it is reflecting the aggravation in the financial risk of the borrower. Default interest compensates the lender for the added risk.\n\nFrom the borrower's perspective, this means failure to make their regular payment for one or two payment periods or failure to pay taxes or insurance premiums for the loan collateral will lead to substantially higher interest for the entire remaining term of the loan.\n\nBanks tend to add default interest to the loan agreements in order to separate between different scenarios.\n\nIn some jurisdictions, default interest clauses are unenforceable as against public policy.\n\nShorter terms often have less risk of default and exposure to inflation because the near future is easier to predict. In these circumstances, short-term interest rates are lower than longer-term interest rates (an upward sloping yield curve).\n\nInterest rates are generally determined by the market, but government intervention - usually by a central bank - may strongly influence short-term interest rates, and is one of the main tools of monetary policy. The central bank offers to borrow (or lend) large quantities of money at a rate which they determine (sometimes this is money that they have created \"ex nihilo\", that is, printed) which has a major influence on supply and demand and hence on market interest rates.\n\nThe Federal Reserve (Fed) implements monetary policy largely by targeting the federal funds rate. This is the rate that banks charge each other for overnight loans of federal funds. Federal funds are the reserves held by banks at the Fed.\n\nOpen market operations are one tool within monetary policy implemented by the Federal Reserve to steer short-term interest rates. Using the power to buy and sell treasury securities, the Open Market Desk at the Federal Reserve Bank of New York can supply the market with dollars by purchasing U.S. Treasury notes, hence increasing the nation's money supply. By increasing the money supply or Aggregate Supply of Funding (ASF), interest rates will fall due to the excess of dollars banks will end up with in their reserves. Excess reserves may be lent in the Fed funds market to other banks, thus driving down rates.\n\nIt is increasingly recognized that during the business cycle, interest rates and credit risk are tightly interrelated. The Jarrow-Turnbull model was the first model of credit risk that explicitly had random interest rates at its core. Lando (2004), Darrell Duffie and Singleton (2003), and van Deventer and Imai (2003) discuss interest rates when the issuer of the interest-bearing instrument can default.\n\nLoans and bonds have some of the characteristics of money and are included in the broad money supply.\n\nNational governments (provided, of course, that the country has retained its own currency) can influence interest rates and thus the supply and demand for such loans, thus altering the total of loans and bonds issued. Generally speaking, a higher real interest rate reduces the broad money supply.\n\nThrough the quantity theory of money, increases in the money supply lead to inflation. This means that interest rates can affect inflation in the future.\n\nLiquidity is the ability to quickly resell an asset for fair or near-fair value. All else equal, an investor will want a higher return on an illiquid asset than a liquid one, to compensate for the loss of the option to sell it at any time. U.S. Treasury bonds are highly liquid with an active secondary market, while some other debts are less liquid. In the mortgage market, the lowest rates are often issued on loans that can be re-sold as securitized loans. Highly non-traditional loans such as seller financing often carry higher interest rates due to lack of liquidity.\n\nAristotle and the Scholastics held that it was unjust to claim payment except in compensation for one's own efforts and sacrifices, and that since money is by its nature sterile, there is no loss in being temporarily separated from it. Compensation for risk or for the trouble of setting up a loan was not necessarily impermissible on these grounds.\n\nNicholas Barbon (c.1640–c.1698) described as a \"mistake\" the view that interest is a monetary value, arguing that because money is typically borrowed to buy assets (goods and stock), the interest that is charged on a loan is a type of rent – \"a payment for the use of goods\". According to Schumpeter, Barbon's theories were forgotten until similar views were put forward by Joseph Massie in 1750.\n\nIn 1752 David Hume published his essay \"Of money\" which relates interest to the \"demand for borrowing\", the \"riches available to supply that demand\" and the \"profits arising from commerce\". Schumpeter considered Hume's theory superior to that of Ricardo and Mill, but the reference to profits concentrates to a surprising degree on 'commerce' rather than on industry.\n\nTurgot brought the theory of interest close to its classical form. Industrialists...\n... share their profits with capitalists who supply the funds (\"Réflexions\", LXXI). The share that goes to the latter is determined like all other prices (LXXV) by the play of supply and demand amongst borrowers and lenders, so that the analysis is from the outset firmly planted in the general theory of prices.\n\nThe classical theory was the work of a number of authors, including Turgot, Ricardo, Mountifort Longfield, J. S. Mill, and Irving Fisher. It was strongly criticised by Keynes whose remarks nonetheless made a positive contribution to it.\n\nMill's theory is set out the chapter \"Of the rate of interest\" in his \"Principles of political economy\". He says that the interest rate adjusts to maintain equilibrium between the demands for lending and borrowing. Individuals lend in order to defer consumption or for the sake of the greater quantity they will be able to consume at a later date owing to interest earned. They borrow in order to anticipate consumption (whose relative desirability is reflected by the time value of money), but entrepreneurs also borrow to fund investment and governments borrow for their own reasons. The three sources of demand compete for loans.\n\nFor entrepreneurial borrowing to be in equilibrium with lending:\nThe interest for money... is... regulated... by the rate of profits which can be made by the employment of capital...\nRicardo's and Mill's 'profit' is made more precise by the concept of the marginal efficiency of capital (the expression, though not the concept, is due to Keynes), which may be defined as the annual revenue which will be yielded by an extra increment of capital as a proportion of its cost. So the interest rate \"r\" in equilibrium will be equal to the marginal efficiency of capital \"r\". Rather than work with \"r\" and \"r\" as separate variables, we can assume that they are equal and let the single variable \"r\" denote their common value.\n\nThe investment schedule \"i\" (\"r\") shows how much investment is possible with a return of at least \"r\". In a stationary economy it is likely to resemble the blue curve in the diagram, with a step shape arising from the assumption that opportunities to invest with yields greater than \"r̂\" have been largely exhausted while there is untapped scope to invest with a lower return.\n\nSaving is the excess of deferred over anticipated consumption, and its dependence on income is much as described by Keynes (see The General Theory), but in classical theory definitely an increasing function of \"r\". (The dependence of \"s\" on income \"y\" was not relevant to classical concerns prior to the development of theories of unemployment.) The rate of interest is given by the intersection of the solid red saving curve with the blue investment schedule. But so long as the investment schedule is almost vertical, a change in income (leading in extreme cases to the broken red saving curve) will make little difference to the interest rate.\n\nIn some cases the analysis will be less simple. The introduction of a new technique, leading to demand for new forms of capital, will shift the step to the right and reduce its steepness. Or a sudden increase in the desire to anticipate consumption (perhaps through military spending in time of war) will absorb most available loans; the interest rate will increase and investment will be reduced to the amount whose return exceeds it. This is illustrated by the dotted red saving curve.\n\nIn the case of extraordinary spending in time of war the government may wish to borrow more than the public would be willing to lend at a normal interest rate. If the dotted red curve started negative and showed no tendency to increase with \"r\", then the government would be trying to buy what the public was unwilling to sell at any price. Keynes mentions this possibility as a point \"which might, perhaps, have warned the classical school that something was wrong\" (p. 182).\n\nHe also remarks (on the same page) that the classical theory doesn't explain the usual supposition that \"an increase in the quantity of money has a tendency to reduce the rate of interest, at any rate in the first instance\".\n\nKeynes's diagram of the investment schecule lacks the step shape which can be seen as part of the classical theory. He objects that\nthe functions used by classical theory... do not furnish material for a theory of the rate of interest; but they could be used to tell us... what the rate of interest will have to be, if the level of employment [which determines income] is maintained at a given figure.\n\nLater (p. 184) Keynes claims that \"it involves a circular argument\" to construct a theory of interest from the investment schedule since \nthe 'marginal efficiency of capital' partly depends on the scale of current investment, and we must already know the rate of interest before we can calculate what this scale will be.\n\nThe classical theory of interest explains it as the capitalist's share of business profits, but the pre-marginalist authors were unable to reconcile these profits with the labor theory of value (excluding Longfield, who was essentially a marginalist). Their responses often had a moral tone: Ricardo and Marx viewed profits as exploitation, and McCulloch's productivity theory justified profits by portraying capital equipment as an embodiment of accumulated labor. The theory that interest is a payment for abstinence is attributed to Nassau Senior, and according to Schumpeter was intended neutrally, but it can easily be understood as making a moral claim and was sharply criticised by Marx and Lassalle.\n\nKnut Wicksell published his \"Interest and Prices\" in 1898, elaborating a comprehensive theory of economic crises based upon a distinction between natural and nominal interest rates. \nWicksell's contribution, in fact, was twofold. First he separated the monetary rate of interest from the hypothetical \"natural\" rate that would have resulted from equilibrium of capital supply and demand in a barter economy, and he assumed that as a result of the presence of money alone, the effective market rate could fail to correspond to this ideal rate in actuality. Next he supposed that through the mechanism of credit, the rate of interest had an influence on prices; that a rise of the monetary rate above the \"natural\" level produced a fall, and a decline below that level a rise, in prices. But Wicksell went on to conclude that if the natural rate coincided with the monetary rate, stability of prices would follow.\nIn the 1930s Wicksell's approach was refined by Bertil Ohlin and Dennis Robertson and became known as the loanable funds theory.\n\nEugen Böhm von Bawerk and other members of the Austrian School also put forward notable theories of the interest rate.\n\nThe doyen of the Austrian school, Murray N. Rothbard, sees the emphasis on the loan market which makes up the general analysis on interest as a mistaken view to take. As he explains in his primary economic work, \"Man, Economy, and State\", the market rate of interest is but a \"manifestation\" of the natural phenomenon of time preference, which is to prefer present goods to future goods. To Rothbard, \n\nInterest is explainable by the rate of time preference among the people. To point to the loan market is insufficient at best. Rather, the rate of interest is what would be observed between the \"stages of production\", indeed a time market itself, where capital goods which are used to make consumers' goods are ordered out further in time away from the final consumers' goods stage of the economy where consumption takes place. It is \"this\" spread (between these various stages which will tend toward uniformity), with consumers' goods representing present goods and producers' goods representing future goods, that the real rate of interest is observed. Rothbard has said that Rothbard has furthermore criticized the Keynesian conception of interest, saying \n\nPareto held that\nThe interest rate, being one of the many elements of the general system of equilibrium, was, of course, simultaneously determined with all of them so that there was no point at all in looking for any particular element that 'caused' interest.\n\nInterest is one of the main components of the economic theories developed in Keynes's 1936 \"General theory of employment, interest, and money\". In his initial account of liquidity preference (the demand for money) in Chapter 13, this demand is solely a function of the interest rate; and since the supply is given and equilibrium is assumed, the interest rate is determined by the money supply.\n\nIn his later account (Chapter 15), interest cannot be separated from other economic variables and needs to be analysed together with them. See The General Theory for details.\n\nJews are forbidden from usury in dealing with fellow Jews, and this lending is to be considered tzedakah, or charity. However, there are permissions to charge interest on loans to non-Jews. This is outlined in the Jewish scriptures of the Torah, which Christians hold as part of the Old Testament, and other books of the Tanakh. From the Jewish Publication Society's 1917 Tanakh, with Christian verse numbers, where different, in parentheses:\n\nSeveral historical rulings in Jewish law have mitigated the allowances for usury toward non-Jews. For instance, the 15th-century commentator Rabbi Isaac Abrabanel specified that the rubric for allowing interest does not apply to Christians or Muslims, because their faith systems have a common ethical basis originating from Judaism. The medieval commentator Rabbi David Kimchi extended this principle to non-Jews who show consideration for Jews, saying they should be treated with the same consideration when they borrow.\n\nThe following quotations are English translations from the Qur'an:\n\nThe attitude of Muhammad to usury is articulated in his Last Sermon\n\nThe first of the scholastic Christian theologians, Saint Anselm of Canterbury, led the shift in thought that labeled charging interest the same as theft. Previously usury had been seen as a lack of charity.\n\nSt. Thomas Aquinas, the leading scholastic theologian of the Roman Catholic Church, argued charging of interest is wrong because it amounts to \"double charging\", charging for both the thing and the use of the thing. Aquinas said this would be morally wrong in the same way as if one sold a bottle of wine, charged for the bottle of wine, and then charged for the person using the wine to actually drink it. Similarly, one cannot charge for a piece of cake and for the eating of the piece of cake. Yet this, said Aquinas, is what usury does. Money is a medium of exchange, and is used up when it is spent. To charge for the money and for its use (by spending) is therefore to charge for the money twice. It is also to sell time since the usurer charges, in effect, for the time that the money is in the hands of the borrower. Time, however, is not a commodity that anyone can charge. In condemning usury Aquinas was much influenced by the recently rediscovered philosophical writings of Aristotle and his desire to assimilate Greek philosophy with Christian theology. Aquinas argued that in the case of usury, as in other aspects of Christian revelation, Christian doctrine is reinforced by Aristotelian natural law rationalism. Aristotle's argument is that interest is unnatural, since money, as a sterile element, cannot naturally reproduce itself. Thus, usury conflicts with natural law just as it offends Christian revelation: see Thought of Thomas Aquinas.\n\nOutlawing usury did not prevent investment, but stipulated that in order for the investor to share in the profit he must share the risk. In short he must be a joint-venturer. Simply to invest the money and expect it to be returned regardless of the success of the venture was to make money simply by having money and not by taking any risk or by doing any work or by any effort or sacrifice at all, which is usury. St Thomas quotes Aristotle as saying that \"to live by usury is exceedingly unnatural\". Islam likewise condemns usury but allowed commerce (Al-Baqarah 2:275) – an alternative that suggests investment and sharing of profit and loss instead of sharing only profit through interests. Judaism condemns usury towards Jews, but allows it towards non-Jews (Deut. 23:19–20). St Thomas allows, however, charges for actual services provided. Thus a banker or credit-lender could charge for such actual work or effort as he did carry out, for example, any fair administrative charges. The Catholic Church, in a decree of the Fifth Council of the Lateran, expressly allowed such charges in respect of credit-unions run for the benefit of the poor known as \"montes pietatis\".\n\nIn the 13th century Cardinal Hostiensis enumerated thirteen situations in which charging interest was not immoral. The most important of these was \"lucrum cessans\" (profits given up) which allowed for the lender to charge interest \"to compensate him for profit foregone in investing the money himself\" . This idea is very similar to opportunity cost. Many scholastic thinkers who argued for a ban on interest charges also argued for the legitimacy of \"lucrum cessans\" profits (for example, Pierre Jean Olivi and St. Bernardino of Siena). However, Hostiensis' exceptions, including for \"lucrum cessans\", were never accepted as official by the Roman Catholic Church.\n\nThe Roman Catholic Church has always condemned usury, but in modern times, with the rise of capitalism and the disestablishment of the Catholic Church in majority Catholic countries, this prohibition on usury has not been enforced.\n\nPope Benedict XIV's encyclical \"Vix Pervenit\" gives the reasons why usury is sinful:\n\n\n"}
