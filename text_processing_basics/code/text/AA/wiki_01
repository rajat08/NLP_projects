{"id": "12594", "url": "https://en.wikipedia.org/wiki?curid=12594", "title": "Gross domestic product", "text": "Gross domestic product\n\nGross domestic product (GDP) is a monetary measure of the market value of all the final goods and services produced in a specific time period. \nGDP (nominal) per capita does not, however, reflect differences in the cost of living and the inflation rates of the countries; therefore using a basis of GDP per capita at purchasing power parity (PPP) is arguably more useful when comparing living standards between nations, while Nominal GDP is more useful comparing national economies on the international market...\n\nThe OECD defines GDP as \"an aggregate measure of production equal to the sum of the gross values added of all resident and institutional units engaged in production and services (plus any taxes, and minus any subsidies, on products not included in the value of their outputs).\" An IMF publication states that, \"GDP measures the monetary value of final goods and services—that are bought by the final user—produced in a country in a given period of time (say a quarter or a year).\"\n\nTotal GDP can also be broken down into the contribution of each industry or sector of the economy. The ratio of GDP to the total population of the region is the per capita GDP and the same is called Mean Standard of Living. GDP is considered the \"world's most powerful statistical indicator of national development and progress\".\n\nWilliam Petty came up with a basic concept of GDP to attack landlords against unfair taxation during warfare between the Dutch and the English between 1654 and 1676. Charles Davenant developed the method further in 1695. The modern concept of GDP was first developed by Simon Kuznets for a US Congress report in 1934. In this report, Kuznets warned against its use as a measure of welfare (see below under \"limitations and criticisms\"). After the Bretton Woods conference in 1944, GDP became the main tool for measuring a country's economy. At that time gross national product (GNP) was the preferred estimate, which differed from GDP in that it measured production by a country's citizens at home and abroad rather than its 'resident institutional units' (see OECD definition above). The switch from GNP to GDP in the US was in 1991, trailing behind most other nations. The role that measurements of GDP played in World War II was crucial to the subsequent political acceptance of GDP values as indicators of national development and progress. A crucial role was played here by the US Department of Commerce under Milton Gilbert where ideas from Kuznets were embedded into governmental institutions.\n\nThe history of the concept of GDP should be distinguished from the history of changes in ways of estimating it. The value added by firms is relatively easy to calculate from their accounts, but the value added by the public sector, by financial industries, and by intangible asset creation is more complex. These activities are increasingly important in developed economies, and the international conventions governing their estimation and their inclusion or exclusion in GDP regularly change in an attempt to keep up with industrial advances. In the words of one academic economist \"The actual number for GDP is therefore the product of a vast patchwork of statistics and a complicated set of processes carried out on the raw data to fit them to the conceptual framework.\"\n\nGDP can be determined in three ways, all of which should, theoretically, give the same result. They are the production (or output or value added) approach, the income approach, or the speculated expenditure approach.\n\nThe most direct of the three is the production approach, which sums the outputs of every class of enterprise to arrive at the total. The expenditure approach works on the principle that all of the product must be bought by somebody, therefore the value of the total product must be equal to people's total expenditures in buying things. The income approach works on the principle that the incomes of the productive factors (\"producers,\" colloquially) must be equal to the value of their product, and determines GDP by finding the sum of all producers' incomes.\n\nThis approach mirrors the OECD definition given above.\n\n\nGross value added = gross value of output – value of intermediate consumption.\n\nValue of output = value of the total sales of goods and services plus value of changes in the inventory.\n\nThe sum of the gross value added in the various economic activities is known as \"GDP at factor cost\".\n\nGDP at factor cost plus indirect taxes less subsidies on products = \"GDP at producer price\".\n\nFor measuring output of domestic product, economic activities (i.e. industries) are classified into various sectors. After classifying economic activities, the output of each sector is calculated by any of the following two methods:\n\nThe value of output of all sectors is then added to get the gross value of output at factor cost. Subtracting each sector's intermediate consumption from gross output value gives the GVA (=GDP) at factor cost. Adding indirect tax minus subsidies to GVA (GDP) at factor cost gives the \"GVA (GDP) at producer prices\".\n\nThe second way of estimating GDP is to use \"the sum of primary incomes distributed by resident producer units\".\n\nIf GDP is calculated this way it is sometimes called gross domestic income (GDI), or GDP (I). GDI should provide the same amount as the expenditure method described later. By definition, GDI is equal to GDP. In practice, however, measurement errors will make the two figures slightly off when reported by national statistical agencies.\n\nThis method measures GDP by adding incomes that firms pay households for factors of production they hire - wages for labour, interest for capital, rent for land and profits for entrepreneurship.\n\nThe US \"National Income and Expenditure Accounts\" divide incomes into five categories:\nThese five income components sum to net domestic income at factor cost.\n\nTwo adjustments must be made to get GDP:\n\nTotal income can be subdivided according to various schemes, leading to various formulae for GDP measured by the income approach. A common one is:\n\n\nThe sum of COE, GOS and GMI is called total factor income; it is the income of all of the factors of production in society. It measures the value of GDP at factor (basic) prices. The difference between basic prices and final prices (those used in the expenditure calculation) is the total taxes and subsidies that the government has levied or paid on that production. So adding taxes less subsidies on production and imports converts GDP(I) at factor cost to GDP(I) at final prices.\n\nTotal factor income is also sometimes expressed as:\n\nThe third way to estimate GDP is to calculate the sum of the final uses of goods and services (all uses except intermediate consumption) measured in purchasers' prices.\n\nMarket goods which are produced are purchased by someone. In the case where a good is produced and unsold, the standard accounting convention is that the producer has bought the good from themselves. Therefore, measuring the total expenditure used to buy things is a way of measuring production. This is known as the expenditure method of calculating GDP.\n\nGDP (Y) is the sum of consumption (C), investment (I), government spending (G) and net exports (X – M).\n\nHere is a description of each GDP component:\n\nNote that C, G, and I are expenditures on final goods and services; expenditures on intermediate goods and services do not count. (Intermediate goods and services are those used by businesses to produce other goods and services within the accounting year.)\n\nAccording to the U.S. Bureau of Economic Analysis, which is responsible for calculating the national accounts in the United States, \"In general, the source data for the expenditures components are considered more reliable than those for the income components [see income method, above].\"\n\nGDP can be contrasted with gross national product (GNP) or, as it is now known, gross national income (GNI). The difference is that GDP defines its scope according to location, while GNI defines its scope according to ownership. In a global context, world GDP and world GNI are, therefore, equivalent terms.\n\nGDP is product produced within a country's borders; GNI is product produced by enterprises owned by a country's citizens. The two would be the same if all of the productive enterprises in a country were owned by its own citizens, and those citizens did not own productive enterprises in any other countries. In practice, however, foreign ownership makes GDP and GNI non-identical. Production within a country's borders, but by an enterprise owned by somebody outside the country, counts as part of its GDP but not its GNI; on the other hand, production by an enterprise located outside the country, but owned by one of its citizens, counts as part of its GNI but not its GDP.\n\nFor example, the GNI of the USA is the value of output produced by American-owned firms, regardless of where the firms are located. Similarly, if a country becomes increasingly in debt, and spends large amounts of income servicing this debt this will be reflected in a decreased GNI but not a decreased GDP. Similarly, if a country sells off its resources to entities outside their country this will also be reflected over time in decreased GNI, but not decreased GDP. This would make the use of GDP more attractive for politicians in countries with increasing national debt and decreasing assets.\n\nGross national income (GNI) equals GDP plus income receipts from the rest of the world minus income payments to the rest of the world.\n\nIn 1991, the United States switched from using GNP to using GDP as its primary measure of production.\nThe relationship between United States GDP and GNP is shown in table 1.7.5 of the \"National Income and Product Accounts\".\n\nThe international standard for measuring GDP is contained in the book \"System of National Accounts\" (1993), which was prepared by representatives of the International Monetary Fund, European Union, Organisation for Economic Co-operation and Development, United Nations and World Bank. The publication is normally referred to as SNA93 to distinguish it from the previous edition published in 1968 (called SNA68) \n\nSNA93 provides a set of rules and procedures for the measurement of national accounts. The standards are designed to be flexible, to allow for differences in local statistical needs and conditions.\n\nWithin each country GDP is normally measured by a national government statistical agency, as private sector organizations normally do not have access to the information required (especially information on expenditure and production by governments).\n\nThe raw GDP figure as given by the equations above is called the nominal, historical, or current, GDP. When one compares GDP figures from one year to another, it is desirable to compensate for changes in the value of money – for the effects of inflation or deflation. To make it more meaningful for year-to-year comparisons, it may be multiplied by the ratio between the value of money in the year the GDP was measured and the value of money in a base year.\n\nFor example, suppose a country's GDP in 1990 was $100 million and its GDP in 2000 was $300 million. Suppose also that inflation had halved the value of its currency over that period. To meaningfully compare its GDP in 2000 to its GDP in 1990, we could multiply the GDP in 2000 by one-half, to make it relative to 1990 as a base year. The result would be that the GDP in 2000 equals $300 million × one-half = $150 million, \"in 1990 monetary terms.\" We would see that the country's GDP had realistically increased 50 percent over that period, not 200 percent, as it might appear from the raw GDP data. The GDP adjusted for changes in money value in this way is called the real, or constant, GDP.\n\nThe factor used to convert GDP from current to constant values in this way is called the \"GDP deflator\". Unlike consumer price index, which measures inflation or deflation in the price of household consumer goods, the GDP deflator measures changes in the prices of all domestically produced goods and services in an economy including investment goods and government services, as well as household consumption goods.\n\nConstant-GDP figures allow us to calculate a GDP growth rate, which indicates how much a country's production has increased (or decreased, if the growth rate is negative) compared to the previous year.\n\nAnother thing that it may be desirable to account for is population growth. If a country's GDP doubled over a certain period, but its population tripled, the increase in GDP may not mean that the standard of living increased for the country's residents; the average person in the country is producing less than they were before. \"Per-capita GDP\" is a measure to account for population growth.\n\nThe level of GDP in countries may be compared by converting their value in national currency according to \"either\" the current currency exchange rate, or the purchasing power parity exchange rate.\n\nThe ranking of countries may differ significantly based on which method is used.\n\nThere is a clear pattern of the \"purchasing power parity method\" decreasing the disparity in GDP between high and low income (GDP) countries, as compared to the \"current exchange rate method\". This finding is called the Penn effect.\n\nFor more information, see Measures of national income and output.\n\nGDP per capita is often used as an indicator of living standards.\n\nThe major advantage of GDP per capita as an indicator of standard of living is that it is measured frequently, widely, and consistently. It is measured frequently in that most countries provide information on GDP on a quarterly basis, allowing trends to be seen quickly. It is measured widely in that some measure of GDP is available for almost every country in the world, allowing inter-country comparisons. It is measured consistently in that the technical definition of GDP is relatively consistent among countries.\n\nGDP does not include several factors that influence the standard of living. In particular, it fails to account for:\n\nIt can be argued that GDP per capita as an indicator standard of living is correlated with these factors, capturing them indirectly. As a result, GDP per capita as a standard of living is a continued usage because most people have a fairly accurate idea of what it is and know it is tough to come up with quantitative measures for such constructs as happiness, quality of life, and well-being.\n\nSimon Kuznets, the economist who developed the first comprehensive set of measures of national income, stated in his first report to the US Congress in 1934, in a section titled \"Uses and Abuses of National Income Measurements\": The valuable capacity of the human mind to simplify a complex situation in a compact characterization becomes dangerous when not controlled in terms of definitely stated criteria. With quantitative measurements especially, the definiteness of the result suggests, often misleadingly, a precision and simplicity in the outlines of the object measured. Measurements of national income are subject to this type of illusion and resulting abuse, especially since they deal with matters that are the center of conflict of opposing social groups where the effectiveness of an argument is often contingent upon oversimplification. [...]\n\nAll these qualifications upon estimates of national income as an index of productivity are just as important when income measurements are interpreted from the point of view of economic welfare. But in the latter case additional difficulties will be suggested to anyone who wants to penetrate below the surface of total figures and market values. Economic welfare cannot be adequately measured unless the personal distribution of income is known. And no income measurement undertakes to estimate the reverse side of income, that is, the intensity and unpleasantness of effort going into the earning of income. The welfare of a nation can, therefore, scarcely be inferred from a measurement of national income as defined above. In 1962, Kuznets stated:Distinctions must be kept in mind between quantity and quality of growth, between costs and returns, and between the short and long run. Goals for more growth should specify more growth of what and for what.\n\nEver since the development of GDP, multiple observers have pointed out limitations of using GDP as the overarching measure of economic and social progress.\n\nMany environmentalists argue that GDP is a poor measure of social progress because it does not take into account harm to the environment.\n\nAlthough a high or rising level of GDP is often associated with increased economic and social progress within a country, a number of scholars have pointed out that this does not necessarily play out in many instances. For example, Jean Drèze and Amartya Sen have pointed out that an increase in GDP or in GDP growth does not necessarily lead to a higher standard of living, particularly in areas such as healthcare and education. Another important area that does not necessarily improve along with GDP is political liberty, which is most notable in China, where GDP growth is strong yet political liberties are heavily restricted.\n\nGDP does not account for the distribution of income among the residents of a country, because GDP is merely an aggregate measure. An economy may be highly developed or growing rapidly, but also contain a wide gap between the rich and the poor in a society. These inequalities often occur on the lines of race, ethnicity, gender, religion, or other minority status within countries. This can lead to misleading characterizations of economic well-being if the income distribution is heavily skewed toward the high end, as the poorer residents will not directly benefit from the overall level of wealth and income generated in their country. Even GDP per capita measures may have the same downside if inequality is high. For example, South Africa during apartheid ranked high in terms of GDP per capita, but the benefits of this immense wealth and income were not shared equally among the country.\n\nGDP does not take into account the value of household and other unpaid work. Some, including Martha Nussbaum, argue that this value should be included in measuring GDP, as household labor is largely a substitute for goods and services that would otherwise be purchased for value. Even under conservative estimates, the value of unpaid labor in Australia has been calculated to be over 50% of the country's GDP. A later study analyzed this value in other countries, with results ranging from a low of about 15% in Canada (using conservative estimates) to high of nearly 70% in the United Kingdom (using more liberal estimates). For the United States, the value was estimated to be between about 20% on the low end to nearly 50% on the high end, depending on the methodology being used. Because many public policies are shaped by GDP calculations and by the related field of national accounts, the non-inclusion of unpaid work in calculating GDP can create distortions in public policy, and some economists have advocated for changes in the way public policies are formed and implemented.\n\nRobert F. Kennedy, an American politician and lawyer, criticized the GDP as a measure of “everything except that which makes life worthwhile”. He continued to criticize that \"It does not include the beauty of our poetry or the strength of our marriages, the intelligence of our public debate or the integrity of our public officials. [...]\"\n\nThe UK's Natural Capital Committee highlighted the shortcomings of GDP in its advice to the UK Government in 2013, pointing out that GDP \"focuses on flows, not stocks. As a result, an economy can run down its assets yet, at the same time, record high levels of GDP growth, until a point is reached where the depleted assets act as a check on future growth\". They then went on to say that \"it is apparent that the recorded GDP growth rate overstates the sustainable growth rate. Broader measures of wellbeing and wealth are needed for this and there is a danger that short-term decisions based solely on what is currently measured by national accounts may prove to be costly in the long-term\".\n\nIt has been suggested that countries that have authoritarian governments, such as the People's Republic of China, and Russia, inflate their GDP figures.\n\nIn response to these and other limitations of using GDP, alternative approaches have emerged.\n\n\n\n"}
{"id": "18178", "url": "https://en.wikipedia.org/wiki?curid=18178", "title": "Labour economics", "text": "Labour economics\n\nLabour economics seeks to understand the functioning and dynamics of the markets for wage labour. Labour is a commodity that supplied by labourers in exchange for a wage paid by demanding firms. \n\nLabour markets or job markets function through the interaction of workers and employers. Labour economics looks at the suppliers of labour services (workers) and the demanders of labour services (employers), and attempts to understand the resulting pattern of wages, employment, and income.\n\nLabour is a measure of the work done by human beings. It is conventionally contrasted with such other factors of production as land and capital. Some theories focus on human capital (referring to the skills that workers possess, not necessarily their actual work). Labour is unique to study because it is a special type of good that cannot be separated from the owner (i.e. the work cannot be separated from the person who does it). A labour market is also different from other markets in that workers are the suppliers and firms are the demanders. \n\nThere are two sides to labour economics. Labour economics can generally be seen as the application of microeconomic or macroeconomic techniques to the labour market. Microeconomic techniques study the role of individuals and individual firms in the labour market. Macroeconomic techniques look at the interrelations between the labour market, the goods market, the money market, and the foreign trade market. It looks at how these interactions influence macro variables such as employment levels, participation rates, aggregate income and gross domestic product.\n\nThe Labour force (LF) is defined as the number of people of working age, who are either employed or actively looking for work (unemployed). The labour force participation rate (LFPR) is the number of people in the labour force divided by the size of the adult civilian non-institutional population (or by the population of working age that is not institutionalized), LFPR = LF/Population.\n\nThe non-labour force includes those who are not looking for work, those who are institutionalized (such as in prisons or psychiatric wards), stay-at home spouses, children not of working age, and those serving in the military. The unemployment level is defined as the labour force minus the number of people currently employed. The unemployment rate is defined as the level of unemployment divided by the labour force. The employment rate is defined as the number of people currently employed divided by the adult population (or by the population of working age). In these statistics, self-employed people are counted as employed.\n\nThe skills required in a labor force can vary from individual to individual, as well as from firm to firm. Some firms have specific skills they are interested in, limiting the labour force to certain criteria. A firm requiring specific skills will help determine the size of the market.\n\nVariables like employment level, unemployment level, labour force, and unfilled vacancies are called stock variables because they measure a quantity at a point in time. They can be contrasted with flow variables which measure a quantity over a duration of time. Changes in the labour force are due to flow variables such as natural population growth, net immigration, new entrants, and retirements. Changes in unemployment depend on inflows (non-employed people starting to look for jobs and employed people who lose their jobs that are looking for new ones) and outflows (people who find new employment and people who stop looking for employment). When looking at the overall macro economy, several types of unemployment have been identified, which can be separated into two categories of natural and unnatural unemployment.\n\n\"Natural Unemployment\"\n\n\n\"Unnatural Unemployment\"\n\n\nNeoclassical economists view the labour market as similar to other markets in that the forces of supply and demand jointly determine price (in this case the wage rate) and quantity (in this case the number of people employed).\n\nHowever, the labour market differs from other markets (like the markets for goods or the financial market) in several ways. In particular, the labour market may act as a non-clearing market. While according to neoclassical theory most markets quickly attain a point of equilibrium without excess supply or demand, this may not be true of the labour market: it may have a persistent level of unemployment. Contrasting the labour market to other markets also reveals persistent compensating differentials among similar workers.\n\nModels that assume perfect competition in the labour market, as discussed below, conclude that workers earn their marginal product of labour.\n\nHouseholds are suppliers of labour. In microeconomic theory, people are assumed to be rational and seeking to maximize their utility function. In the labour market model, their utility function expresses trade-offs in preference between leisure time and income from time used for labour. However, they are constrained by the hours available to them.\n\nLet \"w\" denote the hourly wage, \"k\" denote total hours available for labour and leisure, \"L\" denote the chosen number of working hours, π denote income from non-labour sources, and \"A\" denote leisure hours chosen. The individual's problem is to maximise utility \"U\", which depends on total income available for spending on consumption and also depends on time spent in leisure, subject to a time constraint, with respect to the choices of labour time and leisure time:\n\nThis is shown in the graph below, which illustrates the trade-off between allocating time to leisure activities and allocating it to income-generating activities. The linear constraint indicates that every additional hour of leisure undertaken requires the loss of an hour of labour and thus of the fixed amount of goods that that labour's income could purchase. Individuals must choose how much time to allocate to leisure activities and how much to working. This allocation decision is informed by the indifference curve labelled IC. The curve indicates the combinations of leisure and work that will give the individual a specific level of utility. The point where the highest indifference curve is just tangent to the constraint line (point A), illustrates the optimum for this supplier of labour services.\n\nIf consumption is measured by the value of income obtained, this diagram can be used to show a variety of interesting effects. This is because the absolute value of the slope of the budget constraint is the wage rate. The point of optimisation (point A) reflects the equivalency between the wage rate and the marginal rate of substitution of leisure for income (the absolute value of the slope of the indifference curve). Because the marginal rate of substitution of leisure for income is also the ratio of the marginal utility of leisure (MU) to the marginal utility of income (MU), one can conclude:\n\nwhere \"Y\" is total income and the right side is the wage rate.\nIf the wage rate increases, this individual's constraint line pivots up from X,Y to X,Y. He/she can now purchase more goods and services. His/her utility will increase from point A on IC to point B on IC.\nTo understand what effect this might have on the decision of how many hours to work, one must look at the income effect and substitution effect.\n\nThe wage increase shown in the previous diagram can be decomposed into two separate effects. The pure income effect is shown as the movement from point A to point C in the next diagram. Consumption increases from Y to Y and – since the diagram assumes that leisure is a normal good – leisure time increases from X to X. (Employment time decreases by the same amount as leisure increases.)\n\nBut that is only part of the picture. As the wage rate rises, the worker will substitute away from leisure and into the provision of labour—that is, will work more hours to take advantage of the higher wage rate, or in other words substitute away from leisure because of its higher opportunity cost. This substitution effect is represented by the shift from point C to point B. The net impact of these two effects is shown by the shift from point A to point B. The relative magnitude of the two effects depends on the circumstances. In some cases, such as the one shown, the substitution effect is greater than the income effect (in which case more time will be allocated to working), but in other cases the income effect will be greater than the substitution effect (in which case less time is allocated to working). The intuition behind this latter case is that the individual decides that the higher earnings on the previous amount of labour can be \"spent\" by purchasing more leisure.\n\nIf the substitution effect is greater than the income effect, an individual's supply of labour services will increase as the wage rate rises, which is represented by a positive slope in the labour supply curve (as at point E in the adjacent diagram, which exhibits a positive wage elasticity). This positive relationship is increasing until point F, beyond which the income effect dominates the substitution effect and the individual starts to reduce the amount of labour hours he supplies (point G) as wage increases; in other words, the wage elasticity is now negative.\n\nThe direction of slope may change more than once for some individuals, and the labour supply curve is different for different individuals.\n\nOther variables that affect the labour supply decision, and can be readily incorporated into the model, include taxation, welfare, work environment, and income as a signal of ability or social contribution.\n\nA firm's labour demand is based on its marginal physical product of labour (MPP). This is defined as the additional output (or physical product) that results from an increase of one unit of labour (or from an infinitesimal increase in labour). (See also Production theory basics.)\n\nLabour demand is a derived demand; that is, hiring labour is not desired for its own sake but rather because it aids in producing output, which contributes to an employer's revenue and hence profits. The demand for an additional amount of labour depends on the Marginal Revenue Product (MRP) and the marginal cost (MC) of the worker. With a perfectly competitive goods market, the MRP is calculated by multiplying the price of the end product or service by the Marginal Physical Product of the worker. If the MRP is greater than a firm's Marginal Cost, then the firm will employ the worker since doing so will increase profit. The firm only employs however up to the point where MRP=MC, and not beyond, in neoclassical economic theory.\n\nThe MRP of the worker is affected by other inputs to production with which the worker can work (e.g. machinery), often aggregated under the term \"capital\". It is typical in economic models for greater availability of capital for a firm to increase the MRP of the worker, all else equal. Education and training are counted as \"human capital\". Since the amount of physical capital affects MRP, and since financial capital flows can affect the amount of physical capital available, MRP and thus wages can be affected by financial capital flows within and between countries, and the degree of capital mobility within and between countries.\n\nAccording to neoclassical theory, over the relevant range of outputs, the marginal physical product of labour is declining (law of diminishing returns). That is, as more and more units of labour are employed, their additional output begins to decline.\n\nAdditionally, although the MRP is a good way of expressing an employer's demand, other factors such as social group formation can the demand, as well as the labor supply. This constantly restructures exactly what a labor market is, and leads way to causing problems for theories of inflation.\n\nThe marginal revenue product of labour can be used as the demand for labour curve for this firm in the short run. In competitive markets, a firm faces a perfectly elastic supply of labour which corresponds with the wage rate and the marginal resource cost of labour (W = S = MFC). In imperfect markets, the diagram would have to be adjusted because MFC would then be equal to the wage rate divided by marginal costs. Because optimum resource allocation requires that marginal factor costs equal marginal revenue product, this firm would demand L units of labour as shown in the diagram.\n\nThe demand for labour of this firm can be summed with the demand for labour of all other firms in the economy to obtain the aggregate demand for labour. Likewise, the supply curves of all the individual workers (mentioned above) can be summed to obtain the aggregate supply of labour. These supply and demand curves can be analysed in the same way as any other industry demand and supply curves to determine equilibrium wage and employment levels.\n\nWage differences exist, particularly in mixed and fully/partly flexible labour markets. For example, the wages of a doctor and a port cleaner, both employed by the NHS, differ greatly. There are various factors concerning this phenomenon. This includes the MRP of the worker. A doctor's MRP is far greater than that of the port cleaner. In addition, the barriers to becoming a doctor are far greater than that of becoming a port cleaner. To become a doctor takes a lot of education and training which is costly, and only those who excel in academia can succeed in becoming doctors. The port cleaner however requires relatively less training. The supply of doctors is therefore significantly less elastic than that of port cleaners. Demand is also inelastic as there is a high demand for doctors and medical care is a necessity, so the NHS will pay higher wage rates to attract the profession.\n\nSome labour markets have a single employer and thus do not satisfy the perfect competition assumption of the neoclassical model above. The model of a monopsonistic labour market gives a lower quantity of employment and a lower equilibrium wage rate than does the competitive model.\n\nIn many real-life situations the assumption of perfect information is unrealistic. An employer does not necessarily know how hard workers are working or how productive they are. This provides an incentive for workers to shirk from providing their full effort, called moral hazard. Since it is difficult for the employer to identify the hard-working and the shirking employees, there is no incentive to work hard and productivity falls overall, leading to the hiring of more workers and a lower unemployment rate.\n\nOne solution that is used to avoid moral hazard is stock options that grant employees the chance to benefit directly from a firm's success. However, this solution has attracted criticism as executives with large stock-option packages have been suspected of acting to over-inflate share values to the detriment of the long-run welfare of the firm. Another solution, foreshadowed by the rise of temporary workers in Japan and the firing of many of these workers in response to the financial crisis of 2008, is more flexible job- contracts and -terms that encourage employees to work less than full-time by partially compensating for the loss of hours, relying on workers to adapt their working time in response to job requirements and economic conditions instead of the employer trying to determine how much work is needed to complete a given task and overestimating.\n\nAnother aspect of uncertainty results from the firm's imperfect knowledge about worker ability. If a firm is unsure about a worker's ability, it pays a wage assuming that the worker's ability is the average of similar workers. This wage under compensates high-ability workers which may drive them away from the labour market as well as at the same time attracting low-ability workers. Such a phenomenon, called adverse selection, can sometimes lead to market collapse.\n\nOne way to combat adverse selection, firms will try to use signalling, pioneered by Michael Spence, whereby employers could use various characteristics of applicants differentiate between high-ability or low-ability workers. One common signal used is education, whereby employers assume that high-ability workers will have higher levels of education. Employers can then compensate high-ability workers with higher wages. However, signalling does not always work, and it may appear to an external observer that education has raised the marginal product of labour, without this necessarily being true.\n\nOne of the major research achievements of the 1990-2010 period was the development of a framework with dynamic search, matching, and bargaining.\n\nAt the micro level, one sub-discipline eliciting increased attention in recent decades is analysis of internal labour markets, that is, \"within\" firms (or other organisations), studied in personnel economics from the perspective of personnel management. By contrast, external labour markets \"imply that workers move somewhat fluidly between firms and wages are determined by some aggregate process where firms do not have significant discretion over wage setting.\" The focus is on \"how firms establish, maintain, and end employment relationships and on how firms provide incentives to employees,\" including models and empirical work on incentive systems and as constrained by economic efficiency and risk/incentive tradeoffs relating to personnel compensation.\n\nInequality and discrimination in the workplace can have many affects on workers.\n\nIn the context of labour economics, inequality is usually referring the to unequal distribution of earning between households. Inequality is commonly measured by economists using the Gini coefficient. This coefficient does not have a concrete meaning, but is more used as a way to compare inequality across regions. The higher the Gini coefficient is calculated to be the larger inequality exists in a region. Over time, inequality has, on average, been increasing. This is due to numerous factors including labour supply and demand shifts as well as institutional changes in the labour market. On the shifts in labour supply and demand, factors include demand for skilled workers going up more than the supply of skilled workers and relative to unskilled workers as well as technological changes that increase productivity; all of these things cause wages to go up for skilled labor while unskilled worker wages stay the same or decline. As for the institutional changes, a decrease in union power and a declining real minimum wage, which both reduce unskilled workers wages, and tax cuts for the wealthy all increase the inequality gap between groups of earners.\n\nAs for discrimination, it is the difference in pay that can be attributed to the demographic differences between people, such as gender, race, ethnicity, religion, sexual orientation, etc, even though these factors do not affect the productivity of the worker. Many regions and countries have enacted government policies to combat discrimination, including discrimination in the workplace. Discrimination can be modeled and measured in numerous ways. The oaxaca decomposition is a common method used to calculate the amount of discrimination that exists when wages differ between groups of people. This decomposition aims to calculate the difference in wages that occurs because of differences in skills versus the returns to those skills. A way of modeling discrimination in the workplace when dealing with wages are Gary Becker's taste models. Using taste models, employer discrimination can be thought of as the employer not hiring the minority worker because their perceived cost of hiring that worker is higher than that of the cost of hiring a non-minority worker, which causes less hiring of the minority. Another taste model is for employee discrimination, which does not cause a decline in the hiring of minorities, but instead causes a more segregated workforce because the prejudiced worker feels that they should be paid more to work next to the worker they are prejudiced against or that they are not paid an equal amount as the worker they are prejudiced against. One more taste model involves customer discrimination, whereby the employers themselves are not prejudiced but believe that their customers might be, so therefore the employer is less likely to hire the minority worker if they are going to interact with customers that are prejudiced. There are many other taste models other than these that Gary Becker has made to explain discrimination that causes differences in hiring in wages in the labour market.\n\nMany sociologists, political economists, and heterodox economists claim that labour economics tends to lose sight of the complexity of individual employment decisions. These decisions, particularly on the supply side, are often loaded with considerable emotional baggage and a purely numerical analysis can miss important dimensions of the process, such as social benefits of a high income or wage rate regardless of the marginal utility from increased consumption or specific economic goals.\n\nFrom the perspective of mainstream economics, neoclassical models are not meant to serve as a full description of the psychological and subjective factors that go into a given individual's employment relations, but as a useful approximation of human behaviour in the aggregate, which can be fleshed out further by the use of concepts such as information asymmetry, transaction costs, contract theory etc.\n\nAlso missing from most labour market analyses is the role of unpaid labour such as unpaid internships where workers with little or no experience are allowed to work a job without pay so that they can gain experience in a particular profession. Even though this type of labour is unpaid it can nevertheless play an important part in society if not abused by employers. The most dramatic example is child raising. However, over the past 25 years an increasing literature, usually designated as the economics of the family, has sought to study within household decision making, including joint labour supply, fertility, child raising, as well as other areas of what is generally referred to as home production.\n\nThe labour market, as institutionalised under today's market economic systems, has been criticised, especially by both mainstream socialists and anarcho-syndicalists, who utilise the term wage slavery as a pejorative for wage labour. Socialists draw parallels between the trade of labour as a commodity and slavery. Cicero is also known to have suggested such parallels.\n\nAccording to Noam Chomsky, analysis of the psychological implications of wage slavery goes back to the Enlightenment era. In his 1791 book \"On the Limits of State Action\", classical liberal thinker Wilhelm von Humboldt explained how \"whatever does not spring from a man's free choice, or is only the result of instruction and guidance, does not enter into his very nature; he does not perform it with truly human energies, but merely with mechanical exactness\" and so when the labourer works under external control, \"we may admire what he does, but we despise what he is.\" Both the Milgram and Stanford experiments have been found useful in the psychological study of wage-based workplace relations.\n\nThe American philosopher John Dewey posited that until \"industrial feudalism\" is replaced by \"industrial democracy,\" politics will be \"the shadow cast on society by big business\". Thomas Ferguson has postulated in his investment theory of party competition that the undemocratic nature of economic institutions under capitalism causes elections to become occasions when blocs of investors coalesce and compete to control the state.\n\nAs per anthropologist David Graeber, the earliest wage labour contracts we know about were in fact contracts for the rental of chattel slaves (usually the owner would receive a share of the money, and the slave, another, with which to maintain his or her living expenses.) Such arrangements, according to Graeber, were quite common in New World slavery as well, whether in the United States or Brazil. C. L. R. James argued that most of the techniques of human organisation employed on factory workers during the industrial revolution were first developed on slave plantations.\n\nAdditionally, Marxists posit that labour-as-commodity, which is how they regard wage labour, provides an absolutely fundamental point of attack against capitalism. \"It can be persuasively argued,\" noted one concerned philosopher, \"that the conception of the worker's labour as a commodity confirms Marx's stigmatisation of the wage system of private capitalism as 'wage-slavery;' that is, as an instrument of the capitalist's for reducing the worker's condition to that of a slave, if not below it.\"\n\n\n"}
{"id": "636781", "url": "https://en.wikipedia.org/wiki?curid=636781", "title": "Domestic worker", "text": "Domestic worker\n\nA domestic worker is a person who works within an employer's household. The term \"domestic service\" applies to the equivalent occupational category. In traditional English contexts, such a person was said to be \"in service\". Domestic helpers perform a variety of household services for an individual or a family, from providing care for children and elderly dependents to housekeeping, including cleaning and household maintenance. Other responsibilities may include cooking, laundry and ironing, shopping for food and other household errands. Such work has always needed to be done but before the Industrial Revolution and the advent of labour saving devices, it was physically much harder.\n\nSome domestic helpers live within their employer's household. In some cases, the contribution and skill of servants whose work encompassed complex management tasks in large households have been highly valued. However, for the most part, domestic work, while necessary, is demanding and undervalued. Although legislation protecting domestic workers is in place in many countries, it is often not extensively enforced. In many jurisdictions, domestic work is poorly regulated and domestic workers are subject to serious abuses, including slavery.\n\n\"Servant\" is an older English word for \"domestic worker\", though not all servants worked inside the home. Domestic service, or the employment of people for wages in their employer's residence, was sometimes simply called \"service\" and has often been part of a hierarchical system. In Britain a highly developed system of domestic service peaked towards the close of the Victorian era, perhaps reaching its most complicated and rigidly structured state during the Edwardian period (a period known in the United States as the Gilded Age and in France as the Belle Époque), which reflected the limited social mobility before World War I.\n\nOther terms include domestic helper, domestic servant, manservant or menial.\n\nILO estimates in 2015, based on national surveys and/or censuses of 232 countries and territories, place the number of domestic workers at around 67.1 million. But the ILO itself states that \"experts say that due to the fact that this kind of work is often hidden and unregistered, the total number of domestic workers could be as high as 100 million\". The ILO also states that 83% of domestic workers are women and many are migrant workers.\n\nIn Guatemala, it is estimated that eight percent of all women work as domestic workers. They hardly have any legal protection. According to Guatemalan labor law, domestic work is \"subject neither to a working time statute nor to regulations on the maximum number of working hours in a day\". Legally, domestic helpers are only entitled to ten hours of free time in 24 hours, and one day off per week. But very often, these minimal employment laws are disregarded, and so are basic civil liberties.\n\nIn Brazil, domestic workers must be hired under a registered contract and have many of the rights of any other workers, which includes a minimum wage, remunerated vacations and a remunerated weekly day off. It is not uncommon, however, for employers to hire servants illegally and fail to offer a work contract. Since domestic staff predominantly come from disadvantaged groups with less access to education, they are often vulnerable and uninformed of their rights, especially in rural areas. Nevertheless, domestics employed without a proper contract can successfully sue their employers and be compensated for abuse committed. It is common in Brazil for domestic staff, including childcare staff, to be required to wear uniforms, while this requirement has fallen out of use in other countries.\n\nIn the United States, domestic workers are generally excluded from many of the legal protections afforded to other classes of worker, including the provisions of the National Labor Relations Act. However, in recent years, advocacy groups like the National Domestic Workers' Alliance have succeeded in passing a Domestic Workers' Bill of Rights into state law in New York, Hawaii, and California.\n\nTraditionally domestic workers have mostly been women and are likely to be immigrants. Currently, there are 1.8 million domestic workers, and tens of thousands of people are believed to be in forced labor in the United States. America's domestic home help workers, most of them female members of minority groups, earn low wages and often receive no retirement or health benefits because the lack of basic labor protections.\n\nDomestic workers are also excluded from vacation time, sick time, and overtime, and only thirteen percent of domestic workers get health insurance provided by their employers. A report from the National Domestic Workers Alliance and affiliated groups found that nearly a quarter of nannies, caregivers, and home health workers make less than the minimum wage in the states in which they work, and nearly half – 48 percent – are paid less than needed to adequately support a family. Many of these workers are subjected to abuse, sexual harassment, and social inequality. However, because domestic workers work in the home, their struggles are hidden in the home and out of the public spotlight. Nowadays with an increase of power, the domestic workers' community has formed many organizations, such as the National Domestic Workers Alliance, Domestic Workers United, and The South African Domestic Service and Allied Workers Union.\n\nThe domestic work industry is dominated throughout the world by women. While the domestic work industry is advantageous for women in that it provides them a sector that they have substantial access to, it can also prove to be disadvantageous by reinforcing gender inequality through the idea that domestic work is an industry that should be dominated by women. Within the domestic work industry, the much smaller proportion of jobs that is occupied by men are not the same jobs that are typically occupied by women. Within the childcare industry, men make up only about 3–6% of all workers. Additionally, in the child care industry men, are more likely to fill roles that are not domestic in nature but administrative such as a managerial role in a daycare center.\n\nWhile the domestic work industry was once believed to be an industry that belonged to a past type of society and did not belong in a modern world, trends are showing that although elements of the domestic work industry have been changing the industry itself has shown no signs of fading away, but only signs of transformation. There are several specific causes that are credited to continuing the cycle of the demand for domestic work. One of these causes is that with more women taking up full-time jobs, a dually employed household with children places a heavy burden on parents. It is argued however that this burden wouldn't result in the demand for outside domestic help if men and women were providing equal levels of effort in domestic work and child-rearing within their own home.\n\nThe demand for domestic workers has also become primarily fulfilled by migrant domestic workers from other countries who flock to wealthier nations to fulfill the demand for help at home. This trend of domestic workers flowing from poorer nations to richer nations creates a relationship that on some levels encourages the liberation of one group of people at the expense of the exploitation of another. Although domestic work has far from begun to fade from society, the demand for it and the people who fill that demand has changed drastically over time.\n\nThe United Kingdom's Master and Servant Act 1823 was the first of its kind; the terms referred generally to employers and employees. The Act influenced the creation of domestic service laws in other nations, although legislation tended to favour employers. However, before the passing of such Acts servants, and workers in general, had no protection in law. The only real advantage that domestic service provided was the provision of meals, accommodation, and sometimes clothes, in addition to a modest wage. Service was normally an apprentice system with room for advancement through the ranks.\n\nThe conditions faced by domestic workers have varied considerably throughout history and in the contemporary world. In the course of twentieth-century movements for labour rights, women's rights and immigrant rights, the conditions faced by domestic workers and the problems specific to their class of employment have come to the fore.\n\nIn 2011, the International Labour Organization adopted the Convention Concerning Decent Work for Domestic Workers. Previously, at its 301st Session (March 2008), the International Labour Organization (ILO) Governing Body agreed to place an item on decent work for domestic workers on the agenda of the 99th Session of the International Labour Conference (2010) with a view to the setting of labour standards. In July 2011, at the annual International Labour Conference, held by the ILO, conference delegates adopted the Convention on Domestic Workers by a vote of 396 to 16, with 63 abstentions. The Convention recognized domestic workers as workers with the same rights as other workers. On 26 April 2012, Uruguay was the first country to ratify the convention.\n\nMany domestic workers are live-in domestics. Though they often have their own quarters, their accommodations are not usually as comfortable as those reserved for the family members. In some cases, they sleep in the kitchen or small rooms, such as a box room, sometimes located in the basement or attic. Domestic workers may live in their own home, though more often they are \"live-in\" domestics, meaning that they receive their room and board as part of their salaries. In some countries, because of the large gap between urban and rural incomes, and the lack of employment opportunities in the countryside, even an ordinary middle class urban family can afford to employ a full-time live-in servant. The majority of domestic workers in China, Mexico, India, and other populous developing countries, are people from the rural areas who are employed by urban families.\n\nEmployers may require their domestic workers to wear a uniform, livery or other \"domestic workers' clothes\" when in their employers' residence. The uniform is usually simple, though aristocratic employers sometimes provided elaborate decorative liveries, especially for use on formal occasions. Female servants wore long, plain, dark-coloured dresses or black skirts with white belts and white blouses, and black shoes, and male servants and butlers would wear something from a simple suit, or a white dress shirt, often with tie, and knickers. In traditional portrayals, the attire of domestic workers especially was typically more formal and conservative than that of those whom they serve. For example, in films of the early 20th century, a butler might appear in a tailcoat, while male family members and guests appeared in lounge suits or sports jackets and trousers depending on the occasion. In later portrayals, the employer and guests might wear casual slacks or even jeans, while a male domestic worker wore a jacket and tie or a white dress shirt with black trousers, necktie or bowtie, maybe even waistcoat, or a female domestic worker either a blouse and skirt (or trousers) or a uniform.\n\nOn 30 March 2009, Peru adopted a law banning employers from requiring domestic workers to wear a uniform at public places. However, it's not explained which punishments will be given to employers violating the law. Chile adopted a similar law in 2014, also banning employers to require domestic workers to wear uniform at public places.\n\nMore girls under 16 work as domestic workers than any other category of child labor. Usually, in a practice often called \"confiage\" or entrusting, such as for restaveks in Haiti, parents in the rural poverty make an agreement with someone in the cities who would house and send their child to school in return for domestic work.\n\nSuch children are very vulnerable to exploitation: often they are not allowed to take breaks or are required to work long hours; many suffer from a lack of access to education, which can contribute to social isolation and a lack of future opportunity. UNICEF considers domestic work to be among the lowest status, and reports that most child domestic workers are live-in workers and are under the round-the-clock control of their employers. Child domestic work is common in countries such as Bangladesh and Pakistan. In Pakistan, since January 2010 to December 2013, 52 cases of tortures on child domestic workers are reported including 24 deaths. It has been estimated that globally, at least 10 million children work in domestic labor jobs.\n\nChildren face a number of risks that are common in domestic work service. The International Programme on the Elimination of Child Labour identified that these risks include: long and tiring working days; use of toxic chemicals; carrying heavy loads; handling dangerous items such as knives, axes and hot pans; insufficient or inadequate food and accommodation, and humiliating or degrading treatment including physical and verbal violence, and sexual abuse.\n\nMany countries import domestic workers from abroad, usually from poorer countries, through recruitment agencies and brokers because their own nationals are no longer obliged or inclined to do domestic work, including in most Middle Eastern countries, Hong Kong, Singapore, Malaysia and Taiwan. There are at least one million domestic workers in Saudi Arabia under the kafala system. Major sources of domestic workers include Thailand, Indonesia, India, the Philippines, Bangladesh, Pakistan, Sri Lanka, and Ethiopia. Taiwan also imports domestic workers from Vietnam and Mongolia. Organizations such as Kalayaan support the growing number of these migrant domestic workers.\n\nThe migration of domestic workers can lead to several different effects both on the countries that are sending workers abroad and countries that are receiving domestic workers from abroad. One particular relationship between countries sending workers and countries receiving workers is that the sending country can be filling gaps in labor shortages of the receiving country. This relationship can be potentially beneficial for both countries involved because the demand for labor is being met and fulfilled by workers' demand for jobs. This relationship however can prove to be quite complicated and not always beneficial. When unemployment in a receiving country rises migrant domestic workers are not only no longer needed but their presence can be detrimental to domestic workers of that country.\n\nWhen international migration began to flourish the assumed migrant worker was typically considered to be a man. What studies are now starting to show is that women are dominating large numbers of the international migration patterns by taking up large percentages of domestic workers that leave their home country in search for work as a domestic laborer in another country.\n\nWomen who migrate to take up work as domestic workers are motivated by different reasons and migrate to a variety of different outcomes. While for many women, domestic work abroad is the only opportunity to find work and provide an income for their families, domestic labor is a market they are forced to enter due to blocked mobility in their homelands. Additionally, migrant domestic workers often have to face the stress of leaving family members behind in their home countries while they take up work abroad. Upward mobility is particularly difficult for migrant domestic workers because their opportunities are often limited by their illegal status putting a very definite limitation on the work that is available to them as well as their power to negotiate with employers\n\nSome argue that personal sacrifices of domestic workers has helped to underpin economic and social development globally. Ariel Salleh's article \"Ecological Debt: Embodied Debt\", defines embodied debt as \"debt owed by the Global North and Global South to the 'reproductive workers' who produce and maintain the new labour force.\" According to the ILO, women constitute 80% of domestic workers. The substantially high percentage of women in domestic work some argue results from this sector's association with motherhood, leading to an assumption that domestic work is by nature the work of females. In support, some argue that because domestic work occurs within the private sphere, which is seen as inherently feminine. This argument goes that the constructed link between domestic work and femininity carries the implication that it is often referred to as 'domestic help,' and that domestic workers are referred to as 'nannies' or 'maids.' At least one author has argued that use of language compounded with the association with domestic work with femininities contributes to the exclusion of domestic work from the majority of national labour laws.\n\nDue to a lack of economic opportunity in the Global South, many women with families leave their countries of origin and their own families to pursue work in the Global North. When they arrive in their country of destination, their work often entails caring for another family (including children and the elderly). Domestic workers often migrate to financially support their immediate family, extended family, and even other members of their community. While enduring dangerous and demeaning working and living conditions in the North, the majority of their wages are remitted to their countries of origin.\n\nAn additional argument has been made that because their work takes place within the private sphere, they are often rendered invisible and employers are able to withhold their travel documents, confining them to their employers' home and inhibiting their access to legal redress. Those making this argument assert that the result of what they refer to as a power dynamic and an asserted lack of labour rights, is that domestic workers are often forbidden to contact their families and often go months, years, and even decades without seeing their families, whose lives their remittances are supporting.\n\nFurther, it has been argued that their ability to fill labour shortages and accept positions within the reproductive labour force that citizens of their host countries would reject underpins the development of the global capitalist system, Simultaneously, and that they are enabling the beneficiaries of their remittances in the South to ascend the social ladder. To some, these arguments lead to a conclusion that both circumstances in the North and South constitute embodied debt through the improvement of one's life at the expense of another's hardship, and that the labour of such workers is too often not seen as work, due to the association of their gendered bodies with reproductive labour.\n\nHowever, on June 17, 2011, after 70 years of lobbying by civil society groups, the ILO adopted a convention with the aim of protecting and empowering domestic workers. Much of lobbying that contributed toward the ratification of ILO C189 was done by domestic workers groups, demonstrating that they are not merely victims but agents of change. That only two labour receiving countries have ratified the convention has been argued by some to demonstrates the reluctance of governments to acknowledge what such advocates see as a debt owed by society to such workers and to repay that perceived debt.\n\nSuch advocates assert that the ratification and enforcement of ILO C189 would mean that migrant domestic workers would enjoy the same labour rights as other more 'masculine' fields as well as the citizens of their destination countries. An incomplete list of basic rights guaranteed by ILO C189 under Article 7 includes: maximum working hours; fixed minimum wages; paid leave; provision of food and accommodation; and weekly rest periods. Guaranteeing these rights to migrant domestic workers would not constitute repayment the embodied debt owed to them, but they are entitled to these rights as they are both workers and human beings.\n\nAs women currently dominate the domestic labor market throughout the world, they have learned to navigate the system of domestic work both in their own countries and abroad in order to maximize the benefits of entering the domestic labor market.\n\nAmong the disadvantages of working as a domestic worker is the fact that women working in this sector are working in an area often regarded as a private sphere. Feminist critics of women working in the domestic sphere argue that this woman dominated market is reinforcing gender inequalities by potentially creating mistress-servant relationships between domestic workers and their employers and continuing to put women in a position of lesser power. Other critics point out that working in a privatized sphere robs domestic workers of the advantages of more socialized work in the public sphere.\n\nAdditionally, domestic laborers face other disadvantages. Their isolation is increased by their invisibility in the public sphere and the repetitive, intangible nature of their work decreases its value, making the workers themselves more dispensable. The level of isolation women face also depends on the type of domestic work they are involved with. Live-in nannies for example may sacrifice much of their own independence and sometimes become increasingly isolated when they live with a family of which they are not part and away from their own.\n\nWhile working in a dominantly female privatized world can prove disadvantageous for domestic workers, many women have learned how to help one other move upward economically. Women find that informal networks of friends and families are among the most successful and commonly used means of finding and securing jobs.\n\nWithout the security of legal protection, many women who work without the requisite identity or citizenship papers are vulnerable to abuse. Some have to perform tasks considered degrading showing a manifestation of employer power over worker powerlessness. Employing domestic work from foreign countries can perpetuate the idea that domestic or service work is reserved for other social or racial groups and plays into the stereotype that it is work for inferior groups of people.\n\nGaining employment in the domestic labor market can prove to be difficult for immigrant women. Many subcontract their services to more established women workers, creating an important apprenticeship type of learning experience that can produce better, more independent opportunities in the future. Women who work as domestic workers also gain some employment mobility. Once established they have the option of accepting jobs from multiple employers increasing their income and their experience and most importantly their ability to negotiate prices with their employers.\n\nDomestic helpers in Canada, mainly from the Philippines, work in Canada, including under the\nLive-In Caregiver program.\n\nDomestic helpers (DHs, foreign domestic workers, FDWs) from certain other countries, especially the Philippines and Indonesia, work in Hong Kong on specific visas that exempt employers from many obligations received by other workers, and receive a lower minimum salary. Approximately five percent of Hong Kong's population are FDWs, about 98.5% of them are women, performing household tasks such as cooking, serving, cleaning, dishwashing and child care.\n\nIn Kenya, domestic workers – nearly all female – are known as 'housegirls'. Often from poor villages in neighbouring Uganda, girls are open to exploitation, and there are calls for stronger legal protection.\nIn the Philippines, domestic household workers/helpers such as maidservants (\"katulong\"/\"kasambahay\"), caretakers (\"yaya\"), family drivers (\"drayber\"/\"tsuper\"), laundrywomen (\"labandera\"/\"tagalaba\"), gardeners (\"hardinero\"), security guards (\"guwardiya\"/\"bantay\"), pool cleaners have been a norm in upper class Philippine society for an uncertain amount of time already, perhaps even connected to or influenced from the household slaves/servants in precolonial times of the Philippines that were divided into aliping namamahay and aliping saguiguilid, as indentured household servants. In modern times, it has been a norm among upper and upper-middle-class families in the Philippines to hire at least one maidservant-caretaker (\"katulong\"/\"kasambahay/yaya\") to care for the household and children. Most, particularly maidservant-caretakers (\"katulong\"/\"kasambahay/yaya\"), live together in the house of their master's family with usually only a day off per month. This practice has eventually influenced the architecture of some houses or apartment condos where it has become a norm to section a room where domestic maidservants sleep as their personal room, usually near the kitchen or laundry area. Some wealthy families also section off an area or house where all the maidservants sleep or a part of the kitchen where they eat separate from the master's table. There are also employment agencies and special government laws regarding the regulation of domestic worker employment, such as the \"Domestic Workers Act\" or \"Batas Kasambahay\" in Republic Act No 10361. Many live underpaid since many are informally hired or salaries are not declared truthfully to government offices or have an agreement instead to pay through other means, such as paying for their education, pension, or to send money back to their families. This practice was eventually exported to neighboring countries and all other countries that overseas Filipino workers (OFWs) have worked in, such as the United States, Canada, Hong Kong, Singapore, China, Saudi Arabia, and other countries in the Middle East, and etc., hence some maidservants continue living with the same mindset of how domestic worker culture was practiced in the Philippines. This has also, at times, been used as a cause to look down upon overseas Filipino workers (OFWs) in the countries where they can be found. It has sometimes created controversies in other countries such as abuse charges in several countries in the Middle East or like the case of Flor Contemplacion, who was executed in Singapore for murder allegations. There have also been documentaries or rom-com movies made in the Philippines about the plight or life of domestic workers, particularly maidservant-caretakers (\"katulong\"/\"kasambahay\"/\"yaya\").\n\nIn the United States, slavery legally ended in 1865, however, the Freedmen's Bureau informed the former slaves now classified as freedmen and women that they could either sign labor contracts with white planters or be evicted from the land that they had lived on. Most freedmen in the South signed labor contracts with their former white slave owners because that was the only work experience they had. With limited skills and illiteracy, many men turned to become sharecroppers, whereas the majority of women participated in domestic work. Not only were they not qualified for other jobs, but they were denied other jobs and segregated from American society purely based on the color of their skin. The South wanted to keep segregation alive and hence passed legislation such as the Jim Crow Laws post-Civil war which denied African Americans of legal equality and political rights. These laws kept many African Americans as a second-class status up until new laws ended segregation in the 1960s.\n\nUp until the mid-twentieth century, domestic work was a prominent source of income for many women of different ethnic backgrounds. Many of these women were either African American or immigrants. More specifically, the post-civil war South had a high concentration of African Americans working as domestic workers. At the turn of the nineteenth century, there was also a high concentration of African Americans working as domestic workers in the North. Many African American women migrated to the North for better work opportunities and higher wages compared to their employment options in the South. The African American women who worked as domestic workers were generally treated as poor, childlike beings that were seen as victims of their own ignorance of living in communities of crime and other societal infringements. However, despite the stereotypes labeled upon domestic workers, these women still settled for these positions because the only occupations that were open to African American women before World War I were domestic services. It was necessary they worked along with their husbands in order to keep their families financially supported.\n\nDuring the Great Depression, many domestic workers lost their jobs. This is because many white families lost their source of income and were not able to pay domestic workers to work in their home. At this time, many domestic workers relied on asking strangers on the street for housework such as cleaning. They house jumped, looking for any job that they could get. The domestic workforce was significantly impacted by the Great Depression which caused a decrease in their wages and an intolerable 18 hour workday. Also, agricultural workers and the African American women working as domestic workers at this time were explicitly excluded from social security and the FLSA in the New Deal legislation. This is because the New Dealer politicians were more worried about losing support from the Southern Democrats in Congress who supported segregation rather than refusing coverage for many African Americans. Unlike their white counterparts, African Americans did not form labor unions because they lacked the resources, consciousness, and the access to networks used for union recruiting. On top of that, the domestic workers would not typically have earned enough money to be able to afford being a part of a union. Even if the African American domestic workers wanted to advance in society, it was nearly impossible because the racial structures in the United States rarely allowed them class mobility. However, domestic workers that were white such as the Irish and the Germans utilized working in middle-class homes to their advantage. Working in the middle-class homes served to Americanize, allowing the workers to identify more with their employers than women of their own class and instilled an aspiration to become middle-class status.\n\nNearly ninety percent of African American women worked as domestic workers during the Civil Rights Movement era. Their participation in the Civil Rights Movement went fairly undocumented, and despite their low-status career in the United States, they were beneficial for the betterment of society and the status of the African American race. It has been noted that the southern African American women were the backbone of the Civil Rights Movement.\n\nSince many white households relied on the African American domestic workers for housework, the workers were able to have a direct impact on the white race when rebelling for their civil rights. The African American domestic workers boycotted buses and tried to register to vote, and many were denied and imprisoned. However, the domestic workers utilized imprisonment to educate other African American women on the Civil Rights Movement and what to do to contribute. Additionally, typically the domestic workers rebelled in an informal manner, such as resisting to live in the same home in which they worked. By doing this, the African American domestic workers transformed the domestic services, and collective organizations came about promoting a better work environment for African American domestic workers. Their act of rebellion gave way for a change of how they were treated, how they were paid, and how they were respected.\n\nAccording to a 2008 report by Human Rights Watch (HRW), the Saudi Ministry of Labor provided official figures of 1.2 million household workers in Saudi Arabia including domestic workers, drivers, and gardeners. The report stated that the Gulf country employed nearly 1.5 million women domestic workers from Indonesia, Sri Lanka and Philippines. Domestic workers estimated approximately 600,000 from Indonesia, 275,000 from Sri Lanka and 200,000 from Philippines. However, HRW reported that a number of domestic workers in Saudi Arabia face a range of abuses. Besides, the organization also interviewed Saudi labor and social affairs official, who acknowledged the issue of domestic worker abuse. The report stated that no accurate figure exists to highlight the total violations of labor rights and other human rights that women migrant domestic workers confront in the Arab nation.\n\n\nSome domestic workers have become notable, including: Abdul Karim (the Munshi), servant of Queen Victoria of Great Britain; Paul Burrell, butler to Diana, Princess of Wales; Moa Martinson, author of proletarian literature, kitchen maid; and Charles Spence, Scottish poet, stonemason and footman.\n\n\n\n\n\n"}
{"id": "166784", "url": "https://en.wikipedia.org/wiki?curid=166784", "title": "Factory", "text": "Factory\n\nA factory, manufacturing plant or a production plant is an industrial site, usually consisting of buildings and machinery, or more commonly a complex having several buildings, where workers manufacture goods or operate machines processing one product into another.\n\nFactories arose with the introduction of machinery during the Industrial Revolution when the capital and space requirements became too great for cottage industry or workshops. Early factories that contained small amounts of machinery, such as one or two spinning mules, and fewer than a dozen workers have been called \"glorified workshops\".\n\nMost modern factories have large warehouses or warehouse-like facilities that contain heavy equipment used for assembly line production. Large factories tend to be located with access to multiple modes of transportation, with some having rail, highway and water loading and unloading facilities. In some countries like Australia, it is common to call a factory building a \"Shed\". \n\nFactories may either make discrete products or some type of material continuously produced such as chemicals, pulp and paper, or refined oil products. Factories manufacturing chemicals are often called \"plants\" and may have most of their equipment – tanks, pressure vessels, chemical reactors, pumps and piping – outdoors and operated from control rooms. Oil refineries have most of their equipment outdoors.\n\nDiscrete products may be final consumer goods, or parts and sub-assemblies which are made into final products elsewhere. Factories may be supplied parts from elsewhere or make them from raw materials. Continuous production industries typically use heat or electricity to transform streams of raw materials into finished products.\n\nThe term \"mill\" originally referred to the milling of grain, which usually used natural resources such as water or wind power until those were displaced by steam power in the 19th century. Because many processes like spinning and weaving, iron rolling, and paper manufacturing were originally powered by water, the term survives as in \"steel mill\", \"paper mill\", etc.\n\nMax Weber considered production during ancient times as never warranting classification as factories, with methods of production and the contemporary economic situation incomparable to modern or even pre-modern developments of industry. In ancient times, the earliest production limited to the household, developed into a separate endeavour independent to the place of inhabitation with production at that time only beginning to be characteristic of industry, termed as \"unfree shop industry\", a situation caused especially under the reign of the Egyptian pharaoh, with slave employment and no differentiation of skills within the slave group comparable to modern definitions as division of labour.\n\nAccording to translations of Demosthenes and Herodotus, Naucratis was a, or the only, factory in the entirety of ancient Egypt. A source of 1983 (Hopkins), states the largest factory production in ancient times was of 120 slaves within 4th century BC Athens. An article within the New York Times article dated 13 October 2011 states:\n\n... discovered at Blombos Cave, a cave on the south coast of South Africa where 100,000-year-old tools and ingredients were found with which early modern humans mixed an ochre-based paint.\n\nAlthough The \"Cambridge Online Dictionary\" definition of factory states:\n\nelsewhere:\n\nThe first machine is stated by one source to have been traps used to assist with the capturing of animals, corresponding to the machine as a mechanism operating independently or with very little force by interaction from a human, with a capacity for use repeatedly with operation exactly the same on every occasion of functioning. The wheel was invented c. 3000 BC, the spoked wheel c. 2000 BC. The Iron Age began approximately 1200–1000 BC. However, other sources define machinery as a means of production.\n\nArchaeology provides a date for the earliest city as 5000 BC as Tell Brak (Ur \"et al.\" 2006), therefore a date for cooperation and factors of demand, by an increased community size and population to make something like factory level production a conceivable necessity.\n\nThe watermill was first made in the Persian Empire some time before 350 BC. By the time of the 4th century AD, there was a water-milling installation with a capacity to grind 28 tons of grain per day, a rate sufficient to meet the needs of 80,000 persons, in the Roman Empire.\n\nThe earliest proper factory milling installations appeared in the Islamic world from the 8th century onwards.The large population increase in medieval Islamic cities, such as Baghdad's 1.5 million population, led to the development of large-scale factory milling installations with higher productivity to feed and support the large growing population. A 10th-century grain-processing factory in the Egyptian town of Bilbays, for example, produced an estimated 300 tons of grain and flour per day. Both watermills and windmills were widely used in the Islamic world at the time.\n\nThe Venice Arsenal also provides one of the first examples of a factory in the modern sense of the word. Founded in 1104 in Venice, Republic of Venice, several hundred years before the Industrial Revolution, it mass-produced ships on assembly lines using manufactured parts. The Venice Arsenal apparently produced nearly one ship every day and, at its height, employed 16,000 people.\n\nOne of the earliest factories was John Lombe's water-powered silk mill at Derby, operational by 1721. By 1746, an integrated brass mill was working at Warmley near Bristol. Raw material went in at one end, was smelted into brass and was turned into pans, pins, wire, and other goods. Housing was provided for workers on site. Josiah Wedgwood in Staffordshire and Matthew Boulton at his Soho Manufactory were other prominent early industrialists, who employed the factory system.\n\nThe factory system began widespread use somewhat later when cotton spinning was mechanized.\n\nRichard Arkwright is the person credited with inventing the prototype of the modern factory. After he patented his water frame in 1769, he established Cromford Mill, in Derbyshire, England, significantly expanding the village of Cromford to accommodate the migrant workers new to the area. The factory system was a new way of organizing workforce made necessary by the development of machines which were too large to house in a worker's cottage. Working hours were as long as they had been for the farmer, that is, from dawn to dusk, six days per week. Overall, this practice essentially reduced skilled and unskilled workers to replaceable commodities. Arkwright's factory was the first successful cotton spinning factory in the world; it showed unequivocally the way ahead for industry and was widely copied.\n\nBetween 1770 and 1850 mechanized factories supplanted traditional artisan shops as the predominant form of manufacturing institution, because the larger-scale factories enjoyed a significant technological and supervision advantage over the small artisan shops. The earliest factories (using the factory system) developed in the cotton and wool textiles industry. Later generations of factories included mechanized shoe production and manufacturing of machinery, including machine tools. Factories that supplied the railroad industry included rolling mills, foundries and locomotive works. Agricultural-equipment factories produced cast-steel plows and reapers. Bicycles were mass-produced beginning in the 1880s.\n\nThe Nasmyth, Gaskell and Company's Bridgewater Foundry, which began operation in 1836, was one of the earliest factories to use modern materials handling such as cranes and rail tracks through the buildings for handling heavy items.\n\nLarge scale electrification of factories began around 1900 after the development of the AC motor which was able to run at constant speed depending on the number of poles and the current electrical frequency. At first larger motors were added to line shafts, but as soon as small horsepower motors became widely available, factories switched to unit drive. Eliminating line shafts freed factories of layout constraints and allowed factory layout to be more efficient. Electrification enabled sequential automation using relay logic.\n\nHenry Ford further revolutionized the factory concept in the early 20th century, with the innovation of the mass production. Highly specialized laborers situated alongside a series of rolling ramps would build up a product such as (in Ford's case) an automobile. This concept dramatically decreased production costs for virtually all manufactured goods and brought about the age of consumerism.\n\nIn the mid - to late 20th century, industrialized countries introduced next-generation factories with two improvements:\n\n\nSome speculation as to the future of the factory includes scenarios with rapid prototyping, nanotechnology, and orbital zero-gravity facilities.\n\n\nBefore the advent of mass transportation, factories' needs for ever-greater concentrations of laborers meant that they typically grew up in an urban setting or fostered their own urbanization. Industrial slums developed, and reinforced their own development through the interactions between factories, as when one factory's output or waste-product became the raw materials of another factory (preferably nearby). Canals and railways grew as factories spread, each clustering around sources of cheap energy, available materials and/or mass markets. The exception proved the rule: even greenfield factory sites such as Bournville, founded in a rural setting, developed its own housing and profited from convenient communications systems.\n\nRegulation curbed some of the worst excesses of industrialization's factory-based society, a series of Factory Acts leading the way in Britain. Trams, automobiles and town planning encouraged the separate development of industrial suburbs and residential suburbs, with laborers commuting between them.\n\nThough factories dominated the Industrial Era, the growth in the service sector eventually began to dethrone them: the focus of labor in general shifted to central-city office towers or to semi-rural campus-style establishments, and many factories stood deserted in local rust belts.\n\nThe next blow to the traditional factories came from globalization. Manufacturing processes (or their logical successors, assembly plants) in the late 20th century re-focussed in many instances on Special Economic Zones in developing countries or on maquiladoras just across the national boundaries of industrialized states. Further re-location to the least industrialized nations appears possible as the benefits of out-sourcing and the lessons of flexible location apply in the future.\n\nMuch of management theory developed in response to the need to control factory processes. Assumptions on the hierarchies of unskilled, semi-skilled and skilled laborers and their supervisors and managers still linger on; however an example of a more contemporary approach to handle design applicable to manufacturing facilities can be found in Socio-Technical Systems (STS).\n\nA shadow factory is a term given to dispersed manufacturing sites in times of war to reduce the risk of disruption due to enemy air-raids and often with the dual purpose of increasing manufacturing capacity. Before World War II Britain had built many shadow factories.\n\nProduction of the Supermarine Spitfire at its parent company's base at Woolston, Southampton was vulnerable to enemy attack as a high-profile target and was well within range of \"Luftwaffe\" bombers. Indeed, on 26 September 1940 this facility was completely destroyed by an enemy bombing raid. Supermarine had already established a plant at Castle Bromwich; this action prompted them to further disperse Spitfire production around the country with many premises being requisitioned by the British Government.\n\nConnected to the Spitfire was production of its equally important Rolls-Royce Merlin engine, Rolls-Royce's main aero engine facility was located at Derby, the need for increased output was met by building new factories in Crewe and Glasgow and using a purpose-built factory of Ford of Britain in Trafford Park Manchester.\n\n\n\n"}
{"id": "11162", "url": "https://en.wikipedia.org/wiki?curid=11162", "title": "Finance", "text": "Finance\n\nFinance is the study of money and how it is used. Specifically, it deals with the questions of how an individual, company or government acquires the money needed - called capital in the company context - and how they then spend or invest that money.\n\nFinance is, correspondingly, often split into three areas: personal finance, corporate finance and public finance. \n\nAt the same time, \"finance\" is about the overall \"system\"\n- i.e. the financial markets that allow the flow of money, via investments and other financial instruments, between and within these areas; \nthis \"flow\" is facilitated by the financial services sector.\nA major focus within finance is thus investment management — called money management for individuals, and asset management for institutions — and finance then includes the associated activities of securities trading, investment banking, financial engineering, and risk management. \n\nMore abstractly, \"finance\" is concerned with the investment and deployment of assets and liabilities over \"space and time\": \ni.e. it is about performing valuation and asset allocation today, \nbased on risk and uncertainty of future outcomes, \nincorporating the time value of money (determining the present value of these future values, \"discounting\", requires a risk-appropriate discount rate).\nAs an academic field, finance theory is studied and developed within the disciplines of management, (financial) economics, accountancy and applied mathematics.\nCorrespondingly, given its wide application, there are several related professional qualifications, that can lead to the field.\nAs the debate to whether finance is an art or a science is still open, there have been recent efforts to organize a list of unsolved problems in finance.\n\nAn entity whose income exceeds its expenditure can lend or invest the excess income to help that excess income produce more income in the future. Though on the other hand, an entity whose income is less than its expenditure can raise capital by borrowing or selling equity claims, decreasing its expenses, or increasing its income. The lender can find a borrower—a financial intermediary such as a bank—or buy notes or bonds (corporate bonds, government bonds, or mutual bonds) in the bond market. The lender receives interest, the borrower pays a higher interest than the lender receives, and the financial intermediary earns the difference for arranging the loan.\n\nA bank aggregates the activities of many borrowers and lenders. A bank accepts deposits from lenders, on which it pays interest. The bank then lends these deposits to borrowers. Banks allow borrowers and lenders, of different sizes, to coordinate their activity.\n\nFinance is used by individuals (personal finance), by governments (public finance), by businesses (corporate finance) and by a wide variety of other organizations such as schools and non-profit organizations. In general, the goals of each of the above activities are achieved through the use of appropriate financial instruments and methodologies, with consideration to their institutional setting.\n\nFinance is one of the most important aspects of business management and includes analysis related to the use and acquisition of funds for the enterprise. In corporate finance, a company's capital structure is the total mix of financing methods it uses to raise funds. One method is \"debt financing\", which includes bank loans and bond sales. Another method is \"equity financing\" – the sale of stock by a company to investors, the original shareholders (they own a portion of the business) of a share. Ownership of a share gives the shareholder certain contractual rights and powers, which typically include the right to receive declared dividends and to vote the proxy on important matters (e.g., board elections). The owners of both bonds (either government bonds or corporate bonds) and stock (whether its preferred stock or common stock), may be \"institutional investors\" – financial institutions such as investment banks and pension funds  or private individuals, called \"private investors\" or \"retail investors\".\n\nPersonal finance is defined as the mindful planning of monetary spending and saving, while also considering the possibility of future risk. The following steps, as outlined by the Financial Planning Standards Board, suggest that an individual will understand a potentially secure personal finance plan after:\n\n\nPersonal finance may involve paying for education, financing durable goods such as real estate and cars, buying insurance, e.g. health and property insurance, investing and saving for retirement.\n\nPersonal finance may also involve paying for a loan, or debt obligations. \nThe six key areas of personal financial planning, as suggested by the Financial Planning Standards Board, are:\n\nCorporate finance deals with the sources of funding and the capital structure of corporations, the actions that managers take to increase the value of the firm to the shareholders, and the tools and analysis used to allocate financial resources. Although it is in principle different from managerial finance which studies the financial management of all firms, rather than corporations alone, the main concepts in the study of corporate finance are applicable to the financial problems of all kinds of firms. \n\nCorporate finance generally involves balancing risk and profitability, while attempting to maximize an entity's assets, net incoming cash flow and the value of its stock, and generically entails three primary areas of capital resource allocation. \nShort term financial management is often termed \"working capital management\", and relates to cash-, inventory- and debtors management.\n\nCorporate finance also includes within its scope business valuation, stock investing, or investment management. An investment is an acquisition of an asset in the hope that it will maintain or increase its value over time that will in hope give back a higher rate of return when it comes to disbursing dividends. In investment management in choosing a portfolio one has to use financial analysis to determine \"what\", \"how much\" and \"when\" to invest. To do this, a company must:\n\nFinancial management overlaps with the financial function of the accounting profession. However, financial accounting is the reporting of historical financial information, while financial management is concerned with the allocation of capital resources to increase a firm's value to the shareholders and increase their rate of return on the investments.\n\nFinancial risk management, an element of corporate finance, is the practice of creating and protecting economic value in a firm by using financial instruments to manage exposure to risk, particularly credit risk and market risk. (Other risk types include foreign exchange, shape, volatility, sector, liquidity, inflation risks, etc.) It focuses on when and how to hedge using financial instruments; in this sense it overlaps with financial engineering. Similar to general risk management, financial risk management requires identifying its sources, measuring it (see: Risk measure#Examples), and formulating plans to address these, and can be qualitative and quantitative. In the banking sector worldwide, the Basel Accords are generally adopted by internationally active banks for tracking, reporting and exposing operational, credit and market risks.\n\nCapital, in the financial sense, is the money that gives the business the power to buy goods to be used in the production of other goods or the offering of a service.\n(Capital has two types of sources, equity, and debt).\n\nThe deployment of capital is decided by the budget. This may include the objective of business, targets set, and results in financial terms, e.g., the target set for sale, resulting cost, growth, required investment to achieve the planned sales, and financing source for the investment.\n\nA budget may be long term or short term. Long term budgets have a time horizon of 5–10  years giving a vision to the company; short term is an annual budget which is drawn to control and operate in that particular year.\n\nBudgets will include proposed fixed asset requirements and how these expenditures will be financed. Capital budgets are often adjusted annually (done every year) and should be part of a longer-term Capital Improvements Plan.\n\nA cash budget is also required. \n\nPublic finance describes finance as related to sovereign states and sub-national entities (states/provinces, counties, municipalities, etc.) and related public entities (e.g. school districts) or agencies. It usually encompasses a long-term strategic perspective regarding investment decisions that affect public entities. These long-term strategic periods usually encompass five or more years. Public finance is primarily concerned with:\n\nCentral banks, such as the Federal Reserve System banks in the United States and Bank of England in the United Kingdom, are strong players in public finance, acting as lenders of last resort as well as strong influences on monetary and credit conditions in the economy.\n\nFinancial economics is the branch of economics studying the interrelation of financial variables, such as prices, interest rates and shares, as opposed to goods and services. Financial economics concentrates on influences of real economic variables on financial ones, in contrast to pure finance. It centres on managing risk in the context of the financial markets, and the resultant economic and financial models.\n\nIt essentially explores how rational investors would apply risk and return to the problem of an investment policy. Here, the twin assumptions of rationality and market efficiency lead to modern portfolio theory (the CAPM), and to the Black–Scholes theory for option valuation; it further studies phenomena and models where these assumptions do not hold, or are extended.\n\n\"Financial economics\", at least formally, also considers investment under \"certainty\" (Fisher separation theorem, \"theory of investment value\", Modigliani–Miller theorem) and hence also contributes to corporate finance theory.\n\nFinancial econometrics is the branch of financial economics that uses econometric techniques to parameterize the relationships suggested.\n\nAlthough they are closely related, the disciplines of economics and finance are distinct. The \"economy\" is a social institution that organizes a society's production, distribution, and consumption of goods and services, all of which must be financed.\n\nFinancial mathematics is a field of applied mathematics, concerned with financial markets. The subject has a close relationship with the discipline of financial economics, which is concerned with much of the underlying theory that is involved in financial mathematics. Generally, mathematical finance will derive, and extend, the mathematical or numerical models suggested by financial economics. In terms of practice, mathematical finance also overlaps heavily with the field of computational finance (also known as \"financial engineering\"). Arguably, these are largely synonymous, although the latter focuses on application, while the former focuses on modeling and derivation (\"see: Quantitative analyst\"). The field is largely focused on the modelling of derivatives, although other important subfields include insurance mathematics and quantitative portfolio problems. See Outline of finance: Mathematical tools; Outline of finance: Derivatives pricing.\n\nExperimental finance aims to establish different market settings and environments to observe experimentally and provide a lens through which science can analyze agents' behavior and the resulting characteristics of trading flows, information diffusion, and aggregation, price setting mechanisms, and returns processes. Researchers in experimental finance can study to what extent existing financial economics theory makes valid predictions and therefore prove them, and attempt to discover new principles on which such theory can be extended and be applied to future financial decisions. Research may proceed by conducting trading simulations or by establishing and studying the behavior, and the way that these people act or react, of people in artificial competitive market-like settings.\n\nBehavioral finance studies how the psychology of investors or managers affects financial decisions and markets when making a decision that can impact either negatively or positively on one of their areas. Behavioral finance has grown over the last few decades to become central and very important to finance.\n\nBehavioral finance includes such topics as:\n\nA strand of behavioral finance has been dubbed quantitative behavioral finance, which uses mathematical and statistical methodology to understand behavioral biases in conjunction with valuation. Some of these endeavors has been led by Gunduz Caginalp (Professor of Mathematics and Editor of Journal of Behavioral Finance during 2001–2004) and collaborators including Vernon Smith (2002 Nobel Laureate in Economics), David Porter, Don Balenovich, Vladimira Ilieva, Ahmet Duran). Studies by Jeff Madura, Ray Sturm, and others have demonstrated significant behavioral effects in stocks and exchange traded funds. Among other topics, quantitative behavioral finance studies behavioral effects together with the non-classical assumption of the finiteness of assets.\n\n"}
{"id": "14543", "url": "https://en.wikipedia.org/wiki?curid=14543", "title": "Industry", "text": "Industry\n\nAn industry is a sector that produces goods or related services within an economy. The major source of revenue of a group or company is an indicator of what industry it should be classified in. When a large corporate group has multiple sources of revenue generation, it is considered to be working in different industries. The manufacturing industry became a key sector of production and labour in European and North American countries during the Industrial Revolution, upsetting previous mercantile and feudal economies. This came through many successive rapid advances in technology, such as the development of steam power and the production of steel and coal.\n\nFollowing the Industrial Revolution, possibly a third of the economic output came from manufacturing industries. Many developed countries and many developing/semi-developed countries (China, India etc.) depend significantly on manufacturing Ugly\n\nSlavery, the practice of utilizing forced labor to produce goods and services, has occurred since antiquity throughout the world as a means of low-cost production. It typically produces goods for which profit depends on economies of scale, especially those for which labor was simple and easy to supervise. International law has declared slavery illegal.\n\nGuilds, associations of artisans and merchants, oversee the production and distribution of a particular good. Guilds have their roots in the Roman Empire as \"collegia\" (singular: \"collegium\") Membership in these early guilds was voluntary. The Roman \"collegia\" did not survive the fall of Rome. In the early middle ages, guilds once again began to emerge in Europe, reaching a degree of maturity by the beginning of the 14th century. While few guilds remain , some modern labor structures resemble those of traditional guilds. Other guilds, such as the SAG-AFTRA act as trade unions rather than as classical guilds. Professor Sheilagh Ogilvie claims that guilds negatively affected quality, skills, and innovation in areas that they were present.\n\nThe industrial revolution (from the mid-18th century to the mid-19th century) saw the development and popularization of mechanized means of production as a replacement for hand production. The industrial revolution played a role in the abolition of slavery in Europe and in North America.\n\nIn a process dubbed \"tertiarization\", the economic preponderance of primary and secondary industries has declined in recent centuries relative to the rising importance of tertiary industry,\nresulting in the post-industrial economy. Specialization in industry\nand in the classification of industry has also occurred. Thus (for example) a record producer might claim to speak on behalf of the Japanese rock industry, the recording industry, the music industry or the entertainment industry - and any formulation will sound grandiose and weighty.\n\nThe Industrial Revolution led to the development of factories for large-scale production with consequent changes in society. Originally the factories were steam-powered, but later transitioned to electricity once an electrical grid was developed. The mechanized assembly line was introduced to assemble parts in a repeatable fashion, with individual workers performing specific steps during the process. This led to significant increases in efficiency, lowering the cost of the end process. Later automation was increasingly used to replace human operators. This process has accelerated with the development of the computer and the robot.\n\nHistorically certain manufacturing industries have gone into a decline due to various economic factors, including the development of replacement technology or the loss of competitive advantage. An example of the former is the decline in carriage manufacturing when the automobile was mass-produced.\n\nA recent trend has been the migration of prosperous, industrialized nations towards a post-industrial society. This is manifested by an increase in the service sector at the expense of manufacturing, and the development of an information-based economy, the so-called informational revolution. In a post-industrial society, manufacturers relocate to more profitable locations through a process of off-shoring.\n\nMeasurements of manufacturing industries outputs and economic effect are not historically stable. Traditionally, success has been measured in the number of jobs created. The reduced number of employees in the manufacturing sector has been assumed to result from a decline in the competitiveness of the sector, or the introduction of the lean manufacturing process.\n\nRelated to this change is the upgrading of the quality of the product being manufactured. While it is possible to produce a low-technology product with low-skill labour, the ability to manufacture high-technology products well is dependent on a highly skilled staff.\n\nAn industrial society is a society driven by the use of technology to enable mass production, supporting a large population with a high capacity for division of labour. Today, industry is an important part of most societies and nations. A government must have some kind of industrial policy, regulating industrial placement, industrial pollution, financing and industrial labour.\n\nIn an industrial society, industry employs a major part of the population. This occurs typically in the manufacturing sector. A labour union is an organization of workers who have banded together to achieve common goals in key areas such as wages, hours, and other working conditions. The trade union, through its leadership, bargains with the employer on behalf of union members (rank and file members) and negotiates labour contracts with employers. This movement first rose among industrial workers.\n\nThe Industrial Revolution changed warfare, with mass-produced weaponry and supplies, machine-powered transportation, mobilization, the total war concept and weapons of mass destruction. Early instances of industrial warfare were the Crimean War and the American Civil War, but its full potential showed during the world wars. See also military-industrial complex, arms industries, military industry and modern warfare.\n\n\n\n"}
{"id": "627", "url": "https://en.wikipedia.org/wiki?curid=627", "title": "Agriculture", "text": "Agriculture\n\nAgriculture is the science and art of cultivating plants and livestock. Agriculture was the key development in the rise of sedentary human civilization, whereby farming of domesticated species created food surpluses that enabled people to live in cities. The history of agriculture began thousands of years ago. After gathering wild grains beginning at least 105,000 years ago, nascent farmers began to plant them around 11,500 years ago. Pigs, sheep and cattle were domesticated over 10,000 years ago. Plants were independently cultivated in at least 11 regions of the world. Industrial agriculture based on large-scale monoculture in the twentieth century came to dominate agricultural output, though about 2 billion people still depended on subsistence agriculture into the twenty-first.\n\nModern agronomy, plant breeding, agrochemicals such as pesticides and fertilizers, and technological developments have sharply increased yields, while causing widespread ecological and environmental damage. Selective breeding and modern practices in animal husbandry have similarly increased the output of meat, but have raised concerns about animal welfare and environmental damage. Environmental issues include contributions to global warming, depletion of aquifers, deforestation, antibiotic resistance, and growth hormones in industrial meat production. Genetically modified organisms are widely used, although some are banned in certain countries.\n\nThe major agricultural products can be broadly grouped into foods, fibers, fuels and raw materials (such as rubber). Food classes include cereals (grains), vegetables, fruits, oils, meat, milk, fungi and eggs. Over one-third of the world's workers are employed in agriculture, second only to the service sector, although the number of agricultural workers in developed countries has decreased significantly over the centuries.\n\nThe word \"agriculture\" is a late Middle English adaptation of Latin \"agricultūra\", from \"ager\", \"field\", which in its turn came from Greek αγρός, and \"cultūra\", \"cultivation\" or \"growing\". While agriculture usually refers to human activities, certain species of ant, termite and ambrosia beetle also cultivate crops. Agriculture is defined with varying scopes, in its broadest sense using natural resources to \"produce commodities which maintain life, including food, fiber, forest products, horticultural crops, and their related services\". Thus defined, it includes arable farming, horticulture, animal husbandry and forestry, but horticulture and forestry are in practice often excluded.\n\nThe development of agriculture enabled the human population to grow many times larger than could be sustained by hunting and gathering. Agriculture began independently in different parts of the globe, and included a diverse range of taxa, in at least 11 separate centres of origin. Wild grains were collected and eaten from at least 105,000 years ago. From around 11,500 years ago, the eight Neolithic founder crops, emmer and einkorn wheat, hulled barley, peas, lentils, bitter vetch, chick peas and flax were cultivated in the Levant. Rice was domesticated in China between 11,500 and 6,200 BC with the earliest known cultivation from 5,700 BC, followed by mung, soy and azuki beans. Sheep were domesticated in Mesopotamia between 13,000 and 11,000 years ago. Cattle were domesticated from the wild aurochs in the areas of modern Turkey and Pakistan some 10,500 years ago. Pig production emerged in Eurasia, including Europe, East Asia and Southwest Asia, where wild boar were first domesticated about 10,500 years ago. In the Andes of South America, the potato was domesticated between 10,000 and 7,000 years ago, along with beans, coca, llamas, alpacas, and guinea pigs. Sugarcane and some root vegetables were domesticated in New Guinea around 9,000 years ago. Sorghum was domesticated in the Sahel region of Africa by 7,000 years ago. Cotton was domesticated in Peru by 5,600 years ago, and was independently domesticated in Eurasia. In Mesoamerica, wild teosinte was bred into maize by 6,000 years ago.\nScholars have offered multiple hypotheses to explain the historical origins of agriculture. Studies of the transition from hunter-gatherer to agricultural societies indicate an initial period of intensification and increasing sedentism; examples are the Natufian culture in the Levant, and the Early Chinese Neolithic in China. Then, wild stands that had previously been harvested started to be planted, and gradually came to be domesticated.\n\nIn Eurasia, the Sumerians started to live in villages from about 8,000 BC, relying on the Tigris and Euphrates rivers and a canal system for irrigation. Ploughs appear in pictographs around 3,000 BC; seed-ploughs around 2,300 BC. Farmers grew wheat, barley, vegetables such as lentils and onions, and fruits including dates, grapes, and figs. Ancient Egyptian agriculture relied on the Nile River and its seasonal flooding. Farming started in the predynastic period at the end of the Paleolithic, after 10,000 BC. Staple food crops were grains such as wheat and barley, alongside industrial crops such as flax and papyrus. In India, wheat, barley and jujube were domesticated by 9,000 BC, soon followed by sheep and goats. Cattle, sheep and goats were domesticated in Mehrgarh culture by 8,000–6,000 BC. Cotton was cultivated by the 5th–4th millennium BC. Archeological evidence indicates an animal-drawn plough from 2,500 BC in the Indus Valley Civilisation.\nIn China, from the 5th century BC there was a nationwide granary system and widespread silk farming. Water-powered grain mills were in use by the 1st century BC, followed by irrigation. By the late 2nd century, heavy ploughs had been developed with iron ploughshares and mouldboards. These spread westwards across Eurasia. Asian rice was domesticated 8,200–13,500 years ago – depending on the molecular clock estimate that is used – on the Pearl River in southern China with a single genetic origin from the wild rice \"Oryza rufipogon\". In Greece and Rome, the major cereals were wheat, emmer, and barley, alongside vegetables including peas, beans, and olives. Sheep and goats were kept mainly for dairy products.\n\nIn the Americas, crops domesticated in Mesoamerica (apart from teosinte) include squash, beans, and cocoa. Cocoa was being domesticated by the Mayo Chinchipe of the upper Amazon around 3,000 BC.\nThe turkey was probably domesticated in Mexico or the American Southwest. The Aztecs developed irrigation systems, formed terraced hillsides, fertilized their soil, and developed chinampas or artificial islands. The Mayas used extensive canal and raised field systems to farm swampland from 400 BC. Coca was domesticated in the Andes, as were the peanut, tomato, tobacco, and pineapple. Cotton was domesticated in Peru by 3,600 BC. Animals including llamas, alpacas, and guinea pigs were domesticated there. In North America, the indigenous people of the East domesticated crops such as sunflower, tobacco, squash and \"Chenopodium\". Wild foods including wild rice and maple sugar were harvested. The domesticated strawberry is a hybrid of a Chilean and a North American species, developed by breeding in Europe and North America. The indigenous people of the Southwest and the Pacific Northwest practiced forest gardening and fire-stick farming. The natives controlled fire on a regional scale to create a low-intensity fire ecology that sustained a low-density agriculture in loose rotation; a sort of \"wild\" permaculture. A system of companion planting called the Three Sisters was developed on the Great Plains. The three crops were winter squash, maize, and climbing beans.\n\nIndigenous Australians, long supposed to have been nomadic hunter-gatherers, practised systematic burning to enhance natural productivity in fire-stick farming. The Gunditjmara and other groups developed eel farming and fish trapping systems from some 5,000 years ago. There is evidence of 'intensification' across the whole continent over that period. In two regions of Australia, the central west coast and eastern central, early farmers cultivated yams, native millet, and bush onions, possibly in permanent settlements.\n\nIn the Middle Ages, both in the Islamic world and in Europe, agriculture transformed with improved techniques and the diffusion of crop plants, including the introduction of sugar, rice, cotton and fruit trees (such as the orange) to Europe by way of Al-Andalus. After 1492 the Columbian exchange brought New World crops such as maize, potatoes, tomatoes, sweet potatoes and manioc to Europe, and Old World crops such as wheat, barley, rice and turnips, and livestock (including horses, cattle, sheep and goats) to the Americas.\nIrrigation, crop rotation, and fertilizers advanced from the 17th century with the British Agricultural Revolution, allowing global population to rise significantly. Since 1900 agriculture in developed nations, and to a lesser extent in the developing world, has seen large rises in productivity as mechanization replaces human labor, and assisted by synthetic fertilizers, pesticides, and selective breeding. The Haber-Bosch method allowed the synthesis of ammonium nitrate fertilizer on an industrial scale, greatly increasing crop yields and sustaining a further increase in global population. Modern agriculture has raised or encountered ecological, political, and economic issues including water pollution, biofuels, genetically modified organisms, tariffs and farm subsidies, leading to alternative approaches such as the organic movement.\n\nPastoralism involves managing domesticated animals. In nomadic pastoralism, herds of livestock are moved from place to place in search of pasture, fodder, and water. This type of farming is practised in arid and semi-arid regions of Sahara, Central Asia and some parts of India.\n\nIn shifting cultivation, a small area of forest is cleared by cutting and burning the trees. The cleared land is used for growing crops for a few years until the soil becomes too infertile, and the area is abandoned. Another patch of land is selected and the process is repeated. This type of farming is practiced mainly in areas with abundant rainfall where the forest regenerates quickly. This practice is used in Northeast India, Southeast Asia, and the Amazon Basin.\n\nSubsistence farming is practiced to satisfy family or local needs alone, with little left over for transport elsewhere. It is intensively practiced in Monsoon Asia and South-East Asia. An estimated 2.5 billion subsistence farmers worked in 2018, cultivating about 60% of the earth's arable land.\n\nIntensive farming is cultivation to maximise productivity, with a low fallow ratio and a high use of inputs (water, fertilizer, pesticide and automation). It is practiced mainly in developed countries.\n\nFrom the twentieth century, intensive agriculture increased productivity. It substituted synthetic fertilizers and pesticides for labor, but caused increased water pollution, and often involved farm subsidies. In recent years there has been a backlash against the environmental effects of conventional agriculture, resulting in the organic, regenerative, and sustainable agriculture movements. One of the major forces behind this movement has been the European Union, which first certified organic food in 1991 and began reform of its Common Agricultural Policy (CAP) in 2005 to phase out commodity-linked farm subsidies, also known as decoupling. The growth of organic farming has renewed research in alternative technologies such as integrated pest management, selective breeding, and controlled-environment agriculture. Recent mainstream technological developments include genetically modified food. Demand for non-food biofuel crops, development of former farm lands, rising transportation costs, climate change, growing consumer demand in China and India, and population growth, are threatening food security in many parts of the world. The International Fund for Agricultural Development posits that an increase in smallholder agriculture may be part of the solution to concerns about food prices and overall food security, given the favorable experience of Vietnam. Soil degradation and diseases such as stem rust are major concerns globally; approximately 40% of the world's agricultural land is seriously degraded. By 2015, the agricultural output of China was the largest in the world, followed by the European Union, India and the United States. Economists measure the total factor productivity of agriculture and by this measure agriculture in the United States is roughly 1.7 times more productive than it was in 1948.\n\nFollowing the three-sector theory, the number of people employed in agriculture and other primary activities (such as fishing) can be more than 80% in the least developed countries, and less than 2% in the most highly developed countries. Since the Industrial Revolution, many countries have made the transition to developed economies, and the proportion of people working in agriculture has steadily fallen. During the 16th century in Europe, for example, between 55 and 75% of the population was engaged in agriculture; by the 19th century, this had dropped to between 35 and 65%. In the same countries today, the figure is less than 10%.\nAt the start of the 21st century, some one billion people, or over 1/3 of the available work force, were employed in agriculture. It constitutes approximately 70% of the global employment of children, and in many countries employs the largest percentage of women of any industry. The service sector overtook the agricultural sector as the largest global employer in 2007.\n\nAgriculture, specifically farming, remains a hazardous industry, and farmers worldwide remain at high risk of work-related injuries, lung disease, noise-induced hearing loss, skin diseases, as well as certain cancers related to chemical use and prolonged sun exposure. On industrialized farms, injuries frequently involve the use of agricultural machinery, and a common cause of fatal agricultural injuries in developed countries is tractor rollovers. Pesticides and other chemicals used in farming can also be hazardous to worker health, and workers exposed to pesticides may experience illness or have children with birth defects. As an industry in which families commonly share in work and live on the farm itself, entire families can be at risk for injuries, illness, and death. Ages 0–6 may be an especially vulnerable population in agriculture; common causes of fatal injuries among young farm workers include drowning, machinery and motor accidents, including with all-terrain vehicles.\n\nThe International Labour Organization considers agriculture \"one of the most hazardous of all economic sectors\". It estimates that the annual work-related death toll among agricultural employees is at least 170,000, twice the average rate of other jobs. In addition, incidences of death, injury and illness related to agricultural activities often go unreported. The organization has developed the Safety and Health in Agriculture Convention, 2001, which covers the range of risks in the agriculture occupation, the prevention of these risks and the role that individuals and organizations engaged in agriculture should play.\n\nIn the United States, agriculture has been identified by the National Institute for Occupational Safety and Health as a priority industry sector in the National Occupational Research Agenda to identify and provide intervention strategies for occupational health and safety issues.\nIn the European Union, the European Agency for Safety and Health at Work has issued guidelines on implementing health and safety directives in agriculture, livestock farming, horticulture, and forestry. The Agricultural Safety and Health Council of America (ASHCA) also holds a yearly summit to discuss safety.\n\nOverall production varies by country as listed.\n\nCropping systems vary among farms depending on the available resources and constraints; geography and climate of the farm; government policy; economic, social and political pressures; and the philosophy and culture of the farmer.\n\nShifting cultivation (or slash and burn) is a system in which forests are burnt, releasing nutrients to support cultivation of annual and then perennial crops for a period of several years. Then the plot is left fallow to regrow forest, and the farmer moves to a new plot, returning after many more years (10–20). This fallow period is shortened if population density grows, requiring the input of nutrients (fertilizer or manure) and some manual pest control. Annual cultivation is the next phase of intensity in which there is no fallow period. This requires even greater nutrient and pest control inputs.\n\nFurther industrialization led to the use of monocultures, when one cultivar is planted on a large acreage. Because of the low biodiversity, nutrient use is uniform and pests tend to build up, necessitating the greater use of pesticides and fertilizers. Multiple cropping, in which several crops are grown sequentially in one year, and intercropping, when several crops are grown at the same time, are other kinds of annual cropping systems known as polycultures.\n\nIn subtropical and arid environments, the timing and extent of agriculture may be limited by rainfall, either not allowing multiple annual crops in a year, or requiring irrigation. In all of these environments perennial crops are grown (coffee, chocolate) and systems are practiced such as agroforestry. In temperate environments, where ecosystems were predominantly grassland or prairie, highly productive annual farming is the dominant agricultural system.\n\nImportant categories of food crops include cereals, legumes, forage, fruits and vegetables. Natural fibers include cotton, wool, hemp, silk and flax. Specific crops are cultivated in distinct growing regions throughout the world. Production is listed in millions of metric tons, based on FAO estimates.\n\nAnimal husbandry is the breeding and raising of animals for meat, milk, eggs, or wool, and for work and transport. Working animals, including horses, mules, oxen, water buffalo, camels, llamas, alpacas, donkeys, and dogs, have for centuries been used to help cultivate fields, harvest crops, wrangle other animals, and transport farm products to buyers.\n\nLivestock production systems can be defined based on feed source, as grassland-based, mixed, and landless. , 30% of Earth's ice- and water-free area was used for producing livestock, with the sector employing approximately 1.3 billion people. Between the 1960s and the 2000s, there was a significant increase in livestock production, both by numbers and by carcass weight, especially among beef, pigs and chickens, the latter of which had production increased by almost a factor of 10. Non-meat animals, such as milk cows and egg-producing chickens, also showed significant production increases. Global cattle, sheep and goat populations are expected to continue to increase sharply through 2050. Aquaculture or fish farming, the production of fish for human consumption in confined operations, is one of the fastest growing sectors of food production, growing at an average of 9% a year between 1975 and 2007.\n\nDuring the second half of the 20th century, producers using selective breeding focused on creating livestock breeds and crossbreeds that increased production, while mostly disregarding the need to preserve genetic diversity. This trend has led to a significant decrease in genetic diversity and resources among livestock breeds, leading to a corresponding decrease in disease resistance and local adaptations previously found among traditional breeds.\n\nGrassland based livestock production relies upon plant material such as shrubland, rangeland, and pastures for feeding ruminant animals. Outside nutrient inputs may be used, however manure is returned directly to the grassland as a major nutrient source. This system is particularly important in areas where crop production is not feasible because of climate or soil, representing 30–40 million pastoralists. Mixed production systems use grassland, fodder crops and grain feed crops as feed for ruminant and monogastric (one stomach; mainly chickens and pigs) livestock. Manure is typically recycled in mixed systems as a fertilizer for crops.\n\nLandless systems rely upon feed from outside the farm, representing the de-linking of crop and livestock production found more prevalently in Organisation for Economic Co-operation and Development member countries. Synthetic fertilizers are more heavily relied upon for crop production and manure utilization becomes a challenge as well as a source for pollution. Industrialized countries use these operations to produce much of the global supplies of poultry and pork. Scientists estimate that 75% of the growth in livestock production between 2003 and 2030 will be in confined animal feeding operations, sometimes called factory farming. Much of this growth is happening in developing countries in Asia, with much smaller amounts of growth in Africa. Some of the practices used in commercial livestock production, including the usage of growth hormones, are controversial.\n\nTillage is the practice of breaking up the soil with tools such as the plow or harrow to prepare for planting, for nutrient incorporation, or for pest control. Tillage varies in intensity from conventional to no-till. It may improve productivity by warming the soil, incorporating fertilizer and controlling weeds, but also renders soil more prone to erosion, triggers the decomposition of organic matter releasing CO, and reduces the abundance and diversity of soil organisms.\n\nPest control includes the management of weeds, insects, mites, and diseases. Chemical (pesticides), biological (biocontrol), mechanical (tillage), and cultural practices are used. Cultural practices include crop rotation, culling, cover crops, intercropping, composting, avoidance, and resistance. Integrated pest management attempts to use all of these methods to keep pest populations below the number which would cause economic loss, and recommends pesticides as a last resort.\n\nNutrient management includes both the source of nutrient inputs for crop and livestock production, and the method of utilization of manure produced by livestock. Nutrient inputs can be chemical inorganic fertilizers, manure, green manure, compost and minerals. Crop nutrient use may also be managed using cultural techniques such as crop rotation or a fallow period. Manure is used either by holding livestock where the feed crop is growing, such as in managed intensive rotational grazing, or by spreading either dry or liquid formulations of manure on cropland or pastures.\n\nWater management is needed where rainfall is insufficient or variable, which occurs to some degree in most regions of the world. Some farmers use irrigation to supplement rainfall. In other areas such as the Great Plains in the U.S. and Canada, farmers use a fallow year to conserve soil moisture to use for growing a crop in the following year. Agriculture represents 70% of freshwater use worldwide.\n\nAccording to a report by the International Food Policy Research Institute, agricultural technologies will have the greatest impact on food production if adopted in combination with each other; using a model that assessed how eleven technologies could impact agricultural productivity, food security and trade by 2050, the International Food Policy Research Institute found that the number of people at risk from hunger could be reduced by as much as 40% and food prices could be reduced by almost half.\n\nPayment for ecosystem services is a method of providing additional incentives to encourage farmers to conserve some aspects of the environment. Measures might include paying for reforestation upstream of a city, to improve the supply of fresh water.\n\nCrop alteration has been practiced by humankind for thousands of years, since the beginning of civilization. Altering crops through breeding practices changes the genetic make-up of a plant to develop crops with more beneficial characteristics for humans, for example, larger fruits or seeds, drought-tolerance, or resistance to pests. Significant advances in plant breeding ensued after the work of geneticist Gregor Mendel. His work on dominant and recessive alleles, although initially largely ignored for almost 50 years, gave plant breeders a better understanding of genetics and breeding techniques. Crop breeding includes techniques such as plant selection with desirable traits, self-pollination and cross-pollination, and molecular techniques that genetically modify the organism.\n\nDomestication of plants has, over the centuries increased yield, improved disease resistance and drought tolerance, eased harvest and improved the taste and nutritional value of crop plants. Careful selection and breeding have had enormous effects on the characteristics of crop plants. Plant selection and breeding in the 1920s and 1930s improved pasture (grasses and clover) in New Zealand. Extensive X-ray and ultraviolet induced mutagenesis efforts (i.e. primitive genetic engineering) during the 1950s produced the modern commercial varieties of grains such as wheat, corn (maize) and barley.\n\nThe Green Revolution popularized the use of conventional hybridization to sharply increase yield by creating \"high-yielding varieties\". For example, average yields of corn (maize) in the US have increased from around 2.5 tons per hectare (t/ha) (40 bushels per acre) in 1900 to about 9.4 t/ha (150 bushels per acre) in 2001. Similarly, worldwide average wheat yields have increased from less than 1 t/ha in 1900 to more than 2.5 t/ha in 1990. South American average wheat yields are around 2 t/ha, African under 1 t/ha, and Egypt and Arabia up to 3.5 to 4 t/ha with irrigation. In contrast, the average wheat yield in countries such as France is over 8 t/ha. Variations in yields are due mainly to variation in climate, genetics, and the level of intensive farming techniques (use of fertilizers, chemical pest control, growth control to avoid lodging).\n\nGenetically modified organisms (GMO) are organisms whose genetic material has been altered by genetic engineering techniques generally known as recombinant DNA technology. Genetic engineering has expanded the genes available to breeders to utilize in creating desired germlines for new crops. Increased durability, nutritional content, insect and virus resistance and herbicide tolerance are a few of the attributes bred into crops through genetic engineering. For some, GMO crops cause food safety and food labeling concerns. Numerous countries have placed restrictions on the production, import or use of GMO foods and crops. Currently a global treaty, the Biosafety Protocol, regulates the trade of GMOs. There is ongoing discussion regarding the labeling of foods made from GMOs, and while the EU currently requires all GMO foods to be labeled, the US does not.\n\nHerbicide-resistant seed has a gene implanted into its genome that allows the plants to tolerate exposure to herbicides, including glyphosate. These seeds allow the farmer to grow a crop that can be sprayed with herbicides to control weeds without harming the resistant crop. Herbicide-tolerant crops are used by farmers worldwide. With the increasing use of herbicide-tolerant crops, comes an increase in the use of glyphosate-based herbicide sprays. In some areas glyphosate resistant weeds have developed, causing farmers to switch to other herbicides. Some studies also link widespread glyphosate usage to iron deficiencies in some crops, which is both a crop production and a nutritional quality concern, with potential economic and health implications.\n\nOther GMO crops used by growers include insect-resistant crops, which have a gene from the soil bacterium \"Bacillus thuringiensis\" (Bt), which produces a toxin specific to insects. These crops resist damage by insects. Some believe that similar or better pest-resistance traits can be acquired through traditional breeding practices, and resistance to various pests can be gained through hybridization or cross-pollination with wild species. In some cases, wild species are the primary source of resistance traits; some tomato cultivars that have gained resistance to at least 19 diseases did so through crossing with wild populations of tomatoes.\n\nAgriculture imposes multiple external costs upon society through effects such as pesticide damage to nature (especially herbicides and insecticides), nutrient runoff, excessive water usage, and loss of natural environment. A 2000 assessment of agriculture in the UK determined total external costs for 1996 of £2,343 million, or £208 per hectare. A 2005 analysis of these costs in the US concluded that cropland imposes approximately $5 to $16 billion ($30 to $96 per hectare), while livestock production imposes $714 million. Both studies, which focused solely on the fiscal impacts, concluded that more should be done to internalize external costs. Neither included subsidies in their analysis, but they noted that subsidies also influence the cost of agriculture to society.\n\nAgriculture seeks to increase yield and to reduce costs. Yield increases with inputs such as fertilisers and removal of pathogens, predators, and competitors (such as weeds). Costs decrease with increasing scale of farm units, such as making fields larger; this means removing hedges, ditches and other areas of habitat. Pesticides kill insects, plants and fungi. These and other measures have cut biodiversity to very low levels on intensively farmed land.\n\nIn 2010, the International Resource Panel of the United Nations Environment Programme assessed the environmental impacts of consumption and production. It found that agriculture and food consumption are two of the most important drivers of environmental pressures, particularly habitat change, climate change, water use and toxic emissions. Agriculture is the main source of toxins released into the environment, including insecticides, especially those used on cotton. The 2011 UNEP Green Economy report states that \"[a]agricultural operations, excluding land use changes, produce approximately 13 per cent of anthropogenic global GHG emissions. This includes GHGs emitted by the use of inorganic fertilizers agro-chemical pesticides and herbicides; (GHG emissions resulting from production of these inputs are included in industrial emissions); and fossil fuel-energy inputs. \"On average we find that the total amount of fresh residues from agricultural and forestry production for second- generation biofuel production amounts to 3.8 billion tonnes per year between 2011 and 2050 (with an average annual growth rate of 11 per cent throughout the period analysed, accounting for higher growth during early years, 48 per cent for 2011–2020 and an average 2 per cent annual expansion after 2020).\"\n\nA senior UN official, Henning Steinfeld, said that \"Livestock are one of the most significant contributors to today's most serious environmental problems\". Livestock production occupies 70% of all land used for agriculture, or 30% of the land surface of the planet. It is one of the largest sources of greenhouse gases, responsible for 18% of the world's greenhouse gas emissions as measured in CO equivalents. By comparison, all transportation emits 13.5% of the CO. It produces 65% of human-related nitrous oxide (which has 296 times the global warming potential of CO) and 37% of all human-induced methane (which is 23 times as warming as CO.) It also generates 64% of the ammonia emission. Livestock expansion is cited as a key factor driving deforestation; in the Amazon basin 70% of previously forested area is now occupied by pastures and the remainder used for feedcrops. Through deforestation and land degradation, livestock is also driving reductions in biodiversity. Furthermore, the UNEP states that \"methane emissions from global livestock are projected to increase by 60 per cent by 2030 under current practices and consumption patterns.\"\n\nLand transformation, the use of land to yield goods and services, is the most substantial way humans alter the Earth's ecosystems, and is considered the driving force in the loss of biodiversity. Estimates of the amount of land transformed by humans vary from 39 to 50%. Land degradation, the long-term decline in ecosystem function and productivity, is estimated to be occurring on 24% of land worldwide, with cropland overrepresented. The UN-FAO report cites land management as the driving factor behind degradation and reports that 1.5 billion people rely upon the degrading land. Degradation can be deforestation, desertification, soil erosion, mineral depletion, or chemical degradation (acidification and salinization).\n\nEutrophication, excessive nutrients in aquatic ecosystems resulting in algal bloom and anoxia, leads to fish kills, loss of biodiversity, and renders water unfit for drinking and other industrial uses. Excessive fertilization and manure application to cropland, as well as high livestock stocking densities cause nutrient (mainly nitrogen and phosphorus) runoff and leaching from agricultural land. These nutrients are major nonpoint pollutants contributing to eutrophication of aquatic ecosystems and pollution of groundwater, with harmful effects on human populations. Fertilisers also reduce terrestrial biodiversity by increasing competition for light, favouring those species that are able to benefit from the added nutrients.\nAgriculture accounts for 70 percent of withdrawals of freshwater resources. Agriculture is a major draw on water from aquifers, and currently draws from those underground water sources at an unsustainable rate. It is long known that aquifers in areas as diverse as northern China, the Upper Ganges and the western US are being depleted, and new research extends these problems to aquifers in Iran, Mexico and Saudi Arabia. Increasing pressure is being placed on water resources by industry and urban areas, meaning that water scarcity is increasing and agriculture is facing the challenge of producing more food for the world's growing population with reduced water resources. Agricultural water usage can also cause major environmental problems, including the destruction of natural wetlands, the spread of water-borne diseases, and land degradation through salinization and waterlogging, when irrigation is performed incorrectly.\n\nPesticide use has increased since 1950 to 2.5million short tons annually worldwide, yet crop loss from pests has remained relatively constant. The World Health Organization estimated in 1992 that three million pesticide poisonings occur annually, causing 220,000 deaths. Pesticides select for pesticide resistance in the pest population, leading to a condition termed the \"pesticide treadmill\" in which pest resistance warrants the development of a new pesticide.\n\nAn alternative argument is that the way to \"save the environment\" and prevent famine is by using pesticides and intensive high yield farming, a view exemplified by a quote heading the Center for Global Food Issues website: 'Growing more per acre leaves more land for nature'. However, critics argue that a trade-off between the environment and a need for food is not inevitable, and that pesticides simply replace good agronomic practices such as crop rotation. The Push–pull agricultural pest management technique involves intercropping, using plant aromas to repel pests from crops (push) and to lure them to a place from which they can then be removed (pull).\n\nGlobal warming and agriculture are interrelated on a global scale. Global warming affects agriculture through changes in average temperatures, rainfall, and weather extremes (like storms and heat waves); changes in pests and diseases; changes in atmospheric carbon dioxide and ground-level ozone concentrations; changes in the nutritional quality of some foods; and changes in sea level. Global warming is already affecting agriculture, with effects unevenly distributed across the world. Future climate change will probably negatively affect crop production in low latitude countries, while effects in northern latitudes may be positive or negative. Global warming will probably increase the risk of food insecurity for some vulnerable groups, such as the poor.\n\nAnimal husbandry is also responsible for greenhouse gas production of and a percentage of the world's methane, and future land infertility, and the displacement of wildlife. Agriculture contributes to climate change by anthropogenic emissions of greenhouse gases, and by the conversion of non-agricultural land such as forest for agricultural use. Agriculture, forestry and land-use change contributed around 20 to 25% to global annual emissions in 2010. A range of policies can reduce the risk of negative climate change impacts on agriculture, and greenhouse gas emissions from the agriculture sector.\n\nCurrent farming methods have resulted in over-stretched water resources, high levels of erosion and reduced soil fertility. There is not enough water to continue farming using current practices; therefore how critical water, land, and ecosystem resources are used to boost crop yields must be reconsidered. A solution would be to give value to ecosystems, recognizing environmental and livelihood tradeoffs, and balancing the rights of a variety of users and interests. Inequities that result when such measures are adopted would need to be addressed, such as the reallocation of water from poor to rich, the clearing of land to make way for more productive farmland, or the preservation of a wetland system that limits fishing rights.\n\nTechnological advancements help provide farmers with tools and resources to make farming more sustainable. Technology permits innovations like conservation tillage, a farming process which helps prevent land loss to erosion, reduces water pollution, and enhances carbon sequestration.\n\nAccording to a report by the International Food Policy Research Institute (IFPRI), agricultural technologies will have the greatest impact on food production if adopted in combination with each other; using a model that assessed how eleven technologies could impact agricultural productivity, food security and trade by 2050, IFPRI found that the number of people at risk from hunger could be reduced by as much as 40% and food prices could be reduced by almost half. The caloric demand of Earth's projected population, with current climate change predictions, can be satisfied by additional improvement of agricultural methods, expansion of agricultural areas, and a sustainability-oriented consumer mindset.\n\nSince the 1940s, agricultural productivity has increased dramatically, due largely to the increased use of energy-intensive mechanization, fertilizers and pesticides. The vast majority of this energy input comes from fossil fuel sources. Between the 1960s and the 1980s, the Green Revolution transformed agriculture around the globe, with world grain production increasing significantly (between 70% and 390% for wheat and 60% to 150% for rice, depending on geographic area) as world population doubled. Heavy reliance on petrochemicals has raised concerns that oil shortages could increase costs and reduce agricultural output.\n\nIndustrialized agriculture depends on fossil fuels in two fundamental ways: direct consumption on the farm and manufacture of inputs used on the farm. Direct consumption includes the use of lubricants and fuels to operate farm vehicles and machinery.\n\nIndirect consumption includes the manufacture of fertilizers, pesticides, and farm machinery. In particular, the production of nitrogen fertilizer can account for over half of agricultural energy usage. Together, direct and indirect consumption by US farms accounts for about 2% of the nation's energy use. Direct and indirect energy consumption by U.S. farms peaked in 1979, and has since gradually declined. Food systems encompass not just agriculture but off-farm processing, packaging, transporting, marketing, consumption, and disposal of food and food-related items. Agriculture accounts for less than one-fifth of food system energy use in the US.\n\nAgricultural economics is economics as it relates to the \"production, distribution and consumption of [agricultural] goods and services\". Combining agricultural production with general theories of marketing and business as a discipline of study began in the late 1800s, and grew significantly through the 20th century. Although the study of agricultural economics is relatively recent, major trends in agriculture have significantly affected national and international economies throughout history, ranging from tenant farmers and sharecropping in the post-American Civil War Southern United States to the European feudal system of manorialism. In the United States, and elsewhere, food costs attributed to food processing, distribution, and agricultural marketing, sometimes referred to as the value chain, have risen while the costs attributed to farming have declined. This is related to the greater efficiency of farming, combined with the increased level of value addition (e.g. more highly processed products) provided by the supply chain. Market concentration has increased in the sector as well, and although the total effect of the increased market concentration is likely increased efficiency, the changes redistribute economic surplus from producers (farmers) and consumers, and may have negative implications for rural communities.\n\nNational government policies can significantly change the economic marketplace for agricultural products, in the form of taxation, subsidies, tariffs and other measures. Since at least the 1960s, a combination of trade restrictions, exchange rate policies and subsidies have affected farmers in both the developing and the developed world. In the 1980s, non-subsidized farmers in developing countries experienced adverse effects from national policies that created artificially low global prices for farm products. Between the mid-1980s and the early 2000s, several international agreements limited agricultural tariffs, subsidies and other trade restrictions.\n\nHowever, , there was still a significant amount of policy-driven distortion in global agricultural product prices. The three agricultural products with the greatest amount of trade distortion were sugar, milk and rice, mainly due to taxation. Among the oilseeds, sesame had the greatest amount of taxation, but overall, feed grains and oilseeds had much lower levels of taxation than livestock products. Since the 1980s, policy-driven distortions have seen a greater decrease among livestock products than crops during the worldwide reforms in agricultural policy. Despite this progress, certain crops, such as cotton, still see subsidies in developed countries artificially deflating global prices, causing hardship in developing countries with non-subsidized farmers. Unprocessed commodities such as corn, soybeans, and cattle are generally graded to indicate quality, affecting the price the producer receives. Commodities are generally reported by production quantities, such as volume, number or weight.\n\nAgricultural science is a broad multidisciplinary field of biology that encompasses the parts of exact, natural, economic and social sciences used in the practice and understanding of agriculture. It covers topics such as agronomy, plant breeding and genetics, plant pathology, crop modelling, soil science, entomology, production techniques and improvement, study of pests and their management, and study of adverse environmental effects such as soil degradation, waste management, and bioremediation.\n\nThe scientific study of agriculture began in the 18th century, when Johann Friedrich Mayer conducted experiments on the use of gypsum (hydrated calcium sulphate) as a fertilizer. Research became more systematic when in 1843, John Lawes and Henry Gilbert began a set of long-term agronomy field experiments at Rothamsted Research Station in England; some of them, such as the Park Grass Experiment, are still running. In America, the Hatch Act of 1887 provided funding for what it was the first to call \"agricultural science\", driven by farmers' interest in fertilizers. In agricultural entomology, the USDA began to research biological control in 1881; it instituted its first large program in 1905, searching Europe and Japan for natural enemies of the gypsy moth and brown-tail moth, establishing parasitoids (such as solitary wasps) and predators of both pests in the USA.\n\nAgricultural policy is the set of government decisions and actions relating to domestic agriculture and imports of foreign agricultural products. Governments usually implement agricultural policies with the goal of achieving a specific outcome in the domestic agricultural product markets. Some overarching themes include risk management and adjustment (including policies related to climate change, food safety and natural disasters), economic stability (including policies related to taxes), natural resources and environmental sustainability (especially water policy), research and development, and market access for domestic commodities (including relations with global organizations and agreements with other countries). Agricultural policy can also touch on food quality, ensuring that the food supply is of a consistent and known quality, food security, ensuring that the food supply meets the population's needs, and conservation. Policy programs can range from financial programs, such as subsidies, to encouraging producers to enroll in voluntary quality assurance programs.\n\nThere are many influences on the creation of agricultural policy, including consumers, agribusiness, trade lobbies and other groups. Agribusiness interests hold a large amount of influence over policy making, in the form of lobbying and campaign contributions. Political action groups, including those interested in environmental issues and labor unions, also provide influence, as do lobbying organizations representing individual agricultural commodities. The Food and Agriculture Organization of the United Nations (FAO) leads international efforts to defeat hunger and provides a forum for the negotiation of global agricultural regulations and agreements. Dr. Samuel Jutzi, director of FAO's animal production and health division, states that lobbying by large corporations has stopped reforms that would improve human health and the environment. For example, proposals in 2010 for a voluntary code of conduct for the livestock industry that would have provided incentives for improving standards for health, and environmental regulations, such as the number of animals an area of land can support without long-term damage, were successfully defeated due to large food company pressure.\n\n\n"}
{"id": "239038", "url": "https://en.wikipedia.org/wiki?curid=239038", "title": "Construction", "text": "Construction\n\nConstruction is the process of constructing a building or infrastructure. Construction differs from manufacturing in that manufacturing typically involves mass production of similar items without a designated purchaser, while construction typically takes place on location for a known client. Construction as an industry comprises six to nine percent of the gross domestic product of developed countries. Construction starts with planning, design, and financing; it continues until the project is built and ready for use.\n\nLarge-scale construction requires collaboration across multiple disciplines. A project manager normally manages the budget on the job, and a construction manager, design engineer, construction engineer or architect supervises it. Those involved with the design and execution must consider zoning requirements, environmental impact of the job, scheduling, budgeting, construction-site safety, availability and transportation of building materials, logistics, inconvenience to the public caused by construction delays and bidding. Large construction projects are sometimes referred to as megaprojects.\n\n\"Construction\" is a general term meaning the art and science to form objects, systems, or organizations, and comes from Latin \"constructio\" (from \"com-\" \"together\" and \"struere\" \"to pile up\") and Old French \"construction\". To construct is the verb: the act of building, and the noun construction: how a building was built, the nature of its structure.\n\nIn general, there are three sectors of construction: buildings, infrastructure and industrial. Building construction is usually further divided into residential and non-residential (commercial/institutional). Infrastructure is often called heavy civil or heavy engineering that includes large public works, dams, bridges, highways, railways, water or wastewater and utility distribution. Industrial construction includes refineries, process chemical, power generation, mills and manufacturing plants. There are also other ways to break the industry into sectors or markets.\n\n\"Engineering News-Record\" (\"ENR\"), a trade magazine for the construction industry, each year compiles and reports data about the size of design and construction companies. In 2014, ENR compiled the data in nine market segments divided as transportation, petroleum, buildings, power, industrial, water, manufacturing, sewer/waste, telecom, hazardous waste and a tenth category for other projects. In their reporting, they used data on transportation, sewer, hazardous waste and water to rank firms as heavy contractors.\n\nThe Standard Industrial Classification and the newer North American Industry Classification System have a classification system for companies that perform or engage in construction. To recognize the differences of companies in this sector, it is divided into three subsectors: building construction, heavy and civil engineering construction, and specialty trade contractors. There are also categories for construction service firms (e.g., engineering, architecture) and construction managers (firms engaged in managing construction projects without assuming direct financial responsibility for completion of the construction project).\n\nBuilding construction is the process of adding structure to real property or construction of buildings. The majority of building construction jobs are small renovations, such as addition of a room, or renovation of a bathroom. Often, the owner of the property acts as laborer, paymaster, and design team for the entire project. Although building construction projects consist of common elements such as design, financial, estimating and legal considerations, projects of varying sizes may reach undesirable end results, such as structural collapse, cost overruns, and/or litigation. For this reason, those with experience in the field make detailed plans and maintain careful oversight during the project to ensure a positive outcome.\nCommercial building construction is procured privately or publicly utilizing various delivery methodologies, including cost estimating, hard bid, negotiated price, traditional, management contracting, construction management-at-risk, design & build and design-build bridging.\n\nResidential construction practices, technologies, and resources must conform to local building authority regulations and codes of practice. Materials readily available in the area generally dictate the construction materials used (e.g. brick versus stone, versus timber). Cost of construction on a per square meter (or per square foot) basis for houses can vary dramatically based on site conditions, local regulations, economies of scale (custom designed homes are often more expensive to build) and the availability of skilled tradesmen. Residential construction as well as other types of construction can generate waste such that planning is required.\n\nAccording to McKinsey research, productivity growth per worker in construction has lagged behind many other industries across different countries including in the United States and in European countries. In the United States, construction productivity per worker has declined by half since the 1960s.\n\nThe most popular method of residential construction in North America is wood-framed construction. Typical construction steps for a single-family or small multi-family house are:\n\nIn the industrialized world, construction usually involves the translation of designs into reality. A formal design team may be assembled to plan the physical proceedings, and to integrate those proceedings with the other parts. The design usually consists of drawings and specifications, usually prepared by a design team including architect, civil engineers, mechanical engineers, electrical engineers, structural engineers, fire protection engineers, planning consultants, architectural consultants, and archaeological consultants. The design team is most commonly employed by (i.e. in contract with) the property owner. Under this system, once the design is completed by the design team, a number of construction companies or construction management companies may then be asked to make a bid for the work, either based directly on the design, or on the basis of drawings and a bill of quantities provided by a quantity surveyor. Following evaluation of bids, the owner typically awards a contract to the most cost efficient bidder.\n\nThe best modern trend in design is toward integration of previously separated specialties, especially among large firms. In the past, architects, interior designers, engineers, developers, construction managers, and general contractors were more likely to be entirely separate companies, even in the larger firms. Presently, a firm that is nominally an \"architecture\" or \"construction management\" firm may have experts from all related fields as employees, or to have an associated company that provides each necessary skill. Thus, each such firm may offer itself as \"one-stop shopping\" for a construction project, from beginning to end. This is designated as a \"design build\" contract where the contractor is given a performance specification and must undertake the project from design to construction, while adhering to the performance specifications.\n\nSeveral project structures can assist the owner in this integration, including design-build, partnering and construction management. In general, each of these project structures allows the owner to integrate the services of architects, interior designers, engineers and constructors throughout design and construction. In response, many companies are growing beyond traditional offerings of design or construction services alone and are placing more emphasis on establishing relationships with other necessary participants through the design-build process.\n\nThe increasing complexity of construction projects creates the need for design professionals trained in all phases of the project's life-cycle and develop an appreciation of the building as an advanced technological system requiring close integration of many sub-systems and their individual components, including sustainability. Building engineering is an emerging discipline that attempts to meet this new challenge.\n\nConstruction projects can suffer from preventable financial problems. Underbids happen when builders ask for too little money to complete the project. Cash flow problems exist when the present amount of funding cannot cover the current costs for labour and materials, and because they are a matter of having sufficient funds at a specific time, can arise even when the overall total is enough. Fraud is a problem in many fields, but is notoriously prevalent in the construction field. Financial planning for the project is intended to ensure that a solid plan with adequate safeguards and contingency plans are in place before the project is started and is required to ensure that the plan is properly executed over the life of the project.\n\nMortgage bankers, accountants, and cost engineers are likely participants in creating an overall plan for the financial management of the building construction project. The presence of the mortgage banker is highly likely, even in relatively small projects since the owner's equity in the property is the most obvious source of funding for a building project. Accountants act to study the expected monetary flow over the life of the project and to monitor the payouts throughout the process. Cost engineers and estimators apply expertise to relate the work and materials involved to a proper valuation. Cost overruns with government projects have occurred when the contractor identified change orders or project changes that increased costs, which are not subject to competition from other firms as they have already been eliminated from consideration after the initial bid.\n\nLarge projects can involve highly complex financial plans and often start with a conceptual estimate performed by a building estimator. As portions of a project are completed, they may be sold, supplanting one lender or owner for another, while the logistical requirements of having the right trades and materials available for each stage of the building construction project carries forward. In many English-speaking countries, but not the United States, projects typically use quantity surveyors.\n\nA construction project must fit into the legal framework governing the property. These include governmental regulations on the use of property, and obligations that are created in the process of construction.\n\nWhen applicable, the project must adhere to zoning and building code requirements. Constructing a project that fails to adhere to codes does not benefit the owner. Some legal requirements come from malum in se considerations, or the desire to prevent indisputably bad phenomena, e.g. explosions or bridge collapses. Other legal requirements come from malum prohibitum considerations, or factors that are a matter of custom or expectation, such as isolating businesses from a business district or residences from a residential district. An attorney may seek changes or exemptions in the law that governs the land where the building will be built, either by arguing that a rule is inapplicable (the bridge design will not cause a collapse), or that the custom is no longer needed (acceptance of live-work spaces has grown in the community).\n\nA construction project is a complex net of contracts and other legal obligations, each of which all parties must carefully consider. A contract is the exchange of a set of obligations between two or more parties, but it is not so simple a matter as trying to get the other side to agree to as much as possible in exchange for as little as possible. The time element in construction means that a delay costs money, and in cases of bottlenecks, the delay can be extremely expensive. Thus, the contracts must be designed to ensure that each side is capable of performing the obligations set out. Contracts that set out clear expectations and clear paths to accomplishing those expectations are far more likely to result in the project flowing smoothly, whereas poorly drafted contracts lead to confusion and collapse.\n\nLegal advisors in the beginning of a construction project seek to identify ambiguities and other potential sources of trouble in the contract structure, and to present options for preventing problems. Throughout the process of the project, they work to avoid and resolve conflicts that arise. In each case, the lawyer facilitates an exchange of obligations that matches the reality of the project.\n\nDesign, finance, and legal aspects overlap and interrelate. The design must be not only structurally sound and appropriate for the use and location, but must also be financially possible to build, and legal to use. The financial structure must accommodate the need for building the design provided, and must pay amounts that are legally owed. The legal structure must integrate the design into the surrounding legal framework, and enforce the financial consequences of the construction process.\n\nProcurement describes the merging of activities undertaken by the client to obtain a building. There are many different methods of construction procurement; however, the three most common types of procurement are traditional (design–bid–build), design-build and management contracting.\n\nThere is also a growing number of new forms of procurement that involve relationship contracting where the emphasis is on a co-operative relationship among the principal, the contractor, and other stakeholders within a construction project. New forms include partnering such as Public-Private Partnering (PPPs) aka private finance initiatives (PFIs) and alliances such as \"pure\" or \"project\" alliances and \"impure\" or \"strategic\" alliances. The focus on co-operation is to ameliorate the many problems that arise from the often highly competitive and adversarial practices within the construction industry.\n\nThis is the most common method of construction procurement, and it is well-established and recognized. In this arrangement, the architect or engineer acts as the project coordinator. His or her role is to design the works, prepare the specifications and produce construction drawings, administer the contract, tender the works, and manage the works from inception to completion. There are direct contractual links between the architect's client and the main contractor. Any subcontractor has a direct contractual relationship with the main contractor. The procedure continues until the building is ready to occupy.\n\nThis approach has become more common in recent years, and also involves the client contracting a single entity that both provides a design and builds it. In some cases, the design-build package can also include finding the site, arranging funding and applying for all necessary statutory consents.\n\nThe owner produces a list of requirements for a project, giving an overall view of the project's goals. Several D&B contractors present different ideas about how to accomplish these goals. The owner selects the ideas they like best and hires the appropriate contractor. Often, it is not just one contractor, but a consortium of several contractors working together. Once these have been hired, they begin building the first phase of the project. As they build phase 1, they design phase 2. This is in contrast to a design-bid-build contract, where the project is completely designed by the owner, then bid on, then completed.\n\nKent Hansen pointed out that state departments of transportation usually use design build contracts as a way of progressing projects when states lack the skills-resources. In such departments, design build contracts are usually employed for very large projects.\n\nIn this arrangement the client plays an active role in the procurement system by entering into separate contracts with the designer (architect or engineer), the construction manager, and individual trade contractors. The client takes on the contractual role, while the construction or project manager provides the active role of managing the separate trade contracts, and ensuring that they complete all work smoothly and effectively together.\n\nManagement procurement systems are often used to speed up the procurement processes, allow the client greater flexibility in design variation throughout the contract, give the ability to appoint individual work contractors, separate contractual responsibility on each individual throughout the contract, and to provide greater client control.\n\nIn recent time, construction software starts to get traction—as it digitizes construction industry. Among solutions, there are for example: Procore, GenieBelt, PlanGrid, bouw7, etc.\n\nSustainability during the construction phase is one of the aspects of “green building,\" defined by the United States Environmental Protection Agency (EPA) as \"the practice of creating structures and using processes that are environmentally responsible and resource-efficient throughout a building's life-cycle from siting to design, construction, operation, maintenance, renovation and deconstruction.\"\n\nIn construction, the authority having jurisdiction (AHJ) is the governmental agency or sub-agency that regulates the construction process. In most cases, this is the municipality where the building is located. However, construction performed for supra-municipal authorities are usually regulated directly by the owning authority, which becomes the AHJ.\n\nBefore the foundation can be dug, contractors are typically required to verify and have existing utility lines marked, either by the utilities themselves or through a company specializing in such services. This lessens the likelihood of damage to the existing electrical, water, sewage, phone, and cable facilities, which could cause outages and potentially hazardous situations. During the construction of a building, the municipal building inspector inspects the building periodically to ensure that the construction adheres to the approved plans and the local building code. Once construction is complete and a final inspection has been passed, an occupancy permit may be issued.\n\nAn operating building must remain in compliance with the fire code. The fire code is enforced by the local fire department or a municipal code enforcement office.\n\nChanges made to a building that affect safety, including its use, expansion, structural integrity, and fire protection items, usually require approval of the AHJ for review concerning the building code.\n\nIn the United States, the industry in 2014 has around $960 billion in annual revenue according to statistics tracked by the Census Bureau, of which $680 billion is private (split evenly between residential and nonresidential) and the remainder is government. In 2005, there were about 667,000 firms employing 1 million contractors (200,000 general contractors, 38,000 heavy, and 432,000 specialty); the average contractor employed fewer than 10 employees. As a whole, the industry employed an estimated 5.8 million in April 2013, with a 13.2% unemployment rate. In the United States, approximately 828,000 women were employed in the construction industry as of 2011.\n\nThere are many routes to the different careers within the construction industry. These three main tiers are based on educational background and training, which vary by country:\n\nSkilled occupations include carpenters, electricians, plumbers, ironworkers, masons, and many other manual crafts, as well as those involved in project management. In the UK these require further education qualifications, often in vocational subject areas. These qualifications are either obtained directly after the completion of compulsory education or through \"on the job\" apprenticeship training. In the UK, 8500 construction-related apprenticeships were commenced in 2007.\n\nTechnical and specialized occupations require more training as a greater technical knowledge is required. These professions also hold more legal responsibility. A short list of the main careers with an outline of the educational requirements are given below:\n\nIn 2010 a salary survey revealed the differences in remuneration between different roles, sectors and locations in the construction and built environment industry. The results showed that areas of particularly strong growth in the construction industry, such as the Middle East, yield higher average salaries than in the UK, for example. The average earning for a professional in the construction industry in the Middle East, across all sectors, job types and levels of experience, is £42,090, compared to £26,719 in the UK. This trend is not necessarily due to the fact that more affluent roles are available; however, as architects with 14 or more years' experience working in the Middle East earn on average £43,389 per annum, compared to £40,000 in the UK. Some construction workers in the US/Canada have made more than $100,000 annually, depending on their trade.\n\nConstruction is one of the most dangerous occupations in the world, incurring more occupational fatalities than any other sector in both the United States and in the European Union. In 2009, the fatal occupational injury rate among construction workers in the United States was nearly three times that for all workers, with Falls being one of the most common causes of fatal and non-fatal injuries among construction workers. Proper safety equipment such as harnesses, hard hats and guardrails and procedures such as securing ladders and inspecting scaffolding can curtail the risk of occupational injuries in the construction industry. Other major causes of fatalities in the construction industry include electrocution, transportation accidents, and trench cave-ins.\n\nOther safety risks for workers in construction include hearing loss due to high noise exposure, musculoskeletal injury, chemical exposure, and high levels of stress. Besides that, the high turnover of workers in construction industry imposes a huge challenge of accomplishing the restructuring of work practices in individual workplaces or with individual workers. Construction has been identified by the National Institute for Occupational Safety and Health (NIOSH) as a priority industry sector in the National Occupational Research Agenda (NORA) to identify and provide intervention strategies regarding occupational health and safety issues.\n\nThe first huts and shelters were constructed by hand or with simple tools. As cities grew during the Bronze Age, a class of professional craftsmen, like bricklayers and carpenters, appeared. Occasionally, slaves were used for construction work. In the Middle Ages, the artisan craftsmen were organized into guilds. In the 19th century, steam-powered machinery appeared, and, later, diesel- and electric-powered vehicles such as cranes, excavators and bulldozers.\n\nFast-track construction has been increasingly popular in the 21st century. Some estimates suggest that 40% of construction projects are now fast-track construction.\n\n"}
{"id": "36581", "url": "https://en.wikipedia.org/wiki?curid=36581", "title": "Fishing", "text": "Fishing\n\nFishing is the activity of trying to catch fish. Fish are normally caught in the wild. Techniques for catching fish include hand gathering, spearing, netting, angling and trapping. “Fishing” may include catching aquatic animals other than fish, such as molluscs, cephalopods, crustaceans, and echinoderms. The term is not normally applied to catching farmed fish, or to aquatic mammals, such as whales where the term whaling is more appropriate. In addition to being caught to be eaten, fish are caught as recreational pastimes. Fishing tournaments are held, and caught fish are sometimes kept as preserved or living trophies. When bioblitzes occur, fish are typically caught, identified, and then released.\n\nAccording to the United Nations FAO statistics, the total number of commercial fishermen and fish farmers is estimated to be 38 million. Fisheries and aquaculture provide direct and indirect employment to over 500 million people in developing countries. In 2005, the worldwide per capita consumption of fish captured from wild fisheries was 14.4 kilograms, with an additional 7.4 kilograms harvested from fish farms.\n\nFishing is an ancient practice that dates back to at least the beginning of the Upper Paleolithic period about 40,000 years ago. Isotopic analysis of the skeletal remains of Tianyuan man, a 40,000-year-old modern human from eastern Asia, has shown that he regularly consumed freshwater fish. Archaeology features such as shell middens, discarded fish bones, and cave paintings show that sea foods were important for survival and consumed in significant quantities.\n\nFishing in Africa is evident very early on in human history. Neanderthals were fishing by about 200,000 BC. People could have developed basketry for fish traps, and spinning and early forms of knitting in order to make fishing nets to be able to catch more fish in larger quantities.\n\nDuring this period, most people lived a hunter-gatherer lifestyle and were, of necessity, constantly on the move. However, where there are early examples of permanent settlements (though not necessarily permanently occupied) such as those at Lepenski Vir, they are almost always associated with fishing as a major source of food.\n\nThe British dogger was an early type of sailing trawler from the 17th century, but the modern fishing trawler was developed in the 19th century, at the English fishing port of Brixham. By the early 19th century, the fishermen at Brixham needed to expand their fishing area further than ever before due to the ongoing depletion of stocks that was occurring in the overfished waters of South Devon. The Brixham trawler that evolved there was of a sleek build and had a tall gaff rig, which gave the vessel sufficient speed to make long-distance trips out to the fishing grounds in the ocean. They were also sufficiently robust to be able to tow large trawls in deep water. The great trawling fleet that built up at Brixham, earned the village the title of 'Mother of Deep-Sea Fisheries'.\nThis revolutionary design made large scale trawling in the ocean possible for the first time, resulting in a massive migration of fishermen from the ports in the South of England, to villages further north, such as Scarborough, Hull, Grimsby, Harwich and Yarmouth, that were points of access to the large fishing grounds in the Atlantic Ocean.\n\nThe small village of Grimsby grew to become the largest fishing port in the world by the mid 19th century. An Act of Parliament was first obtained in 1796, which authorised the construction of new quays and dredging of the Haven to make it deeper. It was only in 1846, with the tremendous expansion in the fishing industry, that the Grimsby Dock Company was formed. The foundation stone for the Royal Dock was laid by Albert the Prince consort in 1849. The dock covered and was formally opened by Queen Victoria in 1854 as the first modern fishing port.\n\nThe elegant Brixham trawler spread across the world, influencing fishing fleets everywhere. By the end of the 19th century, there were over 3,000 fishing trawlers in commission in Britain, with almost 1,000 at Grimsby. These trawlers were sold to fishermen around Europe, including from the Netherlands and Scandinavia. Twelve trawlers went on to form the nucleus of the German fishing fleet.\n\nThe earliest steam-powered fishing boats first appeared in the 1870s and used the trawl system of fishing as well as lines and drift nets. These were large boats, usually in length with a beam of around . They weighed 40–50 tons and travelled at . The earliest purpose-built fishing vessels were designed and made by David Allan in Leith, Scotland in March 1875, when he converted a drifter to steam power. In 1877, he built the first screw propelled steam trawler in the world.\n\nSteam trawlers were introduced at Grimsby and Hull in the 1880s. In 1890 it was estimated that there were 20,000 men on the North Sea. The steam drifter was not used in the herring fishery until 1897. The last sailing fishing trawler was built in 1925 in Grimsby. Trawler designs adapted as the way they were powered changed from sail to coal-fired steam by World War I to diesel and turbines by the end of World War II.\n\nIn 1931, the first powered drum was created by Laurie Jarelainen. The drum was a circular device that was set to the side of the boat and would draw in the nets. Since World War II, radio navigation aids and fish finders have been widely used. The first trawlers fished over the side, rather than over the stern. The first purpose-built stern trawler was \"Fairtry\" built-in 1953 at Aberdeen, Scotland. The ship was much larger than any other trawlers then in operation and inaugurated the era of the 'super trawler'. As the ship pulled its nets over the stern, it could lift out a much greater haul of up to 60 tons. The ship served as a basis for the expansion of 'super trawlers' around the world in the following decades.\n\nThe early evolution of fishing as recreation is not clear. For example, there is anecdotal evidence for fly fishing in Japan, however, fly fishing was likely to have been a means of survival, rather than recreation. The earliest English essay on recreational fishing was published in 1496, by Dame Juliana Berners, the prioress of the Benedictine Sopwell Nunnery. The essay was titled \"Treatyse of Fysshynge wyth an Angle\", and included detailed information on fishing waters, the construction of rods and lines, and the use of natural baits and artificial flies.\n\nRecreational fishing took a great leap forward after the English Civil War, where a newly found interest in the activity left its mark on the many books and treatises that were written on the subject at the time. \"Compleat Angler\" was written by Izaak Walton in 1653 (although Walton continued to add to it for a quarter of a century) and described the fishing in the Derbyshire Wye. It was a celebration of the art and spirit of fishing in prose and verse. A second part to the book was added by Walton's friend Charles Cotton.\n\nCharles Kirby designed an improved fishing hook in 1655 that remains relatively unchanged to this day. He went on to invent the Kirby bend, a distinctive hook with an offset point, still commonly used today.\nThe 18th century was mainly an era of consolidation of the techniques developed in the previous century. Running rings began to appear along the fishing rods, which gave anglers greater control over the cast line. The rods themselves were also becoming increasingly sophisticated and specialised for different roles. Jointed rods became common from the middle of the century and bamboo came to be used for the top section of the rod, giving it a much greater strength and flexibility.\n\nThe industry also became commercialised – rods and tackle were sold at the haberdashers store. After the Great Fire of London in 1666, artisans moved to Redditch which became a centre of production of fishing related products from the 1730s. Onesimus Ustonson established his shop in 1761, and his establishment remained as a market leader for the next century. He received a Royal Warrant from three successive monarchs starting with King George IV. He also invented the multiplying winch. The commercialization of the industry came at a time of expanded interest in fishing as a recreational hobby for members of the aristocracy.\n\nThe impact of the Industrial Revolution was first felt in the manufacture of fly lines. Instead of anglers twisting their lines – a laborious and time-consuming process – the new textile spinning machines allowed for a variety of tapered lines to be easily manufactured and marketed.\n\nBritish fly-fishing continued to develop in the 19th Century, with the emergence of fly fishing clubs, along with the appearance of several books on the subject of fly tying and fly fishing techniques.\n\nBy the mid to late 19th century, expanding leisure opportunities for the middle and lower classes began to have its effect on fly fishing, which steadily grew in mass appeal. The expansion of the railway network in Britain allowed the less affluent for the first time to take weekend trips to the seaside or rivers for fishing. Richer hobbyists ventured further abroad. The large rivers of Norway replete with large stocks of salmon began to attract fishers from England in large numbers in the middle of the century – \"Jones's guide to Norway, and salmon-fisher's pocket companion\", published in 1848, was written by Frederic Tolfrey and was a popular guide to the country.\nModern reel design had begun in England during the latter part of the 18th century, and the predominant model in use was known as the 'Nottingham reel'. The reel was a wide drum that spooled out freely and was ideal for allowing the bait to drift along way out with the current. Geared multiplying reels never successfully caught on in Britain, but had more success in the United States, where similar models were modified by George Snyder of Kentucky into his bait-casting reel, the first American-made design in 1810.\n\nThe material used for the rod itself changed from the heavy woods native to England to lighter and more elastic varieties imported from abroad, especially from South America and the West Indies. Bamboo rods became the generally favoured option from the mid 19th century, and several strips of the material were cut from the cane, milled into shape, and then glued together to form the light, strong, hexagonal rods with a solid core that were superior to anything that preceded them. George Cotton and his predecessors fished their flies with long rods, and light lines allowing the wind to do most of the work of getting the fly to the fish.\n\nTackle design began to improve from the 1880s. The introduction of new woods to the manufacture of fly rods made it possible to cast flies into the wind on silk lines, instead of horse hair. These lines allowed for a much greater casting distance. However, these early fly lines proved troublesome as they had to be coated with various dressings to make them float and needed to be taken off the reel and dried every four hours or so to prevent them from becoming waterlogged. Another negative consequence was that it became easy for the much longer line to get into a tangle – this was called a 'tangle' in Britain, and a 'backlash' in the US. This problem spurred the invention of the regulator to evenly spool the line out and prevent tangling.\n\nThe American, Charles F. Orvis, designed and distributed a novel reel and fly design in 1874, described by reel historian Jim Brown as the \"benchmark of American reel design,\" and the first fully modern fly reel.\n\nAlbert Illingworth, 1st Baron Illingworth a textiles magnate, patented the modern form of fixed-spool spinning reel in 1905. When casting Illingworth's reel design, the line was drawn off the leading edge of the spool but was restrained and rewound by a line pickup, a device which orbits around the stationary spool. Because the line did not have to pull against a rotating spool, much lighter lures could be cast than with conventional reels.\n\nThe development of inexpensive fiberglass rods, synthetic fly lines, and monofilament leaders in the early 1950s, that revived the popularity of fly fishing.\n\nThere are many fishing techniques and tactics for catching fish. The term can also be applied to methods for catching other aquatic animals such as molluscs (shellfish, squid, octopus) and edible marine invertebrates.\n\nFishing techniques include hand gathering, spearfishing, netting, angling and trapping. Recreational, commercial and artisanal fishers use different techniques, and also, sometimes, the same techniques. Recreational fishers fish for pleasure, sport, or to provide food for themselves, while commercial fishers fish for profit. Artisanal fishers use traditional, low-tech methods, for survival in third-world countries, and as a cultural heritage in other countries. Usually, recreational fishers use angling methods and commercial fishers use netting methods.\n\nWhy a fish bites a baited hook or lure involves several factors related to the sensory physiology, behaviour, feeding ecology, and biology of the fish as well as the environment and characteristics of the bait/hook/lure. There is an intricate link between various fishing techniques and knowledge about the fish and their behaviour including migration, foraging and habitat. The effective use of fishing techniques often depends on this additional knowledge. Some fishermen follow fishing folklores which claim that fish feeding patterns are influenced by the position of the sun and the moon.\n\nFishing tackle is the equipment used by fishermen when fishing. Almost any equipment or gear used for fishing can be called fishing tackle. Some examples are hooks, lines, sinkers, floats, rods, reels, baits, lures, spears, nets, gaffs, traps, waders and tackle boxes.\n\nTackle that is attached to the end of a fishing line is called terminal tackle. This includes hooks, sinkers, floats, leaders, swivels, split rings and wire, snaps, beads, spoons, blades, spinners and clevises to attach spinner blades to fishing lures. People also tend to use dead or live fish as another form of bait.\n\nFishing tackle refers to the physical equipment that is used when fishing, whereas fishing techniques refers to the ways the tackle is used when fishing.\n\nA fishing vessel is a boat or ship used to catch fish in the sea, or on a lake or river. Many different kinds of vessels are used in commercial, artisanal and recreational fishing.\n\nAccording to the FAO, in 2004 there were four million commercial fishing vessels. About 1.3 million of these are decked vessels with enclosed areas. Nearly all of these decked vessels are mechanised, and 40,000 of them are over 100 tons. At the other extreme, two-thirds (1.8 million) of the undecked boats are traditional craft of various types, powered only by sail and oars. These boats are used by artisan fishers.\n\nIt is difficult to estimate how many recreational fishing boats there are, although the number is high. The term is fluid since most recreational boats are also used for fishing from time to time. Unlike most commercial fishing vessels, recreational fishing boats are often not dedicated just to fishing. Just about anything that will stay afloat can be called a recreational fishing boat, so long as a fisherman periodically climbs aboard with the intent to catch a fish. Fish are caught for recreational purposes from boats which range from dugout canoes, float tubes, kayaks, rafts, pontoon boats and small dinghies to runabouts, cabin cruisers and cruising yachts to large, hi-tech and luxurious big game rigs. Larger boats, purpose-built with recreational fishing in mind, usually have large, open cockpits at the stern, designed for convenient fishing.\nTraditional fishing is any kind of small scale, commercial or subsistence fishing practices using traditional techniques such as rod and tackle, arrows and harpoons, throw nets and drag nets, etc.\n\nRecreational and sport fishing are fishing primarily for pleasure or competition. Recreational fishing has conventions, rules, licensing restrictions and laws that limit how fish may be caught; typically, these prohibit the use of nets and the catching of fish with hooks not in the mouth. The most common form of recreational fishing is done with a rod, reel, line, hooks and any one of a wide range of baits or lures such as artificial flies. The practice of catching or attempting to catch fish with a hook is generally known as angling. In angling, it is sometimes expected or required that fish be returned to the water (catch and release). Recreational or sport fishermen may log their catches or participate in fishing competitions.\n\nBig-game fishing is fishing from boats to catch large open-water species such as tuna, sharks, and marlin. Sportfishing (sometimes game fishing) is recreational fishing where the primary reward is the challenge of finding and catching the fish rather than the culinary or financial value of the fish's flesh. Fish sought after include tarpon, sailfish, mackerel and many others.\n\nThe fishing industry includes any industry or activity concerned with taking, culturing, processing, preserving, storing, transporting, marketing or selling fish or fish products. It is defined by the FAO as including recreational, subsistence and commercial fishing, and the harvesting, processing, and marketing sectors. The commercial activity is aimed at the delivery of fish and other seafood products for human consumption or use as raw material in other industrial processes.\n\nThere are three principal industry sectors:\n\nCommercial fishing is the capture of fish for commercial purposes. Those who practice it must often pursue fish far from the land under adverse conditions. Commercial fishermen harvest almost all aquatic species, from tuna, cod and salmon to shrimp, krill, lobster, clams, squid and crab, in various fisheries for these species. Commercial fishing methods have become very efficient using large nets and sea-going processing factories. Individual fishing quotas and international treaties seek to control the species and quantities caught.\n\nA commercial fishing enterprise may vary from one man with a small boat with hand-casting nets or a few pot traps, to a huge fleet of trawlers processing tons of fish every day.\n\nCommercial fishing gear includes weights, nets (e.g. purse seine), seine nets (e.g. beach seine), trawls (e.g. bottom trawl), dredges, hooks and line (e.g. long line and handline), lift nets, gillnets, entangling nets and traps.\n\nAccording to the Food and Agriculture Organization of the United Nations, the total world capture fisheries production in 2000 was 86 million tons (FAO 2002). The top producing countries were, in order, the People's Republic of China (excluding Hong Kong and Taiwan), Peru, Japan, the United States, Chile, Indonesia, Russia, India, Thailand, Norway, and Iceland. Those countries accounted for more than half of the world's production; China alone accounted for a third of the world's production. Of that production, over 90% was marine and less than 10% was inland.\n\nA small number of species support the majority of the world's fisheries. Some of these species are herring, cod, anchovy, tuna, flounder, mullet, squid, shrimp, salmon, crab, lobster, oyster and scallops. All except these last four provided a worldwide catch of well over a million tonnes in 1999, with herring and sardines together providing a catch of over 22 million metric tons in 1999. Many other species as well are fished in smaller numbers.\n\nFish farming is the principal form of aquaculture, while other methods may fall under mariculture. It involves raising fish commercially in tanks or enclosures, usually for food. A facility that releases juvenile fish into the wild for recreational fishing or to supplement a species' natural population is generally referred to as a fish hatchery. Fish species raised by fish farms include salmon, carp, tilapia, catfish and trout.\n\nIncreased demands on wild fisheries by commercial fishing has caused widespread overfishing. Fish farming offers an alternative solution to the increasing market demand for fish.\n\nFish and fish products are consumed as food all over the world. With other seafoods, it provides the world's prime source of high-quality protein: 14–16 percent of the animal protein consumed worldwide. Over one billion people rely on fish as their primary source of animal protein.\n\nFish and other aquatic organisms are also processed into various food and non-food products, such as sharkskin leather, pigments made from the inky secretions of cuttlefish, isinglass used for the clarification of wine and beer, fish emulsion used as a fertiliser, fish glue, fish oil and fish meal.\n\nFish are also collected live for research and the aquarium trade.\n\nFisheries management draws on fisheries science to find ways to protect fishery resources so sustainable exploitation is possible. Modern fisheries management is often referred to as a governmental system of (hopefully appropriate) management rules based on defined objectives and a mix of management means to implement the rules, which are put in place by a system of monitoring control and surveillance.\n\nFisheries science is the academic discipline of managing and understanding fisheries. It is a multidisciplinary science, which draws on the disciplines of oceanography, marine biology, marine conservation, ecology, population dynamics, economics and management in an attempt to provide an integrated picture of fisheries. In some cases new disciplines have emerged, such as bioeconomics.\n\nIssues involved in the long term sustainability of fishing include overfishing, by-catch, marine pollution, environmental effects of fishing, climate change and fish farming.\n\nConservation issues are part of marine conservation, and are addressed in fisheries science programs. There is a growing gap between how many fish are available to be caught and humanity's desire to catch them, a problem that gets worse as the world population grows.\n\nSimilar to other environmental issues, there can be conflict between the fishermen who depend on fishing for their livelihoods and fishery scientists who realise that if future fish populations are to be sustainable then some fisheries must limit fishing or cease operations.\nHistorically, some doubted that fish could experience pain. Laboratory experiments have shown that fish do react to painful stimuli (e.g., injections of bee venom) in a similar way to mammals. This is controversial and has been disputed. The expansion of fish farming as well as animal welfare concerns in society has led to research into more humane and faster ways of killing fish. In large-scale operations like fish farms, stunning fish with electricity or putting them into water saturated with nitrogen so that they cannot breathe, results in death more rapidly than just taking them out of the water. For sport fishing, it is recommended that fish be killed soon after catching them by hitting them on the head followed by bleeding out or by stabbing the brain with a sharp object (called pithing or \"ike jime\" in Japanese). Some believe it is not cruel if you release the catch back to where it was caught however a study in 2018 states that the hook used to catch causes damage to an important part of the feeding mechanism used to suck in food by the fish ignoring the issue of pain.\n\n\n\n\n\n"}
{"id": "53912", "url": "https://en.wikipedia.org/wiki?curid=53912", "title": "Forestry", "text": "Forestry\n\nForestry is the science and craft of creating, managing, using, conserving, and repairing forests, woodlands, and associated resources for human and environmental benefits. Forestry is practiced in plantations and natural stands. The science of forestry has elements that belong to the biological, physical, social, political and managerial sciences.\n\nModern forestry generally embraces a broad range of concerns, in what is known as multiple-use management, including the provision of timber, fuel wood, wildlife habitat, natural water quality management, recreation, landscape and community protection, employment, aesthetically appealing landscapes, biodiversity management, watershed management, erosion control, and preserving forests as \"sinks\" for atmospheric carbon dioxide. A practitioner of forestry is known as a forester. Other common terms are: a verderer, or a silviculturalist. Silviculture is narrower than forestry, being concerned only with forest plants, but is often used synonymously with forestry.\n\nForest ecosystems have come to be seen as the most important component of the biosphere, and forestry has emerged as a vital applied science, craft, and technology.\n\nForestry is an important economic segment in various industrial countries. For example, in Germany, forests cover nearly a third of the land area, wood is the most important renewable resource, and forestry supports more than a million jobs and about €181 billion of value to the German economy each year.\n\nThe preindustrial age has been dubbed by Werner Sombart and others as the 'wooden age', as timber and firewood were the basic resources for energy, construction and housing. The development of modern forestry is closely connected with the rise of capitalism, economy as a science and varying notions of land use and property.\n\nRoman Latifundiae, large agricultural estates, were quite successful in maintaining the large supply of wood that was necessary for the Roman Empire. Large deforestations came with respectively after the decline of the Romans. However already in the 5th century, monks in the then Byzantine Romagna on the Adriatic coast, were able to establish stone pine plantations to provide fuelwood and food. This was the beginning of the massive forest mentioned by Dante Alighieri in his 1308 poem Divine Comedy.\n\nSimilar sustainable formal forestry practices were developed by the Visigoths in the 7th century when, faced with the ever-increasing shortage of wood, they instituted a code concerned with the preservation of oak and pine forests. The use and management of many forest resources has a long history in China as well, dating back to the Han dynasty and taking place under the landowning gentry. A similar approach was used in Japan. It was also later written about by the Ming dynasty Chinese scholar Xu Guangqi (1562–1633).\n\nIn Europe, land usage rights in medieval and early modern times allowed different users to access forests and pastures. Plant litter and resin extraction were important, as pitch (resin) was essential for the caulking of ships, falking and hunting rights, firewood and building, timber gathering in wood pastures, and for grazing animals in forests. The notion of \"commons\" (German \"Allmende\") refers to the underlying traditional legal term of common land. The idea of enclosed private property came about during modern times. However, most hunting rights were retained by members of the nobility which preserved the right of the nobility to access and use common land for recreation, like fox hunting.\n\nSystematic management of forests for a sustainable yield of timber began in Portugal in the 13th century when Afonso III of Portugal planted the Pinhal do Rei near Leiria to prevent coastal erosion and soil degradation, and as a sustainable source for timber used in naval construction. His successor Dom Dinis continued the practice and the forest exists still today.\n\nForest management also flourished in the German states in the 14th century, e.g. in Nuremberg, and in 16th-century Japan. Typically, a forest was divided into specific sections and mapped; the harvest of timber was planned with an eye to regeneration. As timber rafting allowed for connecting large continental forests, as in south western Germany, via Main, Neckar, Danube and Rhine with the coastal cities and states, early modern forestry and remote trading were closely connected. Large firs in the black forest were called „Holländer“, as they were traded to the Dutch ship yards. Large timber rafts on the Rhine were 200 to 400m in length, 40m in width and consisted of several thousand logs. The crew consisted of 400 to 500 men, including shelter, bakeries, ovens and livestock stables. Timber rafting infrastructure allowed for large interconnected networks all over continental Europe and is still of importance in Finland.\n\nStarting with the sixteenth century, enhanced world maritime trade, a boom in housing construction in Europe and the success and further Berggeschrey (rushes) of the mining industry increased timber consumption sharply. The notion of 'Nachhaltigkeit', sustainability in forestry, is closely connected to the work of Hans Carl von Carlowitz (1645–1714), a mining administrator in Saxony. His book \"Sylvicultura oeconomica, oder haußwirthliche Nachricht und Naturmäßige Anweisung zur wilden Baum-Zucht\" (1713) was the first comprehensive treatise about sustainable yield forestry. In the UK, and, to an extent, in continental Europe, the enclosure movement and the clearances favored strictly enclosed private property. The Agrarian reformers, early economic writers and scientists tried to get rid of the traditional commons. At the time, an alleged tragedy of the commons together with fears of a Holznot, an imminent wood shortage played a watershed role in the controversies about cooperative land use patterns.\n\nThe practice of establishing tree plantations in the British Isles was promoted by John Evelyn, though it had already acquired some popularity. Louis XIV's minister Jean-Baptiste Colbert's oak Forest of Tronçais, planted for the future use of the French Navy, matured as expected in the mid-19th century: \"Colbert had thought of everything except the steamship,\" Fernand Braudel observed. In parallel, schools of forestry were established beginning in the late 18th century in Hesse, Russia, Austria-Hungary, Sweden, France and elsewhere in Europe.\n\nDuring the late 19th and early 20th centuries, forest preservation programs were established in British India, the United States, and Europe. Many foresters were either from continental Europe (like Sir Dietrich Brandis), or educated there (like Gifford Pinchot). Sir Dietrich Brandis is considered the father of tropical forestry, European concepts and practices had to be adapted in tropical and semi arid climate zones. The development of plantation forestry was one of the (controversial) answers to the specific challenges in the tropical colonies. The enactment and evolution of forest laws and binding regulations occurred in most Western nations in the 20th century in response to growing conservation concerns and the increasing technological capacity of logging companies. Tropical forestry is a separate branch of forestry which deals mainly with equatorial forests that yield woods such as teak and mahogany.\n\nForestry mechanization was always in close connection to metal working and the development of mechanical tools to cut and transport timber to its destination. Rafting belongs to the earliest means of transport. Steel saws came up in the 15th century. The 19th century widely increased the availability of steel for whipsaws and introduced Forest railways and railways in general for transport and as forestry customer. Further human induced changes, however, came since World War II, respectively in line with the \"1950s syndrome\". The first portable chainsaw was invented in 1918 in Canada, but large impact of mechanization in forestry started after World War II. Forestry harvesters are among the most recent developments. Although drones, planes, laser scanning, satellites and robots also play a part in forestry.\n\n\nToday a strong body of research exists regarding the management of forest ecosystems and the genetic improvement of tree species and varieties. Forestry studies also include the development of better methods for the planting, protecting, thinning, controlled burning, felling, extracting, and processing of timber. One of the applications of modern forestry is reforestation, in which trees are planted and tended in a given area.\n\nTrees provide numerous environmental, social and economic benefits for people. In many regions the forest industry is of major ecological, economic, and social importance, with the United States producing more timber than any other country in the world. Third-party certification systems that provide independent verification of sound forest stewardship and sustainable forestry have become commonplace in many areas since the 1990s. These certification systems developed as a response to criticism of some forestry practices, particularly deforestation in less-developed regions along with concerns over resource management in the developed world.\n\nIn topographically severe forested terrain, proper forestry is important for the prevention or minimization of serious soil erosion or even landslides. In areas with a high potential for landslides, forests can stabilize soils and prevent property damage or loss, human injury, or loss of life.\n\nForesters work for the timber industry, government agencies, conservation groups, local authorities, urban parks boards, citizens' associations, and private landowners. The forestry profession includes a wide diversity of jobs, with educational requirements ranging from college bachelor's degrees to PhDs for highly specialized work. Industrial foresters plan forest regeneration starting with careful harvesting. Urban foresters manage trees in urban green spaces. Foresters work in tree nurseries growing seedlings for woodland creation or regeneration projects. Foresters improve tree genetics. Forest engineers develop new building systems.\nProfessional foresters measure and model the growth of forests with tools like geographic information systems. Foresters may combat insect infestation, disease, forest and grassland wildfire, but increasingly allow these natural aspects of forest ecosystems to run their course when the likelihood of epidemics or risk of life or property are low. Increasingly, foresters participate in wildlife conservation planning and watershed protection. Foresters have been mainly concerned with timber management, especially reforestation, maintaining forests at prime conditions, and fire control.\n\nForesters develop and implement forest management plans relying on mapped resource inventories showing an area's topographical features as well as its distribution of trees (by species) and other plant cover. Plans also include landowner objectives, roads, culverts, proximity to human habitation, water features and hydrological conditions, and soils information. Forest management plans typically include recommended silvicultural treatments and a timetable for their implementation. Application of digital maps in Geographic Informations systems (GIS) that extracts and integrates different information about forest terrains, soil type and tree covers, etc. using, e.g. laser scanning, enhances forest management plans in modern systems.\n\nForest management plans include recommendations to achieve the landowner's objectives and desired future condition for the property subject to ecological, financial, logistical (e.g. access to resources), and other constraints. On some properties, plans focus on producing quality wood products for processing or sale. Hence, tree species, quantity, and form, all central to the value of harvested products quality and quantity, tend to be important components of silvicultural plans.\n\nGood management plans include consideration of future conditions of the stand after any recommended harvests treatments, including future treatments (particularly in intermediate stand treatments), and plans for natural or artificial regeneration after final harvests.\n\nThe objectives of landowners and leaseholders influence plans for harvest and subsequent site treatment. In Britain, plans featuring \"good forestry practice\" must always consider the needs of other stakeholders such as nearby communities or rural residents living within or adjacent to woodland areas. Foresters consider tree felling and environmental legislation when developing plans. Plans instruct the sustainable harvesting and replacement of trees. They indicate whether road building or other forest engineering operations are required.\n\nAgriculture and forest leaders are also trying to understand how the climate change legislation will affect what they do. The information gathered will provide the data that will determine the role of agriculture and forestry in a new climate change regulatory system.\n\nOver the past centuries, forestry was regarded as a separate science. With the rise of ecology and environmental science, there has been a reordering in the applied sciences. In line with this view, forestry is a primary land-use science comparable with agriculture. Under these headings, the fundamentals behind the management of natural forests comes by way of natural ecology. Forests or tree plantations, those whose primary purpose is the extraction of forest products, are planned and managed utilizing a mix of ecological and agroecological principles.\n\nThe provenance of forest reproductive material used to plant forests has great influence on how the trees develop, hence why it is important to use forest reproductive material of good quality and of high genetic diversity.\n\nThe term, describe differences in DNA sequence between individuals as distinct from variation caused by environmental influences. The unique genetic composition of an individual (its genotype) will determine its performance (its phenotype) at a particular site.\n\nGenetic diversity is needed to maintain the vitality of forests and to provide resilience to pests and diseases. Genetic diversity also ensures that forest trees can survive, adapt and evolve under changing environmental conditions. Furthermore, genetic diversity is the foundation of biological diversity at species and ecosystem levels. Forest genetic resources are therefore important to consider in forest management.\n\nGenetic diversity in forests is threatened by forest fires, pests and diseases, habitat fragmentation, poor silvicultural practices and inappropriate use of forest reproductive material. Furthermore, the marginal populations of many tree species are facing new threats due to climate change.\n\nMost countries in Europe have recommendations or guidelines for selecting species and provenances that can be used in a given site or zone.\n\nThe first dedicated forestry school was established by Georg Ludwig Hartig at Hungen in the Wetterau, Hesse, in 1787, though forestry had been taught earlier in central Europe, including at the University of Giessen, in Hesse-Darmstadt.\n\nIn Spain, the first forestry school was the Forest Engineering School of Madrid (Escuela Técnica Superior de Ingenieros de Montes), founded in 1844.\n\nThe first in North America, the Biltmore Forest School was established near Asheville, North Carolina, by Carl A. Schenck on September 1, 1898, on the grounds of George W. Vanderbilt's Biltmore Estate. Another early school was the New York State College of Forestry, established at Cornell University just a few weeks later, in September 1898. Early 19th century North American foresters went to Germany to study forestry. Some early German foresters also emigrated to North America.\n\nIn South America the first forestry school was established in Brazil, in Viçosa, Minas Gerais, in 1962, and moved the next year to become a faculty at the Federal University of Paraná, in Curitiba.\n\nToday, forestry education typically includes training in general biology, ecology, botany, genetics, soil science, climatology, hydrology, economics and forest management. Education in the basics of sociology and political science is often considered an advantage. Professional skills in conflict resolution and communication are also important in training programs.\n\nIn India, forestry education is imparted in the agricultural universities and in Forest Research Institutes (deemed universities). Four year degree programmes are conducted in these universities at the undergraduate level. Masters and Doctorate degrees are also available in these universities.\n\nIn the United States, postsecondary forestry education leading to a Bachelor's degree or Master's degree is accredited by the Society of American Foresters.\n\nIn Canada the Canadian Institute of Forestry awards silver rings to graduates from accredited university BSc programs, as well as college and technical programs.\n\nIn many European countries, training in forestry is made in accordance with requirements of the Bologna Process and the European Higher Education Area.\n\nThe International Union of Forest Research Organizations is the only international organization that coordinates forest science efforts worldwide.\n\n\n\n"}
{"id": "38791", "url": "https://en.wikipedia.org/wiki?curid=38791", "title": "Hunting", "text": "Hunting\n\nHunting is the practice of seeking, pursuing and capturing or killing wild animals. Hunting wildlife or feral animals is most commonly done by humans for food, recreation, to remove predators that can be dangerous to humans or domestic animals, to remove pests that destroy crops or kill livestock, or for trade. Lawful hunting is distinguished from poaching, which is the illegal killing, trapping or capture of the hunted species. The species that are hunted are referred to as game or prey and are usually mammals and birds. In economic terms, hunting is considered to be part of the primary production alongside forestry, agriculture and fishing.\nHunting arose in \"Homo erectus\" or earlier, on the order of millions of years ago. Hunting is deeply embedded in human culture. Hunting an animal for its meat can also be seen as a more natural way to obtain animal protein since regulated hunting does not cause the same environmental issues as raising domestic animals for meat, especially on factory farms.\nHunting can also be a means of pest control. Hunting advocates state that hunting can be a necessary component of modern wildlife management, for example, to help maintain a population of healthy animals within an environment's ecological carrying capacity when natural checks such as predators are absent or very rare. However, the usefulness of hunting as a control measure has been questioned, and excessive hunting has also heavily contributed to the endangerment, extirpation and extinction of many animals.\nThe pursuit, capture and release, or capture for food of fish is called fishing, which is not commonly categorised as a form of hunting. It is also not considered hunting to pursue animals without intent to kill them, as in wildlife photography, birdwatching, or scientific research activities which involve tranquilizing or tagging of animals or birds. The practice of foraging or gathering materials from plants and mushrooms is also considered separate from hunting.\n\nSkillful tracking and acquisition of an elusive target has caused the word \"hunt\" to be used in the vernacular as a metaphor, as in treasure hunting, \"bargain hunting\", and even \"hunting down\" corruption and waste.\n\nAnimal rights activists argue that hunting is cruel, unnecessary, and unethical.\n\nThe word \"hunt\" serves as both a noun (\"to be on a hunt\") and a verb. The noun has been dated to the early 12th century, \"act of chasing game,\" from the verb \"hunt\". Old English had \"huntung\", \"huntoþ\". The meaning of \"a body of persons associated for the purpose of hunting with a pack of hounds\" is first recorded in the 1570s. Meaning \"the act of searching for someone or something\" is from about 1600.\n\nThe verb, Old English \"huntian\" \"to chase game\" (transitive and intransitive), perhaps developed from \"hunta\" \"hunter,\" is related to \"hentan\" \"to seize,\" from Proto-Germanic \"huntojan\" (the source also of Gothic \"hinþan\" \"to seize, capture,\" Old High German \"hunda\" \"booty\"), which is of uncertain origin. The general sense of \"search diligently\" (for anything) is first recorded c. 1200.\n\nHunting has a long history. It pre-dates the emergence of \"Homo sapiens\" (anatomically modern humans) and may even predate genus \"Homo\".\n\nThe oldest undisputed evidence for hunting dates to the Early Pleistocene, consistent with the emergence and early dispersal of \"Homo erectus\", about 1.7 million years ago (Acheulean).\nWhile it is undisputed that \"Homo erectus\" were hunters, the importance of this for the emergence of \"Homo erectus\" from its australopithecine ancestors, including the production of stone tools and eventually the control of fire, is emphasised in the so-called \"hunting hypothesis\" and de-emphasised in scenarios that stress omnivory and social interaction.\n\nThere is no direct evidence for hunting predating \"Homo erectus\", in either \"Homo habilis\" or in \"Australopithecus\".\nThe early hominid ancestors of humans were probably frugivores or omnivores, with a partially carnivore diet from scavenging rather than hunting.\nEvidence for australopithecine meat consumption was presented in the 1990s.\nIt has nevertheless often been assumed that at least occasional hunting behavior may have been present well before the emergence of \"Homo\".\nThis can be argued on the basis of comparison with chimpanzees, the closest extant relatives of humans, who also engage in hunting, indicating that the behavioral trait may have been present in the Chimpanzee–human last common ancestor as early as 5 million years ago. The common chimpanzee (\"Pan troglodytes\") regularly engages in troop predation behaviour where bands of beta males are led by an alpha male. Bonobos (\"Pan paniscus\") have also been observed to occasionally engage in group hunting, although more rarely than \"Pan troglodytes\", mainly subsisting on a frugivorous diet.\nIndirect evidence for Oldowan era hunting, by early \"Homo\" or late \"Australopithecus\", has been presented in a 2009 study based on\nan Oldowan site in southwestern Kenya.\n\nLouis Binford (1986) criticised the idea that early hominids and early humans were hunters. On the basis of the analysis of the skeletal remains of the consumed animals, he concluded that hominids and early humans were mostly scavengers, not hunters,\nBlumenschine (1986) proposed the idea of \"confrontational scavenging\", which involves challenging and scaring off other predators \"after\" they have made a kill, which he suggests could have been the leading method of obtaining protein-rich meat by early humans.\n\nStone spearheads dated as early as 500,000 years ago were found in South Africa. Wood does not preserve well, however, and Craig Stanford, a primatologist and professor of anthropology at the University of Southern California, has suggested that the discovery of spear use by chimpanzees probably means that early humans used wooden spears as well, perhaps, five million years ago.\nThe earliest dated find of surviving wooden hunting spears dates to the very end of the Lower Paleolithic, just before 300,000 years ago. The Schöningen spears, found in 1976 in Germany, are associated with \"Homo heidelbergensis\".\n\nThe hunting hypothesis sees the emergence of behavioral modernity in the Middle Paleolithic as directly related to hunting, including mating behaviour, the establishment of language, culture, and religion, mythology and animal sacrifice.\n\nEvidence exists that hunting may have been one of the multiple environmental factors leading to the Holocene extinction of megafauna and their replacement by smaller herbivores.\nNorth American megafauna extinction was coincidental with the Younger Dryas impact event, possibly making hunting a less critical factor in prehistoric species loss than had been previously thought.\nHowever, in other locations such as Australia, humans are thought to have played a very significant role in the extinction of the Australian megafauna that was widespread prior to human occupation.\n\nHunting was a crucial component of hunter-gatherer societies before the domestication of livestock and the dawn of agriculture, beginning about 11,000 years ago in some parts of the world. In addition to the spear, hunting weapons developed during the Upper Paleolithic include the atlatl (a spear-thrower; before 30,000 years ago) and the bow (18,000 years ago). By the Mesolithic, hunting strategies had diversified with the development of these more far-reaching weapons and the domestication of the dog about 15,000 years ago. Evidence puts the earliest known mammoth hunting in Asia with spears to approximately 16,200 years ago.\n\nMany species of animals have been hunted throughout history. It has been suggested that in North America and Eurasia, caribou and wild reindeer \"may well be the species of single greatest importance in the entire anthropological literature on hunting\" (see also Reindeer Age), although the varying importance of different species depended on the geographic location.\n\nMesolithic hunter-gathering lifestyles remained prevalent in some parts of the Americas, Sub-Saharan Africa, and Siberia, as well as all of Australia, until the European Age of Discovery. They still persist in some tribal societies, albeit in rapid decline. Peoples that preserved Paleolithic hunting-gathering until the recent past include some indigenous peoples of the Amazonas (Aché), some Central and Southern African (San people), some peoples of New Guinea (Fayu), the Mlabri of Thailand and Laos, the Vedda people of Sri Lanka, and a handful of uncontacted peoples. In Africa, one of the last remaining hunter-gatherer tribes are the Hadza of Tanzania.\n\nEven as animal domestication became relatively widespread and after the development of agriculture, hunting was usually a significant contributor to the human food supply.\nThe supplementary meat and materials from hunting included protein, bone for implements, sinew for cordage, fur, feathers, rawhide and leather used in clothing.\n\nHunting is still vital in marginal climates, especially those unsuited for pastoral uses or agriculture. For example, Inuit people in the Arctic trap and hunt animals for clothing and use the skins of sea mammals to make kayaks, clothing, and footwear.\n\nOn ancient reliefs, especially from Mesopotamia, kings are often depicted as hunters of big game such as lions and are often portrayed hunting from a war chariot. The cultural and psychological importance of hunting in ancient societies is represented by deities such as the horned god Cernunnos and lunar goddesses of classical antiquity, the Greek Artemis or Roman Diana. Taboos are often related to hunting, and mythological association of prey species with a divinity could be reflected in hunting restrictions such as a reserve surrounding a temple. Euripides' tale of Artemis and Actaeon, for example, may be seen as a caution against disrespect of prey or impudent boasting.\n\nWith the domestication of the dog, birds of prey, and the ferret, various forms of animal-aided hunting developed, including venery (scent hound hunting, such as fox hunting), coursing (sight hound hunting), falconry, and ferreting. While these are all associated with medieval hunting, over time, various dog breeds were selected for very precise tasks during the hunt, reflected in such names as pointer and setter.\n\nEven as agriculture and animal husbandry became more prevalent, hunting often remained as a part of human culture where the environment and social conditions allowed. Hunter-gatherer societies persisted, even when increasingly confined to marginal areas. And within agricultural systems, hunting served to kill animals that prey upon domestic and wild animals or to attempt to extirpate animals seen by humans as competition for resources such as water or forage.\n\nWhen hunting moved from a subsistence activity to a social one, two trends emerged:\n\n\nThe meaning of the word \"game\" in Middle English evolved to include an animal which is hunted. As game became more of a luxury than a necessity, the stylised pursuit of it also became a luxury. Dangerous hunting, such as for lions or wild boars, often done on horseback or from a chariot, had a function similar to tournaments and manly sports. Hunting ranked as an honourable, somewhat competitive pastime to help the aristocracy practice skills of war in times of peace.\n\nIn most parts of medieval Europe, the upper class obtained the sole rights to hunt in certain areas of a feudal territory. Game in these areas was used as a source of food and furs, often provided via professional huntsmen, but it was also expected to provide a form of recreation for the aristocracy. The importance of this proprietary view of game can be seen in the Robin Hood legends, in which one of the primary charges against the outlaws is that they \"hunt the King's deer\". In contrast, settlers in Anglophone colonies gloried democratically in hunting for all.\n\nIn Medieval Europe, hunting was considered by Johannes Scotus Eriugena to be part of the set of \"seven mechanical arts\".\n\nAlthough various other animals have been used to aid the hunter, such as ferrets, the dog has assumed many very important uses to the hunter.\nThe domestication of the dog has led to a symbiotic relationship in which the dog's independence from humans is deferred. Though dogs can survive independently of humans, and in many cases do, as with feral dogs, where hunger is not a primary factor, the species tends to defer to human control in exchange for habitation, food and support.\n\nDogs today are used to find, chase, retrieve, and sometimes to kill the game. Hunting dogs allow humans to pursue and kill prey that would otherwise be very difficult or dangerous to hunt. Different breeds of dogs are used for different types of hunting. Waterfowl are commonly hunted using retrieving dogs such as the Labrador Retriever, the Golden Retriever, the Chesapeake Bay Retriever, the Brittany Spaniel, and other similar breeds. Game birds are flushed out using flushing spaniels such as the English Springer Spaniel, the various Cocker Spaniels and similar breeds.\n\nThe hunting of wild mammals in England and Wales with dogs was banned under the Hunting Act 2004. The wild mammals include fox, hare, deer and mink. Hunting with dogs is permissible, however, where it has been carried out in accordance with one of the exceptions in the Act.\n\nMany prehistoric deities are depicted as predators or prey of humans, often in a zoomorphic form, perhaps alluding to the importance of hunting for most Palaeolithic cultures.\n\nIn many pagan religions, specific rituals are conducted before or after a hunt; the rituals done may vary according to the species hunted or the season the hunt is taking place. Often a hunting ground, or the hunt for one or more species, was reserved or prohibited in the context of a temple cult.\n\nHindu scriptures describe hunting as an acceptable occupation, as well as a sport of the kingly. Even figures considered divine are described to have engaged in hunting. One of the names of the god Shiva is Mrigavyadha, which translates as \"the deer hunter\" (\"mriga\" means deer; \"vyadha\" means hunter). The word \"Mriga\", in many Indian languages including Malayalam, not only stands for deer, but for all animals and animal instincts (Mriga Thrishna). Shiva, as Mrigavyadha, is the one who destroys the animal instincts in human beings. In the epic Ramayana, Dasharatha, the father of Rama, is said to have the ability to hunt in the dark. During one of his hunting expeditions, he accidentally killed Shravana, mistaking him for game. During Rama's exile in the forest, Ravana kidnapped his wife, Sita, from their hut, while Rama was asked by Sita to capture a golden deer, and his brother Lakshman went after him. According to the Mahabharat, Pandu, the father of the Pandavas, accidentally killed the sage Kindama and his wife with an arrow, mistaking them for a deer. Krishna is said to have died after being accidentally wounded by an arrow of a hunter.\n\nJainism teaches followers to have tremendous respect for all of life. Prohibitions for hunting and meat eating are the fundamental conditions for being a Jain.\n\nBuddhism's first precept is the respect for all sentient life. The general approach by all Buddhists is to avoid killing any living animals. Buddha explained the issue by saying \"all fear death; comparing others with oneself, one should neither kill nor cause to kill.\"\n\nIn Sikhism, only meat obtained from hunting, or slaughtered with the Jhatka is permitted. The Sikh gurus, especially Guru Hargobind and Guru Gobind Singh were ardent hunters. Many old Sikh Rehatnamas like Prem Sumarag, recommend hunting wild boar and deer. However, among modern Sikhs, the practise of hunting has died down; some even saying that all meat is forbidden.\n\nFrom early Christian times, hunting has been forbidden to Roman Catholic Church clerics. Thus the \"Corpus Juris Canonici\" (C. ii, X, De cleric. venat.) says, \"We forbid to all servants of God hunting and expeditions through the woods with hounds; and we also forbid them to keep hawks or falcons.\" The Fourth Council of the Lateran, held under Pope Innocent III, decreed (canon xv): \"We interdict hunting or hawking to all clerics.\" The decree of the Council of Trent is worded more mildly: \"Let clerics abstain from illicit hunting and hawking\" (Sess. XXIV, De reform., c. xii), which seems to imply that not all hunting is illicit, and canonists generally make a distinction declaring noisy (\"clamorosa\") hunting unlawful, but not quiet (\"quieta\") hunting.\n\nFerraris (s.v. \"Clericus\", art. 6) gives it as the general sense of canonists that hunting is allowed to clerics if it be indulged in rarely and for sufficient cause, as necessity, utility or \"honest\" recreation, and with that moderation which is becoming to the ecclesiastical state. Ziegler, however (De episc., l. IV, c. xix), thinks that the interpretation of the canonists is not in accordance with the letter or spirit of the laws of the church.\n\nNevertheless, although a distinction between lawful and unlawful hunting is undoubtedly permissible, it is certain that a bishop can absolutely prohibit all hunting to the clerics of his diocese, as was done by synods at Milan, Avignon, Liège, Cologne, and elsewhere. Benedict XIV (De synodo diœces., l. II, c. x) declared that such synodal decrees are not too severe, as an absolute prohibition of hunting is more conformable to the ecclesiastical law. In practice, therefore, the synodal statutes of various localities must be consulted to discover whether they allow quiet hunting or prohibit it altogether.\n\nIt is important to note that most Christian, do not observe kosher dietary laws hence most Christian have no religious restrictions on eating the animals hunted. This is in accord with what is found in the Acts of the Apostles 15:28–29, and 1 Timothy 4:4.\n\nIn Jewish law hunting is not forbidden although there is an aversion to it. The great 18th-century authority Rabbi Yechezkel Landau after a study concluded although \"hunting would not be considered cruelty to animals insofar as the animal is generally killed quickly and not tortured... There is an unseemly element in it, namely cruelty.\" The other issue is that hunting can be dangerous and Judaism places an extreme emphasis on the value of human life.\n\nIslamic Sharia Law permits hunting of lawful animals and birds if they cannot be easily caught and slaughtered.\n\nNew Zealand has a strong hunting culture. When humans arrived, the only mammals present on the islands making up New Zealand were bats, although seals and other marine mammals were present along the coasts. However, when humans arrived they brought other species with them. Polynesian voyagers introduced kuri (dogs), kiore (Polynesian rats), as well as a range of plant species. European explorers further added to New Zealand's biota, particularly pigs which were introduced by either Captain Cook or the French explorer De Surville in the 1700s. During the nineteenth century, as European colonisation took place, acclimatisation societies were established. The societies introduced a large number of species with no use other than as prey for hunting. Species that adapted well to the New Zealand terrain include deer, pigs, goats, hare, tahr and chamois. With wilderness areas, suitable forage, and no natural predators, their populations exploded. Government agencies view the animals as pests due to their effects on the natural environment and on agricultural production, but hunters view them as a resource.\n\nDuring the feudal and colonial times in British India, hunting was regarded as a regal sport in the numerous princely states, as many maharajas and nawabs, as well as British officers, maintained a whole corps of \"shikaris\" (big-game hunters), who were native professional hunters. They would be headed by a master of the hunt, who might be styled \"mir-shikar\". Often, they recruited the normally low-ranking local tribes because of their traditional knowledge of the environment and hunting techniques. Big game, such as Bengal tigers, might be hunted from the back of an elephant.\n\nRegional social norms are generally antagonistic to hunting, while a few sects, such as the Bishnoi, lay special emphasis on the conservation of particular species, such as the antelope. India's Wildlife Protection Act of 1972 bans the killing of all wild animals. However, the Chief Wildlife Warden may, if satisfied that any wild animal from a specified list has become dangerous to human life, or is so disabled or diseased as to be beyond recovery, permit any person to hunt such an animal. In this case, the body of any wild animal killed or wounded becomes government property.\n\nA safari, from a Swahili word meaning \"a long journey\", especially in Africa, is defined as an overland journey. Safari as a distinctive way of hunting was popularized by the US author Ernest Hemingway and President Theodore Roosevelt. A safari may consist of a several-days – or even weeks-long journey, with camping in the bush or jungle, while pursuing big game. Nowadays, it is often used to describe tours through African national parks to watch or hunt wildlife.\n\nHunters are usually tourists, accompanied by licensed and highly regulated professional hunters, local guides, skinners, and porters in more difficult terrains. A special safari type is the solo-safari, where all the license acquiring, stalking, preparation, and outfitting is done by the hunter himself.\n\nUnarmed fox hunting on horseback with hounds is the type of hunting most closely associated with the United Kingdom; in fact, \"hunting\" without qualification implies fox hunting. What in other countries is called \"hunting\" is called \"shooting\" (birds) or \"stalking\" (deer) in Britain. Originally a form of vermin control to protect livestock, fox hunting became a popular social activity for newly wealthy upper classes in Victorian times and a traditional rural activity for riders and foot followers alike. Similar to fox hunting in many ways is the chasing of hares with hounds. Pairs of Sight hounds (or long-dogs), such as greyhounds, may be used to pursue a hare in coursing, where the greyhounds are marked as to their skill in coursing the hare (but are not intended to actually catch it), or the hare may be pursued with scent hounds such as beagles or harriers. Other sorts of foxhounds may also be used for hunting stags (deer) or mink. Deer stalking with rifles is carried out on foot without hounds, using stealth.\n\nThese forms of hunting have been controversial in the UK. Animal welfare supporters believe that hunting causes unnecessary suffering to foxes, horses, and hounds. Proponents argue that it is culturally and perhaps economically important. Using dogs to chase wild mammals was made illegal in February 2005 by the Hunting Act 2004; there were a number of exemptions (under which the activity may not be illegal) in the act for hunting with hounds, but no exemptions at all for hare-coursing.\n\nGame birds, especially pheasants, are shot with shotguns for sport in the UK; the British Association for Shooting and Conservation says that over a million people per year participate in shooting, including game shooting, clay pigeon shooting, and target shooting.\nShooting as practised in Britain, as opposed to traditional hunting, requires little questing for game—around thirty-five million birds are released onto shooting estates every year, some having been factory farmed. Shoots can be elaborate affairs with guns placed in assigned positions and assistants to help load shotguns. When in position, \"beaters\" move through the areas of cover, swinging sticks or flags to drive the game out. Such events are often called \"drives\". The open season for grouse in the UK begins on 12 August, the so-called Glorious Twelfth. The definition of game in the United Kingdom is governed by the Game Act 1831.\n\nA similar tradition exists in .\n\nNorth American hunting pre-dates the United States by thousands of years and was an important part of many pre-Columbian Native American cultures. Native Americans retain some hunting rights and are exempt from some laws as part of Indian treaties and otherwise under federal law—examples include eagle feather laws and exemptions in the Marine Mammal Protection Act. This is considered particularly important in Alaskan native communities.\n\nHunting is primarily regulated by state law; additional regulations are imposed through United States environmental law in the case of migratory birds and endangered species. Regulations vary widely from state to state and govern the areas, time periods, techniques and methods by which specific game animals may be hunted. Some states make a distinction between protected species and unprotected species (often vermin or varmints for which there are no hunting regulations). Hunters of protected species require a hunting license in all states, for which completion of a hunting safety course is sometimes a prerequisite.\n\nTypically, game animals are divided into several categories for regulatory purposes. Typical categories, along with example species, are as follows:\n\nHunting big game typically requires a \"tag\" for each animal harvested. Tags must be purchased in addition to the hunting license, and the number of tags issued to an individual is typically limited. In cases where there are more prospective hunters than the quota for that species, tags are usually assigned by lottery. Tags may be further restricted to a specific area, or wildlife management unit. Hunting migratory waterfowl requires a duck stamp from the Fish and Wildlife Service in addition to the appropriate state hunting license.\n\nHarvest of animals other than big game is typically restricted by a bag limit and a possession limit. A bag limit is the maximum number of a specific animal species that an individual can harvest in a single day. A possession limit is the maximum number of a specific animal species that can be in an individual's possession at any time.\n\nGun usage in hunting is typically regulated by game category, area within the state, and time period. Regulations for big-game hunting often specify a minimum caliber or muzzle energy for firearms. The use of rifles is often banned for safety reasons in areas with high population densities or limited topographic relief. Regulations may also limit or ban the use of lead in ammunition because of environmental concerns. Specific seasons for bow hunting or muzzle-loading black-powder guns are often established to limit competition with hunters using more effective weapons.\n\nHunting in the United States is not associated with any particular class or culture; a 2006 poll showed seventy-eight percent of Americans supported legal hunting, although relatively few Americans actually hunt. At the beginning of the 21st century, just six percent of Americans hunted. Southerners in states along the eastern seaboard hunted at a rate of five percent, slightly below the national average, and while hunting was more common in other parts of the South at nine percent, these rates did not surpass those of the Plains states, where twelve percent of Midwesterners hunted. Hunting in other areas of the country fell below the national average. Overall, in the 1996–2006 period, the number of hunters over the age of sixteen declined by ten percent, a drop attributable to a number of factors including habitat loss and changes in recreation habits.\n\nRegulation of hunting within the United States dates from the 19th century. Some modern hunters see themselves as conservationists and sportsmen in the mode of Theodore Roosevelt and the Boone and Crockett Club. Local hunting clubs and national organizations provide hunter education and help protect the future of the sport by buying land for future hunting use. Some groups represent a specific hunting interest, such as Ducks Unlimited, Pheasants Forever, or the Delta Waterfowl Foundation. Many hunting groups also participate in lobbying the federal government and state government.\n\nEach year, nearly $200 million in hunters' federal excise taxes are distributed to state agencies to support wildlife management programs, the purchase of lands open to hunters, and hunter education and safety classes. Since 1934, the sale of Federal Duck Stamps, a required purchase for migratory waterfowl hunters over sixteen years old, has raised over $700 million to help purchase more than of habitat for the National Wildlife Refuge System lands that support waterfowl and many other wildlife species and are often open to hunting. States also collect money from hunting licenses to assist with management of game animals, as designated by law. A key task of federal and state park rangers and game wardens is to enforce laws and regulations related to hunting, including species protection, hunting seasons, and hunting bans.\n\nVarmint hunting is an American phrase for the selective killing of non-game animals seen as pests. While not always an efficient form of pest control, varmint hunting achieves selective control of pests while providing recreation and is much less regulated. Varmint species are often responsible for detrimental effects on crops, livestock, landscaping, infrastructure, and pets. Some animals, such as wild rabbits or squirrels, may be utilised for fur or meat, but often no use is made of the carcass. Which species are varmints depends on the circumstance and area. Common varmints may include various rodents, coyotes, crows, foxes, feral cats, and feral hogs. Some animals once considered varmints are now protected, such as wolves. In the US state of Louisiana, a non-native rodent, the coypu, has become so destructive to the local ecosystem that the state has initiated a bounty program to help control the population.\n\nThe principles of the fair chase have been a part of the American hunting tradition for over one hundred years. The role of the hunter-conservationist, popularised by Theodore Roosevelt, and perpetuated by Roosevelt's formation of the Boone and Crockett Club, has been central to the development of the modern fair chase tradition. \"Beyond Fair Chase: The Ethic and Tradition of Hunting\", a book by Jim Posewitz, describes fair chase:\n\n\"Fundamental to ethical hunting is the idea of fair chase. This concept addresses the balance between the hunter and the hunted. It is a balance that allows hunters to occasionally succeed while animals generally avoid being taken.\"\nWhen Internet hunting was introduced in 2005, allowing people to hunt over the Internet using remotely controlled guns, the practice was widely criticised by hunters as violating the principles of fair chase. As a representative of the National Rifle Association (NRA) explained, \"The NRA has always maintained that fair chase, being in the field with your firearm or bow, is an important element of hunting tradition. Sitting at your desk in front of your computer, clicking at a mouse, has nothing to do with hunting.\"\n\nOne hunting club declares that a fair chase shall not involve the taking of animals under the following conditions:\n\nIndian blackbuck, nilgai, axis deer, fallow deer, zebras, barasingha and many other exotics can now be found on hunting ranches in Texas, where they were introduced for sport hunting. These hunters can be found paying in excess of $10,000 dollars to take trophy animals on these controlled ranches. \n\nThe Russian imperial hunts evolved from hunting traditions of early Russian rulers—Grand Princes and Tsars—under the influence of hunting customs of European royal courts. The imperial hunts were organised mainly in Peterhof, Tsarskoye Selo, and Gatchina.\n\nHunting in Australia has evolved around the hunting and eradication of various animals considered to be pests. All native animals are protected by law, and can only be killed under a special permit. Hunted introduced species include deer, pigs, goats, foxes, and rabbits.\n\nThe numbers of licensed hunters in Japan, including those using snares and guns, is generally decreasing, while their average age is increasing. , there were approximately 190,000 registered hunters, approximately 65% of whom were sixty years old or older.\n\nThere is a very active tradition of hunting of small to medium-sized wild game in Trinidad and Tobago. Hunting is carried out with firearms, and aided by the use of hounds, with the illegal use of trap guns and snare nets. With approximately 12,000 sport hunters applying for hunting permits in recent years (in a very small country of about the size of the state of Delaware at about 5128 square kilometers and 1.3 million inhabitants), there is some concern that the practice might not be sustainable. In addition there are at present no bag limits and the open season is comparatively very long (5 months – October to February inclusive). As such hunting pressure from legal hunters is very high. Added to that, there is a thriving and very lucrative black market for poached wild game (sold and enthusiastically purchased as expensive luxury delicacies) and the numbers of commercial poachers in operation is unknown but presumed to be fairly high. As a result, the populations of the five major mammalian game species (red-rumped agouti, lowland paca, nine-banded armadillo, collared peccary, and red brocket deer) are thought to be quite low (although scientifically conducted population studies are only just recently being conducted ). It appears that the red brocket deer population has been extirpated on Tobago as a result of over-hunting. Various herons, ducks, doves, the green iguana, the gold tegu, the spectacled caiman and the common opossum are also commonly hunted and poached. There is also some poaching of 'fully protected species', including red howler monkeys and capuchin monkeys, southern tamanduas, Brazilian porcupines, yellow-footed tortoises, Trinidad piping guans and even one of the national birds, the scarlet ibis. Legal hunters pay very small fees to obtain hunting licences and undergo no official basic conservation biology or hunting-ethics training. There is presumed to be relatively very little subsistence hunting in the country (with most hunting for either sport or commercial profit). The local wildlife management authority is under-staffed and under-funded, and as such very little in the way of enforcement is done to uphold existing wildlife management laws, with hunting occurring both in and out of season, and even in wildlife sanctuaries. There is some indication that the government is beginning to take the issue of wildlife management more seriously, with well drafted legislation being brought before Parliament in 2015. It remains to be seen if the drafted legislation will be fully adopted and financially supported by the current and future governments, and if the general populace will move towards a greater awareness of the importance of wildlife conservation and change the culture of wanton consumption to one of sustainable management.\n\nHunting is claimed to give resource managers an important tool in managing populations that might exceed the carrying capacity of their habitat and threaten the well-being of other species, or, in some instances, damage human health or safety.\n\nIn some cases, hunting actually can increase the population of predators such as coyotes by removing territorial bounds that would otherwise be established, resulting in excess neighbouring migrations into an area, thus artificially increasing the population. Hunting advocates assert that hunting reduces intraspecific competition for food and shelter, reducing mortality among the remaining animals. Some environmentalists assert that (re)introducing predators would achieve the same end with greater efficiency and less negative effect, such as introducing significant amounts of free lead into the environment and food chain.\n\nIn the United States, wildlife managers are frequently part of hunting regulatory and licensing bodies, where they help to set rules on the number, manner and conditions in which game may be hunted.\n\nManagement agencies sometimes rely on hunting to control specific animal populations, as has been the case with deer in North America. These hunts may sometimes be carried out by professional shooters, although others may include amateur hunters. Many US city and local governments hire professional and amateur hunters each year to reduce populations of animals such as deer that are becoming hazardous in a restricted area, such as neighbourhood parks and metropolitan open spaces.\n\nA large part of managing populations involves managing the number and, sometimes, the size or age of animals harvested so as to ensure the sustainability of the population. Tools that are frequently used to control harvest are bag limits and season closures, although gear restrictions such as archery-only seasons are becoming increasingly popular in an effort to reduce hunter success rates in countries that rely on bag limits per hunter instead of per area.\n\nIllegal hunting and harvesting of wild species contrary to local and international conservation and wildlife management laws is called poaching. Game preservation is one of the tactics used to prevent poaching. Violations of hunting laws and regulations involving poaching are normally punishable by law. Punishment can include confiscation of equipment, fines or a prison sentence.\n\nThe right to hunt − sometimes in combination with the right to fish − is protected implicitly, as a consequence of the right of ownership, or explicitly, as a right on its own, in a number of jurisdictions. For instance, as of 2019, a total of 22 U.S. states explicitly recognize a subjective right to hunt in their constitutions.\n\nBag limits are provisions under the law that control how many animals of a given species or group of species can be killed, although there are often species for which bag limits do not apply. There are also jurisdictions where bag limits are not applied at all or are not applied under certain circumstances. The phrase \"bag limits\" comes from the custom among hunters of small game to carry successful kills in a small basket, similar to a fishing creel.\n\nWhere bag limits are used, there can be daily or seasonal bag limits; for example, ducks can often be harvested at a rate of six per hunter per day. Big game, like moose, most often have a seasonal bag limit of one animal per hunter. Bag limits may also regulate the size, sex, or age of animal that a hunter can kill. In many cases, bag limits are designed to allocate harvest among the hunting population more equitably rather than to protect animal populations, as protecting the population would necessitate regional density-dependent maximum bags.\n\nA closed season is a time during which hunting an animal of a given species is contrary to law. Typically, closed seasons are designed to protect a species when they are most vulnerable or to protect them during their breeding season. By extension, the period that is not the closed season is known as the open season.\n\nHistorical, subsistence, and sport hunting techniques can differ radically, with modern hunting regulations often addressing issues of where, when, and how hunts are conducted. Techniques may vary depending on government regulations, a hunter's personal ethics, local custom, hunting equipment, and the animal being hunted. Often a hunter will use a combination of more than one technique. Laws may forbid sport hunters from using some methods used primarily in poaching and wildlife management.\n\nTrophy hunting is the selective seeking of wild game. It may also include the controversial hunting of captive or semi-captive animals expressly bred and raised under controlled or semi-controlled conditions so as to attain trophy characteristics; this is sometimes known as canned hunts.\n\nIn the 19th century, southern and central European sport hunters often pursued game only for a trophy, usually the head or pelt of an animal, which was then displayed as a sign of prowess. The rest of the animal was typically discarded. Some cultures, however, disapprove of such waste. In Nordic countries, hunting for trophies was—and still is—frowned upon. Hunting in North America in the 19th century was done primarily as a way to supplement food supplies, although it is now undertaken mainly for sport. The safari method of hunting was a development of sport hunting that saw elaborate travel in Africa, India and other places in pursuit of trophies. In modern times, trophy hunting persists and is a significant industry in some areas.\n\nAccording to the U.S. Fish and Wildlife Service, hunting \"provides an economic incentive\" for ranchers to continue to breed those species, and that hunting \"reduces the threat of the species' extinction.\"\n\nA scientific study in the journal, \"Biological Conservation\", states that trophy hunting is of \"major importance to conservation in Africa by creating economic incentives for conservation over vast areas, including areas which may be unsuitable for alternative wildlife-based land uses such as photographic ecotourism.\" However, another study states that less than 3% of a trophy hunters' expenditures reach the local level, meaning that the economic incentive and benefit is \"minimal, particularly when we consider the vast areas of land that hunting concessions occupy.\"\n\nFinancial incentives from trophy hunting effectively more than double the land area that is used for wildlife conservation, relative to what would be conserved relying on national parks alone according to \"Biological Conservation\", although local communities usually derive no more than 18 cents per hectare from trophy hunting.\n\nTrophy hunting has been considered essential for providing economic incentives to conserve large carnivores according to research studies in \"Conservation Biology\", \"Journal of Sustainable Tourism\", \"Wildlife Conservation by Sustainable Use\", and \"Animal Conservation\". Studies by the Centre for Responsible Tourism and the IUCN state that ecotourism, which includes more than hunting, is a superior economic incentive, generating twice the revenue per acre and 39 times more permanent employment. At the crosssection of trophy hunting, ecotourism and conservation is green hunting, a trophy hunting alternative where hunters pay to dart animals that need to be tranquilized for conservation projects.\n\nThe U.S. House Committee on Natural Resources in 2016 concluded that trophy hunting may be contributing to the extinction of certain animals. Conservationist groups such as IFAW assert that trophy hunting is a key factor in the \"silent extinction\" of giraffes.\n\nAccording to a national survey that the U.S. Fish and Wildlife Service conducts every five years, fewer people are hunting, even as population rises. National Public Radio reported, a graph shows 2016 statistics, that only about 5 percent of Americans, 16 years old and older, actually hunt, which is half of what it was 50 years ago. The decline in popularity of hunting is expected to accelerate over the next decade, which threatens how US will pay for conservation.\nTrophy hunting is most often criticised when it involves rare or endangered animals. Opponents may also see trophy hunting as an issue of morality or animal cruelty, criticising the killing of living creatures for recreation. Victorian era dramatist W. S. Gilbert remarked, \"Deer-stalking would be a very fine sport if only the deer had guns.\"\n\nThere is also debate about the extent to which trophy hunting benefits the local economy. Hunters argue that fees paid contribute to the local economy and provide value to animals that would otherwise be seen as competition for grazing, livestock, and crops. This analysis is disputed by many conservationist organizations and other opponents of trophy hunting. It is argued that the animals are worth more to the community for ecotourism than hunting.\n\nA variety of industries benefit from hunting and support hunting on economic grounds. In Tanzania, it is estimated that a safari hunter spends fifty to one hundred times that of the average ecotourist. While the average photo tourist may seek luxury accommodation, the average safari hunter generally stays in tented camps. Safari hunters are also more likely to use remote areas, uninviting to the typical ecotourist. Advocates argue that these hunters allow for anti-poaching activities and revenue for local communities.\n\nIn the United Kingdom, the game hunting of birds as an industry is said to be extremely important to the rural economy. The Cobham Report of 1997 suggested it to be worth around £700 million, and hunting and shooting lobby groups claimed it to be worth over a billion pounds less than ten years later.\n\nHunting also has a significant financial impact in the United States, with many companies specialising in hunting equipment or speciality tourism. Many different technologies have been created to assist hunters, even including iPhone applications. Today's hunters come from a broad range of economic, social, and cultural backgrounds. In 2001, over thirteen million hunters averaged eighteen days hunting, and spent over $20.5 billion on their sport. In the US, proceeds from hunting licenses contribute to state game management programs, including preservation of wildlife habitat.\n\nLead bullets that miss their target or remain in an unretrieved carcass could become a toxicant in the environment but lead in ammunition because of its metallic form has a lower solubility and higher resistance to corrosion than other forms of lead making it hardly available to biological systems. Waterfowl or other birds may ingest the lead and poison themselves with the neurotoxicant, but studies have demonstrated that effects of lead in ammunition are negligible on animal population size and growth. Since 1991, US federal law forbids lead shot in waterfowl hunts, and 30 states have some type of restriction.\n\nIn December 2014, a federal appeals court denied a lawsuit by environmental groups that the EPA must use the Toxic Substances Control Act to regulate lead in shells and cartridges. The groups sought EPA to regulate \"spent lead\", yet the court found EPA could not regulate spent lead without also regulating cartridges and shells.\n\nHunters have been driving forces throughout history in the movement to ensure the preservation of wildlife habitats and wildlife for further hunting. However, excessive hunting and poachers have also contributed heavily to the endangerment, extirpation and extinction of many animals, such as the quagga, the great auk, Steller's sea cow, the thylacine, the bluebuck, the Arabian oryx, the Caspian and Javan tigers, the markhor, the Sumatran rhinoceros, the bison, the North American cougar, the Altai argali sheep, the Asian elephant and many more, primarily for commercial sale or sport. All these animals have been hunted to endangerment or extinction. Poaching currently threatens bird and mammalian populations around the world.\n\nIn 1937, American hunters successfully lobbied the US Congress to pass the Pittman-Robertson Wildlife Restoration Act, which placed an eleven percent tax on all hunting equipment. This self-imposed tax now generates over $700 million each year and is used exclusively to establish, restore and protect wildlife habitats. The act is named for Nevada Senator Key Pittman and Virginia Congressman Absalom Willis Robertson.\n\nOn 16 March 1934, President Franklin D. Roosevelt signed the Migratory Bird Hunting Stamp Act, which requires an annual stamp purchase by all hunters over the age of sixteen. The stamps are created on behalf of the program by the US Postal Service and depict wildlife artwork chosen through an annual contest. They play an important role in habitat conservation because ninety-eight percent of all funds generated by their sale go directly toward the purchase or lease of wetland habitat for protection in the National Wildlife Refuge System. In addition to waterfowl, it is estimated that one third of the nation's endangered species seek food and shelter in areas protected using Duck Stamp funds.\n\nSince 1934, the sale of Federal Duck Stamps has generated $670 million, and helped to purchase or lease of habitat. The stamps serve as a license to hunt migratory birds, an entrance pass for all National Wildlife Refuge areas, and are also considered collectors items often purchased for aesthetic reasons outside of the hunting and birding communities. Although non-hunters buy a significant number of Duck Stamps, eighty-seven percent of their sales are contributed by hunters, which is logical, as hunters are required to purchase them. Distribution of funds is managed by the Migratory Bird Conservation Commission (MBCC).\n\nThe Arabian oryx, a species of large antelope, once inhabited much of the desert areas of the Middle East. However, the species' striking appearance made it (along with the closely related scimitar-horned oryx and addax) a popular quarry for sport hunters, especially foreign executives of oil companies working in the region. The use of automobiles and high-powered rifles destroyed their only advantage: speed, and they became extinct in the wild exclusively due to sport hunting in 1972. The scimitar-horned oryx followed suit, while the addax became critically endangered. However, the Arabian oryx has now made a comeback and been upgraded from \"extinct in the wild\" to \"vulnerable\" due to conservation efforts like captive breeding\n\nThe markhor is an endangered species of wild goat which inhabits the mountains of Central Asia and Pakistan. The colonization of these regions by Britain gave British sport hunters access to the species, and they were hunted heavily, almost to the point of extinction. Only their willingness to breed in captivity and the inhospitability of their mountainous habitat prevented this. Despite these factors, the markhor is still endangered.\n\nThe American bison is a large bovid which inhabited much of western North America prior to the 1800s, living on the prairies in large herds. However, the vast herds of bison attracted market hunters, who killed dozens of bison for their hides only, leaving the rest to rot. Thousands of these hunters quickly eliminated the bison herds, bringing the population from several million in the early 1800s to a few hundred by the 1880s. Conservation efforts have allowed the population to increase, but the bison remains near-threatened due to lack of habitat.\n\nThe \"Journal of International Wildlife Law and Policy\" cites that the legalization of white rhinoceros hunting in South Africa motivated private landowners to reintroduce the species onto their lands. As a result, the country saw an increase in white rhinos from fewer than one hundred individuals to more than 11,000, even while a limited number were killed as trophies.\n\nHowever, the illegal hunting of rhinoceros for their horns is highly damaging to the population and is currently growing globally, with 1004 being killed in South Africa alone according to the most recent estimate.\n\nAccording to Richard Conniff, Namibia is home to 1,750 of the roughly 5,000 black rhinos surviving in the wild because it allows trophy hunting of various species. Namibia's mountain zebra population has increased to 27,000 from 1,000 in 1982. Elephants, which \"are gunned down elsewhere for their ivory\", have gone to 20,000 from 15,000 in 1995. Lions, which were on the brink of extinction \"from Senegal to Kenya\", are increasing in Namibia.\n\nIn contrast, Botswana has recently been forced to ban trophy hunting following a precipitous wildlife decline. The numbers of antelope plummeted across Botswana, with a resultant decline in predator numbers, while elephant numbers remained stable and hippopotamus numbers rose. According to the government of Botswana, trophy hunting is at least partly to blame for this, but many other factors, such as poaching, drought and habitat loss are also to blame. Uganda recently did the same, arguing that \"the share of benefits of sport hunting were lopsided and unlikely to deter poaching or improve [Uganda's] capacity to manage the wildlife reserves.\"\n\nA study issued by the Wildlife Society concluded that hunting and trapping are cost effective tools that reduce wildlife damage by reducing a population below the capacity of the environment to carry it and changing the behaviors of animals to stop them from causing damage. The study furthermore states that the cessation of hunting could cause wildlife to be severely harmed, rural property values to fall, and the incentive of landowners to maintain natural habitats to diminish.\n\nAnimal rights activists state that killing animals for sport is unethical, cruel, and unnecessary. They note the suffering and cruelty inflicted on animals hunted for sport: \"Many animals endure prolonged, painful deaths when they are injured but not killed by hunters [...] Hunting disrupts migration and hibernation patterns and destroys families.\" Animal rights activists also comment that hunting is not needed in order to maintain an ecological balance, and that \"nature takes care of its own\". They say that hunting can be combated on public lands by \"spread deer repellent or human hair (from barber shops) near hunting areas\". Animal rights activists also argue that hunting is speciesist:\n\n\"Whether hunters try to justify their killing by citing human deaths caused by wild animals, by making conservationist claims, by claiming that it’s acceptable to hunt as long as the animals’ bodies are eaten, or simply because of the pleasure it brings them, the fact remains that hunting is morally unacceptable if we consider the interests of nonhuman animals. Hunted animals endure fear and pain, and then are deprived of their lives. Understanding the injustices of speciesism and the interests of nonhuman animals makes it clear that human pleasure cannot justify nonhuman animals’ pain.\"\n\n"}
{"id": "39388", "url": "https://en.wikipedia.org/wiki?curid=39388", "title": "Manufacturing", "text": "Manufacturing\n\nManufacturing is the production of products for use or sale using labor and machines, tools, chemical or biological processing or formulation and is the essence of secondary industry. The term may refer to a range of human activity from handicraft to high tech but is most commonly applied to industrial design, in which raw materials from primary industry are transformed into finished goods on a large scale. Such finished goods may be sold to other manufacturers for the production of other more complex products (such as aircraft, household appliances, furniture, sports equipment or automobiles), or distributed via the tertiary industry to end users and consumers (usually through wholesalers, who in turn sell to retailers, who then sell them to individual customers).\n\nManufacturing engineering or manufacturing process are the steps through which raw materials are transformed into a final product. The manufacturing process begins with the product design, and materials specification from which the product is made. These materials are then modified through manufacturing processes to become the required part.\n\nModern manufacturing includes all intermediate processes required in the production and integration of a product's components. Some industries, such as semiconductor and steel manufacturers use the term \"fabrication\" instead.\n\nThe manufacturing sector is closely connected with engineering and industrial design. Examples of major manufacturers in North America include General Motors Corporation, General Electric, Procter & Gamble, General Dynamics, Boeing, Pfizer, and Precision Castparts. Examples in Europe include Volkswagen Group, Siemens, FCA and Michelin. Examples in Asia include Toyota, Yamaha, Panasonic, LG, Samsung and Tata Motors.\n\nIn its earliest form, manufacturing was usually carried out by a single skilled artisan with assistants. Training was by apprenticeship. In much of the pre-industrial world, the guild system protected the privileges and trade secrets of urban artisans.\n\nIn the pre-industrial world, most manufacturing occurred in rural areas, where household-based manufacturing served as a supplemental subsistence strategy to agriculture (and continues to do so in places). Entrepreneurs organized a number of manufacturing households into a single enterprise through the putting-out system.\n\nThe factory system was first adopted in Britain at the beginning of the Industrial Revolution in the late 18th century and later spread around the world. The main characteristic of the factory system is the use of machinery, originally powered by water or steam and later by electricity. Increased use of economies of scale, the centralization of factories, and standardization of interchangeable parts were adopted in the American system of manufacturing in the nineteenth century.\n\nManufacturing in the Soviet Union was based on collectivism. \n\n\nEmerging technologies have provided some new growth in advanced manufacturing employment opportunities in the Manufacturing Belt in the United States. Manufacturing provides important material support for national infrastructure and for national defense.\n\nOn the other hand, most manufacturing may involve significant social and environmental costs. The clean-up costs of hazardous waste, for example, may outweigh the benefits of a product that creates it. Hazardous materials may expose workers to health risks. These costs are now well known and there is effort to address them by improving efficiency, reducing waste, using industrial symbiosis, and eliminating harmful chemicals.\n\nThe negative costs of manufacturing can also be addressed legally. Developed countries regulate manufacturing activity with labor laws and environmental laws. Across the globe, manufacturers can be subject to regulations and pollution taxes to offset the environmental costs of manufacturing activities. Labor unions and craft guilds have played a historic role in the negotiation of worker rights and wages. Environment laws and labor protections that are available in developed nations may not be available in the third world. Tort law and product liability impose additional costs on manufacturing. These are significant dynamics in the ongoing process, occurring over the last few decades, of manufacture-based industries relocating operations to \"developing-world\" economies where the costs of production are significantly lower than in \"developed-world\" economies.\n\nManufacturing has unique health and safety challenges and has been recognized by the National Institute for Occupational Safety and Health (NIOSH) as a priority industry sector in the National Occupational Research Agenda (NORA) to identify and provide intervention strategies regarding occupational health and safety issues.\n\nSurveys and analyses of trends and issues in manufacturing and investment around the world focus on such things as:\n\nIn addition to general overviews, researchers have examined the features and factors affecting particular key aspects of manufacturing development. They have compared production and investment in a range of Western and non-Western countries and presented case studies of growth and performance in important individual industries and market-economic sectors.\n\nOn June 26, 2009, Jeff Immelt, the CEO of General Electric, called for the United States to increase its manufacturing base employment to 20% of the workforce, commenting that the U.S. has outsourced too much in some areas and can no longer rely on the financial sector and consumer spending to drive demand. Further, while U.S. manufacturing performs well compared to the rest of the U.S. economy, research shows that it performs poorly compared to manufacturing in other high-wage countries. A total of 3.2 million – one in six U.S. manufacturing jobs – have disappeared between 2000 and 2007. In the UK, EEF the manufacturers organization has led calls for the UK economy to be rebalanced to rely less on financial services and has actively promoted the manufacturing agenda.\n\nList of top 20 manufacturing countries by total value of manufacturing in US dollars for its noted year according to World Bank.\n\n\n\n\n"}
{"id": "20381", "url": "https://en.wikipedia.org/wiki?curid=20381", "title": "Mining", "text": "Mining\n\nMining is the extraction of valuable minerals or other geological materials from the Earth, usually from an ore body, lode, vein, seam, reef or placer deposit. These deposits form a mineralized package that is of economic interest to the miner.\n\nOres recovered by mining include metals, coal, oil shale, gemstones, limestone, chalk, dimension stone, rock salt, potash, gravel, and clay. Mining is required to obtain any material that cannot be grown through agricultural processes, or feasibly created artificially in a laboratory or factory. Mining in a wider sense includes extraction of any non-renewable resource such as petroleum, natural gas, or even water.\n\nMining of stones and metal has been a human activity since pre-historic times. Modern mining processes involve prospecting for ore bodies, analysis of the profit potential of a proposed mine, extraction of the desired materials, and final reclamation of the land after the mine is closed.\n\nMining operations usually create a negative environmental impact, both during the mining activity and after the mine has closed. Hence, most of the world's nations have passed regulations to decrease the impact. Work safety has long been a concern as well, and modern practices have significantly improved safety in mines.\n\nLevels of metal recycling are generally low. Unless future end-of-life recycling rates are stepped up, some rare metals may become unavailable for use in a variety of consumer products. Due to the low recycling rates, some landfills now contain higher concentrations of metal than mines themselves.\n\nSince the beginning of civilization, people have used stone, ceramics and, later, metals found close to the Earth's surface. These were used to make early tools and weapons; for example, high quality flint found in northern France, southern England and Poland was used to create flint tools. Flint mines have been found in chalk areas where seams of the stone were followed underground by shafts and galleries. The mines at Grimes Graves and Krzemionki are especially famous, and like most other flint mines, are Neolithic in origin (c. 4000–3000 BC). Other hard rocks mined or collected for axes included the greenstone of the Langdale axe industry based in the English Lake District.\n\nThe oldest-known mine on archaeological record is the Ngwenya Mine in Eswatini (Swaziland), which radiocarbon dating shows to be about 43,000 years old. At this site Paleolithic humans mined hematite to make the red pigment ochre. Mines of a similar age in Hungary are believed to be sites where Neanderthals may have mined flint for weapons and tools.\n\nAncient Egyptians mined malachite at Maadi. At first, Egyptians used the bright green malachite stones for ornamentations and pottery. Later, between 2613 and 2494 BC, large building projects required expeditions abroad to the area of Wadi Maghareh in order to secure minerals and other resources not available in Egypt itself. Quarries for turquoise and copper were also found at Wadi Hammamat, Tura, Aswan and various other Nubian sites on the Sinai Peninsula and at Timna.\n\nMining in Egypt occurred in the earliest dynasties. The gold mines of Nubia were among the largest and most extensive of any in Ancient Egypt. These mines are described by the Greek author Diodorus Siculus, who mentions fire-setting as one method used to break down the hard rock holding the gold. One of the complexes is shown in one of the earliest known maps. The miners crushed the ore and ground it to a fine powder before washing the powder for the gold dust.\n\nMining in Europe has a very long history. Examples include the silver mines of Laurium, which helped support the Greek city state of Athens. Although they had over 20,000 slaves working them, their technology was essentially identical to their Bronze Age predecessors. At other mines, such as on the island of Thassos, marble was quarried by the Parians after they arrived in the 7th century BC. The marble was shipped away and was later found by archaeologists to have been used in buildings including the tomb of Amphipolis. Philip II of Macedon, the father of Alexander the Great, captured the gold mines of Mount Pangeo in 357 BC to fund his military campaigns. He also captured gold mines in Thrace for minting coinage, eventually producing 26 tons per year.\n\nHowever, it was the Romans who developed large scale mining methods, especially the use of large volumes of water brought to the minehead by numerous aqueducts. The water was used for a variety of purposes, including removing overburden and rock debris, called hydraulic mining, as well as washing comminuted, or crushed, ores and driving simple machinery.\n\nThe Romans used hydraulic mining methods on a large scale to prospect for the veins of ore, especially a now-obsolete form of mining known as hushing. They built numerous aqueducts to supply water to the minehead. There, the water stored in large reservoirs and tanks. When a full tank was opened, the flood of water sluiced away the overburden to expose the bedrock underneath and any gold veins. The rock was then worked upon by fire-setting to heat the rock, which would be quenched with a stream of water. The resulting thermal shock cracked the rock, enabling it to be removed by further streams of water from the overhead tanks. The Roman miners used similar methods to work cassiterite deposits in Cornwall and lead ore in the Pennines.\n\nThe methods had been developed by the Romans in Spain in 25 AD to exploit large alluvial gold deposits, the largest site being at Las Medulas, where seven long aqueducts tapped local rivers and sluiced the deposits. The Romans also exploited the silver present in the argentiferous galena in the mines of Cartagena (\"Cartago Nova\"), Linares (\"Castulo\"), Plasenzuela and Azuaga, among many others. Spain was one of the most important mining regions, but all regions of the Roman Empire were exploited. In Great Britain the natives had mined minerals for millennia, but after the Roman conquest, the scale of the operations increased dramatically, as the Romans needed Britannia's resources, especially gold, silver, tin, and lead.\n\nRoman techniques were not limited to surface mining. They followed the ore veins underground once opencast mining was no longer feasible. At Dolaucothi they stoped out the veins and drove adits through bare rock to drain the stopes. The same adits were also used to ventilate the workings, especially important when fire-setting was used. At other parts of the site, they penetrated the water table and dewatered the mines using several kinds of machines, especially reverse overshot water-wheels. These were used extensively in the copper mines at Rio Tinto in Spain, where one sequence comprised 16 such wheels arranged in pairs, and lifting water about . They were worked as treadmills with miners standing on the top slats. Many examples of such devices have been found in old Roman mines and some examples are now preserved in the British Museum and the National Museum of Wales.\n\nMining as an industry underwent dramatic changes in medieval Europe. The mining industry in the early Middle Ages was mainly focused on the extraction of copper and iron. Other precious metals were also used, mainly for gilding or coinage. Initially, many metals were obtained through open-pit mining, and ore was primarily extracted from shallow depths, rather than through deep mine shafts. Around the 14th century, the growing use of weapons, armour, stirrups, and horseshoes greatly increased the demand for iron. Medieval knights, for example, were often laden with up to of plate or chain link armour in addition to swords, lances and other weapons. The overwhelming dependency on iron for military purposes spurred iron production and extraction processes.\n\nThe silver crisis of 1465 occurred when all mines had reached depths at which the shafts could no longer be pumped dry with the available technology. Although an increased use of banknotes, credit and copper coins during this period did decrease the value of, and dependence on, precious metals, gold and silver still remained vital to the story of medieval mining.\n\nDue to differences in the social structure of society, the increasing extraction of mineral deposits spread from central Europe to England in the mid-sixteenth century. On the continent, mineral deposits belonged to the crown, and this regalian right was stoutly maintained. But in England, royal mining rights were restricted to gold and silver (of which England had virtually no deposits) by a judicial decision of 1568 and a law in 1688. England had iron, zinc, copper, lead, and tin ores. Landlords who owned the base metals and coal under their estates then had a strong inducement to extract these metals or to lease the deposits and collect royalties from mine operators. English, German, and Dutch capital combined to finance extraction and refining. Hundreds of German technicians and skilled workers were brought over; in 1642 a colony of 4,000 foreigners was mining and smelting copper at Keswick in the northwestern mountains.\n\nUse of water power in the form of water mills was extensive. The water mills were employed in crushing ore, raising ore from shafts, and ventilating galleries by powering giant bellows. Black powder was first used in mining in Selmecbánya, Kingdom of Hungary (now Banská Štiavnica, Slovakia) in 1627. Black powder allowed blasting of rock and earth to loosen and reveal ore veins. Blasting was much faster than fire-setting and allowed the mining of previously impenetrable metals and ores. In 1762, the world's first mining academy was established in the same town there.\n\nThe widespread adoption of agricultural innovations such as the iron plowshare, as well as the growing use of metal as a building material, was also a driving force in the tremendous growth of the iron industry during this period. Inventions like the arrastra were often used by the Spanish to pulverize ore after being mined. This device was powered by animals and used the same principles used for grain threshing.\n\nMuch of the knowledge of medieval mining techniques comes from books such as Biringuccio’s \"De la pirotechnia\" and probably most importantly from Georg Agricola's \"De re metallica\" (1556). These books detail many different mining methods used in German and Saxon mines. A prime issue in medieval mines, which Agricola explains in detail, was the removal of water from mining shafts. As miners dug deeper to access new veins, flooding became a very real obstacle. The mining industry became dramatically more efficient and prosperous with the invention of mechanical and animal driven pumps.\n\nMining in the Philippines began around 1000 BC. The early Filipinos worked various mines of gold, silver, copper and iron. Jewels, gold ingots, chains, calombigas and earrings were handed down from antiquity and inherited from their ancestors. Gold dagger handles, gold dishes, tooth plating, and huge gold ornaments were also used. In Laszlo Legeza's \"Tantric elements in pre-Hispanic Philippines Gold Art\", he mentioned that gold jewelry of Philippine origin was found in Ancient Egypt. According to Antonio Pigafetta, the people of Mindoro possessed great skill in mixing gold with other metals and gave it a natural and perfect appearance that could deceive even the best of silversmiths. The natives were also known for the pieces of jewelry made of other precious stones such as carnelian, agate and pearl. Some outstanding examples of Philippine jewelry included necklaces, belts, armlets and rings placed around the waist.\n\nDuring prehistoric times, large amounts of copper was mined along Lake Superior's Keweenaw Peninsula and in nearby Isle Royale; metallic copper was still present near the surface in colonial times. Indigenous peoples used Lake Superior copper from at least 5,000 years ago; copper tools, arrowheads, and other artifacts that were part of an extensive native trade network have been discovered. In addition, obsidian, flint, and other minerals were mined, worked, and traded. Early French explorers who encountered the sites made no use of the metals due to the difficulties of transporting them, but the copper was eventually traded throughout the continent along major river routes. \n\nIn the early colonial history of the Americas, \"native gold and silver was quickly expropriated and sent back to Spain in fleets of gold- and silver-laden galleons,\" the gold and silver originating mostly from mines in Central and South America. Turquoise dated at 700 AD was mined in pre-Columbian America; in the Cerillos Mining District in New Mexico, estimates are that \"about 15,000 tons of rock had been removed from Mt. Chalchihuitl using stone tools before 1700.\"\n\nIn 1727, Louis Denys (Denis) (1675–1741), sieur de La Ronde – brother of Simon-Pierre Denys de Bonaventure and the son-in-law of René Chartier – took command of Fort La Pointe at Chequamegon Bay; where natives informed him of an island of copper. La Ronde obtained permission from the French crown to operate mines in 1733, becoming \"the first practical miner on Lake Superior\"; seven years later, mining was halted by an outbreak between Sioux and Chippewa tribes.\n\nMining in the United States became prevalent in the 19th century, and the General Mining Act of 1872 was passed to encourage mining of federal lands. As with the California Gold Rush in the mid-19th century, mining for minerals and precious metals, along with ranching, was a driving factor in the Westward Expansion to the Pacific coast. With the exploration of the West, mining camps were established and \"expressed a distinctive spirit, an enduring legacy to the new nation;\" Gold Rushers would experience the same problems as the Land Rushers of the transient West that preceded them. Aided by railroads, many traveled West for work opportunities in mining. Western cities such as Denver and Sacramento originated as mining towns.\n\nWhen new areas were explored, it was usually the gold (placer and then lode) and then silver that were taken into possession and extracted first. Other metals would often wait for railroads or canals, as coarse gold dust and nuggets do not require smelting and are easy to identify and transport.\n\nIn the early 20th century, the gold and silver rush to the western United States also stimulated mining for coal as well as base metals such as copper, lead, and iron. Areas in modern Montana, Utah, Arizona, and later Alaska became predominate suppliers of copper to the world, which was increasingly demanding copper for electrical and households goods. Canada's mining industry grew more slowly than did the United States' due to limitations in transportation, capital, and U.S. competition; Ontario was the major producer of the early 20th century with nickel, copper, and gold.\n\nMeanwhile, Australia experienced the Australian gold rushes and by the 1850s was producing 40% of the world's gold, followed by the establishment of large mines such as the Mount Morgan Mine, which ran for nearly a hundred years, Broken Hill ore deposit (one of the largest zinc-lead ore deposits), and the iron ore mines at Iron Knob. After declines in production, another boom in mining occurred in the 1960s. Now, in the early 21st century, Australia remains a major world mineral producer.\n\nAs the 21st century begins, a globalized mining industry of large multinational corporations has arisen. Peak minerals and environmental impacts have also become a concern. Different elements, particularly rare earth minerals, have begun to increase in demand as a result of new technologies.\n\nThe process of mining from discovery of an ore body through extraction of minerals and finally to returning the land to its natural state consists of several distinct steps. The first is discovery of the ore body, which is carried out through prospecting or exploration to find and then define the extent, location and value of the ore body. This leads to a mathematical resource estimation to estimate the size and grade of the deposit.\n\nThis estimation is used to conduct a pre-feasibility study to determine the theoretical economics of the ore deposit. This identifies, early on, whether further investment in estimation and engineering studies is warranted and identifies key risks and areas for further work. The next step is to conduct a feasibility study to evaluate the financial viability, the technical and financial risks, and the robustness of the project.\n\nThis is when the mining company makes the decision whether to develop the mine or to walk away from the project. This includes mine planning to evaluate the economically recoverable portion of the deposit, the metallurgy and ore recoverability, marketability and payability of the ore concentrates, engineering concerns, milling and infrastructure costs, finance and equity requirements, and an analysis of the proposed mine from the initial excavation all the way through to reclamation. The proportion of a deposit that is economically recoverable is dependent on the enrichment factor of the ore in the area.\n\nTo gain access to the mineral deposit within an area it is often necessary to mine through or remove waste material which is not of immediate interest to the miner. The total movement of ore and waste constitutes the mining process. Often more waste than ore is mined during the life of a mine, depending on the nature and location of the ore body. Waste removal and placement is a major cost to the mining operator, so a detailed characterization of the waste material forms an essential part of the geological exploration program for a mining operation.\n\nOnce the analysis determines a given ore body is worth recovering, development begins to create access to the ore body. The mine buildings and processing plants are built, and any necessary equipment is obtained. The operation of the mine to recover the ore begins and continues as long as the company operating the mine finds it economical to do so. Once all the ore that the mine can produce profitably is recovered, reclamation begins to make the land used by the mine suitable for future use.\n\nMining techniques can be divided into two common excavation types: surface mining and sub-surface (underground) mining. Today, surface mining is much more common, and produces, for example, 85% of minerals (excluding petroleum and natural gas) in the United States, including 98% of metallic ores.\n\nTargets are divided into two general categories of materials: \"placer deposits\", consisting of valuable minerals contained within river gravels, beach sands, and other unconsolidated materials; and \"lode deposits\", where valuable minerals are found in veins, in layers, or in mineral grains generally distributed throughout a mass of actual rock. Both types of ore deposit, placer or lode, are mined by both surface and underground methods.\n\nSome mining, including much of the rare earth elements and uranium mining, is done by less-common methods, such as in-situ leaching: this technique involves digging neither at the surface nor underground. The extraction of target minerals by this technique requires that they be soluble, e.g., potash, potassium chloride, sodium chloride, sodium sulfate, which dissolve in water. Some minerals, such as copper minerals and uranium oxide, require acid or carbonate solutions to dissolve.\n\nSurface mining is done by removing (stripping) surface vegetation, dirt, and, if necessary, layers of bedrock in order to reach buried ore deposits. Techniques of surface mining include: open-pit mining, which is the recovery of materials from an open pit in the ground, quarrying, identical to open-pit mining except that it refers to sand, stone and clay; strip mining, which consists of stripping surface layers off to reveal ore/seams underneath; and mountaintop removal, commonly associated with coal mining, which involves taking the top of a mountain off to reach ore deposits at depth. Most (but not all) placer deposits, because of their shallowly buried nature, are mined by surface methods. Finally, landfill mining involves sites where landfills are excavated and processed. Landfill mining has been thought of as a solution to dealing with long-term methane emissions and local pollution\n\nHigh wall mining is another form of surface mining that evolved from auger mining. In high wall mining, the coal seam is penetrated by a continuous miner propelled by a hydraulic Push-beam Transfer Mechanism (PTM). A typical cycle includes sumping (launch-pushing forward) and shearing (raising and lowering the cutter-head boom to cut the entire height of the coal seam). As the coal recovery cycle continues, the cutter-head is progressively launched into the coal seam for 19.72 feet (6.01 m). Then, the Push-beam Transfer Mechanism (PTM) automatically inserts a 19.72-foot (6.01 m) long rectangular Push-beam (Screw-Conveyor Segment) into the center section of the machine between the Powerhead and the cutter-head. The Push-beam system can penetrate nearly 1,000 feet (300 m) into the coal seam. One patented high wall mining system uses augers enclosed inside the Push-beam that prevent the mined coal from being contaminated by rock debris during the conveyance process. Using a video imaging and/or a gamma ray sensor and/or other Geo-Radar systems like a coal-rock interface detection sensor (CID), the operator can see ahead projection of the seam-rock interface and guide the continuous miner's progress. High wall mining can produce thousands of tons of coal in contour-strip operations with narrow benches, previously mined areas, trench mine applications and steep-dip seams with controlled water-inflow pump system and/or a gas (inert) venting system.\n\nSub-surface mining consists of digging tunnels or shafts into the earth to reach buried ore deposits. Ore, for processing, and waste rock, for disposal, are brought to the surface through the tunnels and shafts. Sub-surface mining can be classified by the type of access shafts used, and the extraction method or the technique used to reach the mineral deposit. Drift mining utilizes horizontal access tunnels, slope mining uses diagonally sloping access shafts, and shaft mining utilizes vertical access shafts. Mining in hard and soft rock formations require different techniques.\n\nOther methods include shrinkage stope mining, which is mining upward, creating a sloping underground room, long wall mining, which is grinding a long ore surface underground, and room and pillar mining, which is removing ore from rooms while leaving pillars in place to support the roof of the room. Room and pillar mining often leads to retreat mining, in which supporting pillars are removed as miners retreat, allowing the room to cave in, thereby loosening more ore. Additional sub-surface mining methods include hard rock mining, which is mining of hard rock (igneous, metamorphic or sedimentary) materials, bore hole mining, drift and fill mining, long hole slope mining, sub level caving, and block caving.\n\nHeavy machinery is used in mining to explore and develop sites, to remove and stockpile overburden, to break and remove rocks of various hardness and toughness, to process the ore, and to carry out reclamation projects after the mine is closed. Bulldozers, drills, explosives and trucks are all necessary for excavating the land. In the case of placer mining, unconsolidated gravel, or alluvium, is fed into machinery consisting of a hopper and a shaking screen or trommel which frees the desired minerals from the waste gravel. The minerals are then concentrated using sluices or jigs.\n\nLarge drills are used to sink shafts, excavate stopes, and obtain samples for analysis. Trams are used to transport miners, minerals and waste. Lifts carry miners into and out of mines, and move rock and ore out, and machinery in and out, of underground mines. Huge trucks, shovels and cranes are employed in surface mining to move large quantities of overburden and ore. Processing plants utilize large crushers, mills, reactors, roasters and other equipment to consolidate the mineral-rich material and extract the desired compounds and metals from the ore.\n\nOnce the mineral is extracted, it is often then processed. The science of extractive metallurgy is a specialized area in the science of metallurgy that studies the extraction of valuable metals from their ores, especially through chemical or mechanical means.\n\nMineral processing (or mineral dressing) is a specialized area in the science of metallurgy that studies the mechanical means of crushing, grinding, and washing that enable the separation (extractive metallurgy) of valuable metals or minerals from their gangue (waste material). Processing of placer ore material consists of gravity-dependent methods of separation, such as sluice boxes. Only minor shaking or washing may be necessary to disaggregate (unclump) the sands or gravels before processing. Processing of ore from a lode mine, whether it is a surface or subsurface mine, requires that the rock ore be crushed and pulverized before extraction of the valuable minerals begins. After lode ore is crushed, recovery of the valuable minerals is done by one, or a combination of several, mechanical and chemical techniques.\n\nSince most metals are present in ores as oxides or sulfides, the metal needs to be reduced to its metallic form. This can be accomplished through chemical means such as smelting or through electrolytic reduction, as in the case of aluminium. Geometallurgy combines the geologic sciences with extractive metallurgy and mining.\n\nIn 2018, led by Chemistry and Biochemistry professor Bradley D. Smith, University of Notre Dame researchers \"invented a new class of molecules whose shape and size enable them to capture and contain precious metal ions,\" reported in a study published by the Journal of the American Chemical Society. The new method \"converts gold-containing ore into chloroauric acid and extracts it using an industrial solvent. The container molecules are able to selectively separate the gold from the solvent without the use of water stripping.\" The newly developed molecules can eliminate water stripping, whereas mining traditionally \"relies on a 125-year-old method that treats gold-containing ore with large quantities of poisonous sodium cyanide... this new process has a milder environmental impact and that, besides gold, it can be used for capturing other metals such as platinum and palladium,\" and could also be used in urban mining processes that remove precious metals from wastewater streams.\n\nEnvironmental issues can include erosion, formation of sinkholes, loss of biodiversity, and contamination of soil, groundwater and surface water by chemicals from mining processes. In some cases, additional forest logging is done in the vicinity of mines to create space for the storage of the created debris and soil. Contamination resulting from leakage of chemicals can also affect the health of the local population if not properly controlled. Extreme examples of pollution from mining activities include coal fires, which can last for years or even decades, producing massive amounts of environmental damage.\n\nMining companies in most countries are required to follow stringent environmental and rehabilitation codes in order to minimize environmental impact and avoid impacting human health. These codes and regulations all require the common steps of environmental impact assessment, development of environmental management plans, mine closure planning (which must be done before the start of mining operations), and environmental monitoring during operation and after closure. However, in some areas, particularly in the developing world, government regulations may not be well enforced.\n\nFor major mining companies and any company seeking international financing, there are a number of other mechanisms to enforce environmental standards. These generally relate to financing standards such as the Equator Principles, IFC environmental standards, and criteria for Socially responsible investing. Mining companies have used this oversight from the financial sector to argue for some level of industry self-regulation. In 1992, a Draft Code of Conduct for Transnational Corporations was proposed at the Rio Earth Summit by the UN Centre for Transnational Corporations (UNCTC), but the Business Council for Sustainable Development (BCSD) together with the International Chamber of Commerce (ICC) argued successfully for self-regulation instead.\n\nThis was followed by the Global Mining Initiative which was begun by nine of the largest metals and mining companies and which led to the formation of the International Council on Mining and Metals, whose purpose was to \"act as a catalyst\" in an effort to improve social and environmental performance in the mining and metals industry internationally. The mining industry has provided funding to various conservation groups, some of which have been working with conservation agendas that are at odds with an emerging acceptance of the rights of indigenous people – particularly the right to make land-use decisions.\n\nCertification of mines with good practices occurs through the International Organization for Standardization (ISO). For example, ISO 9000 and ISO 14001, which certify an \"auditable environmental management system\", involve short inspections, although they have been accused of lacking rigor. Certification is also available through Ceres' Global Reporting Initiative, but these reports are voluntary and unverified. Miscellaneous other certification programs exist for various projects, typically through nonprofit groups.\n\nThe purpose of a 2012 EPS PEAKS paper was to provide evidence on policies managing ecological costs and maximise socio-economic benefits of mining using host country regulatory initiatives. It found existing literature suggesting donors encourage developing countries to:\n\nOre mills generate large amounts of waste, called tailings. For example, 99 tons of waste are generated per ton of copper, with even higher ratios in gold mining – because only 5.3 g of gold is extracted per ton of ore, a ton of gold produces 200,000 tons of tailings. (As time goes on and richer deposits are exhausted – and technology improves to permit – this number is going down to .5 g and less.) These tailings can be toxic. Tailings, which are usually produced as a slurry, are most commonly dumped into ponds made from naturally existing valleys. These ponds are secured by impoundments (dams or embankment dams). In 2000 it was estimated that 3,500 tailings impoundments existed, and that every year, 2 to 5 major failures and 35 minor failures occurred; for example, in the Marcopper mining disaster at least 2 million tons of tailings were released into a local river. In 2015, Barrick Gold spilled over 1 million liters of cyanide into a total of five rivers in Argentina near their Veladero mine. In central Finland, Talvivaara Terrafame polymetal mine waste effluent since 2008 and numerous leaks of saline mine water has resulted in ecological collapse of nearby lake. Subaqueous tailings disposal is another option. The mining industry has argued that submarine tailings disposal (STD), which disposes of tailings in the sea, is ideal because it avoids the risks of tailings ponds; although the practice is illegal in the United States and Canada, it is used in the developing world.\n\nThe waste is classified as either sterile or mineralised, with acid generating potential, and the movement and storage of this material forms a major part of the mine planning process. When the mineralised package is determined by an economic cut-off, the near-grade mineralised waste is usually dumped separately with view to later treatment should market conditions change and it becomes economically viable. Civil engineering design parameters are used in the design of the waste dumps, and special conditions apply to high-rainfall areas and to seismically active areas. Waste dump designs must meet all regulatory requirements of the country in whose jurisdiction the mine is located. It is also common practice to rehabilitate dumps to an internationally acceptable standard, which in some cases means that higher standards than the local regulatory standard are applied.\n\nMany mining sites are remote and not connected to the grid. Electricity is typically generated with diesel generators. Due to high transportation cost and theft during transportation the cost for generating electricity is normally high. Renewable energy applications are becoming an alternative or amendment. Both solar and wind power plants can contribute in saving diesel costs at mining sites. Renewable energy applications have been built at mining sites.\nCost savings can reach up to 70%.\n\nMining exists in many countries. London is known as the capital of global \"mining houses\" such as Rio Tinto Group, BHP Billiton, and Anglo American PLC. The US mining industry is also large, but it is dominated by the coal and other nonmetal minerals (e.g., rock and sand), and various regulations have worked to reduce the significance of mining in the United States. In 2007 the total market capitalization of mining companies was reported at US$962 billion, which compares to a total global market cap of publicly traded companies of about US$50 trillion in 2007. In 2002, Chile and Peru were reportedly the major mining countries of South America. The mineral industry of Africa includes the mining of various minerals; it produces relatively little of the industrial metals copper, lead, and zinc, but according to one estimate has as a percent of world reserves 40% of gold, 60% of cobalt, and 90% of the world's platinum group metals. Mining in India is a significant part of that country's economy. In the developed world, mining in Australia, with BHP Billiton founded and headquartered in the country, and mining in Canada are particularly significant. For rare earth minerals mining, China reportedly controlled 95% of production in 2013.\n\nWhile exploration and mining can be conducted by individual entrepreneurs or small businesses, most modern-day mines are large enterprises requiring large amounts of capital to establish. Consequently, the mining sector of the industry is dominated by large, often multinational, companies, most of them publicly listed. It can be argued that what is referred to as the 'mining industry' is actually two sectors, one specializing in exploration for new resources and the other in mining those resources. The exploration sector is typically made up of individuals and small mineral resource companies, called \"juniors\", which are dependent on venture capital. The mining sector is made up of large multinational companies that are sustained by production from their mining operations. Various other industries such as equipment manufacture, environmental testing, and metallurgy analysis rely on, and support, the mining industry throughout the world. Canadian stock exchanges have a particular focus on mining companies, particularly junior exploration companies through Toronto's TSX Venture Exchange; Canadian companies raise capital on these exchanges and then invest the money in exploration globally. Some have argued that below juniors there exists a substantial sector of illegitimate companies primarily focused on manipulating stock prices.\n\nMining operations can be grouped into five major categories in terms of their respective resources. These are oil and gas extraction, coal mining, metal ore mining, nonmetallic mineral mining and quarrying, and mining support activities. Of all of these categories, oil and gas extraction remains one of the largest in terms of its global economic importance. Prospecting potential mining sites, a vital area of concern for the mining industry, is now done using sophisticated new technologies such as seismic prospecting and remote-sensing satellites. Mining is heavily affected by the prices of the commodity minerals, which are often volatile. The 2000s commodities boom (\"commodities supercycle\") increased the prices of commodities, driving aggressive mining. In addition, the price of gold increased dramatically in the 2000s, which increased gold mining; for example, one study found that conversion of forest in the Amazon increased six-fold from the period 2003–2006 (292 ha/yr) to the period 2006–2009 (1,915 ha/yr), largely due to artisanal mining.\n\nMining companies can be classified based on their size and financial capabilities:\n\nNew regulations and a process of legislative reforms aim to improve the harmonization and stability of the mining sector in mineral-rich countries. New legislation for mining industry in African countries still appears to be an issue, but has the potential to be solved, when a consensus is reached on the best approach. By the beginning of the 21st century the booming and increasingly complex mining sector in mineral-rich countries was providing only slight benefits to local communities, especially in given the sustainability issues. Increasing debate and influence by NGOs and local communities called for a new approaches which would also include disadvantaged communities, and work towards sustainable development even after mine closure (including transparency and revenue management). By the early 2000s, community development issues and resettlements became mainstream concerns in World Bank mining projects. Mining-industry expansion after mineral prices increased in 2003 and also potential fiscal revenues in those countries created an omission in the other economic sectors in terms of finances and development. Furthermore, this highlighted regional and local demand for mining revenues and an inability of sub-national governments to effectively use the revenues. The Fraser Institute (a Canadian think tank) has highlighted the environmental protection laws in developing countries, as well as voluntary efforts by mining companies to improve their environmental impact.\n\nIn 2007 the Extractive Industries Transparency Initiative (EITI) was mainstreamed in all countries cooperating with the World Bank in mining industry reform. The EITI operates and was implemented with the support of the EITI multi-donor trust fund, managed by the World Bank. The EITI aims to increase transparency in transactions between governments and companies in extractive industries by monitoring the revenues and benefits between industries and recipient governments. The entrance process is voluntary for each country and is monitored by multiple stakeholders including governments, private companies and civil society representatives, responsible for disclosure and dissemination of the reconciliation report; however, the competitive disadvantage of company-by company public report is for some of the businesses in Ghana at least, the main constraint. Therefore, the outcome assessment in terms of failure or success of the new EITI regulation does not only \"rest on the government's shoulders\" but also on civil society and companies.\n\nOn the other hand, implementation has issues; inclusion or exclusion of artisanal mining and small-scale mining (ASM) from the EITI and how to deal with \"non-cash\" payments made by companies to subnational governments. Furthermore, the disproportionate revenues the mining industry can bring to the comparatively small number of people that it employs, causes other problems, like a lack of investment in other less lucrative sectors, leading to swings in government revenuebecause of volatility in the oil markets. Artisanal mining is clearly an issue in EITI Countries such as the Central African Republic, D.R. Congo, Guinea, Liberia and Sierra Leone – i.e. almost half of the mining countries implementing the EITI. Among other things, limited scope of the EITI involving disparity in terms of knowledge of the industry and negotiation skills, thus far flexibility of the policy (e.g. liberty of the countries to expand beyond the minimum requirements and adapt it to their needs), creates another risk of unsuccessful implementation. Public awareness increase, where government should act as a bridge between public and initiative for a successful outcome of the policy is an important element to be considered.\n\nThe World Bank has been involved in mining since 1955, mainly through grants from its International Bank for Reconstruction and Development, with the Bank's Multilateral Investment Guarantee Agency offering political risk insurance. Between 1955 and 1990 it provided about $2 billion to fifty mining projects, broadly categorized as reform and rehabilitation, greenfield mine construction, mineral processing, technical assistance, and engineering. These projects have been criticized, particularly the Ferro Carajas project of Brazil, begun in 1981. The World Bank established mining codes intended to increase foreign investment; in 1988 it solicited feedback from 45 mining companies on how to increase their involvement.\n\nIn 1992 the World Bank began to push for privatization of government-owned mining companies with a new set of codes, beginning with its report \"The Strategy for African Mining\". In 1997, Latin America's largest miner Companhia Vale do Rio Doce (CVRD) was privatized. These and other developments such as the Philippines 1995 Mining Act led the bank to publish a third report (\"Assistance for Minerals Sector Development and Reform in Member Countries\") which endorsed mandatory environment impact assessments and attention to the concerns of the local population. The codes based on this report are influential in the legislation of developing nations. The new codes are intended to encourage development through tax holidays, zero custom duties, reduced income taxes, and related measures. The results of these codes were analyzed by a group from the University of Quebec, which concluded that the codes promote foreign investment but \"fall very short of permitting sustainable development\". The observed negative correlation between natural resources and economic development is known as the resource curse.\n\nSafety has long been a concern in the mining business, especially in sub-surface mining. The Courrières mine disaster, Europe's worst mining accident, involved the death of 1,099 miners in Northern France on March 10, 1906. This disaster was surpassed only by the Benxihu Colliery accident in China on April 26, 1942, which killed 1,549 miners. While mining today is substantially safer than it was in previous decades, mining accidents still occur. Government figures indicate that 5,000 Chinese miners die in accidents each year, while other reports have suggested a figure as high as 20,000. Mining accidents continue worldwide, including accidents causing dozens of fatalities at a time such as the 2007 Ulyanovskaya Mine disaster in Russia, the 2009 Heilongjiang mine explosion in China, and the 2010 Upper Big Branch Mine disaster in the United States. Mining has been identified by the National Institute for Occupational Safety and Health (NIOSH) as a priority industry sector in the National Occupational Research Agenda (NORA) to identify and provide intervention strategies regarding occupational health and safety issues. The Mining Safety and Health Administration (MSHA) was established in 1978 to \"work to prevent death, illness, and injury from mining and promote safe and healthful workplaces for US miners.\" Since its implementation in 1978, the number of miner fatalities has decreased from 242 miners in 1978 to 28 miners in 2015.\n\nThere are numerous occupational hazards associated with mining, including exposure to rockdust which can lead to diseases such as silicosis, asbestosis, and pneumoconiosis. Gases in the mine can lead to asphyxiation and could also be ignited. Mining equipment can generate considerable noise, putting workers at risk for hearing loss. Cave-ins, rock falls, and exposure to excess heat are also known hazards. The current NIOSH Recommended Exposure Limit (REL) of noise is 85 dBA with a 3 dBA exchange rate and the MSHA Permissible Exposure Limit (PEL) is 90 dBA with a 5 dBA exchange rate as an 8-hour time-weighted average. NIOSH has found that 25% of noise-exposed workers in Mining, Quarrying, and Oil and Gas Extraction have hearing impairment. The prevalence of hearing loss increased by 1% from 1991-2001 within these workers.\n\nNoise studies have been conducted in several mining environments. Stageloaders (84-102 dBA), shearers (85-99 dBA), auxiliary fans (84–120 dBA), continuous mining machines (78–109 dBA), and roof bolters (92–103 dBA) represent some of the noisiest equipment in underground coal mines. Dragline oilers, dozer operators, and welders using air arcing were occupations with the highest noise exposures among surface coal miners. Coal mines had the highest hearing loss injury likelihood.\n\nProper ventilation, hearing protection, and spraying equipment with water are important safety practices in mines.\n\nAs of 2008, the deepest mine in the world is TauTona in Carletonville, South Africa, at , replacing the neighboring Savuka Mine in the North West Province of South Africa at . East Rand Mine in Boksburg, South Africa briefly held the record at , and the first mine declared the deepest in the world was also TauTona when it was at .\n\nThe Moab Khutsong gold mine in North West Province (South Africa) has the world's longest winding steel wire rope, which is able to lower workers to in one uninterrupted four-minute journey.\n\nThe deepest mine in Europe is the 16th shaft of the uranium mines in Příbram, Czech Republic, at , second is Bergwerk Saar in Saarland, Germany, at . \n\nThe deepest open-pit mine in the world is Bingham Canyon Mine in Bingham Canyon, Utah, United States, at over . The largest and second deepest open-pit copper mine in the world is Chuquicamata in northern Chile at , which annually produces 443,000 tons of copper and 20,000 tons of molybdenum. \n\nThe deepest open-pit mine with respect to sea level is Tagebau Hambach in Germany, where the base of the pit is below sea level.\n\nThe largest underground mine is Kiirunavaara Mine in Kiruna, Sweden. With of roads, 40 million tonnes of annually produced ore, and a depth of , it is also one of the most modern underground mines. The deepest borehole in the world is Kola Superdeep Borehole at , but this is connected to scientific drilling, not mining.\n\nDuring the 20th century, the variety of metals used in society grew rapidly. Today, the development of major nations such as China and India and advances in technologies are fueling an ever-greater demand. The result is that metal mining activities are expanding and more and more of the world's metal stocks are above ground in use rather than below ground as unused reserves. An example is the in-use stock of copper. Between 1932 and 1999, copper in use in the US rose from to per person.\n\n95% of the energy used to make aluminium from bauxite ore is saved by using recycled material. However, levels of metals recycling are generally low. In 2010, the International Resource Panel, hosted by the United Nations Environment Programme (UNEP), published reports on metal stocks that exist within society and their recycling rates.\n\nThe report's authors observed that the metal stocks in society can serve as huge mines above ground. However, they warned that the recycling rates of some rare metals used in applications such as mobile phones, battery packs for hybrid cars, and fuel cells are so low that unless future end-of-life recycling rates are dramatically stepped up these critical metals will become unavailable for use in modern technology.\n\nAs recycling rates are low and so much metal has already been extracted, some landfills now contain a higher concentrations of metal than mines themselves. This is especially true of aluminium, used in cans, and precious metals, found in discarded electronics. Furthermore, waste after 15 years has still not broken down, so less processing would be required when compared to mining ores. A study undertaken by Cranfield University has found £360 million of metals could be mined from just 4 landfill sites. There is also up to 20MJ/kg of energy in waste, potentially making the re-extraction more profitable. However, although the first landfill mine opened in Tel Aviv, Israel in 1953, little work has followed due to the abundance of accessible ores.\n\n\n"}
{"id": "195137", "url": "https://en.wikipedia.org/wiki?curid=195137", "title": "Oil refinery", "text": "Oil refinery\n\nAn oil refinery or petroleum refinery is an industrial process plant where crude oil is transformed and refined into more useful products such as petroleum naphtha, gasoline, diesel fuel, asphalt base, heating oil, kerosene, liquefied petroleum gas, jet fuel and fuel oils. Petrochemicals feed stock like ethylene and propylene can also be produced directly by cracking crude oil without the need of using refined products of crude oil such as naphtha.\n\nOil refineries are typically large, sprawling industrial complexes with extensive piping running throughout, carrying streams of fluids between large chemical processing units, such as distillation columns. In many ways, oil refineries use much of the technology, and can be thought of, as types of chemical plants.\n\nThe crude oil feedstock has typically been processed by an oil production plant. There is usually an oil depot at or near an oil refinery for the storage of incoming crude oil feedstock as well as bulk liquid products.\n\nPetroleum refineries are very large industrial complexes that involve many different processing units and auxiliary facilities such as utility units and storage tanks. Each refinery has its own unique arrangement and combination of refining processes largely determined by the refinery location, desired products and economic considerations.\n\nAn oil refinery is considered an essential part of the downstream side of the petroleum industry.\n\nSome modern petroleum refineries process as much as 800,000 to 900,000 barrels (127,000 to 143,000 cubic meters) of crude oil per day.\n\nAccording to the Oil and Gas Journal in the world a total of 636 refineries were operated on the 31 December 2014 for a total capacity of .\n\nJamnagar Refinery is the largest oil refinery, since 25 December 2008, with a processing capacity of . Located in Gujarat, India, it is owned by Reliance Industries.\n\nThe Chinese were among the first civilizations to refine oil. As early as the first century, the Chinese were refining crude oil for use as an energy source. Between 512 and 518, in the late Northern Wei Dynasty, the Chinese geographer, writer and politician Li Daoyuan introduced the process of refining oil into various lubricants in his famous work \"Commentary on the Water Classic\".\n\nCrude oil was often distilled by Arab chemists, with clear descriptions given in Arabic handbooks such as those of Muhammad ibn Zakarīya Rāzi (854–925). The streets of Baghdad were paved with tar, derived from petroleum that became accessible from natural fields in the region. In the 9th century, oil fields were exploited in the area around modern Baku, Azerbaijan. These fields were described by the Arab geographer Abu al-Hasan 'Alī al-Mas'ūdī in the 10th century, and by Marco Polo in the 13th century, who described the output of those wells as hundreds of shiploads. Arab and Persian chemists also distilled crude oil in order to produce flammable products for military purposes. Through Islamic Spain, distillation became available in Western Europe by the 12th century.\n\nIn the Northern Song Dynasty (960–1127), a workshop called the \"Fierce Oil Workshop\", was established in the city of Kaifeng to produce refined oil for the Song military as a weapon. The troops would then fill iron cans with refined oil and throw them toward the enemy troops, causing a fire – effectively the world's first \"fire bomb\". The workshop was one of the world's earliest oil refining factories where thousands of people worked to produce Chinese oil powered weaponry.\n\nPrior to the nineteenth century, petroleum was known and utilized in various fashions in Babylon, Egypt, China, Philippines, Rome and Azerbaijan. However, the modern history of the petroleum industry is said to have begun in 1846 when Abraham Gessner of Nova Scotia, Canada devised a process to produce kerosene from coal. Shortly thereafter, in 1854, Ignacy Łukasiewicz began producing kerosene from hand-dug oil wells near the town of Krosno, Poland. \n\nThe world's first systematic petroleum refinery was built in Ploiești, Romania in 1856 using the abundant oil available in Romania.\n\nIn North America, the first oil well was drilled in 1858 by James Miller Williams in Oil Springs, Ontario, Canada. In the United States, the petroleum industry began in 1859 when Edwin Drake found oil near Titusville, Pennsylvania. The industry grew slowly in the 1800s, primarily producing kerosene for oil lamps. In the early twentieth century, the introduction of the internal combustion engine and its use in automobiles created a market for gasoline that was the impetus for fairly rapid growth of the petroleum industry. The early finds of petroleum like those in Ontario and Pennsylvania were soon outstripped by large oil \"booms\" in Oklahoma, Texas and California.\n\nSamuel Kier established America's first oil refinery in Pittsburgh on Seventh avenue near Grant Street, in 1853. Polish pharmacist and inventor Ignacy Łukasiewicz established an oil refinery in Jasło, then part of the Austro-Hungarian Empire (now in Poland) in 1854. The first large refinery opened at Ploiești, Romania, in 1856–1857. After being taken over by Nazi Germany, the Ploiești refineries were bombed in Operation Tidal Wave by the Allies during the Oil Campaign of World War II. Another close contender for the title of hosting the world's oldest oil refinery is Salzbergen in Lower Saxony, Germany. Salzbergen's refinery was opened in 1860.\n\nAt one point, the refinery in Ras Tanura, Saudi Arabia owned by Saudi Aramco was claimed to be the largest oil refinery in the world. For most of the 20th century, the largest refinery was the Abadan Refinery in Iran. This refinery suffered extensive damage during the Iran–Iraq War. Since 25 December 2008, the world's largest refinery complex is the Jamnagar Refinery Complex, consisting of two refineries side by side operated by Reliance Industries Limited in Jamnagar, India with a combined production capacity of . PDVSA's Paraguaná Refinery Complex in Paraguaná Peninsula, Venezuela with a capacity of and SK Energy's Ulsan in South Korea with are the second and third largest, respectively.\n\nPrior to World War II in the early 1940s, most petroleum refineries in the United States consisted simply of crude oil distillation units (often referred to as atmospheric crude oil distillation units). Some refineries also had vacuum distillation units as well as thermal cracking units such as visbreakers (viscosity breakers, units to lower the viscosity of the oil). All of the many other refining processes discussed below were developed during the war or within a few years after the war. They became commercially available within 5 to 10 years after the war ended and the worldwide petroleum industry experienced very rapid growth. The driving force for that growth in technology and in the number and size of refineries worldwide was the growing demand for automotive gasoline and aircraft fuel.\n\nIn the United States, for various complex economic and political reasons, the construction of new refineries came to a virtual stop in about the 1980s. However, many of the existing refineries in the United States have revamped many of their units and/or constructed add-on units in order to: increase their crude oil processing capacity, increase the octane rating of their product gasoline, lower the sulfur content of their diesel fuel and home heating fuels to comply with environmental regulations and comply with environmental air pollution and water pollution requirements.\n\nThe size of oil refining market in 2017 was valued over USD 6 trillion in 2017 and is set to witness a consumption of over 100 million barrels per day (MBPD) by 2024. Oil refining market will witness an appreciable growth because of rapid industrialization and economic transformation. Changing demographics, growing population and improvement in living standards across developing nations are some of factors positively influencing the industry landscape.\n\nIn the 19th century, refineries in the U.S. processed crude oil primarily to recover the kerosene. There was no market for the more volatile fraction, including gasoline, which was considered waste and was often dumped directly into the nearest river. The invention of the automobile shifted the demand to gasoline and diesel, which remain the primary refined products today.\n\nToday, national and state legislation require refineries to meet stringent air and water cleanliness standards. In fact, oil companies in the U.S. perceive obtaining a permit to build a modern refinery to be so difficult and costly that no new refineries were built (though many have been expanded) in the U.S. from 1976 until 2014, when the small Dakota Prairie Refinery in North Dakota began operation. More than half the refineries that existed in 1981 are now closed due to low utilization rates and accelerating mergers. As a result of these closures total US refinery capacity fell between 1981 and 1995, though the operating capacity stayed fairly constant in that time period at around . Increases in facility size and improvements in efficiencies have offset much of the lost physical capacity of the industry. In 1982 (the earliest data provided), the United States operated 301 refineries with a combined capacity of of crude oil each calendar day. In 2010, there were 149 operable U.S. refineries with a combined capacity of per calendar day. By 2014 the number of refinery had reduced to 140 but the total capacity increased to per calendar day. Indeed, in order to reduce operating costs and depreciation, refining is operated in fewer sites but of bigger capacity.\n\nIn 2009 through 2010, as revenue streams in the oil business dried up and profitability of oil refineries fell due to lower demand for product and high reserves of supply preceding the economic recession, oil companies began to close or sell the less profitable refineries.\n\nRaw or unprocessed crude oil is not generally useful in industrial applications, although \"light, sweet\" (low viscosity, low sulfur) crude oil has been used directly as a burner fuel to produce steam for the propulsion of seagoing vessels. The lighter elements, however, form explosive vapors in the fuel tanks and are therefore hazardous, especially in warships. Instead, the hundreds of different hydrocarbon molecules in crude oil are separated in a refinery into components that can be used as fuels, lubricants, and feedstocks in petrochemical processes that manufacture such products as plastics, detergents, solvents, elastomers, and fibers such as nylon and polyesters.\n\nPetroleum fossil fuels are burned in internal combustion engines to provide power for ships, automobiles, aircraft engines, lawn mowers, dirt bikes, and other machines. Different boiling points allow the hydrocarbons to be separated by distillation. Since the lighter liquid products are in great demand for use in internal combustion engines, a modern refinery will convert heavy hydrocarbons and lighter gaseous elements into these higher value products.\n\nOil can be used in a variety of ways because it contains hydrocarbons of varying molecular masses, forms and lengths such as paraffins, aromatics, naphthenes (or cycloalkanes), alkenes, dienes, and alkynes. While the molecules in crude oil include different atoms such as sulfur and nitrogen, the hydrocarbons are the most common form of molecules, which are molecules of varying lengths and complexity made of hydrogen and carbon atoms, and a small number of oxygen atoms. The differences in the structure of these molecules account for their varying physical and chemical properties, and it is this variety that makes crude oil useful in a broad range of several applications.\n\nOnce separated and purified of any contaminants and impurities, the fuel or lubricant can be sold without further processing. Smaller molecules such as isobutane and propylene or butylenes can be recombined to meet specific octane requirements by processes such as alkylation, or more commonly, dimerization. The octane grade of gasoline can also be improved by catalytic reforming, which involves removing hydrogen from hydrocarbons producing compounds with higher octane ratings such as aromatics. Intermediate products such as gasoils can even be reprocessed to break a heavy, long-chained oil into a lighter short-chained one, by various forms of cracking such as fluid catalytic cracking, thermal cracking, and hydrocracking. The final step in gasoline production is the blending of fuels with different octane ratings, vapor pressures, and other properties to meet product specifications. Another method for reprocessing and upgrading these intermediate products (residual oils) uses a devolatilization process to separate usable oil from the waste asphaltene material.\n\nOil refineries are large scale plants, processing about a hundred thousand to several hundred thousand barrels of crude oil a day. Because of the high capacity, many of the units operate continuously, as opposed to processing in batches, at steady state or nearly steady state for months to years. The high capacity also makes process optimization and advanced process control very desirable.\n\nPetroleum products are materials derived from crude oil (petroleum) as it is processed in oil refineries. The majority of petroleum is converted to petroleum products, which includes several classes of fuels.\n\nOil refineries also produce various intermediate products such as hydrogen, light hydrocarbons, reformate and pyrolysis gasoline. These are not usually transported but instead are blended or processed further on-site. Chemical plants are thus often adjacent to oil refineries or a number of further chemical processes are integrated into it. For example, light hydrocarbons are steam-cracked in an ethylene plant, and the produced ethylene is polymerized to produce polyethene.\n\nBecause technical reasons and environment protection demand a very low sulfur content in all but the heaviest products, it is transformed to hydrogen sulfide via catalytic hydrodesulfurization and removed from the product stream via amine gas treating. Using the Claus process, hydrogen sulfide is afterwards transformed to elementary sulfur to be sold to the chemical industry. The rather large heat energy freed by this process is directly used in the other parts of the refinery. Often an electrical power plant is combined into the whole refinery process to take up the excess heat.\n\nAccording to the composition of the crude oil and depending on the demands of the market, refineries can produce different shares of petroleum products. The largest share of oil products is used as \"energy carriers\", i.e. various grades of fuel oil and gasoline. These fuels include or can be blended to give gasoline, jet fuel, diesel fuel, heating oil, and heavier fuel oils. Heavier (less volatile) fractions can also be used to produce asphalt, tar, paraffin wax, lubricating and other heavy oils. Refineries also produce other chemicals, some of which are used in chemical processes to produce plastics and other useful materials. Since petroleum often contains a few percent sulfur-containing molecules, elemental sulfur is also often produced as a petroleum product. Carbon, in the form of petroleum coke, and hydrogen may also be produced as petroleum products. The hydrogen produced is often used as an intermediate product for other oil refinery processes such as hydrocracking and hydrodesulfurization.\n\nPetroleum products are usually grouped into four categories: light distillates (LPG, gasoline, naphtha), middle distillates (kerosene, jet fuel, diesel), heavy distillates and residuum (heavy fuel oil, lubricating oils, wax, asphalt). These require blending various feedstocks, mixing appropriate additives, providing short term storage, and preparation for bulk loading to trucks, barges, product ships, and railcars. This classification is based on the way crude oil is distilled and separated into fractions.\n\n\nOver 6,000 items are made from petroleum waste by-products including: fertilizer, floor coverings, perfume, insecticide, petroleum jelly, soap, vitamin capsules. See link to partial list of 144 by-products listed by Ranken Energy \n\n\nThe image below is a schematic flow diagram of a typical oil refinery that depicts the various unit processes and the flow of intermediate product streams that occurs between the inlet crude oil feedstock and the final end products. The diagram depicts only one of the literally hundreds of different oil refinery configurations. The diagram also does not include any of the usual refinery facilities providing utilities such as steam, cooling water, and electric power as well as storage tanks for crude oil feedstock and for intermediate products and end products.\n\nThere are many process configurations other than that depicted above. For example, the vacuum distillation unit may also produce fractions that can be refined into end products such as: spindle oil used in the textile industry, light machinery oil, motor oil, and various waxes.\n\nThe crude oil distillation unit (CDU) is the first processing unit in virtually all petroleum refineries. The CDU distills the incoming crude oil into various fractions of different boiling ranges, each of which are then processed further in the other refinery processing units. The CDU is often referred to as the \"atmospheric distillation unit\" because it operates at slightly above atmospheric pressure.\n\nBelow is a schematic flow diagram of a typical crude oil distillation unit. The incoming crude oil is preheated by exchanging heat with some of the hot, distilled fractions and other streams. It is then desalted to remove inorganic salts (primarily sodium chloride).\n\nFollowing the desalter, the crude oil is further heated by exchanging heat with some of the hot, distilled fractions and other streams. It is then heated in a fuel-fired furnace (fired heater) to a temperature of about 398 °C and routed into the bottom of the distillation unit.\n\nThe cooling and condensing of the distillation tower overhead is provided partially by exchanging heat with the incoming crude oil and partially by either an air-cooled or water-cooled condenser. Additional heat is removed from the distillation column by a pumparound system as shown in the diagram below.\n\nAs shown in the flow diagram, the overhead distillate fraction from the distillation column is naphtha. The fractions removed from the side of the distillation column at various points between the column top and bottom are called \"sidecuts\". Each of the sidecuts (i.e., the kerosene, light gas oil and heavy gas oil) is cooled by exchanging heat with the incoming crude oil. All of the fractions (i.e., the overhead naphtha, the sidecuts and the bottom residue) are sent to intermediate storage tanks before being processed further.\n\nA party searching for a site to construct a refinery or a chemical plant needs to consider the following issues:\n\n\nRefineries which use a large amount of steam and cooling water need to have an abundant source of water. Oil refineries therefore are often located nearby navigable rivers or on a sea shore, nearby a port. Such location also gives access to transportation by river or by sea. The advantages of transporting crude oil by pipeline are evident, and oil companies often transport a large volume of fuel to distribution terminals by pipeline. Pipeline may not be practical for products with small output, and rail cars, road tankers, and barges are used.\n\nPetrochemical plants and solvent manufacturing (fine fractionating) plants need spaces for further processing of a large volume of refinery products for further processing, or to mix chemical additives with a product at source rather than at blending terminals.\n\nThe refining process releases a number of different chemicals into the atmosphere (see AP 42 Compilation of Air Pollutant Emission Factors) and a notable odor normally accompanies the presence of a refinery. Aside from air pollution impacts there are also wastewater concerns, risks of industrial accidents such as fire and explosion, and noise health effects due to industrial noise.\n\nMany governments worldwide have mandated restrictions on contaminants that refineries release, and most refineries have installed the equipment needed to comply with the requirements of the pertinent environmental protection regulatory agencies. In the United States, there is strong pressure to prevent the development of new refineries, and no major refinery has been built in the country since Marathon's Garyville, Louisiana facility in 1976. However, many existing refineries have been expanded during that time. Environmental restrictions and pressure to prevent construction of new refineries may have also contributed to rising fuel prices in the United States. Additionally, many refineries (more than 100 since the 1980s) have closed due to obsolescence and/or merger activity within the industry itself.\n\nEnvironmental and safety concerns mean that oil refineries are sometimes located some distance away from major urban areas. Nevertheless, there are many instances where refinery operations are close to populated areas and pose health risks. In California's Contra Costa County and Solano County, a shoreline necklace of refineries, built in the early 20th century before this area was populated, and associated chemical plants are adjacent to urban areas in Richmond, Martinez, Pacheco, Concord, Pittsburg, Vallejo and Benicia, with occasional accidental events that require \"shelter in place\" orders to the adjacent populations. A number of refineries are located in Sherwood Park, Alberta, directly adjacent to the City of Edmonton. The Edmonton metro area has a population of over 1,000,000 residents.\n\nNIOSH criteria for occupational exposure to refined petroleum solvents have been available since 1977.\n\nModern petroleum refining involves a complicated system of interrelated chemical reactions that produce a wide variety of petroleum-based products. Many of these reactions require precise temperature and pressure parameters.  The equipment and monitoring required to ensure the proper progression of these processes is complex, and has evolved through the advancement of the scientific field of petroleum engineering.\n\nThe wide array of high pressure and/or high temperature reactions, along with the necessary chemical additives or extracted contaminants, produces an astonishing number of potential health hazards to the oil refinery worker.  Through the advancement of technical chemical and petroleum engineering, the vast majority of these processes are automated and enclosed, thus greatly reducing the potential health impact to workers.  However, depending on the specific process in which a worker is engaged, as well as the particular method employed by the refinery in which he/she works, significant health hazards remain.\n\nAlthough U.S. occupational injuries were not routinely tracked/reported at the time, reports of the health impacts of working in an oil refinery can be found as early as the 1800s. For instance, an explosion in a Chicago refinery killed 20 workers in 1890. Since then, numerous fires, explosions, and other significant events have from time to time drawn the public's attention to the health of oil refinery workers. Such events continue today, with explosions reported in refineries in Wisconsin and Germany in 2018.\n\nHowever, there are many less visible hazards that endanger oil refinery workers.\n\nGiven the highly automated and technically advanced nature of modern petroleum refineries, nearly all processes are contained within engineering controls and represent a substantially decreased risk of exposure to workers compared to earlier times. However, certain situations or work tasks may subvert these safety mechanisms, and expose workers to a number of chemical (see table above) or physical (described below) hazards. Examples of these scenarios include:\n\n\nInterestingly, even though petroleum refineries utilize and produce chemicals that are known carcinogens, the literature on cancer rates among refinery workers is mixed. For example, benzene has been shown to have a relationship with leukemia, however studies examining benzene exposure and resultant leukemia specifically in the context of oil refinery workers have come to opposing conclusions. Asbestos-related mesothelioma is another particular cancer-carcinogen relationship that has been investigated in the context of oil refinery workers. To date, this work has shown a marginally significant link to refinery employment and mesothelioma. Notably, a meta-analysis which included data on more than 350,000 refinery workers failed to find any statistically significant excess rates of cancer mortality, except for a marginally significant increase in melanoma deaths. An additional U.S.-based study included a follow-up period of 50 years among over 17,000 workers. This study concluded that there was no excess mortality among this cohort as a result of employment \n\nBTX stands for benzene, toluene, xylene. This is a group of common volatile organic compounds (VOC's) that are found in the oil refinery environment, and serve as a paradigm for more in depth discussion of occupational exposure limits, chemical exposure and surveillance among refinery workers.\n\nThe most important route of exposure for BTEX chemicals is inhalation due to the low boiling point of these chemicals. The majority of the gaseous production of BTEX occurs during tank cleaning and fuel transfer, which causes offgassing of these chemicals into the air. Exposure can also occur through ingestion via contaminated water, but this is unlikely in an occupational setting. Dermal exposure and absorption is also possible, but is again less likely in an occupational setting where appropriate personal protective equipment is in place.\n\nOSHA, NIOSH, and ACGIH have all established occupational exposure limits (OEL's) for many of the chemicals above that workers may be exposed to in petroleum refineries.\n\nBenzene, in particular, has multiple biomarkers that can be measured to determine exposure. Benzene itself can be measured in the breath, blood, and urine, and metabolites such as phenol, \"t\",\"t\"-muconic acid (\"t\",\"t\"MA) and S-phenylmercapturic acid (\"s\"PMA) can be measured in urine. In addition to monitoring the exposure levels via these biomarkers, employers are required by OSHA to perform regular blood tests on workers to test for early signs of some of the feared hematologic outcomes, of which the most widely recognized is leukemia. Required testing includes complete blood count with cell differentials and peripheral blood smear \"on a regular basis\". The utility of these tests is supported by formal scientific studies.\n\nWorkers are at risk of physical injuries due to the large number of high-powered machines in the relatively close proximity of the oil refinery.  The high pressure required for many of the chemical reactions also presents the possibility of localized system failures resulting in blunt or penetrating trauma from exploding system components. However, Bureau of Labor (BLS) statistical reports indicate that petroleum refinery workers have a significantly lower rate of occupational injury (0.7 OSHA-recordable cases per 100 full-time workers) than all industries (3.1), oil and gas extraction (1.0), and petroleum manufacturing in general (1.6).\n\nHeat is also a hazard. The temperature required for the proper progression of certain reactions in the refining process can reach 1600 degrees F.  As with chemicals, the operating system is designed to safely contain this hazard without injury to the worker.  However, in system failures this is a potent threat to workers’ health.  Concerns include both direct injury through a heat illness or injury, as well as the potential for devastating burns should the worker come in contact with super-heated reagents/equipment.\n\nNoise is another hazard. Refineries can be very loud environments, and have previously been shown to be associated with hearing loss among workers. The interior environment of an oil refinery can reach levels in excess of 90 dB. An average of 90 dB is the OSHA Permissible Exposure Limit (PEL) for an 8 hour work-day. Noise exposures that average greater than 85 dB over an 8 hour require a hearing conservation program to regularly evaluate workers' hearing and to promote its protection.  Regular evaluation of workers’ auditory capacity and faithful use of properly vetted hearing protection are essential parts of such programs.\n\nWhile not specific to the industry, oil refinery workers may also be at risk for hazards such as vehicle-related accidents, machinery-associated injuries, work in a confined space, explosions/fires, ergonomic hazards, shift-work related sleep disorders, and falls.\n\nThe theory of hierarchy of controls can be applied to petroleum refineries and their efforts to ensure worker safety.\n\nElimination and substitution are unlikely in petroleum refineries, as many of the raw materials, waste products, and finished products are hazardous in one form or another (e.g. flammable, carcinogenic).\n\nExamples of engineering controls include a fire detection/extinguishing system, pressure/chemical sensors to detect/predict loss of structural integrity, and adequate maintenance of piping to prevent hydrocarbon-induced corrosion (leading to structural failure). Other examples employed in petroleum refineries include the post-construction protection of steel components with vermiculite to improve heat/fire resistance. Compartmentalization can help to prevent a fire or other systems failure from spreading to affect other areas of the structure, and may help prevent dangerous reactions by keeping difference chemicals separate from one another until they can be safely combined in the proper environment.\n\nAdministrative controls include careful planning and oversight of the refinery cleaning, maintenance, and turnaround processes. These occur when many of the engineering controls are shut down or suppressed, and may be especially dangerous to workers. Detailed coordination is necessary to ensure that maintenance of one part of the facility will not cause dangerous exposures to those performing the maintenance, or to workers in other areas of the plant. Due to the highly flammable nature of many of the involved chemical, smoking areas are tightly controlled and carefully placed.\n\nPersonal protective equipment may be necessary depending on the specific chemical being processed or produced. Particular care is needed during sampling of the partially-completed product, tank cleaning, and other high-risk tasks as mentioned above. Such activities may require the use of impervious outer wear, acid hood, disposable coveralls, etc. More generally, all personnel in operating areas should use appropriate hearing and vision protection, avoid clothes made of flammable material (nylon, Dacron, acrylic, or blends), and full-length pants/sleeves.\n\nWorker health and safety in oil refineries is closely monitored by both OSHA and NIOSH. CalOSHA has been particularly active in regulating worker health in this industry, and adopted a policy in 2017 that requires petroleum refineries to perform a Hierarchy of Hazard Controls Analysis (see above \"Controls\" section) for each process safety hazard.\n\nBelow is a list of the most common regulations referenced in petroleum refinery safety citations issued by OSHA:\n\n\nCorrosion of metallic components is a major factor of inefficiency in the refining process. Because it leads to equipment failure, it is a primary driver for the refinery maintenance schedule. Corrosion-related direct costs in the U.S. petroleum industry as of 1996 were estimated at US $3.7 billion.\n\nCorrosion occurs in various forms in the refining process, such as pitting corrosion from water droplets, embrittlement from hydrogen, and stress corrosion cracking from sulfide attack. From a materials standpoint, carbon steel is used for upwards of 80 per cent of refinery components, which is beneficial due to its low cost. Carbon steel is resistant to the most common forms of corrosion, particularly from hydrocarbon impurities at temperatures below 205 °C, but other corrosive chemicals and environments prevent its use everywhere. Common replacement materials are low alloy steels containing chromium and molybdenum, with stainless steels containing more chromium dealing with more corrosive environments. More expensive materials commonly used are nickel, titanium, and copper alloys. These are primarily saved for the most problematic areas where extremely high temperatures and/or very corrosive chemicals are present.\n\nCorrosion is fought by a complex system of monitoring, preventative repairs and careful use of materials. Monitoring methods include both offline checks taken during maintenance and online monitoring. Offline checks measure corrosion after it has occurred, telling the engineer when equipment must be replaced based on the historical information they have collected. This is referred to as preventative management.\n\nOnline systems are a more modern development, and are revolutionizing the way corrosion is approached. There are several types of online corrosion monitoring technologies such as linear polarization resistance, electrochemical noise and electrical resistance. Online monitoring has generally had slow reporting rates in the past (minutes or hours) and been limited by process conditions and sources of error but newer technologies can report rates up to twice per minute with much higher accuracy (referred to as real-time monitoring). This allows process engineers to treat corrosion as another process variable that can be optimized in the system. Immediate responses to process changes allow the control of corrosion mechanisms, so they can be minimized while also maximizing production output. In an ideal situation having online corrosion information that is accurate and real-time will allow conditions that cause high corrosion rates to be identified and reduced. This is known as predictive management.\n\nMaterials methods include selecting the proper material for the application. In areas of minimal corrosion, cheap materials are preferable, but when bad corrosion can occur, more expensive but longer lasting materials should be used. Other materials methods come in the form of protective barriers between corrosive substances and the equipment metals. These can be either a lining of refractory material such as standard Portland cement or other special acid-resistant cements that are shot onto the inner surface of the vessel. Also available are thin overlays of more expensive metals that protect cheaper metal against corrosion without requiring lots of material.\n\n\n"}
{"id": "29789", "url": "https://en.wikipedia.org/wiki?curid=29789", "title": "Tourism", "text": "Tourism\n\nTourism is travel for pleasure or business; also the theory and practice of touring, the business of attracting, accommodating, and entertaining tourists, and the business of operating tours. The World Tourism Organization defines tourism more generally, in terms which go \"beyond the common perception of tourism as being limited to holiday activity only\", as people \"traveling to and staying in places outside their usual environment for not more than one consecutive year for leisure and not less than 24 hours, business and other purposes\".\n\nTourism can be domestic (within the traveller's own country) or international, and international tourism has both incoming and outgoing implications on a country's balance of payments.\n\nTourism numbers declined as a result of a strong economic slowdown (the late-2000s recession) between the second half of 2008 and the end of 2009, and in consequence of the outbreak of the 2009 H1N1 influenza virus, but slowly recovered. Globally, international tourism receipts (the travel item in balance of payments) grew to trillion ( billion) in 2005, corresponding to an increase in real terms of 3.8% from 2010. International tourist arrivals surpassed the milestone of 1 billion tourists globally for the first time in 2012, emerging source markets such as China, Russia, and Brazil had significantly increased their spending over the previous decade. The ITB Berlin is the world's leading tourism trade-fair. Global tourism accounts for 8% of global greenhouse-gas emissions.\n\nThe word \"tourist\" was used in 1772 and \"tourism\" in 1811. It is formed from the word \"tour\", which is derived from Old English \"turian\", from Old French \"torner\", from Latin \"tornare\"; 'to turn on a lathe,' which is itself from Ancient Greek \"tornos\" (τόρνος); 'lathe'.\n\nThe tourism industry, as part of the service sector,\nhas become an important source of income for many regions and even for entire countries. The \"Manila Declaration on World Tourism of 1980\" recognized its importance as \"an activity essential to the life of nations because of its direct effects on the social, cultural, educational, and economic sectors of national societies, and on their international relations.\"\n\nTourism brings large amounts of income into a local economy in the form of payment for goods and services needed by tourists, accounting for 30% of the world's trade in services, and, as an invisible export, for 6% of overall exports of goods and services. It also generates opportunities for employment in the service sector of the economy associated with tourism.\n\nThe hospitality industries which benefit from tourism include transportation services (such as airlines, cruise ships, trains and taxicabs); lodging (including hotels, hostels, homestays, resorts and renting out rooms); and entertainment venues (such as amusement parks, restaurants, casinos, shopping malls, music venues, and theatres). This is in addition to goods bought by tourists, including souvenirs.\n\nOn the flip-side, tourism can degrade people\nand sour relationships between host and guest.\n\nIn 1936, the League of Nations defined a \"foreign tourist\" as \"someone traveling abroad for at least twenty-four hours\". Its successor, the United Nations, amended this definition in 1945, by including a maximum stay of six months.\n\nIn 1941, Hunziker and Kraft defined tourism as \"the sum of the phenomena and relationships arising from the travel and stay of non-residents, insofar as they do not lead to permanent residence and are not connected with any earning activity.\" In 1976, the Tourism Society of England's definition was: \"Tourism is the temporary, short-term movement of people to destinations outside the places where they normally live and work and their activities during the stay at each destination. It includes movements for all purposes.\" In 1981, the International Association of Scientific Experts in Tourism defined tourism in terms of particular activities chosen and undertaken outside the home.\n\nIn 1994, the United Nations identified three forms of tourism in its \"Recommendations on Tourism Statistics\":\n\nThe terms \"tourism\" and \"travel\" are sometimes used interchangeably. In this context, travel has a similar definition to tourism but implies a more purposeful journey. The terms \"tourism\" and \"tourist\" are sometimes used pejoratively, to imply a shallow interest in the cultures or locations visited. By contrast, \"traveler\" is often used as a sign of distinction. The sociology of tourism has studied the cultural values underpinning these distinctions and their implications for class relations.\n\nInternational tourist arrivals reached 1.035 billion in 2012, up from over 996 million in 2011, and 952 million in 2010. In 2011 and 2012, international travel demand continued to recover from the losses resulting from the late-2000s recession, where tourism suffered a strong slowdown from the second half of 2008 through the end of 2009. After a 5% increase in the first half of 2008, growth in international tourist arrivals moved into negative territory in the second half of 2008, and ended up only 2% for the year, compared to a 7% increase in 2007. The negative trend intensified during 2009, exacerbated in some countries due to the outbreak of the H1N1 influenza virus, resulting in a worldwide decline of 4.2% in 2009 to 880 million international tourists arrivals, and a 5.7% decline in international tourism receipts.\n\nThe World Tourism Organization reports the following ten destinations as the most visited in terms of the number of international travelers in 2018.\n\nThe World Tourism Organization reports that international tourism receipts were US$1.7 trillion in 2018, an increase in real terms of 4% over 2017. The top ten tourism earners in 2018 were:\n\nThe World Tourism Organization reports the following countries as the ten biggest spenders on international tourism for the year 2018. \n\nEuromonitor International rated these the world's cities most visited by international tourists in 2017:\n\nTravel outside a person's local area for leisure was largely confined to wealthy classes, who at times traveled to distant parts of the world, to see great buildings and works of art, learn new languages, experience new cultures, and to taste different cuisines. As early as Shulgi, however, kings praised themselves for protecting roads and building way stations for travelers. Travelling for pleasure can be seen in Egypt as early on as 1500 BC. During the Roman Republic, spas and coastal resorts such as Baiae were popular among the rich. Pausanias wrote his \"Description of Greece\" in the second century AD. In ancient China, nobles sometimes made a point of visiting Mount Tai and, on occasion, all five Sacred Mountains.\n\nBy the Middle Ages, Christianity and Buddhism and Islam had traditions of pilgrimage. Chaucer's Canterbury Tales and Wu Cheng'en's \"Journey to the West\" remain classics of English and Chinese literature.\n\nThe 10th- to 13th-century Song dynasty also saw secular travel writers such as Su Shi (11th century) and Fan Chengda (12th century) become popular in China. Under the Ming, Xu Xiake continued the practice. In medieval Italy, Francesco Petrarch also wrote an allegorical account of his 1336 ascent of Mount Ventoux that praised the act of traveling and criticized \"frigida incuriositas\" (\"cold lack of curiosity\"). The Burgundian poet later composed his own horrified recollections of a 1430 trip through the Jura Mountains.\n\nModern tourism can be traced to what was known as the Grand Tour, which was a traditional trip around Europe (especially Germany and Italy), undertaken by mainly upper-class European young men of means, mainly from Western and Northern European countries. In 1624, young Prince of Poland, Ladislaus Sigismund Vasa, the eldest son of Sigismund III, embarked for a journey across Europe, as was in custom among Polish nobility. He travelled through territories of today's Germany, Belgium, Netherlands, where he admired the Siege of Breda by Spanish forces, France, Switzerland to Italy, Austria, and the Czech Republic. It was an educational journey and one of the outcomes was introduction of Italian opera in the Polish–Lithuanian Commonwealth.\n\nThe custom flourished from about 1660 until the advent of large-scale rail transit in the 1840s and generally followed a standard itinerary. It was an educational opportunity and rite of passage. Though primarily associated with the British nobility and wealthy landed gentry, similar trips were made by wealthy young men of Protestant Northern European nations on the Continent, and from the second half of the 18th century some South American, US, and other overseas youth joined in. The tradition was extended to include more of the middle class after rail and steamship travel made the journey easier, and Thomas Cook made the \"Cook's Tour\" a byword.\n\nThe Grand Tour became a real status symbol for upper-class students in the 18th and 19th centuries. In this period, Johann Joachim Winckelmann's theories about the supremacy of classic culture became very popular and appreciated in the European academic world. Artists, writers, and travelers (such as Goethe) affirmed the supremacy of classic art of which Italy, France, and Greece provide excellent examples. For these reasons, the Grand Tour's main destinations were to those centers, where upper-class students could find rare examples of classic art and history.\n\n\"The New York Times\" recently described the Grand Tour in this way:\n\nThe primary value of the Grand Tour, it was believed, laid in the exposure both to the cultural legacy of classical antiquity and the Renaissance, and to the aristocratic and fashionably polite society of the European continent.\n\nLeisure travel was associated with the Industrial Revolution in the United Kingdomthe first European country to promote leisure time to the increasing industrial population. Initially, this applied to the owners of the machinery of production, the economic oligarchy, factory owners and traders. These comprised the new middle class. Cox & Kings was the first official travel company to be formed in 1758.\n\nThe British origin of this new industry is reflected in many place names. In Nice, France, one of the first and best-established holiday resorts on the French Riviera, the long esplanade along the seafront is known to this day as the \"Promenade des Anglais\"; in many other historic resorts in continental Europe, old, well-established palace hotels have names like the \"Hotel Bristol\", \"Hotel Carlton\", or \"Hotel Majestic\"reflecting the dominance of English customers.\n\nA pioneer of the travel agency business, Thomas Cook's idea to offer excursions came to him while waiting for the stagecoach on the London Road at Kibworth. With the opening of the extended Midland Counties Railway, he arranged to take a group of 540 temperance campaigners from Leicester Campbell Street station to a rally in Loughborough, away. On 5 July 1841, Thomas Cook arranged for the rail company to charge one shilling per person; this included rail tickets and food for the journey. Cook was paid a share of the fares charged to the passengers, as the railway tickets, being legal contracts between company and passenger, could not have been issued at his own price. This was the first privately chartered excursion train to be advertised to the general public; Cook himself acknowledged that there had been previous, unadvertised, private excursion trains. During the following three summers he planned and conducted outings for temperance societies and Sunday school children. In 1844 the Midland Counties Railway Company agreed to make a permanent arrangement with him, provided he found the passengers. This success led him to start his own business running rail excursions for pleasure, taking a percentage of the railway fares.\n\nIn 1855, he planned his first excursion abroad, when he took a group from Leicester to Calais to coincide with the Paris Exhibition. The following year he started his \"grand circular tours\" of Europe. During the 1860s he took parties to Switzerland, Italy, Egypt, and the United States. Cook established \"inclusive independent travel\", whereby the traveler went independently but his agency charged for travel, food, and accommodation for a fixed period over any chosen route. Such was his success that the Scottish railway companies withdrew their support between 1862 and 1863 to try the excursion business for themselves.\n\nCruising is a popular form of water tourism.\nLeisure cruise ships were introduced by the \"Peninsular & Oriental Steam Navigation Company\" (P&O) in 1844, sailing from Southampton to destinations such as Gibraltar, Malta and Athens. In 1891, German businessman Albert Ballin sailed the ship \"Augusta Victoria\" from Hamburg into the Mediterranean Sea. 29 June 1900 saw the launching of the first purpose-built cruise ship was \"Prinzessin Victoria Luise\", built in Hamburg for the Hamburg America Line.\n\nMany leisure-oriented tourists travel to seaside resorts on their nearest coast or further afield. Coastal areas in the tropics are popular in both summer and winter.\n\nAcademics have defined mass tourism as travel by groups on pre-scheduled tours, usually under the organization of tourism professionals. This form of tourism developed during the second half of the 19th century in the United Kingdom and was pioneered by Thomas Cook. Cook took advantage of Europe's rapidly expanding railway network and established a company that offered affordable day trip excursions to the masses, in addition to longer holidays to Continental Europe, India, Asia and the Western Hemisphere which attracted wealthier customers. By the 1890s over 20,000 tourists per year used Thomas Cook & Son.\n\nThe relationship between tourism companies, transportation operators and hotels is a central feature of mass tourism. Cook was able to offer prices that were below the publicly advertised price because his company purchased large numbers of tickets from railroads. One contemporary form of mass tourism, package tourism, still incorporates the partnership between these three groups.\n\nTravel developed during the early 20th century and was facilitated by the development of the automobiles and later by airplanes.\nImprovements in transport allowed many people to travel quickly to places of leisure interest so that more people could begin to enjoy the benefits of leisure time.\n\nIn Continental Europe, early seaside resorts included: Heiligendamm, founded in 1793 at the Baltic Sea, being the first seaside resort; Ostend, popularised by the people of Brussels; Boulogne-sur-Mer and Deauville for the Parisians; Taormina in Sicily. In the United States, the first seaside resorts in the European style were at Atlantic City, New Jersey and Long Island, New York.\n\nBy the mid-20th century, the Mediterranean Coast became the principal mass tourism destination. The 1960s and 1970s saw mass tourism play a major role in the Spanish economic \"miracle\".\n\nNiche tourism refers to the numerous specialty forms of tourism that have emerged over the years, each with its own adjective. Many of these terms have come into common use by the tourism industry and academics. Others are emerging concepts that may or may not gain popular usage. Examples of the more common niche tourism markets are:\n\n\nOther terms used for niche or specialty travel forms include the term \"destination\" in the descriptions, such as destination weddings, and terms such as location vacation.\n\nSt. Moritz, Switzerland became the cradle of the developing winter tourism in the 1860s: hotel manager Johannes Badrutt invited some summer guests from England to return in the winter to see the snowy landscape, thereby inaugurating a popular trend. It was, however, only in the 1970s when winter tourism took over the lead from summer tourism in many of the Swiss ski resorts. Even in winter, up to one third of all guests (depending on the location) consist of non-skiers.\n\nMajor ski resorts are located mostly in the various European countries (e.g. Andorra, Austria, Bulgaria, Bosnia-Herzegovina, Croatia, Czech Republic, Cyprus, Finland, France, Germany, Greece, Iceland, Italy, Norway, Latvia, Lithuania, Poland, Romania, Serbia, Sweden, Slovakia, Slovenia, Spain, Switzerland, Turkey), Canada, the United States (e.g. Montana, Utah, Colorado, California, Wyoming, Vermont, New Hampshire, New York) Argentina, New Zealand, Japan, South Korea, Chile, and Lebanon.\n\nSome places that already have ski opportunities can also have glaciers in the area. Some of these places that already offer a glacier hike to see these glaciers. One of these places is New Zealand; New Zealand has several glaciers that are available for this experience. The Franz Josef is one of these glaciers that tourism is available. The only way to get to the glacier is via a helicopter. Before helicopters were invented, the way that people were able to get up to the glacier was by hiking up to the glacier. The companies have to make sure that people are safe when they are on the glacier. This would fall under environmental tourism as well as winter tourism. Visits to New Zealand require an eTA from 1 October 2019 which is available online.\n\nThere has been an up-trend in tourism over the last few decades, especially in Europe, where international travel for short breaks is common. Tourists have a wide range of budgets and tastes, and a wide variety of resorts and hotels have developed to cater for them. For example, some people prefer simple beach vacations, while others want more specialized holidays, quieter resorts, family-oriented holidays, or niche market-targeted destination hotels.\n\nThe developments in air transport infrastructure, such as jumbo jets, low-cost airlines, and more accessible airports have made many types of tourism more affordable. The WHO estimated in 2009 that there are around half a million people on board aircraft at any given time. There have also been changes in lifestyle, for example, some retirement-age people sustain year-round tourism. This is facilitated by internet sales of tourist services. Some sites have now started to offer dynamic packaging, in which an inclusive price is quoted for a tailor-made package requested by the customer upon impulse.\n\nThere have been a few setbacks in tourism, such as the September 11 attacks and terrorist threats to tourist destinations, such as in Bali and several European cities. Also, on 26 December 2004, a tsunami, caused by the 2004 Indian Ocean earthquake, hit the Asian countries on the Indian Ocean, including the Maldives. Thousands of lives were lost including many tourists. This, together with the vast clean-up operations, stopped or severely hampered tourism in the area for a time.\n\nIndividual low-price or even zero-price overnight stays have become more popular in the 2000s, especially with a strong growth in the hostel market and services like CouchSurfing and airbnb being established. There has also been examples of jurisdictions wherein a significant portion of GDP is being spent on altering the primary sources of revenue towards tourism, as has occurred for instance in Dubai.\n\n\"Sustainable tourism is envisaged as leading to management of all resources in such a way that economic, social and aesthetic needs can be fulfilled while maintaining cultural integrity, essential ecological processes, biological diversity and life support systems.\" (World Tourism Organization)\n\nSustainable development implies \"meeting the needs of the present without compromising the ability of future generations to meet their own needs.\" (World Commission on Environment and Development, 1987)\n\nAn important part of sustainable tourism is something known as the three pillars of sustainability which include Economic, Environmental/Ecological and Socio-cultural. For a destination to be truly sustainable it must have an equal balance among the three pillars. Economic is in relation to money and making and maintaining a certain amount of cash. Environmental is of course in relation to the environment it looks into whether the local ecosystems can support the influx of visitors and also how these visitors affect the ecosystem. Then finally Socio-cultural is about how well the culture of this area is able to maintain its traditions with the incoming tourists. These pillars are important because they are the true key to being sustainable when discussing tourism.\n\nSustainable tourism can be seen as having regard to ecological and social-cultural carrying capacities and includes involving the community of the destination in tourism development planning (that was done e.g. in Fruška Gora National Park in Serbia). It also involves integrating tourism to match current economic and growth policies so as to mitigate some of the negative economic and social impacts of 'mass tourism'. Murphy (1985) advocates the use of an 'ecological approach', to consider both 'plants' and 'people' when implementing the sustainable tourism development process. This is in contrast to the 'boosterism' and 'economic' approaches to tourism planning, neither of which consider the detrimental ecological or sociological impacts of tourism development to a destination.\n\nHowever, Butler questions the exposition of the term 'sustainable' in the context of tourism, citing its ambiguity and stating that \"the emerging sustainable development philosophy of the 1990s can be viewed as an extension of the broader realization that a preoccupation with economic growth without regard to its social and environmental consequences is self-defeating in the long term.\" Thus 'sustainable tourism development' is seldom considered as an autonomous function of economic regeneration as separate from general economic growth.\n\nTextile tourism refers to people traveling to experience the places related to textile, and are provided knowledge on different fabrics, process, practice of weaving and to know about the technicalities involved the weaving and rural handicraft of handloom, it involves traveling to experience the historical places of textile-like Jaipur, Mysore, Varanasi, Kancheepuram & so on.\n\nEcotourism, also known as ecological tourism, is responsible travel to fragile, pristine, and usually protected areas that strives to be low-impact and (often) small-scale. It helps educate the traveler; provides funds for conservation; directly benefits the economic development and political empowerment of local communities, and fosters respect for different cultures and for human rights.\"Take only memories and leave only footprints\" is a very common slogan in protected areas. Tourist destinations are shifting to low carbon emissions following the trend of visitors more focused in being environmentally responsible adopting a sustainable behavior.\n\nThe movie tourism is a form of tourism for those who visit the film and television locations, i.e. the places used for filming a film or a television series. In addition to organized tours (and not) to film locations lately has widened the tendency to a type of tourism, linked to the cinema, which relates to events, conventions and more like the case of the Dizionario del Turismo Cinematografico.\n\nThe Dizionario del Turismo Cinematografico is an artistic costume movement originally born as a journalistic column on various online and paper publications officially in 2012 (with a genesis formed in the previous decade) but, in the following years, it has become a real costume fashion popularized in sites, associations, institutions, municipal administrations, political parties, movements and television listings all over the world. It also includes Museums and Sports Groups linked to its brand. The purpose of the work is varied: from the redevelopment of territorial areas thanks to the artistic interest raised to be film and fiction locations (Movie tourism) to promote events linked to the Cinema as film anniversaries, festivals, parties to theme (Toga Party, Monster Party, Cosplay Party, Hollywood Party, Pajama Party, etc.), manifestations born in films or that the cinema has helped to divulge (though already existing) as, for example, the Demolition Derby, village festivals disseminated by the Cinema (such as those appearing in the Mondo Cane film series, etc.). We wanted to differentiate from Movie Tourism (a fashion that has existed for several decades) to be more varied and not limited to tourism (that is a part of the Dizionario del Turismo Cinematografico).\nIn the mid-2000s, the student of video advertising and journalistic communications at the Turin branch of the Fellini Institute Davide Lingua (called Dave Lingua), of Verolengo, obsessed with customary phenomena, has in mind to create a totally new object to redevelop areas territories hit by the crisis but fun and that leads to fashion accessible to all. This is the genesis for the creation of the Dizionario del Turismo Cinematografico. A few years later (between 2010, the beginning of the collaboration, and 2012) creates with this name a column (which initially deals with Cine tourism, Cinema Museums and Costume Party with a cinematic theme) within the site (in that period related to the homonymous paper magazine) of the Milan group Mondadori filmtv.it which soon became the most popular of the magazine with a myriad of collaborators. In the following period the Dizionario del Turismo Cinematografico appears as a column in various newspapers and magazines (the Netwerk group, La Voce, is mentioned in La Stampa and many other newspapers) and officially appears as a cultural movement that gives full freedom to all to join simply using the Dizionario del Turismo Cinematografico (respecting however the topics of interest of the movement) coming to create totally independent sections (but always within legally registered bodies or associations), with their own statutes and directives but with only provided that the official founder (helped at the beginning by the first members) Davide Lingua is recognized as Permanent Director for life (in fact director and not president because he wants to underline the journalistic origin of the project).\n\nFrom its birth until today the Dizionario del Turismo Cinematografico is a worldwide journalistic column, television broadcasting, has sections in many associations, institutions that collaborate with municipal administrations, has dealt with the official celebrations of film shooting anniversaries (for example Salasco of the film Bitter Rice), appears in the credits of many films for the collaboration given, organizes communication courses, cultural and sporting events, etc. ...\n\nVolunteer tourism (or voluntourism) is growing as a largely Western phenomenon, with volunteers traveling to aid those less fortunate than themselves in order to counter global inequalities. Wearing (2001) defines volunteer tourism as applying \"to those tourists who, for various reasons, volunteer in an organised way to undertake holidays that might involve aiding or alleviating the material poverty of some groups in society\". VSO was founded in the UK in 1958 and the US Peace Corps was subsequently founded in 1960. These were the first large scale voluntary sending organisations, initially arising to modernise less economically developed countries, which it was hoped would curb the influence of communism.\n\nThis form of tourism is largely praised for its more sustainable approach to travel, with tourists attempting to assimilate into local cultures, and avoiding the criticisms of consumptive and exploitative mass tourism. However, increasingly voluntourism is being criticised by scholars who suggest it may have negative effects as it begins to undermine local labour, and force unwilling host communities to adopt Western initiatives, while host communities without a strong heritage fail to retain volunteers who become dissatisfied with experiences and volunteer shortages persist. Increasingly organisations such as VSO have been concerned with community-centric volunteer programmes where power to control the future of the community is in the hands of local people.\n\nPro-poor tourism, which seeks to help the poorest people in developing countries, has been receiving increasing attention by those involved in development; the issue has been addressed through small-scale projects in local communities and through attempts by Ministries of Tourism to attract large numbers of tourists. Research by the Overseas Development Institute suggests that neither is the best way to encourage tourists' money to reach the poorest as only 25% or less (far less in some cases) ever reaches the poor; successful examples of money reaching the poor include mountain-climbing in Tanzania and cultural tourism in Luang Prabang, Laos. There is also the possibility of pro-poor tourism principles being adopted in centre sites of regeneration in the developed world.\n\nRecession tourism is a travel trend which evolved by way of the world economic crisis. Recession tourism is defined by low-cost and high-value experiences taking place of once-popular generic retreats. Various recession tourism hotspots have seen business boom during the recession thanks to comparatively low costs of living and a slow world job market suggesting travelers are elongating trips where their money travels further. This concept is not widely used in tourism research. It is related to the short-lived phenomenon that is more widely known as staycation.\n\nWhen there is a significant price difference between countries for a given medical procedure, particularly in Southeast Asia, India, Eastern Europe, Cuba and Canada where there are different regulatory regimes, in relation to particular medical procedures (e.g. dentistry), traveling to take advantage of the price or regulatory differences is often referred to as \"medical tourism\". India encourages medical tourism and also allows for a Medical Attendant Visa in addition to Medical Visa for the main patient.\n\nEducational tourism is developed because of the growing popularity of teaching and learning of knowledge and the enhancing of technical competency outside of the classroom environment. In educational tourism, the main focus of the tour or leisure activity includes visiting another country to learn about the culture, study tours, or to work and apply skills learned inside the classroom in a different environment, such as in the International Practicum Training Program.\n\nThis type of tourism is focused on tourists coming into a region to either participate in an event or to see an organized event put on by the city/region. This type of tourism can also fall under sustainable tourism as well and companies that create a sustainable event to attend open up a chance to not only the consumer but their workers to learn and develop from the experience. Creating a sustainable atmosphere it creates a chance to inform and encourage sustainable practices. An example of event tourism would be the music festival South by Southwest that is hosted in Austin, Texas annually. This is a perfect example because every year people from all over the world flock to this one city for one week to sit in on technology talks and see a whole city of bands perform. These people are being drawn here to experience something that they are not able to experience in their hometown which is exactly what event tourism is about.\n\nCreative tourism has existed as a form of cultural tourism, since the early beginnings of tourism itself. Its European roots date back to the time of the Grand Tour, which saw the sons of aristocratic families traveling for the purpose of mostly interactive, educational experiences. More recently, creative tourism has been given its own name by Crispin Raymond and Greg Richards, who as members of the Association for Tourism and Leisure Education (ATLAS), have directed a number of projects for the European Commission, including cultural and crafts tourism, known as sustainable tourism. They have defined \"creative tourism\" as tourism related to the active participation of travelers in the culture of the host community, through interactive workshops and informal learning experiences.\n\nMeanwhile, the concept of creative tourism has been picked up by high-profile organizations such as UNESCO, who through the Creative Cities Network, have endorsed creative tourism as an engaged, authentic experience that promotes an active understanding of the specific cultural features of a place.\nMore recently, creative tourism has gained popularity as a form of cultural tourism, drawing on active participation by travelers in the culture of the host communities they visit. Several countries offer examples of this type of tourism development, including the United Kingdom, Austria, France, the Bahamas, Jamaica, Spain, Italy, New Zealand and South Korea.\n\nThe growing interest of tourists in this new way to discover a culture regards particularly the operators and branding managers, attentive to the possibility of attracting a quality tourism, highlighting the intangible heritage (craft workshops, cooking classes, etc.) and optimizing the use of existing infrastructure (for example, through the rent of halls and auditorium).\n\nExperiential travel (or \"immersion travel\") is one of the major market trends in the modern tourism industry. It is an approach to travelling which focuses on experiencing a country, city or particular place by connecting to its history, people, food and culture.\n\nThe term \"experiential travel\" has been mentioned in publications since 1985, but it wasn't discovered as a meaningful market trend until much later.\n\nOne emerging area of special interest has been identified by Lennon and Foley (2000) as \"dark\" tourism. This type of tourism involves visits to \"dark\" sites, such as battlegrounds, scenes of horrific crimes or acts of genocide, for example concentration camps. Its origins are rooted in fairgrounds and medieval fairs.\n\nPhilip Stone argues that dark tourism is a way of imagining one's own death through the real death of others. Erik H Cohen introduces the term \"populo sites\" to evidence the educational character of dark tourism. Popular sites transmit the story of victimized people to visitors. Based on a study at Yad Vashem, the Shoah (Holocaust) memorial museum in Jerusalem, a new term—\"in populo\"—is proposed to describe dark tourism sites at a spiritual and population center of the people to whom a tragedy befell. Learning about the Shoah in Jerusalem offers an encounter with the subject which is different from visits to sites in Europe, but equally authentic. It is argued that a dichotomy between \"authentic\" sites at the location of a tragedy and \"created\" sites elsewhere is insufficient. Participants' evaluations of seminars for European teachers at Yad Vashem indicate that the location is an important aspect of a meaningful encounter with the subject. Implications for other cases of dark tourism at \"in populo\" locations are discussed. In this vein, Peter Tarlow defines dark tourism as the tendency to visit the scenes of tragedies or historically noteworthy deaths, which continue to impact our lives. This issue cannot be understood without the figure of trauma.\n\nSocial tourism is making tourism available to poor people who otherwise could not afford to travel for their education or recreation. It includes youth hostels and low-priced holiday accommodation run by church and voluntary organisations, trade unions, or in Communist times publicly owned enterprises. In May 1959, at the second Congress of Social Tourism in Austria, Walter Hunziker proposed the following definition: \"Social tourism is a type of tourism practiced by low-income groups, and which is rendered possible and facilitated by entirely separate and therefore easily recognizable services\".\n\nAlso known as \"Tourism of Doom,\" or \"Last Chance Tourism\" this emerging trend involves traveling to places that are environmentally or otherwise threatened (such as the ice caps of Mount Kilimanjaro, the melting glaciers of Patagonia, or the coral of the Great Barrier Reef) before it is too late. Identified by travel trade magazine Travel Age West editor-in-chief Kenneth Shapiro in 2007 and later explored in \"The New York Times\", this type of tourism is believed to be on the rise. Some see the trend as related to sustainable tourism or ecotourism due to the fact that a number of these tourist destinations are considered threatened by environmental factors such as global warming, overpopulation or climate change. Others worry that travel to many of these threatened locations increases an individual's carbon footprint and only hastens problems threatened locations are already facing.\n\nReligious tourism, in particular pilgrimage, can serve to strengthen faith and to demonstrate devotion - both of which are central tenets of many major religions. Religious tourists may seek destinations whose image encourages them to believe that they can strengthen the religious elements of their self-identity in a positive manner. Given this, the perceived image of a destination may be positively influenced by whether it conforms to the requirements of their religious self-identity or not.\n\nDNA tourism, also called \"ancestry tourism\" or \"heritage travel\", is tourism based on DNA testing. DNA tourists visit their remote relatives or places where their ancestors came from, or where their relatives reside, based on the results of DNA tests. According to the media, DNA testing has become a growing trend in 2019.\n\nExcessive hordes of visitors - or of the wrong sort of visitors - can provoke backlashes from otherwise friendly hosts in popular destinations.\nNegative environmental consequences related to tourism activities, such as greenhouse gas emissions from air travel, and litter at popular locations, can be significant.\n\nTourism is sometimes associated with export or theft of contraband such as endangered species or certain cultural artifacts, and illegal sex trade activities.\n\nIn the last years, there are many places in the world that the local population develops an anti-tourism sentiment and protests against tourists. One of the most prominent examples of such a mobilization was the so-called \"Tourists go home\" movement, which emerged in 2014 in Spain due to the slogans and mottos calling the tourists to go back to their homes. Barcelona, as one of the most visited cities of the globe, has millions of tourists per year. The irresponsible behavior of the tourists in association with the overpopulation, usually during the summer months, caused the rage of the local population against the tourists. Besides, citizens also tend to blame platforms such as Airbnb for raising the renting prices and promoting the tourism industry, making it difficult for the citizens to find an inexpensive place to live. Venice was also facing such problems, and the \"Tourists go home\" slogans appeared on the walls of the city. Moreover, several other countries, such as Japan and the Philippines, are having problems with overtourism. Nevertheless, the year 2017 seems to a landmark for the anti-tourism sentiment as \"a new Spanish social movement against an economic development model based on mass tourism gained following high-profile attacks targeting foreign tourists and local business interests.\" The anti-tourism sentiment also seems to be linked with a clash of identity and people’s individualism.\n\nThe World Tourism Organization (UNWTO) forecasts that international tourism will continue growing at the average annual rate of 4%. With the advent of e-commerce, tourism products have become prominent traded items on the internet. Tourism products and services have been made available through intermediaries, although tourism providers (hotels, airlines, etc.), including small-scale operators, can sell their services directly. This has put pressure on intermediaries from both on-line and traditional shops.\n\nIt has been suggested there is a strong correlation between tourism expenditure per capita and the degree to which countries play in the global context. Not only as a result of the important economic contribution of the tourism industry, but also as an indicator of the degree of confidence with which global citizens leverage the resources of the globe for the benefit of their local economies. This is why any projections of growth in tourism may serve as an indication of the relative influence that each country will exercise in the future.\n\nThere has been a limited amount of orbital space tourism, with only the Russian Space Agency providing transport to date. A 2010 report into space tourism anticipated that it could become a billion-dollar market by 2030.\n\nSince the late 1980s, sports tourism has become increasingly popular. Events such as rugby, Olympics, Commonwealth Games, and FIFA World Cups have enabled specialist travel companies to gain official ticket allocation and then sell them in packages that include flights, hotels and excursions.\n\nAs a result of the late-2000s recession, international arrivals suffered a strong slowdown beginning in June 2008. Growth from 2007 to 2008 was only 3.7% during the first eight months of 2008. This slowdown on international tourism demand was also reflected in the air transport industry, with a negative growth in September 2008 and a 3.3% growth in passenger traffic through September. The hotel industry also reported a slowdown, with room occupancy declining. In 2009 worldwide tourism arrivals decreased by 3.8%. By the first quarter of 2009, real travel demand in the United States had fallen 6% over six quarters. While this is considerably milder than what occurred after the 9/11 attacks, the decline was at twice the rate as real GDP has fallen.\n\nHowever, evidence suggests that tourism as a global phenomenon shows no signs of substantially abating in the long term. It has been suggested that travel is necessary in order to maintain relationships, as social life is increasingly networked and conducted at a distance. For many people vacations and travel are increasingly being viewed as a necessity rather than a luxury, and this is reflected in tourist numbers recovering some 6.6% globally over 2009, with growth up to 8% in emerging economies.\n\n\n"}
{"id": "14276", "url": "https://en.wikipedia.org/wiki?curid=14276", "title": "Hotel", "text": "Hotel\n\nA hotel is an establishment that provides paid lodging on a short-term basis. Facilities provided may range from a modest-quality mattress in a small room to large suites with bigger, higher-quality beds, a dresser, a refrigerator and other kitchen facilities, upholstered chairs, a flat screen television, and en-suite bathrooms. Small, lower-priced hotels may offer only the most basic guest services and facilities. Larger, higher-priced hotels may provide additional guest facilities such as a swimming pool, business centre (with computers, printers, and other office equipment), childcare, conference and event facilities, tennis or basketball courts, gymnasium, restaurants, day spa, and social function services. Hotel rooms are usually numbered (or named in some smaller hotels and B&Bs) to allow guests to identify their room. Some boutique, high-end hotels have custom decorated rooms. Some hotels offer meals as part of a room and board arrangement. In the United Kingdom, a hotel is required by law to serve food and drinks to all guests within certain stated hours. In Japan, capsule hotels provide a tiny room suitable only for sleeping and shared bathroom facilities.\n\nThe precursor to the modern hotel was the inn of medieval Europe. For a period of about 200 years from the mid-17th century, coaching inns served as a place for lodging for coach travelers. Inns began to cater to richer clients in the mid-18th century. One of the first hotels in a modern sense was opened in Exeter in 1768. Hotels proliferated throughout Western Europe and North America in the early 19th century, and luxury hotels began to spring up in the later part of the 19th century.\n\nHotel operations vary in size, function, complexity, and cost. Most hotels and major hospitality companies have set industry standards to classify hotel types. An upscale full-service hotel facility offers luxury amenities, full service accommodations, an on-site restaurant, and the highest level of personalized service, such as a concierge, room service, and clothes pressing staff. Full service hotels often contain upscale full-service facilities with many full-service accommodations, an on-site full-service restaurant, and a variety of on-site amenities. Boutique hotels are smaller independent, non-branded hotels that often contain upscale facilities. Small to medium-sized hotel establishments offer a limited amount of on-site amenities. Economy hotels are small to medium-sized hotel establishments that offer basic accommodations with little to no services. Extended stay hotels are small to medium-sized hotels that offer longer-term full service accommodations compared to a traditional hotel.\n\nTimeshare and destination clubs are a form of property ownership involving ownership of an individual unit of accommodation for seasonal usage. A motel is a small-sized low-rise lodging with direct access to individual rooms from the car park. Boutique hotels are typically hotels with a unique environment or intimate setting. A number of hotels have entered the public consciousness through popular culture, such as the Ritz Hotel in London. Some hotels are built specifically as a destination in itself, for example at casinos and holiday resorts.\n\nMost hotel establishments are run by a General Manager who serves as the head executive (often referred to as the \"Hotel Manager\"), department heads who oversee various departments within a hotel (e.g., food service), middle managers, administrative staff, and line-level supervisors. The organizational chart and volume of job positions and hierarchy varies by hotel size, function and class, and is often determined by hotel ownership and managing companies.\n\nThe word \"hotel\" is derived from the French \"hôtel\" (coming from the same origin as \"hospital\"), which referred to a French version of a building seeing frequent visitors, and providing care, rather than a place offering accommodation. In contemporary French usage, \"hôtel\" now has the same meaning as the English term, and \"hôtel particulier\" is used for the old meaning, as well as \"hôtel\" in some place names such as Hôtel-Dieu (in Paris), which has been a hospital since the Middle Ages. The French spelling, with the circumflex, was also used in English, but is now rare. The circumflex replaces the 's' found in the earlier \"hostel\" spelling, which over time took on a new, but closely related meaning. Grammatically, hotels usually take the definite article – hence \"The Astoria Hotel\" or simply \"The Astoria.\"\n\nFacilities offering hospitality to travellers have been a feature of the earliest civilizations. In Greco-Roman culture and ancient Persia, hospitals for recuperation and rest were built at thermal baths. Japan's Nishiyama Onsen Keiunkan, founded in 705, was officially recognised by the Guinness World Records as the oldest hotel in the world. During the Middle Ages, various religious orders at monasteries and abbeys would offer accommodation for travellers on the road.\n\nThe precursor to the modern hotel was the inn of medieval Europe, possibly dating back to the rule of Ancient Rome. These would provide for the needs of travellers, including food and lodging, stabling and fodder for the traveller's horse(s) and fresh horses for the mail coach. Famous London examples of inns include the George and the Tabard. A typical layout of an inn had an inner court with bedrooms on the two sides, with the kitchen and parlour at the front and the stables at the back.\n\nFor a period of about 200 years from the mid-17th century, coaching inns served as a place for lodging for coach travellers (in other words, a roadhouse). Coaching inns stabled teams of horses for stagecoaches and mail coaches and replaced tired teams with fresh teams. Traditionally they were seven miles apart, but this depended very much on the terrain.\nSome English towns had as many as ten such inns and rivalry between them was intense, not only for the income from the stagecoach operators but for the revenue for food and drink supplied to the wealthy passengers. By the end of the century, coaching inns were being run more professionally, with a regular timetable being followed and fixed menus for food.\n\nInns began to cater for richer clients in the mid-18th century, and consequently grew in grandeur and the level of service provided. One of the first hotels in a modern sense was opened in Exeter in 1768, although the idea only really caught on in the early 19th century. In 1812, Mivart's Hotel opened its doors in London, later changing its name to Claridge's.\n\nHotels proliferated throughout Western Europe and North America in the 19th century, and luxury hotels, including the Savoy Hotel in the United Kingdom and the Ritz chain of hotels in London and Paris and Tremont House and Astor House in the United States, began to spring up in the later part of the century, catering to an extremely wealthy clientele.\n\nHotels cater to travelers from many countries and languages, since no one country dominates the travel industry.\n\nHotel operations vary in size, function, and cost. Most hotels and major hospitality companies that operate hotels have set widely accepted industry standards to classify hotel types. General categories include the following:\n\nInternational luxury hotels offer high quality amenities, full service accommodations, on-site full-service restaurants, and the highest level of personalized and professional service in major or capital cities. International luxury hotels are classified with at least a Five Diamond rating or Five Star hotel rating depending on the country and local classification standards. \"Examples include: Grand Hyatt, Waldorf Astoria, Conrad, InterContinental, Sofitel, Mandarin Oriental, Four Seasons, The Peninsula, Rosewood, St. Regis, JW Marriott and The Ritz-Carlton.\"\n\nLifestyle luxury resorts are branded hotels that appeal to a guest with lifestyle or personal image in specific locations. They are typically full-service and classified as luxury. A key characteristic of lifestyle resorts are focus on providing a unique guest experience as opposed to simply providing lodging. Normally, lifestyle resorts are classified with a Five Star hotel rating depending on the country and local classification standards. Examples include: W Hotels, Shangri-La, Sheraton, Oberoi, Belmond, Jumeirah, Aman, Taj Hotels, Hoshino, Raffles, Fairmont, Banyan Tree, Regent and Park Hyatt.\n\nUpscale full service hotels often provide a wide array of guest services and on-site facilities. Commonly found amenities may include: on-site food and beverage (room service and restaurants), meeting and conference services and facilities, fitness center, and business center. Upscale full-service hotels range in quality from upscale to luxury. This classification is based upon the quality of facilities and amenities offered by the hotel. Examples include: Langham, Kempinski, \nKimpton Hotels, Hilton, Lotte, Renaissance, Marriott and Hyatt Regency brands.\n\nBoutique hotels are smaller independent non-branded hotels that often contain mid-scale to upscale facilities of varying size in unique or intimate settings with full service accommodations. These hotels are generally 100 rooms or fewer.\n\nSmall to medium-sized hotel establishments that offer a limited number of on-site amenities that only cater and market to a specific demographic of travelers, such as the single business traveler. Most focused or select service hotels may still offer full service accommodations but may lack leisure amenities such as an on-site restaurant or a swimming pool. Examples include Hyatt Place, Holiday Inn, Courtyard by Marriott and Hilton Garden Inn.\n\nSmall to medium-sized hotel establishments that offer a very limited number of on-site amenities and often only offer basic accommodations with little to no services, these facilities normally only cater and market to a specific demographic of travelers, such as the budget-minded traveler seeking a \"no frills\" accommodation. Limited service hotels often lack an on-site restaurant but in return may offer a limited complimentary food and beverage amenity such as on-site continental breakfast service. Examples include Ibis Budget, Hampton Inn, Aloft, Holiday Inn Express, Fairfield Inn, Four Points by Sheraton.\n\nExtended stay hotels are small to medium-sized hotels that offer longer term full service accommodations compared to a traditional hotel. Extended stay hotels may offer non-traditional pricing methods such as a weekly rate that caters towards travelers in need of short-term accommodations for an extended period of time. Similar to limited and select service hotels, on-site amenities are normally limited and most extended stay hotels lack an on-site restaurant. Examples include Staybridge Suites, Candlewood Suites, Homewood Suites by Hilton, Home2 Suites by Hilton, Residence Inn by Marriott, Element, and Extended Stay America.\n\nTimeshare and Destination clubs are a form of property ownership also referred to as a vacation ownership involving the purchase and ownership of an individual unit of accommodation for seasonal usage during a specified period of time. Timeshare resorts often offer amenities similar that of a Full service hotel with on-site restaurant(s), swimming pools, recreation grounds, and other leisure-oriented amenities. Destination clubs on the other hand may offer more exclusive private accommodations such as private houses in a neighborhood-style setting. Examples of timeshare brands include Hilton Grand Vacations, Marriott Vacation Club International, Westgate Resorts, Disney Vacation Club, and Holiday Inn Club Vacations.\n\nA motel, an abbreviation for \"motor hotel\", is a small-sized low-rise lodging establishment similar to a limited service, lower-cost hotel, but typically with direct access to individual rooms from the car park. Motels were built to serve road travellers, including travellers on road trip vacations and workers who drive for their job (travelling salespeople, truck drivers, etc.). Common during the 1950s and 1960s, motels were often located adjacent to a major highway, where they were built on inexpensive land at the edge of towns or along stretches of freeway.\n\nNew motel construction is rare in the 2000s as hotel chains have been building economy-priced, limited service franchised properties at freeway exits which compete for largely the same clientele, largely saturating the market by the 1990s. Motels are still useful in less populated areas for driving travelers, but the more populated an area becomes, the more hotels move in to meet the demand for accommodation. While many motels are unbranded and independent, many of the other motels which remain in operation joined national franchise chains, often rebranding themselves as hotels, inns or lodges. Some examples of chains with motels include EconoLodge, Motel 6, Super 8, and Travelodge.\n\nMotels in some parts of the world are more often regarded as places for romantic assignations where rooms are often rented by the hour. This is fairly common in parts of Latin America.\n\nHotels may offer rooms for microstays, a type of booking for less than 24 hours where the customer chooses the check in time and the length of the stay. This allows the hotel increased revenue by reselling the same room several times a day.\n\nHotel management is a globally accepted professional career field and academic field of study. Degree programs such as hospitality management studies, a business degree, and/or certification programs formally prepare hotel managers for industry practice.\n\nMost hotel establishments consist of a General Manager who serves as the head executive (often referred to as the \"Hotel Manager\"), department heads who oversee various departments within a hotel, middle managers, administrative staff, and line-level supervisors. The organizational chart and volume of job positions and hierarchy varies by hotel size, function, and is often determined by hotel ownership and managing companies.\n\nBoutique hotels are typically hotels with a unique environment or intimate setting.\nSome hotels have gained their renown through tradition, by hosting significant events or persons, such as Schloss Cecilienhof in Potsdam, Germany, which derives its fame from the Potsdam Conference of the World War II allies Winston Churchill, Harry Truman and Joseph Stalin in 1945. The Taj Mahal Palace & Tower in Mumbai is one of India's most famous and historic hotels because of its association with the Indian independence movement. Some establishments have given name to a particular meal or beverage, as is the case with the Waldorf Astoria in New York City, United States where the Waldorf Salad was first created or the Hotel Sacher in Vienna, Austria, home of the Sachertorte. Others have achieved fame by association with dishes or cocktails created on their premises, such as the Hotel de Paris where the crêpe Suzette was invented or the Raffles Hotel in Singapore, where the Singapore Sling cocktail was devised.\n\nA number of hotels have entered the public consciousness through popular culture, such as the Ritz Hotel in London, through its association with Irving Berlin's song, 'Puttin' on the Ritz'. The Algonquin Hotel in New York City is famed as the meeting place of the literary group, the Algonquin Round Table, and Hotel Chelsea, also in New York City, has been the subject of a number of songs and the scene of the stabbing of Nancy Spungen (allegedly by her boyfriend Sid Vicious).\n\nSome hotels are built specifically as a destination in itself to create a captive trade, example at casinos, amusement parks and holiday resorts. Though hotels have always been built in popular destinations, the defining characteristic of a resort hotel is that it exists purely to serve another attraction, the two having the same owners.\n\nOn the Las Vegas Strip there is a tradition of one-upmanship with luxurious and extravagant hotels in a concentrated area. This trend now has extended to other resorts worldwide, but the concentration in Las Vegas is still the world's highest: nineteen of the world's twenty-five largest hotels by room count are on the Strip, with a total of over 67,000 rooms.\n\n\nThe Null Stern Hotel in Teufen, Appenzellerland, Switzerland and the Concrete Mushrooms in Albania are former nuclear bunkers transformed into hotels.\n\nThe Cuevas Pedro Antonio de Alarcón (named after the author) in Guadix, Spain, as well as several hotels in Cappadocia, Turkey, are notable for being built into natural cave formations, some with rooms underground. The Desert Cave Hotel in Coober Pedy, South Australia is built into the remains of an opal mine.\n\nLocated on the coast but high above sea level, these hotels offer unobstructed panoramic views and a great sense of privacy without the feeling of total isolation. Some examples from around the globe are the Riosol Hotel in Gran Canaria, Caruso Belvedere Hotel in Amalfi Coast (Italy), Aman Resorts Amankila in Bali, Birkenhead House in Hermanus (South Africa), The Caves in Jamaica and Caesar Augustus in Capri.\n\nCapsule hotels are a type of economical hotel first introduced in Japan, where people sleep in stacks of rectangular containers.\n\nSome hotels fill daytime occupancy with day rooms, for example, Rodeway Inn and Suites near Port Everglades in Fort Lauderdale, Florida. Day rooms are booked in a block of hours typically between 8 am and 5 pm, before the typical night shift. These are similar to transit hotels in that they appeal to travelers, however, unlike transit hotels, they do not eliminate the need to go through Customs.\n\nGarden hotels, famous for their gardens before they became hotels, include Gravetye Manor, the home of garden designer William Robinson, and Cliveden, designed by Charles Barry with a rose garden by Geoffrey Jellicoe.\n\nThe Ice Hotel in Jukkasjärvi, Sweden, was the first ice hotel in the world; first built in 1990, it is built each winter and melts every spring. The Hotel de Glace in Duschenay, Canada, opened in 2001 and it's North America's only ice hotel. It is redesigned and rebuilt in its entirety every year. \nIce hotels can also be included within larger ice complexes; for example, the Mammut Snow Hotel in Finland is located within the walls of the Kemi snow castle; and the Lainio Snow Hotel is part of a snow village near Ylläs, Finland. There is an arctic snowhotel in Rovaniemi in Lapland, Finland, along with glass igloos. The first glass igloos were built in 1999 in Finland,they became the Kakslauttanen Arctic Resort with 65 buildings, 53 small ones for two people and 12 large ones for four people. Glass igloos, with their roof made of thermal glass, allow guests to admire auroras comfortably from their beds. \n\nA love hotel (also 'love motel', especially in Taiwan) is a type of short-stay hotel found around the world, operated primarily for the purpose of allowing guests privacy for sexual activities, typically for one to three hours, but with overnight as an option. Styles of premises vary from extremely low-end to extravagantly appointed. In Japan, love hotels have a history of over 400 years.\n\nA referral hotel is a hotel chain that offers branding to independently-operated hotels; the chain itself is founded by or owned by the member hotels as a group. Many former referral chains have been converted to franchises; the largest surviving member-owned chain is Best Western.\n\nThe first recorded purpose-built railway hotel was the Great Western Hotel, which opened adjacent to Reading railway station in 1844, shortly after the Great Western Railway opened its line from London. The building still exists, and although it has been used for other purposes over the years, it is now again a hotel and a member of the Malmaison hotel chain.\n\nFrequently, expanding railway companies built grand hotels at their termini, such as the Midland Hotel, Manchester next to the former Manchester Central Station, and in London the ones above St Pancras railway station and Charing Cross railway station. London also has the Chiltern Court Hotel above Baker Street tube station, there are also Canada's grand railway hotels. They are or were mostly, but not exclusively, used by those traveling by rail.\n\nThe Maya Guesthouse in Nax Mont-Noble in the Swiss Alps, is the first hotel in Europe built entirely with straw bales. Due to the insulation values of the walls it needs no conventional heating or air conditioning system, although the Maya Guesthouse is built at an altitude of in the Alps.\n\nTransit hotels are short stay hotels typically used at international airports where passengers can stay while waiting to change airplanes. The hotels are typically on the airside and do not require a visa for a stay or re-admission through security checkpoints.\n\nSome hotels are built with living trees as structural elements, for example the Treehotel near Piteå, Sweden, the Costa Rica Tree House in the Gandoca-Manzanillo Wildlife Refuge, Costa Rica; the Treetops Hotel in Aberdare National Park, Kenya; the Ariau Towers near Manaus, Brazil, on the Rio Negro in the Amazon; and Bayram's Tree Houses in Olympos, Turkey.\n\nSome hotels have accommodation underwater, such as Utter Inn in Lake Mälaren, Sweden. Hydropolis, project in Dubai, would have had suites on the bottom of the Persian Gulf, and Jules' Undersea Lodge in Key Largo, Florida requires scuba diving to access its rooms.\n\nA resort island is an island or an archipelago that contains resorts, hotels, overwater bungalows, restaurants, tourist attractions and its amenities. Maldives has the most overwater bungalows resorts.\n\nIn 2006, \"Guinness World Records\" listed the First World Hotel in Genting Highlands, Malaysia, as the world's largest hotel with a total of 6,118 rooms (and which has now expanded to 7,351 rooms). The Izmailovo Hotel in Moscow has the most beds, with 7,500, followed by The Venetian and The Palazzo complex in Las Vegas (7,117 rooms) and MGM Grand Las Vegas complex (6,852 rooms).\n\nAccording to the Guinness Book of World Records, the oldest hotel in operation is the Nisiyama Onsen Keiunkan in Yamanashi, Japan. The hotel, first opened in AD 707, has been operated by the same family for forty-six generations. The title was held until 2011 by the Hoshi Ryokan, in the Awazu Onsen area of Komatsu, Japan, which opened in the year 718, as the history of the Nisiyama Onsen Keiunkan was virtually unknown.\n\nThe Rosewood Guangzhou located on the top 39 floors of the 108-story Guangzhou CTF Finance Centre in Tianhe District, Guangzhou, China. Soaring to 530-meters at its highest point, earns the singular status as the world’s highest hotel.\n\nIn October 2014, the Anbang Insurance Group, based in China, purchased the Waldorf Astoria New York in Manhattan for US$1.95 billion, making it the world's most expensive hotel ever sold.\n\nA number of public figures have notably chosen to take up semi-permanent or permanent residence in hotels.\n\n"}
{"id": "33557", "url": "https://en.wikipedia.org/wiki?curid=33557", "title": "Whaling", "text": "Whaling\n\nWhaling is the hunting of whales for their usable products such as meat and blubber, which can be turned into a type of oil which became increasingly important in the Industrial Revolution.\nIt was practiced as an organized industry as early as 875 AD. By the 16th century, it had risen to be the principal industry in the coastal regions of Spain and France. The industry spread throughout the world, and became increasingly profitable in terms of trade and resources. Some regions of the world's oceans, along the animals' migration routes, had a particularly dense whale population, and became the targets for large concentrations of whaling ships, and the industry continued to grow well into the 20th century. The depletion of some whale species to near extinction led to the banning of whaling in many countries by 1969, and to a worldwide cessation of whaling as an industry in the late 1980s.\n\nThe earliest forms of whaling date to at least circa 3000 BC. Coastal communities around the world have long histories of subsistence use of cetaceans, by dolphin drive hunting and by harvesting drift whales. Industrial whaling emerged with organized fleets of whaleships in the 17th century; competitive national whaling industries in the 18th and 19th centuries; and the introduction of factory ships along with the concept of whale harvesting in the first half of the 20th century. By the late 1930s more than 50,000 whales were killed annually. In 1986, the International Whaling Commission (IWC) banned commercial whaling because of the extreme depletion of most of the whale stocks.\n\nContemporary whaling is subject to intense debate. Canada, Iceland, Japan, Norway, Russia, South Korea, the United States and the Danish dependencies of the Faroe Islands and Greenland continue to hunt in the 21st century. Countries that support commercial whaling, notably Iceland, Japan, and Norway, wish to lift the IWC moratorium on certain whale stocks for hunting. Anti-whaling countries and environmental groups oppose lifting the ban. Under the terms of the IWC moratorium, aboriginal whaling is allowed to continue on a subsistence basis. Over the past few decades, whale watching has become a significant industry in many parts of the world; in some countries it has replaced whaling, but in a few others, the two business models exist in an uneasy tension. The live capture of cetaceans for display in aquaria (e.g. captive killer whales) continues.\n\nWhaling began in prehistoric times in coastal waters. The earliest depictions of whaling are the Neolithic Bangudae Petroglyphs in Korea, which may date back to 6000 BC. These images are the earliest evidence for whaling. Although prehistoric hunting and gathering is generally considered to have had little ecological impact, early whaling in the Arctic may have altered freshwater ecology.\n\nEarly whaling affected the development of widely disparate cultures on different continents. The Basques were the first to catch whales commercially, and dominated the trade for five centuries, spreading to the far corners of the North Atlantic and even reaching the South Atlantic. The development of modern whaling techniques was spurred in the 19th century by the increase in demand for whale oil, sometimes known as \"train oil\", and in the 20th century by a demand for margarine and later whale meat.\n\nMany countries which once had significant industries, such as the Netherlands, Scotland, and Argentina, ceased whaling long ago, and so are not covered in this article. Canada, Iceland, Japan, Norway, Russia, South Korea, the United States and the Danish dependencies of the Faroe Islands and Greenland continue to hunt in the 21st century.\n\nThe primary species hunted are minke whales,\nbelugas, narwhals,\nand pilot whales, which are some of the smallest species of whales. There are also smaller numbers killed of gray whales, sei whales, fin whales, bowhead whales, Bryde's whales, sperm whales and humpback whales.\n\nRecent scientific surveys estimate a population of 103,000 minkes in the northeast Atlantic. With respect to the populations of Antarctic minke whales, as of January 2010, the IWC states that it is \"unable to provide reliable estimates at the present time\" and that a \"major review is underway by the Scientific Committee.\"\n\nWhale oil is used little today and modern whaling is primarily done for food: for pets, fur farms, sled dogs and humans, and for making carvings of tusks, teeth and vertebrae. Both meat and blubber (muktuk) are eaten from narwhals, belugas and bowheads. From commercially hunted minkes, meat is eaten by humans or animals, and blubber is rendered down mostly to cheap industrial products such as animal feed or, in Iceland, as a fuel supplement for whaling ships.\n\nInternational cooperation on whaling regulation began in 1931 and culminated in the signing of the International Convention for the Regulation of Whaling (ICRW) in 1946. Its aim is to:\n\nThe International Whaling Commission (IWC) was set up under the ICRW to decide hunting quotas and other relevant matters based on the findings of its Scientific Committee. Non-member countries are not bound by its regulations and conduct their own management programs. It regulates hunting of 13 species of great whales, and has not reached consensus on whether it may regulate smaller species.\n\nThe IWC voted on July 23, 1982, to establish a moratorium on commercial whaling of great whales beginning in the 1985–86 season. Since 1992, the IWC's Scientific Committee has requested that it be allowed to give quota proposals for some whale stocks, but this has so far been refused by the Plenary Committee.\n\nAt the 2010 meeting of the International Whaling Commission in Morocco, representatives of the 88 member states discussed whether or not to lift the 24-year ban on commercial whaling. Japan, Norway and Iceland have urged the organisation to lift the ban. A coalition of anti-whaling nations has offered a compromise plan that would allow these countries to continue whaling, but with smaller catches and under close supervision. Their plan would also completely ban whaling in the Southern Ocean. More than 200 scientists and experts have opposed the compromise proposal for lifting the ban, and have also opposed allowing whaling in the Southern Ocean, which was declared a whale sanctuary in 1994. Opponents of the compromise plan want to see an end to all commercial whaling, but are willing to allow subsistence-level catches by indigenous peoples.\n\nThese totals include great whales: counts from IWC and WDC\nand IWC Summary Catch Database version 6.1, July 2016.\n\nThe IWC database is supplemented by Faroese catches of pilot whales,\nGreenland's and Canada's catches of narwhals (data 1954-2014), belugas from multiple sources shown in the Beluga whale article, Indonesia's catches of sperm whales,\nand bycatch in Korea.\n\nKey elements of the debate over whaling include sustainability, ownership, national sovereignty, cetacean intelligence, suffering during hunting, health risks, the value of 'lethal sampling' to establish catch quotas, the value of controlling whales' impact on fish stocks and the rapidly approaching extinction of a few whale species.\n\nThe World Wide Fund for Nature says that 90% of all northern right whales killed by human activities are from ship collision, calling for restrictions on the movement of shipping in certain areas. Noise pollution threatens the existence of cetaceans. Large ships and boats make a tremendous amount of noise that falls into the same frequency range of many whales. By-catch also kills more animals than hunting. Some scientists believe pollution to be a factor. Moreover, since the IWC moratorium, there have been several instances of illegal whale hunting by IWC nations. In 1994, the IWC reported evidence from genetic testing of whale meat and blubber for sale on the open market in Japan in 1993. In addition to the legally permitted minke whale, the analyses showed that the 10–25% tissues sample came from non minke, baleen whales, neither of which were then allowed under IWC rules. Further research in 1995 and 1996 shows significant drop of non-minke baleen whales sample to 2.5%. In a separate paper, Baker stated that \"many of these animals certainly represent a bycatch (incidental entrapment in fishing gear)\" and stated that DNA monitoring of whale meat is required to adequately track whale products.\n\nIt was revealed in 1994 that the Soviet Union had been systematically undercounting its catch. For example, from 1948 to 1973, the Soviet Union caught 48,477 humpback whales rather than the 2,710 it officially reported to the IWC. On the basis of this new information, the IWC stated that it would have to rewrite its catch figures for the last forty years. According to Ray Gambell, then Secretary of the IWC, the organization had raised its suspicions with the former Soviet Union, but it did not take further action because it could not interfere with national sovereignty.\n\nWhaling was a major maritime industry in Australia from 1791 until its final cessation in 1978. At least 45 whaling stations operated in Tasmania during the 19th century and bay whaling was conducted out of a number of other mainland centres. Modern whaling using harpoon guns and iron hulled catchers was conducted in the twentieth century from shore-based stations in Western Australia, New South Wales and Queensland, also in Norfolk Island. Overfishing saw the closure of some whaling stations before a government ban on the industry was introduced in 1978.\n\nCanadians kill about 600 narwhals per year. They kill 100 belugas per year in the Beaufort Sea,\n300 in northern Quebec (Nunavik),\nand an unknown number in Nunavut.\nThe total annual kill in Beaufort and Quebec areas varies between 300 and 400 belugas per year. Numbers are not available for Nunavut since 2003, when the Arviat area, with about half Nunavut's hunters, killed 200-300 belugas, though the authors say hunters resist giving complete numbers.\n\nHarvested meat is sold through shops and supermarkets in northern communities where whale meat is a component of the traditional diet. Hunters in Hudson's Bay rarely eat beluga meat. They give a little to dogs, and leave the rest for wild animals. Other areas may dry the meat for later consumption by humans. An average of one or two vertebrae and one or two teeth per beluga or narwhal are carved and sold. One estimate of the annual gross value received from Beluga hunts in Hudson Bay in 2013 was for 190 belugas, or per beluga, and for 81 narwhals, or per narwhal. However the net income, after subtracting costs in time and equipment, was a loss of per person for belugas and per person for narwhals. Hunts receive subsidies, but they continue as a tradition, rather than for the money, and the economic analysis noted that whale watching may be an alternate revenue source. Of the gross income, was for Beluga skin and meat, to replace beef, pork and chickens which would otherwise be bought, was received for carved vertebrae and teeth. was for Narwhal skin and meat, was received for tusks, and carved vertebrae and teeth of males, and was received for carved vertebrae and teeth of female Narwhals.\n\nTwo Senators, members of First Nations, said in 2018,\n\nThe Whale and Dolphin Conservation says:\n\n\nCanada left the IWC in 1982, and the only IWC-regulated species currently harvested by the Canadian Inuit is the bowhead whale. As of 2004, the limit on bowhead whale hunting allows for the hunt of one whale every two years from the Hudson Bay-Foxe Basin population, and one whale every 13 years from the Baffin Bay-Davis Strait population. This is roughly one-fiftieth of the bowhead whale harvest limits in Alaska (see below).\n\nThe Faroe Islands are legally part of the Kingdom of Denmark, but are geographically isolated and culturally distinct. The hunt, known as the Grindadráp, is regulated by Faroese authorities but not by the IWC, which does not claim jurisdiction over small cetaceans.\n\nAround 800 long-finned pilot whales (\"Globicephala melaena\") are caught each year, mainly during the summer. Other species are not hunted, though occasionally Atlantic white-sided dolphin can be found among the pilot whales.\n\nMost Faroese consider the hunt an important part of their culture and history and arguments about the topic raise strong emotions. Animal-rights groups criticize the hunt as being cruel and unnecessary and economically insignificant. Hunters claim that most journalists lack knowledge of the catch methods used to capture and kill the whales.\n\nGreenlandic Inuit whalers catch around 175 large whales per year, mostly minke whales,\nas well as 360 narwhals,\n200 belugas,\n190 pilot whales and 2,300 porpoises.\n\nIWC sets limits for large whales. The government of Greenland sets limits for narwhals and belugas. There are no limits on pilot whales and porpoises.\n\nThe IWC treats the west and east coasts of Greenland as two separate population areas and sets separate quotas for each coast. The far more densely populated west coast accounts for over 90 percent of the catch. The average per year from 2012-2016 was around 150 minke and 17 fin whales and humpback whales taken from west coast waters and around 10 minke from east coast waters. In April 2009 Greenland landed its first bowhead whale in nearly forty years. It landed three bowheads each year in 2009 and 2010, one each in 2011 and 2015.\n\nThe Inuit already caught whales around Greenland since the years 1200–1300. They mastered the art of whaling around the year 1000 in the Bering Strait. The technique consists of spearing a whale with a spear connected to an inflated seal bladder. The bladder would float and exhaust the whale when diving, and when it surfaces; the Inuit hunters would spear it again, further exhausting the animal until they were able to kill it.\n\nVikings on Greenland also ate whale meat, but archaeologists believe they never hunted them on sea.\n\nBeing originally one of the most successful whaling nations, German whaling vessels started from Hamburg and other, smaller cities on the Elbe river, hunting for whales around Greenland and Spitsbergen. While 1770 is recorded to have been the most successful year of German whaling, German whaling went into steep decline with the beginning of the Napoleonic Wars and never really recovered. After the Napoleonic Wars, Germany tried but could never re-establish a successful whaling industry. German whaling boats in the mid to late 1800s would generally not be staffed with experienced sailors but rather with members of more wealthy farming communities, going for short trips to Scandinavia during the end of spring / beginning of summer, when their labor was not required on the fields. This kind of whaling was ineffective. Many journeys would not lead to any whales caught, instead seal- and polar bear skins were brought back to shore. Communities often paid more for equipping the vessels in the first place than making money with the goods brought back to shore. Today, local historians believe that German whaling in the late 1800s was more a rite of passage for the sons of wealthy farmers from northern German islands than an action undertaken for true commercial reason. German whaling was abandoned in 1872.\n\nPrior to the first world war, attempts to re-establish large scale German whaling were undertaken with ships either going from Germany to Iceland or from the newly established German colonies to African waters. This attempts never were commercially successful and quickly given up. Only in the 1930s Germany could - with mainly Norwegian personnel - re-establish a large and successful whaling industry with more than 15,000 caught whales between 1930 and 1939. With the beginning of the second world war, German whaling was abandoned completely.\n\nIn the early 1950s, Germany maintained one whaling vessel for testing purpose as it considered re-establishing a German whaling fleet, but abandoned these plans in 1956. The last remaining German whalers worked for Dutch vessels in the 1950s and 1960s.\n\nIceland is one of a handful of countries that still maintain a whaling fleet. One company concentrates on hunting fin whales, largely for export to Japan, while the only other one hunts minke whales for domestic consumption, as the meat is popular with tourists. Iceland now has its own whale watching sector, which exists in uneasy tension with the whaling industry.\n\nIceland did not object to the 1986 IWC moratorium. Between 1986 and 1989 around 60 animals per year were taken under a scientific permit. However, under strong pressure from anti-whaling countries, who viewed scientific whaling as a circumvention of the moratorium, Iceland ceased whaling in 1989. Following the IWC's 1991 refusal to accept its Scientific Committee's recommendation to allow sustainable commercial whaling, Iceland left the IWC in 1992.\n\nIceland rejoined the IWC in 2002 with a reservation to the moratorium. Iceland presented a feasibility study to the 2003 IWC meeting for catches in 2003 and 2004. The primary aim of the study was to deepen the understanding of fish–whale interactions. Amid disagreement within the IWC Scientific Committee about the value of the research and its relevance to IWC objectives, no decision on the proposal was reached. However, under the terms of the convention the Icelandic government issued permits for a scientific catch. In 2003 Iceland resumed scientific whaling which continued in 2004 and 2005.\n\nIceland resumed commercial whaling in 2006. Its annual quota was 30 minke whales (out of an estimated 174,000 animals in the central and north-eastern North Atlantic) and nine fin whales (out of an estimated 30,000 animals in the central and north-eastern North Atlantic). For the 2012 commercial whaling season, starting in April and lasting six months, the quota was set to 216 minke whales, of which 52 were caught.\n\nLamalera, on the south coast of the island of Lembata, and Lamakera on neighbouring Solor, are the two remaining Indonesian whaling communities. The hunters obey religious taboos that ensure that they use every part of the animal. About half of the catch is kept in the village; the rest is bartered in local markets.\n\nIn 1973, the United Nations's Food and Agriculture Organization (FAO) sent a whaling ship and a Norwegian whaler to modernize their hunt. This effort lasted three years, and was not successful. According to the FAO report, the Lamalerans \"have evolved a method of whaling which suits their natural resources, cultural tenets and style.\" Lamalerans say they returned the ship because they immediately caught five sperm whales, too many to butcher and eat without refrigeration. Since these communities only hunt whales for noncommercial purposes, it is categorized as 'aboriginal subsistence hunters' by International Whaling Commission (IWC).\n\nThe Lamalerans hunt for several species of whales but catching sperm whales are preferable, while other whales, such as baleen whales, are considered taboo to hunt. They caught five sperm whales in 1973, about 40 per year in the 1960s and mid 1990s, 13 total from 2002-2006, 39 in 2007, an average of 20 per year through 2014, and 3 in 2015.\n\nTraditional Lamaleran whaling used wooden fishing boats built by a group of local craftsmen clan called \"ata molã\" and the fishermen will mourn the \"death\" of their ships for two months. These days, the Lamalerans use motor engine to power their boats; however, their tradition dictates that once a whale has been caught, fishermen will have to row their boats and the whale back to the shore. The traditional practices made whaling a dangerous hunt. In one case, a boat was pulled approximately 120 km away towards Timor (see Nantucket sleighride), while in another case, the hunted whale capsized the boat and forced the fishermen to swim for 12 hours back to the shore.\n\nWhen the commercial whaling moratorium was introduced by the IWC in 1982, Japan lodged an official objection. However, in response to US threats to cut Japan's fishing quota in US territorial waters under the terms of the Packwood-Magnuson Amendment, Japan withdrew its objection in 1987. According to the BBC, America went back on this promise, effectively destroying the deal. Since Japan could not resume commercial whaling, it began whaling on a purported scientific-research basis. Australia, Greenpeace, the Sea Shepherd Conservation Society and other groups dispute the Japanese claim of research “as a disguise for commercial whaling, which is banned.” The Sea Shepherd Conservation Society has attempted to disrupt Japanese whaling in the Antarctic since 2003.\n\nThe stated purpose of the research program is to establish the size and dynamics of whale populations. The Japanese government wishes to resume whaling in a sustainable manner under the oversight of the IWC, both for whale products (meat, etc.) and to help preserve fishing resources by culling whales. Anti-whaling organizations claim that the research program is a front for commercial whaling, that the sample size is needlessly large and that equivalent information can be obtained by non-lethal means, for example by studying samples of whale tissue (such as skin) or feces. The Japanese government sponsored Institute of Cetacean Research (ICR), which conducts the research, disagrees, stating that the information obtainable from tissue and/or feces samples is insufficient and that the sample size is necessary in order to be representative.\n\nJapan's scientific whaling program is controversial in anti-whaling countries. Countries opposed to whaling have passed non-binding resolutions in the IWC urging Japan to stop the program. Japan claims that whale stocks for some species are sufficiently large to sustain commercial hunting and blame filibustering by the anti-whaling side for the continuation of scientific whaling. Deputy whaling commissioner, Joji Morishita, told BBC News:\n\nThis collusive relationship between the whaling industry and the Japanese government is sometimes criticized by pro-whaling activists who support local, small-scale coastal whaling such as the Taiji dolphin drive hunt.\n\nOn 26 December 2018, Japan announced that since the IWC failed its duty to promote sustainable hunting, which is one of its stated goals, Japan is withdrawing its membership. Japanese officials also announced they will resume commercial hunting within its territorial waters and its 200-mile exclusive economic zones starting in July 2019, but it will cease whaling activities in the Antarctic Ocean, the northwest Pacific ocean, and the Australian Whale Sanctuary.\n\nNorway registered an objection to the International Whaling Commission moratorium and is thus not bound by it. Commercial whaling ceased for a five-year period to allow a small scientific catch for gauging the stock's sustainability and resumed 1993. Minke whales are the only legally hunted species. Catches have fluctuated between 487 animals in 2000 to 592 in 2007. For the year 2011 the quota is set at 1,286 minke whales. The catch is made solely from the Northeast Atlantic minke whale population, which is estimated at 102,000.\n\nWhaling in the Philippines has been illegal since 1997 since the Fisheries Administrative Order 185 of 1991 was amended. The order initially only made illegal the catching, selling, or transporting of dolphins but the 1997 amendment widened the scope of the ban to include all Cetaceans including whales. The calls for ban on whaling and dolphin hunting in the Philippines were raised by both domestic and international groups after local whaling and dolphin hunting traditions of residents of Pamilacan in Bohol were featured in newspapers in the 1990s. As compromise for residents of Pamilacan who were dependent on whaling and dolphin hunting, whale and dolphin watching is being promoted in the island as a source of tourism income. Despite the ban, it is believed that the whaling industry in the Philippines did not cease to exist but went underground.\n\nRussia had a significant whaling hunt of orcas and dolphins along with Iceland and Japan. The Soviet Union's harvest of over 534,000 whales between the 1930s and the 1980s has been called one of the most senseless environmental crimes of the 20th century. In 1970, a study published by Bigg M.A. following photographic recognition of orcas found a significant difference in the suspected ages of whale populations and their actual ages. Following this evidence, the Soviet Union and then Russia continued a scientific whale hunt, though the verisimilitude of the intentions of the hunt over the last 40 years are questioned.\n\nThe Soviet Union's intensive illegal whaling program from 1948 to 1973 was controlled and managed by the central government. In Soviet society, whaling was perceived to be a glamorous and well-paid job. Whalers were esteemed as well-traveled adventurers, and their return to land was often celebrated elaborately such as with fanfare and parades. In regard to economics, the Soviet Union transformed from a \"rural economy into an industrial giant\" by disregarding the sustainability of a resource to fill high production targets. The government had controlled all industries, including fisheries, and whaling was not constrained by the need for sustainability through profits. Managers' and workers' production was incentivized with salary bonuses of 25%-60% and various other benefits, awards, and privileges. Many industries, whaling included, became a “manic numbers game”.\n\nCurrently, Russians in Chukotka Autonomous Okrug in the Russian Far East are permitted under IWC regulation to take up to 140 gray whales from the North-East Pacific population each year. About 40 beluga whales are caught in the Sea of Okhotsk each year.\nThere are no recent data on catches in the Arctic Ocean or Bering Sea, where about 60 belugas per year were caught in the early 1980s.\n\nNatives of Saint Vincent and the Grenadines on the island of Bequia have a quota from the International Whaling Commission of up to four humpback whales per year using traditional hunting methods and equipment.\n\nIn early July 2012, during IWC discussions in Panama, South Korea said it would undertake scientific whaling as allowed despite the global moratorium on whaling. South Korea's envoy to the summit, Kang Joon-Suk, said that consumption of whale meat \"dates back to historical times\" and that there had been an increase in the minke whale population since the ban took place in 1986. \"Legal whaling has been strictly banned and subject to strong punishments, though the 26 years have been painful and frustrating for the people who have been traditionally taking whales for food.\" He said that South Korea would undertake whaling in its own waters. New Zealand's Commissioner Gerard van Bohemen accused South Korea of putting the whale population at risk. He also cited Japan as having not contributed to science for several years despite undertaking scientific whaling. New Zealand's stated position may be seen by its media as less solid than Australia's on the matter given that its indigenous people are pushing forward with plans, unopposed by the government, to recommence whaling there. The people of Ulsan have also traditionally and contemporarily eaten whale meat. South Korea's representative at the IWC said that \"this is not a forum for moral debate. This is a forum for legal debate. As a responsible member of the commission we do not accept any such categorical, absolute proposition that whales should not be killed or caught.\"\n\nIn the United States, beluga whaling is widely carried out, catching about 300 belugas per year,\nmonitored by the Alaska Beluga Whale Committee. The annual catch ranges between 250-600 per year.\n\nSubsistence hunting of the bowhead whale is carried out by nine different indigenous Alaskan communities, and is managed by the Alaska Eskimo Whaling Commission which reports to the National Oceanic and Atmospheric Administration. The hunt takes around 50 bowhead whales a year from a population of about 10,500 in Alaskan waters. Conservationists fear this hunt is not sustainable, though the IWC Scientific Committee, the same group that provided the above population estimate, projects a population growth of 3.2% per year. The hunt also took an average of one or two gray whales each year until 1996. The quota was reduced to zero in that year due to sustainability concerns. A future review may result in the gray whale hunt being resumed. Bowhead whales weigh approximately 5–10 times as much as minke whales.\n\nThe Makah tribe in Washington State also reinstated whaling in 1999, despite protests from animal rights groups. They are currently seeking to resume whaling of the gray whale, a right recognized in the Treaty of Neah Bay, within limits (Article 4 of the Treaty).\n\n\n\n"}
{"id": "38286", "url": "https://en.wikipedia.org/wiki?curid=38286", "title": "Inflation", "text": "Inflation\n\nIn economics, inflation is a sustained increase in the general price level of goods and services in an economy over a period of time.\nWhen the general price level rises, each unit of currency buys fewer goods and services; consequently, inflation reflects a reduction in the purchasing power per unit of money a loss of real value in the medium of exchange and unit of account within the economy. The opposite of inflation is deflation, a sustained decrease in the general price level of goods and services. The common measure of inflation is the inflation rate, the annualized percentage change in a general price index, usually the consumer price index, over time.\n\nEconomists generally believe that very high rates of inflation and hyperinflation are caused by an excessive growth of the money supply. Views on which factors determine low to moderate rates of inflation are more varied. Low or moderate inflation may be attributed to fluctuations in real demand for goods and services, or changes in available supplies such as during scarcities. However, the consensus view is that a long sustained period of inflation is caused by money supply growing faster than the rate of economic growth.\n\nInflation affects economies in various positive and negative ways. The negative effects of inflation include an increase in the opportunity cost of holding money, uncertainty over future inflation which may discourage investment and savings, and if inflation were rapid enough, shortages of goods as consumers begin hoarding out of concern that prices will increase in the future. Positive effects include reducing unemployment due to nominal wage rigidity, allowing the central bank more leeway in carrying out monetary policy, encouraging loans and investment instead of money hoarding, and avoiding the inefficiencies associated with deflation.\n\nToday, most economists favor a low and steady rate of inflation. Low (as opposed to zero or negative) inflation reduces the severity of economic recessions by enabling the labor market to adjust more quickly in a downturn, and reduces the risk that a liquidity trap prevents monetary policy from stabilizing the economy. The task of keeping the rate of inflation low and stable is usually given to monetary authorities. Generally, these monetary authorities are the central banks that control monetary policy through the setting of interest rates, through open market operations, and through the setting of banking reserve requirements.\n\nHistorically, rapid increases in the quantity of money or in the overall money supply have occurred in many different societies throughout history, changing with different forms of money used. For instance, when gold was used as currency, the government could collect gold coins, melt them down, mix them with other metals such as silver, copper, or lead, and reissue them at the same nominal value. By diluting the gold with other metals, the government could issue more coins without increasing the amount of gold used to make them. When the cost of each coin is lowered in this way, the government profits from an increase in seigniorage. This practice would increase the money supply but at the same time the relative value of each coin would be lowered. As the relative value of the coins becomes lower, consumers would need to give more coins in exchange for the same goods and services as before. These goods and services would experience a price increase as the value of each coin is reduced.\n\nSong Dynasty China introduced the practice of printing paper money to create fiat currency. During the Mongol Yuan Dynasty, the government spent a great deal of money fighting costly wars, and reacted by printing more money, leading to inflation. Fearing the inflation that plagued the Yuan dynasty, the Ming Dynasty initially rejected the use of paper money, and reverted to using copper coins.\n\nHistorically, large infusions of gold or silver into an economy also led to inflation. From the second half of the 15th century to the first half of the 17th, Western Europe experienced a major inflationary cycle referred to as the \"price revolution\", with prices on average rising perhaps sixfold over 150 years. This was largely caused by the sudden influx of gold and silver from the New World into Habsburg Spain. The silver spread throughout a previously cash-starved Europe and caused widespread inflation. Demographic factors also contributed to upward pressure on prices, with European population growth after depopulation caused by the Black Death pandemic.\n\nBy the nineteenth century, economists categorized three separate factors that cause a rise or fall in the price of goods: a change in the \"value\" or production costs of the good, a change in the \"price of money\" which then was usually a fluctuation in the commodity price of the metallic content in the currency, and \"currency depreciation\" resulting from an increased supply of currency relative to the quantity of redeemable metal backing the currency. Following the proliferation of private banknote currency printed during the American Civil War, the term \"inflation\" started to appear as a direct reference to the \"currency depreciation\" that occurred as the quantity of redeemable banknotes outstripped the quantity of metal available for their redemption. At that time, the term inflation referred to the devaluation of the currency, and not to a rise in the price of goods.\n\nThis relationship between the over-supply of banknotes and a resulting depreciation in their value was noted by earlier classical economists such as David Hume and David Ricardo, who would go on to examine and debate what effect a currency devaluation (later termed \"monetary inflation\") has on the price of goods (later termed \"price inflation\", and eventually just \"inflation\").\n\nThe adoption of fiat currency by many countries, from the 18th century onwards, made much larger variations in the supply of money possible. Rapid increases in the money supply have taken place a number of times in countries experiencing political crises, producing hyperinflations episodes of extreme inflation rates much higher than those observed in earlier periods of commodity money. The hyperinflation in the Weimar Republic of Germany is a notable example. Currently, the hyperinflation in Venezuela is the highest in the world, with an annual inflation rate of 833,997% as of October 2018.\n\nHowever, since the 1980s, inflation has been held low and stable in countries with strong independent central banks. This has led to a moderation of the business cycle and a reduction in variation in most macroeconomic indicators - an event known as the Great Moderation.\n\nThe term \"inflation\" originally referred to a rise in the general price level caused by an imbalance between the quantity of money and trade needs. However, it is common for economists today to use the term \"inflation\" to refer to a rise in the price level. An increase in the money supply may be called monetary inflation, to distinguish it from rising prices, which may also for clarity be called \"price inflation\". Economists generally agree that in the long run, inflation is caused by increases in the money supply.<ref name=\"federalreserve2004/hh/2004/july/testimony.htm\"> Federal Reserve Board's semiannual Monetary Policy Report to the Congress. Introductory statement by Jean-Claude Trichet on July 1, 2004</ref>\n\nConceptually, inflation refers to the general trend of prices, not changes in any specific price. For example, if people choose to buy more cucumbers than tomatoes, cucumbers consequently become more expensive and tomatoes cheaper. These changes are not related to inflation; they reflect a shift in tastes. Inflation is related to the value of currency itself. When currency was linked with gold, if new gold deposits were found, the price of gold and the value of currency would fall, and consequently prices of all other goods would become higher.\n\nOther economic concepts related to inflation include: deflation a fall in the general price level; disinflation a decrease in the rate of inflation; hyperinflation an out-of-control inflationary spiral; stagflation a combination of inflation, slow economic growth and high unemployment; reflation an attempt to raise the general level of prices to counteract deflationary pressures; and asset price inflation a general rise in the prices of financial assets without a corresponding increase in the prices of goods or services.\n\nInflation expectations or expected inflation is the rate of inflation that is anticipated for some period of time in the foreseeable future. There are two major approaches to modeling the formation of inflation expectations. Adaptive expectations models them as a weighted average of what was expected one period earlier and the actual rate of inflation that most recently occurred. Rational expectations models them as unbiased, in the sense that the expected inflation rate is not systematically above or systematically below the inflation rate that actually occurs.\n\nA long-standing survey of inflation expectations is the University of Michigan survey.\n\nInflation expectations affect the economy in several ways. They are more or less built into nominal interest rates, so that a rise (or fall) in the expected inflation rate will typically result in a rise (or fall) in nominal interest rates, giving a smaller effect if any on real interest rates. In addition, higher expected inflation tends to be built into the rate of wage increases, giving a smaller effect if any on the changes in real wages. Moreover, the response of inflationary expectations to monetary policy can influence the division of the effects of policy between inflation and unemployment (see Monetary policy credibility).\n\nSince there are many possible measures of the price level, there are many possible measures of price inflation. Most frequently, the term \"inflation\" refers to a rise in a broad price index representing the overall price level for goods and services in the economy. The Consumer Price Index (CPI), the Personal consumption expenditures price index (PCEPI) and the GDP deflator are some examples of broad price indices. However, \"inflation\" may also be used to describe a rising price level within a narrower set of assets, goods or services within the economy, such as commodities (including food, fuel, metals), tangible assets (such as real estate), financial assets (such as stocks, bonds), services (such as entertainment and health care), or labor. Although the values of capital assets are often casually said to \"inflate,\" this should not be confused with inflation as a defined term; a more accurate description for an increase in the value of a capital asset is appreciation. The Reuters-CRB Index (CCI), the Producer Price Index, and Employment Cost Index (ECI) are examples of narrow price indices used to measure price inflation in particular sectors of the economy. Core inflation is a measure of inflation for a subset of consumer prices that excludes food and energy prices, which rise and fall more than other prices in the short term. The Federal Reserve Board pays particular attention to the core inflation rate to get a better estimate of long-term future inflation trends overall.\n\nThe inflation rate is most widely calculated by calculating the movement or change in a price index, typically the consumer price index.\nThe inflation rate is the percentage change of a price index over time. The Retail Prices Index is also a measure of inflation that is commonly used in the United Kingdom. It is broader than the CPI and contains a larger basket of goods and services.\n\nTo illustrate the method of calculation, in January 2007, the U.S. Consumer Price Index was 202.416, and in January 2008 it was 211.080. The formula for calculating the annual percentage rate inflation in the CPI over the course of the year is: formula_1\nThe resulting inflation rate for the CPI in this one-year period is 4.28%, meaning the general level of prices for typical U.S. consumers rose by approximately four percent in 2007.\n\nOther widely used price indices for calculating price inflation include the following:\n\nOther common measures of inflation are:\n\n∴ formula_2\n\nMeasuring inflation in an economy requires objective means of differentiating changes in nominal prices on a common set of goods and services, and distinguishing them from those price shifts resulting from changes in value such as volume, quality, or performance. For example, if the price of a can of corn changes from $0.90 to $1.00 over the course of a year, with no change in quality, then this price difference represents inflation. This single price change would not, however, represent general inflation in an overall economy. To measure overall inflation, the price change of a large \"basket\" of representative goods and services is measured. This is the purpose of a price index, which is the combined price of a \"basket\" of many goods and services. The combined price is the sum of the weighted prices of items in the \"basket\". A weighted price is calculated by multiplying the unit price of an item by the number of that item the average consumer purchases. Weighted pricing is a necessary means to measuring the impact of individual unit price changes on the economy's overall inflation. The Consumer Price Index, for example, uses data collected by surveying households to determine what proportion of the typical consumer's overall spending is spent on specific goods and services, and weights the average prices of those items accordingly. Those weighted average prices are combined to calculate the overall price. To better relate price changes over time, indexes typically choose a \"base year\" price and assign it a value of 100. Index prices in subsequent years are then expressed in relation to the base year price. While comparing inflation measures for various periods one has to take into consideration the base effect as well.\n\nInflation measures are often modified over time, either for the relative weight of goods in the basket, or in the way in which goods and services from the present are compared with goods and services from the past. Over time, adjustments are made to the type of goods and services selected to reflect changes in the sorts of goods and services purchased by 'typical consumers'. New products may be introduced, older products disappear, the quality of existing products may change, and consumer preferences can shift. Both the sorts of goods and services which are included in the \"basket\" and the weighted price used in inflation measures will be changed over time to keep pace with the changing marketplace. Different segments of the population may naturally consume different \"baskets\" of goods and services and may even experience different inflation rates. It is argued that companies have put more innovation into bringing down prices for wealthy families than for poor families.\n\nInflation numbers are often seasonally adjusted to differentiate expected cyclical cost shifts. For example, home heating costs are expected to rise in colder months, and seasonal adjustments are often used when measuring for inflation to compensate for cyclical spikes in energy or fuel demand. Inflation numbers may be averaged or otherwise subjected to statistical techniques to remove statistical noise and volatility of individual prices.\n\nWhen looking at inflation, economic institutions may focus only on certain kinds of prices, or \"special indices\", such as the core inflation index which is used by central banks to formulate monetary policy.\n\nMost inflation indices are calculated from weighted averages of selected price changes. This necessarily introduces distortion, and can lead to legitimate disputes about what the true inflation rate is. This problem can be overcome by including all available price changes in the calculation, and then choosing the median value. In some other cases, governments may intentionally report false inflation rates; for instance, during the presidency of Cristina Kirchner (2007–2015) the government of Argentina was criticised for manipulating economic data, such as inflation and GDP figures, for political gain and to reduce payments on its inflation-indexed debt.\n\nHistorically, a great deal of economic literature was concerned with the question of what causes inflation and what effect it has. There were different schools of thought as to the causes of inflation. Most can be divided into two broad areas: quality theories of inflation and quantity theories of inflation.\n\nThe quality theory of inflation rests on the expectation of a seller accepting currency to be able to exchange that currency at a later time for goods they desire as a buyer. The quantity theory of inflation rests on the quantity equation of money that relates the money supply, its velocity, and the nominal value of exchanges.\n\nCurrently, the quantity theory of money is widely accepted as an accurate model of inflation in the long run. Consequently, there is now broad agreement among economists that in the long run, the inflation rate is essentially dependent on the growth rate of the money supply relative to the growth of the economy. However, in the short and medium term inflation may be affected by supply and demand pressures in the economy, and influenced by the relative elasticity of wages, prices and interest rates.\n\nThe question of whether the short-term effects last long enough to be important is the central topic of debate between monetarist and Keynesian economists. In monetarism prices and wages adjust quickly enough to make other factors merely marginal behavior on a general trend-line. In the Keynesian view, prices and wages adjust at different rates, and these differences have enough effects on real output to be \"long term\" in the view of people in an economy.\n\nKeynesian economics proposes that changes in the money supply do not directly affect prices in the short run, and that visible inflation is the result of pressures in the economy expressing themselves in prices.\n\nThere are three major types of inflation, as part of what Robert J. Gordon calls the \"triangle model\":\n\nDemand-pull theory states that inflation accelerates when aggregate demand increases beyond the ability of the economy to produce (its potential output). Hence, any factor that increases aggregate demand can cause inflation. However, in the long run, aggregate demand can be held above productive capacity only by increasing the quantity of money in circulation faster than the real growth rate of the economy. Another (although much less common) cause can be a rapid decline in the \"demand\" for money, as happened in Europe during the Black Death, or in the Japanese occupied territories just before the defeat of Japan in 1945.\n\nThe effect of money on inflation is most obvious when governments finance spending in a crisis, such as a civil war, by printing money excessively. This sometimes leads to hyperinflation, a condition where prices can double in a month or less. The money supply is also thought to play a major role in determining moderate levels of inflation, although there are differences of opinion on how important it is. For example, monetarist economists believe that the link is very strong; Keynesian economists, by contrast, typically emphasize the role of aggregate demand in the economy rather than the money supply in determining inflation. That is, for Keynesians, the money supply is only one determinant of aggregate demand.\n\nSome Keynesian economists also disagree with the notion that central banks fully control the money supply, arguing that central banks have little control, since the money supply adapts to the demand for bank credit issued by commercial banks. This is known as the theory of endogenous money, and has been advocated strongly by post-Keynesians as far back as the 1960s. This position is not universally accepted banks create money by making loans, but the aggregate volume of these loans diminishes as real interest rates increase. Thus, central banks can influence the money supply by making money cheaper or more expensive, thus increasing or decreasing its production.\n\nA fundamental concept in inflation analysis is the relationship between inflation and unemployment, called the Phillips curve. This model suggests that there is a trade-off between price stability and employment. Therefore, some level of inflation could be considered desirable to minimize unemployment. The Phillips curve model described the U.S. experience well in the 1960s but failed to describe the stagflation experienced in the 1970s. Thus, modern macroeconomics describes inflation using a Phillips curve that is able to shift due to such matters as supply shocks and structural inflation. The former refers to such events like the 1973 oil crisis, while the latter refers to the price/wage spiral and inflationary expectations implying that inflation is the new normal. Thus, the Phillips curve represents only the demand-pull component of the triangle model.\n\nAnother concept of note is the potential output (sometimes called the \"natural gross domestic product\"), a level of GDP, where the economy is at its optimal level of production given institutional and natural constraints. (This level of output corresponds to the Non-Accelerating Inflation Rate of Unemployment, NAIRU, or the \"natural\" rate of unemployment or the full-employment unemployment rate.) If GDP exceeds its potential (and unemployment is below the NAIRU), the theory says that inflation will \"accelerate\" as suppliers increase their prices and built-in inflation worsens. If GDP falls below its potential level (and unemployment is above the NAIRU), inflation will \"decelerate\" as suppliers attempt to fill excess capacity, cutting prices and undermining built-in inflation.\n\nHowever, one problem with this theory for policy-making purposes is that the exact level of potential output (and of the NAIRU) is generally unknown and tends to change over time. Inflation also seems to act in an asymmetric way, rising more quickly than it falls. Worse, it can change because of policy: for example, high unemployment under British Prime Minister Margaret Thatcher might have led to a rise in the NAIRU (and a fall in potential) because many of the unemployed found themselves as structurally unemployed, unable to find jobs that fit their skills. A rise in structural unemployment implies that a smaller percentage of the labor force can find jobs at the NAIRU, where the economy avoids crossing the threshold into the realm of accelerating inflation.\n\nA connection between inflation and unemployment has been drawn since the emergence of large scale unemployment in the 19th century, and connections continue to be drawn today. However, the unemployment rate generally only affects inflation in the short-term but not the long-term. In the long term, the velocity of money is far more predictive of inflation than low unemployment.\n\nIn Marxian economics, the unemployed serve as a reserve army of labor, which restrain wage inflation. In the 20th century, similar concepts in Keynesian economics include the NAIRU (Non-Accelerating Inflation Rate of Unemployment) and the Phillips curve.\n\nMonetarists believe the most significant factor influencing inflation or deflation is how fast the money supply grows or shrinks. They consider fiscal policy, or government spending and taxation, as ineffective in controlling inflation. The monetarist economist Milton Friedman famously stated, \"Inflation is always and everywhere a monetary phenomenon.\"\n\nMonetarists assert that the empirical study of monetary history shows that inflation has always been a monetary phenomenon. The quantity theory of money, simply stated, says that any change in the amount of money in a system will change the price level. This theory begins with the equation of exchange:\n\nwhere\n\nIn this formula, the general price level is related to the level of real economic activity (\"Q\"), the quantity of money (\"M\") and the velocity of money (\"V\"). The formula is an identity because the velocity of money (\"V\") is defined to be the ratio of final nominal expenditure (formula_8) to the quantity of money (\"M\").\n\nMonetarists assume that the velocity of money is unaffected by monetary policy (at least in the long run), and the real value of output is determined in the long run by the productive capacity of the economy. Under these assumptions, the primary driver of the change in the general price level is changes in the quantity of money. With exogenous velocity (that is, velocity being determined externally and not being influenced by monetary policy), the money supply determines the value of nominal output (which equals final expenditure) in the short run. In practice, velocity is not exogenous in the short run, and so the formula does not necessarily imply a stable short-run relationship between the money supply and nominal output. However, in the long run, changes in velocity are assumed to be determined by the evolution of the payments mechanism. If velocity is relatively unaffected by monetary policy, the long-run rate of increase in prices (the inflation rate) is equal to the long-run growth rate of the money supply plus the exogenous long-run rate of velocity growth minus the long run growth rate of real output.\n\nIf economic growth matches the growth of the money supply, inflation should not occur when all else is equal. A large variety of factors can affect the rate of both. For example, investment in market production, infrastructure, education, and preventive health care can all grow an economy in greater amounts than the investment spending.\n\nRational expectations theory holds that economic actors look rationally into the future when trying to maximize their well-being, and do not respond solely to immediate opportunity costs and pressures. In this view, while generally grounded in monetarism, future expectations and strategies are important for inflation as well.\n\nA core assertion of rational expectations theory is that actors will seek to \"head off\" central-bank decisions by acting in ways that fulfill predictions of higher inflation. This means that central banks must establish their credibility in fighting inflation, or economic actors will make bets that the central bank will expand the money supply rapidly enough to prevent recession, even at the expense of exacerbating inflation. Thus, if a central bank has a reputation as being \"soft\" on inflation, when it announces a new policy of fighting inflation with restrictive monetary growth economic agents will not believe that the policy will persist; their inflationary expectations will remain high, and so will inflation. On the other hand, if the central bank has a reputation of being \"tough\" on inflation, then such a policy announcement will be believed and inflationary expectations will come down rapidly, thus allowing inflation itself to come down rapidly with minimal economic disruption.\n\nThere are also other theories about inflation that are no longer accepted by mainstream economists.\n\nThe Austrian School stresses that inflation is not uniform over all assets, goods, and services. Inflation depends on differences in markets and on where newly created money and credit enter the economy. Ludwig von Mises said that inflation should refer to an increase in the quantity of money that is not offset by a corresponding increase in the need for money, and that price inflation will necessarily follow.\n\nThe real bills doctrine asserts that banks should issue their money in exchange for short-term real bills of adequate value. As long as banks only issue a dollar in exchange for assets worth at least a dollar, the issuing bank's assets will naturally move in step with its issuance of money, and the money will hold its value. Should the bank fail to get or maintain assets of adequate value, then the bank's money will lose value, just as any financial security will lose value if its asset backing diminishes. The real bills doctrine (also known as the backing theory) thus asserts that inflation results when money outruns its issuer's assets. The quantity theory of money, in contrast, claims that inflation results when money outruns the economy's production of goods.\n\nCurrency and banking schools of economics argue the RBD, that banks should also be able to issue currency against bills of trading, which is \"real bills\" that they buy from merchants. This theory was important in the 19th century in debates between \"Banking\" and \"Currency\" schools of monetary soundness, and in the formation of the Federal Reserve. In the wake of the collapse of the international gold standard post 1913, and the move towards deficit financing of government, RBD has remained a minor topic, primarily of interest in limited contexts, such as currency boards. It is generally held in ill repute today, with Frederic Mishkin, a governor of the Federal Reserve going so far as to say it had been \"completely discredited.\"\n\nThe debate between currency, or quantity theory, and the banking schools during the 19th century prefigures current questions about the credibility of money in the present. In the 19th century the banking schools had greater influence in policy in the United States and Great Britain, while the currency schools had more influence \"on the continent\", that is in non-British countries, particularly in the Latin Monetary Union and the earlier Scandinavia monetary union.\n\nAn increase in the general level\nof prices implies a decrease in the purchasing power of the currency. That is, when the general level of prices rise, each monetary unit buys fewer goods and services. The effect of inflation is not distributed evenly in the economy, and as a consequence there are hidden costs to some and benefits to others from this decrease in the purchasing power of money. For example, with inflation, those segments in society which own physical assets, such as property, stock etc., benefit from the price/value of their holdings going up, when those who seek to acquire them will need to pay more for them. Their ability to do so will depend on the degree to which their income is fixed. For example, increases in payments to workers and pensioners often lag behind inflation, and for some people income is fixed. Also, individuals or institutions with cash assets will experience a decline in the purchasing power of the cash. Increases in the price level (inflation) erode the real value of money (the functional currency) and other items with an underlying monetary nature.\n\nDebtors who have debts with a fixed nominal rate of interest will see a reduction in the \"real\" interest rate as the inflation rate rises. The real interest on a loan is the nominal rate minus the inflation rate. The formula \"R = N-I\" approximates the correct answer as long as both the nominal interest rate and the inflation rate are small. The correct equation is \"r = n/i\" where \"r\", \"n\" and \"i\" are expressed as ratios (e.g. 1.2 for +20%, 0.8 for −20%). As an example, when the inflation rate is 3%, a loan with a nominal interest rate of 5% would have a real interest rate of approximately 2% (in fact, it's 1.94%). Any unexpected increase in the inflation rate would decrease the real interest rate. Banks and other lenders adjust for this inflation risk either by including an inflation risk premium to fixed interest rate loans, or lending at an adjustable rate.\n\nHigh or unpredictable inflation rates are regarded as harmful to an overall economy. They add inefficiencies in the market, and make it difficult for companies to budget or plan long-term. Inflation can act as a drag on productivity as companies are forced to shift resources away from products and services to focus on profit and losses from currency inflation. Uncertainty about the future purchasing power of money discourages investment and saving. Inflation can also impose hidden tax increases. For instance, inflated earnings push taxpayers into higher income tax rates unless the tax brackets are indexed to inflation.\n\nWith high inflation, purchasing power is redistributed from those on fixed nominal incomes, such as some pensioners whose pensions are not indexed to the price level, towards those with variable incomes whose earnings may better keep pace with the inflation. This redistribution of purchasing power will also occur between international trading partners. Where fixed exchange rates are imposed, higher inflation in one economy than another will cause the first economy's exports to become more expensive and affect the balance of trade. There can also be negative impacts to trade from an increased instability in currency exchange prices caused by unpredictable inflation.\n\n\n\n\n\n\n\n\n\n\n\n\nAlthough both fiscal and monetary policy can affect inflation, ever since the 1980s, most countries primarily rely on monetary policy to control inflation. When inflation beyond an acceptable level is taking place, the country’s central bank can increase the interest rate, which typically will tend to slow or stop the growth of the money supply. Some central banks have a symmetrical inflation target while others only control inflation when it rises above a threshold, whether publicly disclosed or not.\n\nIn the 21st century, most economists favor a low and steady rate of inflation. In most countries, central banks or other monetary authorities are tasked with keeping their interbank lending rates at low stable levels, and the target inflation rate of about 2% to 3%. Central banks target a low inflation rate because they believe that high inflation is economically costly because it would create uncertainty about differences in relative prices and about the inflation rate itself. A low positive inflation rate is targeted rather than a zero or negative one because the latter could cause or worsen recessions; low (as opposed to zero or negative) inflation reduces the severity of economic recessions by enabling the labor market to adjust more quickly in a downturn, and reduces the risk that a liquidity trap prevents monetary policy from stabilizing the economy.\n\nHigher interest rates reduce the economy’s money supply because fewer people seek loans. When banks make loans, the loan proceeds are generally deposited in bank accounts that are part of the money supply. Therefore, when a person pays back a loan and no other loans are made to replace it, the amount of bank deposits and hence the money supply decrease. For example, in the early 1980s, when the federal funds rate exceeded 15%, the quantity of Federal Reserve dollars fell 8.1%, from US$8.6 trillion down to $7.9 trillion.\n\nIn the latter part of the 20th century, there was a debate between Keynesians and monetarists about the appropriate instrument to use to control inflation. Monetarists emphasize a low and steady growth rate of the money supply, while the Keynesians emphasize reducing aggregate demand during economic expansions and increasing demand during recessions to keep inflation stable. Control of aggregate demand can be achieved using both monetary policy and fiscal policy (increased taxation or reduced government spending to reduce demand).\n\nA variety of other methods and policies have been proposed and used to control inflation.\n\nUnder a fixed exchange rate currency regime, a country's currency is tied in value to another single currency or to a basket of other currencies (or sometimes to another measure of value, such as gold). A fixed exchange rate is usually used to stabilize the value of a currency, vis-a-vis the currency it is pegged to. It can also be used as a means to control inflation. However, as the value of the reference currency rises and falls, so does the currency pegged to it. This essentially means that the inflation rate in the fixed exchange rate country is determined by the inflation rate of the country the currency is pegged to. In addition, a fixed exchange rate prevents a government from using domestic monetary policy to achieve macroeconomic stability.\n\nUnder the Bretton Woods agreement, most countries around the world had currencies that were fixed to the U.S. dollar. This limited inflation in those countries, but also exposed them to the danger of speculative attacks. After the Bretton Woods agreement broke down in the early 1970s, countries gradually turned to floating exchange rates. However, in the later part of the 20th century, some countries reverted to a fixed exchange rate as part of an attempt to control inflation. This policy of using a fixed exchange rate to control inflation was used in many countries in South America in the later part of the 20th century (e.g. Argentina (1991–2002), Bolivia, Brazil, and Chile). \n\nThe gold standard is a monetary system in which a region's common medium of exchange is paper notes that are normally freely convertible into pre-set, fixed quantities of gold. The standard specifies how the gold backing would be implemented, including the amount of specie per currency unit. The currency itself has no \"innate value\", but is accepted by traders because it can be redeemed for the equivalent specie. A U.S. silver certificate, for example, could be redeemed for an actual piece of silver.\n\nThe gold standard was partially abandoned via the international adoption of the Bretton Woods system. Under this system all other major currencies were tied at fixed rates to the dollar, which itself was tied to gold at the rate of US$35 per ounce. The Bretton Woods system broke down in 1971, causing most countries to switch to fiat money money backed only by the laws of the country.\n\nUnder a gold standard, the long term rate of inflation (or deflation) would be determined by the growth rate of the supply of gold relative to total output. Critics argue that this will cause arbitrary fluctuations in the inflation rate, and that monetary policy would essentially be determined by gold mining.\n\nAnother method attempted in the past have been wage and price controls (\"incomes policies\"). Wage and price controls have been successful in wartime environments in combination with rationing. However, their use in other contexts is far more mixed. Notable failures of their use include the 1972 imposition of wage and price controls by Richard Nixon. More successful examples include the Prices and Incomes Accord in Australia and the Wassenaar Agreement in the Netherlands.\n\nIn general, wage and price controls are regarded as a temporary and exceptional measure, only effective when coupled with policies designed to reduce the underlying causes of inflation during the wage and price control regime, for example, winning the war being fought. They often have perverse effects, due to the distorted signals they send to the market. Artificially low prices often cause rationing and shortages and discourage future investment, resulting in yet further shortages. The usual economic analysis is that any product or service that is under-priced is overconsumed. For example, if the official price of bread is too low, there will be too little bread at official prices, and too little investment in bread making by the market to satisfy future needs, thereby exacerbating the problem in the long term.\n\nTemporary controls may \"complement\" a recession as a way to fight inflation: the controls make the recession more efficient as a way to fight inflation (reducing the need to increase unemployment), while the recession prevents the kinds of distortions that controls cause when demand is high. However, in general the advice of economists is not to impose price controls but to liberalize prices by assuming that the economy will adjust and abandon unprofitable economic activity. The lower activity will place fewer demands on whatever commodities were driving inflation, whether labor or resources, and inflation will fall with total economic output. This often produces a severe recession, as productive capacity is reallocated and is thus often very unpopular with the people whose livelihoods are destroyed (see creative destruction).\n\nThe real purchasing power of fixed payments is eroded by inflation unless they are inflation-adjusted to keep their real values constant. In many countries, employment contracts, pension benefits, and government entitlements (such as social security) are tied to a cost-of-living index, typically to the consumer price index. A \"cost-of-living adjustment\" (COLA) adjusts salaries based on changes in a cost-of-living index. It does not control inflation, but rather seeks to mitigate the consequences of inflation for those on fixed incomes. Salaries are typically adjusted annually in low inflation economies. During hyperinflation they are adjusted more often. They may also be tied to a cost-of-living index that varies by geographic location if the employee moves.\n\nAnnual escalation clauses in employment contracts can specify retroactive or future percentage increases in worker pay which are not tied to any index. These negotiated increases in pay are colloquially referred to as cost-of-living adjustments (\"COLAs\") or cost-of-living increases because of their similarity to increases tied to externally determined indexes.\n\n\n\n"}
{"id": "48847", "url": "https://en.wikipedia.org/wiki?curid=48847", "title": "Deflation", "text": "Deflation\n\nIn economics, deflation is a decrease in the general price level of goods and services. Deflation occurs when the inflation rate falls below 0% (a negative inflation rate). Inflation reduces the value of currency over time, but sudden deflation increases it. This allows more goods and services to be bought than before with the same amount of currency. Deflation is distinct from disinflation, a slow-down in the inflation rate, i.e. when inflation declines to a lower rate but is still positive.\n\nEconomists generally believe that a sudden deflationary shock is a problem in a modern economy because it increases the real value of debt, especially if the deflation is unexpected. Deflation may also aggravate recessions and lead to a deflationary spiral.\n\nDeflation usually happens when supply is high (when excess production occurs), when demand is low (when consumption decreases), or when the money supply decreases (sometimes in response to a contraction created from careless investment or a credit crunch) or because of a net capital outflow from the economy. It can also occur due to too much competition and too little market concentration.\n\nIn the IS–LM model (investment and saving equilibrium liquidity preference and money supply equilibrium model), deflation is caused by a shift in the supply and demand curve for goods and services. This in turn can be caused by an increase in supply, a fall in demand, or both.\n\nWhen prices are falling, consumers have an incentive to delay purchases and consumption until prices fall further, which in turn reduces overall economic activity. When purchases are delayed, productive capacity is idled and investment falls, leading to further reductions in aggregate demand. This is the deflationary spiral. The way to reverse this quickly would be to introduce an economic stimulus. The government could increase productive spending on things like infrastructure or the central bank could start expanding the money supply.\n\nDeflation is also related to risk aversion, where investors and buyers will start hoarding money because its value is now increasing over time. This can produce a liquidity trap or it may lead to shortages that entice investments yielding more jobs and commodity production. A central bank cannot, normally, charge negative interest for money, and even charging zero interest often produces less stimulative effect than slightly higher rates of interest. In a closed economy, this is because charging zero interest also means having zero return on government securities, or even negative return on short maturities. In an open economy it creates a carry trade, and devalues the currency. A devalued currency produces higher prices for imports without necessarily stimulating exports to a like degree.\n\nDeflation is the natural condition of economies when the supply of money is fixed, or does not grow as quickly as population and the economy. When this happens, the available amount of hard currency per person falls, in effect making money more scarce, and consequently, the purchasing power of each unit of currency increases. Deflation also occurs when improvements in production efficiency lower the overall price of goods. Competition in the marketplace often prompts those producers to apply at least some portion of these cost savings into reducing the asking price for their goods. When this happens, consumers pay less for those goods, and consequently deflation has occurred, since purchasing power has increased.\n\nRising productivity and reduced transportation cost created structural deflation during the accelerated productivity era from 1870–1900, but there was mild inflation for about a decade before the establishment of the Federal Reserve in 1913. There was inflation during World War I, but deflation returned again after the war and during the 1930s depression. Most nations abandoned the gold standard in the 1930s so that there is less reason to expect deflation, aside from the collapse of speculative asset classes, under a fiat monetary system with low productivity growth.\n\nIn mainstream economics, deflation may be caused by a combination of the supply and demand for goods and the supply and demand for money, specifically the supply of money going down and the supply of goods going up. Historic episodes of deflation have often been associated with the supply of goods going up (due to increased productivity) without an increase in the supply of money, or (as with the Great Depression and possibly Japan in the early 1990s) the demand for goods going down combined with a decrease in the money supply. Studies of the Great Depression by Ben Bernanke have indicated that, in response to decreased demand, the Federal Reserve of the time decreased the money supply, hence contributing to deflation.\n\nDemand-side causes are:\n\n\n\nSupply-side causes are:\n\n\nDebt deflation is a complicated phenomenon associated with the end of long-term credit cycles. It was proposed as a theory by Irving Fisher (1933) to explain the deflation of the Great Depression.\n\nFrom a monetarist perspective, deflation is caused primarily by a reduction in the velocity of money and/or the amount of money supply per person.\n\nA historical analysis of money velocity and monetary base shows an inverse correlation: for a given percentage decrease in the monetary base the result is nearly equal percentage increase in money velocity. This is to be expected because monetary base (M), velocity of base money (V), price level (P) and real output (Y) are related by definition: MV = PY. However, it is important to note that the monetary base is a much narrower definition of money than M money supply. Additionally, the velocity of the monetary base is interest rate sensitive, the highest velocity being at the highest interest rates.\n\nIn the early history of the United States there was no national currency and an insufficient supply of coinage. Banknotes were the majority of the money in circulation. During financial crises many banks failed and their notes became worthless. Also, banknotes were discounted relative to gold and silver, the discount depending on the financial strength of the bank.\n\nIn recent years changes in the money supply have historically taken a long time to show up in the price level, with a rule of thumb lag of at least 18 months. More recently Alan Greenspan cited the time lag as taking between 12 and 13 quarters. Bonds, equities and commodities have been suggested as reservoirs for buffering changes in money supply.\n\nIn modern credit-based economies, deflation may be caused by the central bank \"initiating\" higher interest rates (i.e., to 'control' inflation), thereby possibly popping an asset bubble. In a credit-based economy, a slow-down or fall in lending leads to less money in circulation, with a further sharp fall in money supply as confidence reduces and velocity weakens, with a consequent sharp fall-off in demand for employment or goods. The fall in demand causes a fall in prices as a supply glut develops. This becomes a deflationary spiral when prices fall below the costs of financing production, or repaying debt levels incurred at the prior price level. Businesses, unable to make enough profit no matter how low they set prices, are then liquidated. Banks get assets which have fallen dramatically in value since their mortgage loan was made, and if they sell those assets, they further glut supply, which only exacerbates the situation. To slow or halt the deflationary spiral, banks will often withhold collecting on non-performing loans (as in Japan, and most recently America and Spain). This is often no more than a stop-gap measure, because they must then restrict credit, since they do not have money to lend, which further reduces demand, and so on.\n\nIn the early economic history of the United States, cycles of inflation and deflation correlated with capital flows between regions, with money being loaned from the financial center in the Northeast to the commodity producing regions of the [mid]-West and South. In a procyclical manner, prices of commodities rose when capital was flowing in, that is, when banks were willing to lend, and fell in the depression years of 1818 and 1839 when banks called in loans. Also, there was no national paper currency at the time and there was a scarcity of coins. Most money circulated as banknotes, which typically sold at a discount according to distance from the issuing bank and the bank's perceived financial strength.\n\nWhen banks failed their notes were redeemed for bank reserves, which often did not result in payment at par value, and sometimes the notes became worthless. Notes of weak surviving banks traded at steep discounts. During the Great Depression, people who owed money to a bank whose deposits had been frozen would sometimes buy bank books (deposits of other people at the bank) at a discount and use them to pay off their debt at par value.\n\nDeflation occurred periodically in the U.S. during the 19th century (the most important exception was during the Civil War). This deflation was at times caused by technological progress that created significant economic growth, but at other times it was triggered by financial crises — notably the Panic of 1837 which caused deflation through 1844, and the Panic of 1873 which triggered the Long Depression that lasted until 1879. These deflationary periods preceded the establishment of the U.S. Federal Reserve System and its active management of monetary matters. Episodes of deflation have been rare and brief since the Federal Reserve was created (a notable exception being the Great Depression) while U.S. economic progress has been unprecedented.\n\nA financial crisis in England in 1818 caused banks to call in loans and curtail new lending, draining specie out of the U.S. The Bank of the United States also reduced its lending. Prices for cotton and tobacco fell. The price of agricultural commodities also were pressured by a return of normal harvests following 1816, the \"year without a summer\", that caused large scale famine and high agricultural prices.\n\nThere were several causes of the deflation of the severe depression of 1839-43, which included an oversupply of agricultural commodities (importantly cotton) as new cropland came into production following large federal land sales a few years earlier, banks requiring payment in gold or silver, the failure of several banks, default by several states on their bonds and British banks cutting back on specie flow to the U.S.\n\nThis cycle has been traced out on the broad scale during the Great Depression. Partly because of overcapacity and market saturation and partly as a result of the Smoot-Hawley Tariff Act, international trade contracted sharply, severely reducing demand for goods, thereby idling a great deal of capacity, and setting off a string of bank failures. A similar situation in Japan, beginning with the stock and real estate market collapse in the early 1990s, was arrested by the Japanese government preventing the collapse of most banks and taking over direct control of several in the worst condition.\n\nThe United States had no national paper money until 1862 (greenbacks used to fund the Civil War), but these notes were discounted to gold until 1877. There was also a shortage of U.S. minted coins. Foreign coins, such as Mexican silver, were commonly used. At times banknotes were as much as 80% of currency in circulation before the Civil War. In the financial crises of 1818–19 and 1837–41, many banks failed, leaving their money to be redeemed below par value from reserves. Sometimes the notes became worthless, and the notes of weak surviving banks were heavily discounted. The Jackson administration opened branch mints, which over time increased the supply of coins. Following the 1848 finding of gold in the Sierra Nevada, enough gold came to market to devalue gold relative to silver. To equalize the value of the two metals in coinage, the US mint slightly reduced the silver content of new coinage in 1853.\n\nWhen structural deflation appeared in the years following 1870, a common explanation given by various government inquiry committees was a scarcity of gold and silver, although they usually mentioned the changes in industry and trade we now call productivity. However, David A. Wells (1890) notes that the U. S. money supply during the period 1879-1889 actually rose 60%, the increase being in gold and silver, which rose against the percentage of national bank and legal tender notes. Furthermore, Wells argued that the deflation only lowered the cost of goods that benefited from recent improved methods of manufacturing and transportation. Goods produced by craftsmen did not decrease in price, nor did many services, and the cost of labor actually increased. Also, deflation did not occur in countries that did not have modern manufacturing, transportation and communications.\n\nBy the end of the 19th century, deflation ended and turned to mild inflation. William Stanley Jevons predicted rising gold supply would cause inflation decades before it actually did. Irving Fisher blamed the worldwide inflation of the pre-WWI years on rising gold supply.\n\nIn economies with an unstable currency, barter and other alternate currency arrangements such as dollarization are common, and therefore when the 'official' money becomes scarce (or unusually unreliable), commerce can still continue (e.g., most recently in Zimbabwe). Since in such economies the central government is often unable, even if it were willing, to adequately control the internal economy, there is no pressing need for individuals to acquire official currency except to pay for imported goods. In effect, barter acts as a protective tariff in such economies, encouraging local consumption of local production. It also acts as a spur to mining and exploration, because one easy way to make money in such an economy is to dig it out of the ground.\n\nDeflation was present during most economic depressions in US history Deflation is generally regarded negatively, as it causes a transfer of wealth from borrowers and holders of illiquid assets, to the benefit of savers and of holders of liquid assets and currency, and because confused pricing signals cause malinvestment, in the form of under-investment.\n\nIn this sense it is the opposite of the more usual scenario of inflation, whose effect is to tax currency holders and lenders (savers) and use the proceeds to subsidize borrowers, including governments, and to cause malinvestment as overinvestment. Thus inflation encourages short term consumption and can similarly over-stimulate investment in projects that may not be worthwhile in real terms (for example the housing or Dot-com bubbles), while deflation retards investment even when there is a real-world demand not being met. In modern economies, deflation is usually caused by a drop in aggregate demand, and is associated with economic depression, as occurred in the Great Depression and the Long Depression.\n\nNobel laureate Friedrich Hayek, a libertarian Austrian Economist, stated about the Great Depression deflation:\n\nWhile an increase in the purchasing power of one's money benefits some, it amplifies the sting of debt for others: after a period of deflation, the payments to service a debt represent a larger amount of purchasing power than they did when the debt was first incurred. Consequently, deflation can be thought of as an effective increase in a loan's interest rate. If, as during the Great Depression in the United States, deflation averages 10% per year, even an interest-free loan is unattractive as it must be repaid with money worth 10% more each year.\n\nUnder normal conditions, the Fed and most other central banks implement policy by setting a target for a short-term interest rate the overnight federal funds rate in the U.S. and enforcing that target by buying and selling securities in open capital markets. When the short-term interest rate hits zero, the central bank can no longer ease policy by lowering its usual interest-rate target. With interest rates near zero, debt relief becomes an increasingly important tool in managing deflation.\n\nIn recent times, as loan terms have grown in length and loan financing (or leveraging) is common among many types of investments, the costs of deflation to borrowers has grown larger. Deflation can discourage private investment, because there is reduced expectations on future profits when future prices are lower. Consequently, with reduced private investments, spiraling deflation can cause a collapse in aggregate demand. Without the \"hidden risk of inflation\", it may become more prudent for institutions to hold on to money, and not to spend or invest it (burying money). They are therefore rewarded by holding money. This \"hoarding\" behavior is seen as undesirable by most economists, as Hayek points out:\n\nSome believe that, in the absence of large amounts of debt, deflation would be a welcome effect because the lowering of prices increases purchasing power.\n\nSince deflationary periods disfavor debtors (including most farmers), they are often periods of rising populist backlash. For example, in the late 19th century, populists in the US wanted debt relief or to move off the new gold standard and onto a silver standard (the supply of silver was increasing relatively faster than the supply of gold, making silver less deflationary than gold), bimetal standard, or paper money like the recently ended Greenbacks.\n\nA \"deflationary spiral\" is a situation where decreases in the price level lead to lower production, which in turn leads to lower wages and demand, which leads to further decreases in the price level. Since reductions in general price level are called deflation, a deflationary spiral occurs when reductions in price lead to a vicious circle, where a problem exacerbates its own cause . In science, this effect is also known as a positive feedback loop. Another economic example of this principle is a bank run.\n\nThe Great Depression was regarded by some as a deflationary spiral. A deflationary spiral is the modern macroeconomic version of the general glut controversy of the 19th century. Another related idea is Irving Fisher's theory that excess debt can cause a continuing deflation. Whether deflationary spirals can actually occur is controversial, with their possibility being disputed by freshwater economists (including the Chicago school of economics) and Austrian School economists.\n\nDuring severe deflation, targeting an interest rate (the usual method of determining how much currency to create) may be ineffective, because even lowering the short-term interest rate to zero may result in a real interest rate which is too high to attract credit-worthy borrowers. In the 21st century negative interest rate has been tried, but it can't be too negative, since people might withdraw cash from bank accounts if they have negative interest rate. Thus the central bank must directly set a target for the quantity of money (called \"quantitative easing\") and may use extraordinary methods to increase the supply of money, e.g. purchasing financial assets of a type not usually used by the central bank as reserves (such as mortgage-backed securities). Before he was Chairman of the United States Federal Reserve, Ben Bernanke claimed in 2002, \"...sufficient injections of money will ultimately always reverse a deflation\", although Japan's deflationary spiral was not broken by the amount of quantitative easing provided by the Bank of Japan.\n\nUntil the 1930s, it was commonly believed by economists that deflation\nwould cure itself. As prices decreased, demand would naturally increase and the economic system would correct itself without outside intervention.\n\nThis view was challenged in the 1930s during the Great Depression. Keynesian economists argued that the economic system was not self-correcting with respect to deflation and that governments and central banks had to take active measures to boost demand through tax cuts or increases in government spending. Reserve requirements from the central bank were high compared to recent times. So were it not for redemption of currency for gold (in accordance with the gold standard), the central bank could have effectively increased money supply by simply reducing the reserve requirements and through open market operations (e.g., buying treasury bonds for cash) to offset the reduction of money supply in the private sectors due to the collapse of credit (credit is a form of money).\n\nWith the rise of monetarist ideas, the focus in fighting deflation was put on expanding demand by lowering interest rates (i.e., reducing the \"cost\" of money). This view has received a setback in light of the failure of accommodative policies in both Japan and the US to spur demand after stock market shocks in the early 1990s and in 2000–02, respectively. Austrian economists worry about the inflationary impact of monetary policies on asset prices. Sustained low real rates can cause higher asset prices and excessive debt accumulation. Therefore, lowering rates may prove to be only a temporary palliative, aggravating an eventual debt deflation crisis.\n\nWith interest rates near zero, debt relief becomes an increasingly important tool in managing deflation.\n\nWhen the central bank has lowered nominal interest rates to zero, it can no longer further stimulate demand by lowering interest rates. This is the famous liquidity trap. When deflation takes hold, it requires \"special arrangements\" to lend money at a zero nominal rate of interest (which could still be a very high \"real\" rate of interest, due to the \"negative\" inflation rate) in order to artificially increase the money supply.\n\nAlthough the values of capital assets are often casually said to deflate when they decline, this usage is not consistent with the usual definition of deflation; a more accurate description for a decrease in the value of a capital asset is economic depreciation. Another term, the accounting conventions of depreciation are standards to determine a decrease in values of capital assets when market values are not readily available or practical.\n\nFollowing the Asian financial crisis in late 1997, Hong Kong experienced a long period of deflation which did not end until the 4th quarter of 2004. Many East Asian currencies devalued following the crisis. The Hong Kong dollar however, was pegged to the US dollar, leading to an adjustment instead by a deflation of consumer prices. The situation was worsened by the increasingly cheap exports from Mainland China, and \"weak Consumer confidence\" in Hong Kong. This deflation was accompanied by an economic slump that was more severe and prolonged than those of the surrounding countries that devalued their currencies in the wake of the Asian financial crisis.\n\nIn February 2009, Ireland's Central Statistics Office announced that during January 2009, the country experienced deflation, with prices falling by 0.1% from the same time in 2008. This is the first time deflation has hit the Irish economy since 1960. Overall consumer prices decreased by 1.7% in the month.\n\nBrian Lenihan, Ireland's Minister for Finance, mentioned deflation in an interview with RTÉ Radio. According to RTÉ's account , \"Minister for Finance Brian Lenihan has said that deflation must be taken into account when Budget cuts in child benefit, public sector pay and professional fees are being considered. Mr Lenihan said month-on-month there has been a 6.6% decline in the cost of living this year.\"\n\nThis interview is notable in that the deflation referred to is not discernibly regarded negatively by the Minister in the interview. The Minister mentions the deflation as an item of data helpful to the arguments for a cut in certain benefits. The alleged economic harm caused by deflation is not alluded to or mentioned by this member of government. This is a notable example of deflation in the modern era being discussed by a senior financial Minister without any mention of how it might be avoided, or whether it should be.\n\nDeflation started in the early 1990s. The Bank of Japan and the government tried to eliminate it by reducing interest rates and 'quantitative easing', but did not create a sustained increase in broad money and deflation persisted. In July 2006, the zero-rate policy was ended.\n\nSystemic reasons for deflation in Japan can be said to include:\n\n\nIn November 2009, Japan returned to deflation, according to the Wall Street Journal. Bloomberg L.P. reports that consumer prices fell in October 2009 by a near-record 2.2%.\n\nDuring World War I the British pound sterling was removed from the gold standard. The motivation for this policy change was to finance World War I; one of the results was inflation, and a rise in the gold price, along with the corresponding drop in international exchange rates for the pound. When the pound was returned to the gold standard after the war it was done on the basis of the pre-war gold price, which, since it was higher than equivalent price in gold, required prices to fall to realign with the higher target value of the pound.\n\nThe UK experienced deflation of approx 10% in 1921, 14% in 1922, and 3 to 5% in the early 1930s.\n\nThere have been four significant periods of deflation in the United States.\n\nThe first and most severe was during the depression in 1818–1821 when prices of agricultural commodities declined by almost 50%. A credit contraction caused by a financial crisis in England drained specie out of the U.S. The Bank of the United States also contracted its lending. The price of agricultural commodities fell by almost 50% from the high in 1815 to the low in 1821, and did not recover until the late 1830s, although to a significantly lower price level. Most damaging was the price of cotton, the U.S.'s main export. Food crop prices, which had been high because of the famine of 1816 that was caused by the year without a summer, fell after the return of normal harvests in 1818. Improved transportation, mainly from turnpikes, and to a minor extent the introduction of steamboats, significantly lowered transportation costs.\n\nThe second was the depression of the late 1830s to 1843, following the Panic of 1837, when the currency in the United States contracted by about 34% with prices falling by 33%. The magnitude of this contraction is only matched by the Great Depression. (See: Historical examples of credit deflation) This \"deflation\" satisfies both definitions, that of a decrease in prices and a decrease in the available quantity of money. Despite the deflation and depression, GDP rose 16% from 1839 to 1843.\n\nThe third was after the Civil War, sometimes called The Great Deflation. It was possibly spurred by return to a gold standard, retiring paper money printed during the Civil War.\nThe fourth was in 1930–1933 when the rate of deflation was approximately 10 percent/year, part of the United States' slide into the Great Depression, where banks failed and unemployment peaked at 25%.\n\nThe deflation of the Great Depression occurred partly because there was an enormous contraction of credit (money), bankruptcies creating an environment where cash was in frantic demand, and when the Federal Reserve was supposed to accommodate that demand, it instead contracted the money supply by 30% in enforcement of its new real bills doctrine, so banks toppled one-by-one (because they were unable to meet the sudden demand for cash see fractional-reserve banking). From the standpoint of the Fisher equation (see above), there was a concomitant drop both in money supply (credit) and the velocity of money which was so profound that price deflation took hold despite the increases in money supply spurred by the Federal Reserve.\n\nThroughout the history of the United States, inflation has approached zero and dipped below for short periods of time. This was quite common in the 19th century, and in the 20th century until the permanent abandonment of the gold standard for the Bretton Woods system in 1948. In the past 60 years, the United States has only experienced deflation two times; in 2009 with the Great Recession and in 2015, when the CPI barely broke below 0% at -0.1%.\n\nSome economists believe the United States may have experienced deflation as part of the financial crisis of 2007–10; compare the theory of debt deflation. Year-on-year, consumer prices dropped for six months in a row to end-August 2009, largely due to a steep decline in energy prices. Consumer prices dropped 1 percent in October, 2008. This was the largest one-month fall in prices in the US since at least 1947. That record was again broken in November, 2008 with a 1.7% decline. In response, the Federal Reserve decided to continue cutting interest rates, down to a near-zero range as of December 16, 2008.\n\nIn late 2008 and early 2009, some economists feared the US could enter a deflationary spiral. Economist Nouriel Roubini predicted that the United States would enter a deflationary recession, and coined the term \"stag-deflation\" to describe it. It is the opposite of stagflation, which was the main fear during the spring and summer of 2008. The United States then began experiencing measurable deflation, steadily decreasing from the first measured deflation of -0.38% in March, to July's deflation rate of -2.10%. On the wage front, in October 2009 the state of Colorado announced that its state minimum wage, which is indexed to inflation, is set to be cut, which would be the first time a state has cut its minimum wage since 1938.\n\n\n"}
{"id": "15176", "url": "https://en.wikipedia.org/wiki?curid=15176", "title": "Insurance", "text": "Insurance\n\nInsurance is a means of protection from financial loss. It is a form of risk management, primarily used to hedge against the risk of a contingent or uncertain loss.\n\nAn entity which provides insurance is known as an insurer, insurance company, insurance carrier or underwriter. A person or entity who buys insurance is known as an insured or as a policyholder. The insurance transaction involves the insured assuming a guaranteed and known relatively small loss in the form of payment to the insurer in exchange for the insurer's promise to compensate the insured in the event of a covered loss. The loss may or may not be financial, but it must be reducible to financial terms, and usually involves something in which the insured has an insurable interest established by ownership, possession, or pre-existing relationship.\n\nThe insured receives a contract, called the insurance policy, which details the conditions and circumstances under which the insurer will compensate the insured. The amount of money charged by the insurer to the policyholder for the coverage set forth in the insurance policy is called the premium. If the insured experiences a loss which is potentially covered by the insurance policy, the insured submits a claim to the insurer for processing by a claims adjuster. The insurer may hedge its own risk by taking out reinsurance, whereby another insurance company agrees to carry some of the risk, especially if the primary insurer deems the risk too large for it to carry.\n\nMethods for transferring or distributing risk were practiced by Chinese and Babylonian traders as long ago as the 3rd and 2nd millennia BC, respectively. Chinese merchants travelling treacherous river rapids would redistribute their wares across many vessels to limit the loss due to any single vessel's capsizing. The Babylonians developed a system which was recorded in the famous Code of Hammurabi, c. 1750 BC, and practiced by early Mediterranean sailing merchants. If a merchant received a loan to fund his shipment, he would pay the lender an additional sum in exchange for the lender's guarantee to cancel the loan should the shipment be stolen, or lost at sea.\n\nCirca 800 BC, the inhabitants of Rhodes created the 'general average'. This allowed groups of merchants to pay to insure their goods being shipped together. The collected premiums would be used to reimburse any merchant whose goods were jettisoned during transport, whether due to storm or sinkage.\n\nSeparate insurance contracts (i.e., insurance policies not bundled with loans or other kinds of contracts) were invented in Genoa in the 14th century, as were insurance pools backed by pledges of landed estates. The first known insurance contract dates from Genoa in 1347, and in the next century maritime insurance developed widely and premiums were intuitively varied with risks. These new insurance contracts allowed insurance to be separated from investment, a separation of roles that first proved useful in marine insurance.\n\nInsurance became far more sophisticated in Enlightenment era Europe, and specialized varieties developed.\nProperty insurance as we know it today can be traced to the Great Fire of London, which in 1666 devoured more than 13,000 houses. The devastating effects of the fire converted the development of insurance \"from a matter of convenience into one of urgency, a change of opinion reflected in Sir Christopher Wren's inclusion of a site for 'the Insurance Office' in his new plan for London in 1667.\" A number of attempted fire insurance schemes came to nothing, but in 1681, economist Nicholas Barbon and eleven associates established the first fire insurance company, the \"Insurance Office for Houses\", at the back of the Royal Exchange to insure brick and frame homes. Initially, 5,000 homes were insured by his Insurance Office.\n\nAt the same time, the first insurance schemes for the underwriting of business ventures became available. By the end of the seventeenth century, London's growing importance as a center for trade was increasing demand for marine insurance. In the late 1680s, Edward Lloyd opened a coffee house, which became the meeting place for parties in the shipping industry wishing to insure cargoes and ships, and those willing to underwrite such ventures. These informal beginnings led to the establishment of the insurance market Lloyd's of London and several related shipping and insurance businesses.\nThe first life insurance policies were taken out in the early 18th century. The first company to offer life insurance was the Amicable Society for a Perpetual Assurance Office, founded in London in 1706 by William Talbot and Sir Thomas Allen. Edward Rowe Mores established the Society for Equitable Assurances on Lives and Survivorship in 1762.\n\nIt was the world's first mutual insurer and it pioneered age based premiums based on mortality rate laying \"the framework for scientific insurance practice and development\" and \"the basis of modern life assurance upon which all life assurance schemes were subsequently based.\"\n\nIn the late 19th century \"accident insurance\" began to become available. The first company to offer accident insurance was the Railway Passengers Assurance Company, formed in 1848 in England to insure against the rising number of fatalities on the nascent railway system.\n\nBy the late 19th century governments began to initiate national insurance programs against sickness and old age. Germany built on a tradition of welfare programs in Prussia and Saxony that began as early as in the 1840s. In the 1880s Chancellor Otto von Bismarck introduced old age pensions, accident insurance and medical care that formed the basis for Germany's welfare state. In Britain more extensive legislation was introduced by the Liberal government in the 1911 National Insurance Act. This gave the British working classes the first contributory system of insurance against illness and unemployment. This system was greatly expanded after the Second World War under the influence of the Beveridge Report, to form the first modern welfare state.\n\nInsurance involves pooling funds from \"many\" insured entities (known as exposures) to pay for the losses that some may incur. The insured entities are therefore protected from risk for a fee, with the fee being dependent upon the frequency and severity of the event occurring. In order to be an insurable risk, the risk insured against must meet certain characteristics. Insurance as a financial intermediary is a commercial enterprise and a major part of the financial services industry, but individual entities can also self-insure through saving money for possible future losses.\n\nRisk which can be insured by private companies typically shares seven common characteristics:\n\n\nWhen a company insures an individual entity, there are basic legal requirements and regulations. Several commonly cited legal principles of insurance include:\n\nTo \"indemnify\" means to make whole again, or to be reinstated to the position that one was in, to the extent possible, prior to the happening of a specified event or peril. Accordingly, life insurance is generally not considered to be indemnity insurance, but rather \"contingent\" insurance (i.e., a claim arises on the occurrence of a specified event). There are generally three types of insurance contracts that seek to indemnify an insured:\n\nFrom an insured's standpoint, the result is usually the same: the insurer pays the loss and claims expenses.\n\nIf the Insured has a \"reimbursement\" policy, the insured can be required to pay for a loss and then be \"reimbursed\" by the insurance carrier for the loss and out of pocket costs including, with the permission of the insurer, claim expenses.\n\nUnder a \"pay on behalf\" policy, the insurance carrier would defend and pay a claim on behalf of the insured who would not be out of pocket for anything. Most modern liability insurance is written on the basis of \"pay on behalf\" language which enables the insurance carrier to manage and control the claim.\n\nUnder an \"indemnification\" policy, the insurance carrier can generally either \"reimburse\" or \"pay on behalf of\", whichever is more beneficial to it and the insured in the claim handling process.\n\nAn entity seeking to transfer risk (an individual, corporation, or association of any type, etc.) becomes the 'insured' party once risk is assumed by an 'insurer', the insuring party, by means of a contract, called an insurance policy. Generally, an insurance contract includes, at a minimum, the following elements: identification of participating parties (the insurer, the insured, the beneficiaries), the premium, the period of coverage, the particular loss event covered, the amount of coverage (i.e., the amount to be paid to the insured or beneficiary in the event of a loss), and exclusions (events not covered). An insured is thus said to be \"indemnified\" against the loss covered in the policy.\n\nWhen insured parties experience a loss for a specified peril, the coverage entitles the policyholder to make a claim against the insurer for the covered amount of loss as specified by the policy. The fee paid by the insured to the insurer for assuming the risk is called the premium. Insurance premiums from many insureds are used to fund accounts reserved for later payment of claims – in theory for a relatively few claimants – and for overhead costs. So long as an insurer maintains adequate funds set aside for anticipated losses (called reserves), the remaining margin is an insurer's profit.\n\nPolicies typically include a number of exclusions, including typically:\n\nInsurance can have various effects on society through the way that it changes who bears the cost of losses and damage. On one hand it can increase fraud; on the other it can help societies and individuals prepare for catastrophes and mitigate the effects of catastrophes on both households and societies.\n\nInsurance can influence the probability of losses through moral hazard, insurance fraud, and preventive steps by the insurance company. Insurance scholars have typically used moral hazard to refer to the increased loss due to unintentional carelessness and insurance fraud to refer to increased risk due to intentional carelessness or indifference. Insurers attempt to address carelessness through inspections, policy provisions requiring certain types of maintenance, and possible discounts for loss mitigation efforts. While in theory insurers could encourage investment in loss reduction, some commentators have argued that in practice insurers had historically not aggressively pursued loss control measures—particularly to prevent disaster losses such as hurricanes—because of concerns over rate reductions and legal battles. However, since about 1996 insurers have begun to take a more active role in loss mitigation, such as through building codes.\n\nAccording to the study books of The Chartered Insurance Institute, there are variant methods of insurance as follows:\n\nThe business model is to collect more in premium and investment income than is paid out in losses, and to also offer a competitive price which consumers will accept. Profit can be reduced to a simple equation:\n\nInsurers make money in two ways:\n\nThe most complicated aspect of the insurance business is the actuarial science of ratemaking (price-setting) of policies, which uses statistics and probability to approximate the rate of future claims based on a given risk. After producing rates, the insurer will use discretion to reject or accept risks through the underwriting process.\n\nAt the most basic level, initial ratemaking involves looking at the frequency and severity of insured perils and the expected average payout resulting from these perils. Thereafter an insurance company will collect historical loss data, bring the loss data to present value, and compare these prior losses to the premium collected in order to assess rate adequacy. Loss ratios and expense loads are also used. Rating for different risk characteristics involves at the most basic level comparing the losses with \"loss relativities\"—a policy with twice as many losses would therefore be charged twice as much. More complex multivariate analyses are sometimes used when multiple characteristics are involved and a univariate analysis could produce confounded results. Other statistical methods may be used in assessing the probability of future losses.\n\nUpon termination of a given policy, the amount of premium collected minus the amount paid out in claims is the insurer's underwriting profit on that policy. Underwriting performance is measured by something called the \"combined ratio\", which is the ratio of expenses/losses to premiums. A combined ratio of less than 100% indicates an underwriting profit, while anything over 100 indicates an underwriting loss. A company with a combined ratio over 100% may nevertheless remain profitable due to investment earnings.\n\nInsurance companies earn investment profits on \"float\". Float, or available reserve, is the amount of money on hand at any given moment that an insurer has collected in insurance premiums but has not paid out in claims. Insurers start investing insurance premiums as soon as they are collected and continue to earn interest or other income on them until claims are paid out. The Association of British Insurers (gathering 400 insurance companies and 94% of UK insurance services) has almost 20% of the investments in the London Stock Exchange. In 2007, U.S. industry profits from float totaled $58 billion. In a 2009 letter to investors, Warren Buffett wrote, \"we were \"paid\" $2.8 billion to hold our float in 2008.\"\n\nIn the United States, the underwriting loss of property and casualty insurance companies was $142.3 billion in the five years ending 2003. But overall profit for the same period was $68.4 billion, as the result of float. Some insurance industry insiders, most notably Hank Greenberg, do not believe that it is forever possible to sustain a profit from float without an underwriting profit as well, but this opinion is not universally held. Reliance on float for profit has led some industry experts to call insurance companies \"investment companies that raise the money for their investments by selling insurance.\"\n\nNaturally, the float method is difficult to carry out in an economically depressed period. Bear markets do cause insurers to shift away from investments and to toughen up their underwriting standards, so a poor economy generally means high insurance premiums. This tendency to swing between profitable and unprofitable periods over time is commonly known as the underwriting, or insurance, cycle.\n\nClaims and loss handling is the materialized utility of insurance; it is the actual \"product\" paid for. Claims may be filed by insureds directly with the insurer or through brokers or agents. The insurer may require that the claim be filed on its own proprietary forms, or may accept claims on a standard industry form, such as those produced by ACORD.\n\nInsurance company claims departments employ a large number of claims adjusters supported by a staff of records management and data entry clerks. Incoming claims are classified based on severity and are assigned to adjusters whose settlement authority varies with their knowledge and experience. The adjuster undertakes an investigation of each claim, usually in close cooperation with the insured, determines if coverage is available under the terms of the insurance contract, and if so, the reasonable monetary value of the claim, and authorizes payment.\n\nThe policyholder may hire their own public adjuster to negotiate the settlement with the insurance company on their behalf. For policies that are complicated, where claims may be complex, the insured may take out a separate insurance policy add-on, called loss recovery insurance, which covers the cost of a public adjuster in the case of a claim.\n\nAdjusting liability insurance claims is particularly difficult because there is a third party involved, the plaintiff, who is under no contractual obligation to cooperate with the insurer and may in fact regard the insurer as a deep pocket. The adjuster must obtain legal counsel for the insured (either inside \"house\" counsel or outside \"panel\" counsel), monitor litigation that may take years to complete, and appear in person or over the telephone with settlement authority at a mandatory settlement conference when requested by the judge.\n\nIf a claims adjuster suspects under-insurance, the condition of average may come into play to limit the insurance company's exposure.\n\nIn managing the claims handling function, insurers seek to balance the elements of customer satisfaction, administrative handling expenses, and claims overpayment leakages. As part of this balancing act, fraudulent insurance practices are a major business risk that must be managed and overcome. Disputes between insurers and insureds over the validity of claims or claims handling practices occasionally escalate into litigation (see insurance bad faith).\n\nInsurers will often use insurance agents to initially market or underwrite their customers. Agents can be captive, meaning they write only for one company, or independent, meaning that they can issue policies from several companies. The existence and success of companies using insurance agents is likely due to improved and personalized service. Companies also use Broking firms, Banks and other corporate entities (like Self Help Groups, Microfinance Institutions, NGOs, etc.) to market their products.\n\nAny risk that can be quantified can potentially be insured. Specific kinds of risk that may give rise to claims are known as perils. An insurance policy will set out in detail which perils are covered by the policy and which are not. Below are non-exhaustive lists of the many different types of insurance that exist. A single policy that may cover risks in one or more of the categories set out below. For example, vehicle insurance would typically cover both the property risk (theft or damage to the vehicle) and the liability risk (legal claims arising from an accident). A home insurance policy in the United States typically includes coverage for damage to the home and the owner's belongings, certain legal claims against the owner, and even a small amount of coverage for medical expenses of guests who are injured on the owner's property.\n\nBusiness insurance can take a number of different forms, such as the various kinds of professional liability insurance, also called professional indemnity (PI), which are discussed below under that name; and the business owner's policy (BOP), which packages into one policy many of the kinds of coverage that a business owner needs, in a way analogous to how homeowners' insurance packages the coverages that a homeowner needs.\n\nAuto insurance protects the policyholder against financial loss in the event of an incident involving a vehicle they own, such as in a traffic collision.\n\nCoverage typically includes:\n\nGap insurance covers the excess amount on your auto loan in an instance where your insurance company does not cover the entire loan. Depending on the company's specific policies it might or might not cover the deductible as well. This coverage is marketed for those who put low down payments, have high interest rates on their loans, and those with 60-month or longer terms. Gap insurance is typically offered by a finance company when the vehicle owner purchases their vehicle, but many auto insurance companies offer this coverage to consumers as well.\n\nHealth insurance policies cover the cost of medical treatments. Dental insurance, like medical insurance, protects policyholders for dental costs. In most developed countries, all citizens receive some health coverage from their governments, paid through taxation. In most countries, health insurance is often part of an employer's benefits.\n\n\nCasualty insurance insures against accidents, not necessarily tied to any specific property. It is a broad spectrum of insurance that a number of other types of insurance could be classified, such as auto, workers compensation, and some liability insurances.\n\nLife insurance provides a monetary benefit to a decedent's family or other designated beneficiary, and may specifically provide for income to an insured person's family, burial, funeral and other final expenses. Life insurance policies often allow the option of having the proceeds paid to the beneficiary either in a lump sum cash payment or an annuity. In most states, a person cannot purchase a policy on another person without their knowledge.\n\nAnnuities provide a stream of payments and are generally classified as insurance because they are issued by insurance companies, are regulated as insurance, and require the same kinds of actuarial and investment management expertise that life insurance requires. Annuities and pensions that pay a benefit for life are sometimes regarded as insurance against the possibility that a retiree will outlive his or her financial resources. In that sense, they are the complement of life insurance and, from an underwriting perspective, are the mirror image of life insurance.\n\nCertain life insurance contracts accumulate cash values, which may be taken by the insured if the policy is surrendered or which may be borrowed against. Some policies, such as annuities and endowment policies, are financial instruments to accumulate or liquidate wealth when it is needed.\n\nIn many countries, such as the United States and the UK, the tax law provides that the interest on this cash value is not taxable under certain circumstances. This leads to widespread use of life insurance as a tax-efficient method of saving as well as protection in the event of early death.\n\nIn the United States, the tax on interest income on life insurance policies and annuities is generally deferred. However, in some cases the benefit derived from tax deferral may be offset by a low return. This depends upon the insuring company, the type of policy and other variables (mortality, market return, etc.). Moreover, other income tax saving vehicles (e.g., IRAs, 401(k) plans, Roth IRAs) may be better alternatives for value accumulation.\n\nBurial insurance is a very old type of life insurance which is paid out upon death to cover final expenses, such as the cost of a funeral. The Greeks and Romans introduced burial insurance c. 600 CE when they organized guilds called \"benevolent societies\" which cared for the surviving families and paid funeral expenses of members upon death. Guilds in the Middle Ages served a similar purpose, as did friendly societies during Victorian times.\n\nProperty insurance provides protection against risks to property, such as fire, theft or weather damage. This may include specialized forms of insurance such as fire insurance, flood insurance, earthquake insurance, home insurance, inland marine insurance or boiler insurance.\nThe term \"property insurance\" may, like casualty insurance, be used as a broad category of various subtypes of insurance, some of which are listed below:\n\n\nLiability insurance is a very broad superset that covers legal claims against the insured. Many types of insurance include an aspect of liability coverage. For example, a homeowner's insurance policy will normally include liability coverage which protects the insured in the event of a claim brought by someone who slips and falls on the property; automobile insurance also includes an aspect of liability insurance that indemnifies against the harm that a crashing car can cause to others' lives, health, or property. The protection offered by a liability insurance policy is twofold: a legal defense in the event of a lawsuit commenced against the policyholder and indemnification (payment on behalf of the insured) with respect to a settlement or court verdict. Liability policies typically cover only the negligence of the insured, and will not apply to results of wilful or intentional acts by the insured.\nOften a commercial insured's liability insurance program consists of several layers. The first layer of insurance generally consists of primary insurance, which provides first dollar indemnity for judgments and settlements up to the limits of liability of the primary policy. Generally, primary insurance is subject to a deductible and obligates the insured to defend the insured against lawsuits, which is normally accomplished by assigning counsel to defend the insured. In many instances, a commercial insured may elect to self-insure. Above the primary insurance or self-insured retention, the insured may have one or more layers of excess insurance to provide coverage additional limits of indemnity protection. There are a variety of types of excess insurance, including \"stand-alone\" excess policies (policies that contain their own terms, conditions, and exclusions), \"follow form\" excess insurance (policies that follow the terms of the underlying policy except as specifically provided), and \"umbrella\" insurance policies (excess insurance that in some circumstances could provide coverage that is broader than the underlying insurance).\n\nCredit insurance repays some or all of a loan when the borrower is insolvent.\n\n\n\n\nSome communities prefer to create virtual insurance amongst themselves by other means than contractual risk transfer, which assigns explicit numerical values to risk. A number of religious groups, including the Amish and some Muslim groups, depend on support provided by their communities when disasters strike. The risk presented by any given person is assumed collectively by the community who all bear the cost of rebuilding lost property and supporting people whose needs are suddenly greater after a loss of some kind. In supportive communities where others can be trusted to follow community leaders, this tacit form of insurance can work. In this manner the community can even out the extreme differences in insurability that exist among its members. Some further justification is also provided by invoking the moral hazard of explicit insurance contracts.\n\nIn the United Kingdom, The Crown (which, for practical purposes, meant the civil service) did not insure property such as government buildings. If a government building was damaged, the cost of repair would be met from public funds because, in the long run, this was cheaper than paying insurance premiums. Since many UK government buildings have been sold to property companies and rented back, this arrangement is now less common and may have disappeared altogether.\n\nIn the United States, the most prevalent form of self-insurance is governmental risk management pools. They are self-funded cooperatives, operating as carriers of coverage for the majority of governmental entities today, such as county governments, municipalities, and school districts. Rather than these entities independently self-insure and risk bankruptcy from a large judgment or catastrophic loss, such governmental entities form a risk pool. Such pools begin their operations by capitalization through member deposits or bond issuance. Coverage (such as general liability, auto liability, professional liability, workers compensation, and property) is offered by the pool to its members, similar to coverage offered by insurance companies. However, self-insured pools offer members lower rates (due to not needing insurance brokers), increased benefits (such as loss prevention services) and subject matter expertise. Of approximately 91,000 distinct governmental entities operating in the United States, 75,000 are members of self-insured pools in various lines of coverage, forming approximately 500 pools. Although a relatively small corner of the insurance market, the annual contributions (self-insured premiums) to such pools have been estimated up to 17 billion dollars annually.\n\nInsurance companies may sell any combination of insurance types, but are often classified into three groups:\n\n\nGeneral insurance companies can be further divided into these sub categories.\n\nIn most countries, life and non-life insurers are subject to different regulatory regimes and different tax and accounting rules. The main reason for the distinction between the two types of company is that life, annuity, and pension business is very long-term in nature – coverage for life assurance or a pension can cover risks over many decades. By contrast, non-life insurance cover usually covers a shorter period, such as one year.\n\nInsurance companies are generally classified as either mutual or proprietary companies. Mutual companies are owned by the policyholders, while shareholders (who may or may not own policies) own proprietary insurance companies.\n\nDemutualization of mutual insurers to form stock companies, as well as the formation of a hybrid known as a mutual holding company, became common in some countries, such as the United States, in the late 20th century. However, not all states permit mutual holding companies.\n\nReinsurance companies are insurance companies that sell policies to other insurance companies, allowing them to reduce their risks and protect themselves from very large losses. The reinsurance market is dominated by a few very large companies, with huge reserves. A reinsurer may also be a direct writer of insurance risks as well.\n\nCaptive insurance companies may be defined as limited-purpose insurance companies established with the specific objective of financing risks emanating from their parent group or groups. This definition can sometimes be extended to include some of the risks of the parent company's customers. In short, it is an in-house self-insurance vehicle. Captives may take the form of a \"pure\" entity (which is a 100% subsidiary of the self-insured parent company); of a \"mutual\" captive (which insures the collective risks of members of an industry); and of an \"association\" captive (which self-insures individual risks of the members of a professional, commercial or industrial association). Captives represent commercial, economic and tax advantages to their sponsors because of the reductions in costs they help create and for the ease of insurance risk management and the flexibility for cash flows they generate. Additionally, they may provide coverage of risks which is neither available nor offered in the traditional insurance market at reasonable prices.\n\nThe types of risk that a captive can underwrite for their parents include property damage, public and product liability, professional indemnity, employee benefits, employers' liability, motor and medical aid expenses. The captive's exposure to such risks may be limited by the use of reinsurance.\n\nCaptives are becoming an increasingly important component of the risk management and risk financing strategy of their parent. This can be understood against the following background:\n\nOther possible forms for an insurance company include reciprocals, in which policyholders reciprocate in sharing risks, and Lloyd's organizations.\n\nAdmitted insurance companies are those in the United States that have been admitted or licensed by the state licensing agency. The insurance they sell is called admitted insurance. Non-admitted companies have not been approved by the state licensing agency, but are allowed to sell insurance under special circumstances when they meet an insurance need that admitted companies cannot or will not meet.\n\nThere are also companies known as \"insurance consultants\". Like a mortgage broker, these companies are paid a fee by the customer to shop around for the best insurance policy amongst many companies. Similar to an insurance consultant, an 'insurance broker' also shops around for the best insurance policy amongst many companies. However, with insurance brokers, the fee is usually paid in the form of commission from the insurer that is selected rather than directly from the client.\n\nNeither insurance consultants nor insurance brokers are insurance companies and no risks are transferred to them in insurance transactions. Third party administrators are companies that perform underwriting and sometimes claims handling services for insurance companies. These companies often have special expertise that the insurance companies do not have.\n\nThe financial stability and strength of an insurance company should be a major consideration when buying an insurance contract. An insurance premium paid currently provides coverage for losses that might arise many years in the future. For that reason, the viability of the insurance carrier is very important. In recent years, a number of insurance companies have become insolvent, leaving their policyholders with no coverage (or coverage only from a government-backed insurance pool or other arrangement with less attractive payouts for losses). A number of independent rating agencies provide information and rate the financial viability of insurance companies.\n\nInsurance companies are rated by various agencies such as A. M. Best. The ratings include the company's financial strength, which measures its ability to pay claims. It also rates financial instruments issued by the insurance company, such as bonds, notes, and securitization products.\n\nGlobal insurance premiums grew by 2.7% in inflation-adjusted terms in 2010 to $4.3 trillion, climbing above pre-crisis levels. The return to growth and record premiums generated during the year followed two years of decline in real terms. Life insurance premiums increased by 3.2% in 2010 and non-life premiums by 2.1%. While industrialised countries saw an increase in premiums of around 1.4%, insurance markets in emerging economies saw rapid expansion with 11% growth in premium income. The global insurance industry was sufficiently capitalised to withstand the financial crisis of 2008 and 2009 and most insurance companies restored their capital to pre-crisis levels by the end of 2010. With the continuation of the gradual recovery of the global economy, it is likely the insurance industry will continue to see growth in premium income both in industrialised countries and emerging markets in 2011.\n\nAdvanced economies account for the bulk of global insurance. With premium income of $1.62 trillion, Europe was the most important region in 2010, followed by North America $1.41 trillion and Asia $1.16 trillion. Europe has however seen a decline in premium income during the year in contrast to the growth seen in North America and Asia. The top four countries generated more than a half of premiums. The United States and Japan alone accounted for 40% of world insurance, much higher than their 7% share of the global population. Emerging economies accounted for over 85% of the world's population but only around 15% of premiums. Their markets are however growing at a quicker pace. The country expected to have the biggest impact on the insurance share distribution across the world is China. According to Sam Radwan of ENHANCE International LLC, low premium penetration (insurance premium as a % of GDP), an ageing population and the largest car market in terms of new sales, premium growth has averaged 15–20% in the past five years, and China is expected to be the largest insurance market in the next decade or two.\n\nIn the United States, insurance is regulated by the states under the McCarran-Ferguson Act, with \"periodic proposals for federal intervention\", and a nonprofit coalition of state insurance agencies called the National Association of Insurance Commissioners works to harmonize the country's different laws and regulations. The National Conference of Insurance Legislators (NCOIL) also works to harmonize the different state laws.\n\nIn the European Union, the Third Non-Life Directive and the Third Life Directive, both passed in 1992 and effective 1994, created a single insurance market in Europe and allowed insurance companies to offer insurance anywhere in the EU (subject to permission from authority in the head office) and allowed insurance consumers to purchase insurance from any insurer in the EU. As far as insurance in the United Kingdom, the Financial Services Authority took over insurance regulation from the General Insurance Standards Council in 2005; laws passed include the Insurance Companies Act 1973 and another in 1982, and reforms to warranty and other aspects under discussion .\n\nThe insurance industry in China was nationalized in 1949 and thereafter offered by only a single state-owned company, the People's Insurance Company of China, which was eventually suspended as demand declined in a communist environment. In 1978, market reforms led to an increase in the market and by 1995 a comprehensive Insurance Law of the People's Republic of China was passed, followed in 1998 by the formation of China Insurance Regulatory Commission (CIRC), which has broad regulatory authority over the insurance market of China.\n\nIn India IRDA is insurance regulatory authority. As per the section 4 of IRDA Act 1999, Insurance Regulatory and Development Authority (IRDA), which was constituted by an act of parliament. National Insurance Academy, Pune is apex insurance capacity builder institute promoted with support from Ministry of Finance and by LIC, Life & General Insurance companies.\n\nIn 2017, within the framework of the joint project of the Bank of Russia and Yandex, a special check mark (a green circle with a tick and 'Реестр ЦБ РФ' (Unified state register of insurance entities) text box) appeared in the search for Yandex system, informing the consumer that the company's financial services are offered on the marked website, which has the status of an insurance company, a broker or a mutual insurance association.\n\nInsurance is just a risk transfer mechanism wherein the financial burden which may arise due to some fortuitous event is transferred to a bigger entity called an Insurance Company by way of paying premiums. This only reduces the financial burden and not the actual chances of happening of an event. Insurance is a risk for both the insurance company and the insured. The insurance company understands the risk involved and will perform a risk assessment when writing the policy. As a result, the premiums may go up if they determine that the policyholder will file a claim. If a person is financially stable and plans for life's unexpected events, they may be able to go without insurance. However, they must have enough to cover a total and complete loss of employment and of their possessions. Some states will accept a surety bond, a government bond, or even making a cash deposit with the state.\n\nAn insurance company may inadvertently find that its insureds may not be as risk-averse as they might otherwise be (since, by definition, the insured has transferred the risk to the insurer), a concept known as moral hazard. This 'insulates' many from the\ntrue costs of living with risk, negating measures that can mitigate or adapt to risk and leading some to describe insurance schemes as potentially maladaptive. To reduce their own financial exposure, insurance companies have contractual clauses that mitigate their obligation to provide coverage if the insured engages in behavior that grossly magnifies their risk of loss or liability.\n\nFor example, life insurance companies may require higher premiums or deny coverage altogether to people who work in hazardous occupations or engage in dangerous sports. Liability insurance providers do not provide coverage for liability arising from intentional torts committed by or at the direction of the insured. Even if a provider desired to provide such coverage, it is against the public policy of most countries to allow such insurance to exist, and thus it is usually illegal.\n\nInsurance policies can be complex and some policyholders may not understand all the fees and coverages included in a policy. As a result, people may buy policies on unfavorable terms. In response to these issues, many countries have enacted detailed statutory and regulatory regimes governing every aspect of the insurance business, including minimum standards for policies and the ways in which they may be advertised and sold.\n\nFor example, most insurance policies in the English language today have been carefully drafted in plain English; the industry learned the hard way that many courts will not enforce policies against insureds when the judges themselves cannot understand what the policies are saying. Typically, courts construe ambiguities in insurance policies against the insurance company and in favor of coverage under the policy.\n\nMany institutional insurance purchasers buy insurance through an insurance broker. While on the surface it appears the broker represents the buyer (not the insurance company), and typically counsels the buyer on appropriate coverage and policy limitations, in the vast majority of cases a broker's compensation comes in the form of a commission as a percentage of the insurance premium, creating a conflict of interest in that the broker's financial interest is tilted towards encouraging an insured to purchase more insurance than might be necessary at a higher price. A broker generally holds contracts with many insurers, thereby allowing the broker to \"shop\" the market for the best rates and coverage possible.\n\nInsurance may also be purchased through an agent. A tied agent, working exclusively with one insurer, represents the insurance company from whom the policyholder buys (while a free agent sells policies of various insurance companies). Just as there is a potential conflict of interest with a broker, an agent has a different type of conflict. Because agents work directly for the insurance company, if there is a claim the agent may advise the client to the benefit of the insurance company. Agents generally cannot offer as broad a range of selection compared to an insurance broker.\n\nAn independent insurance consultant advises insureds on a fee-for-service retainer, similar to an attorney, and thus offers completely independent advice, free of the financial conflict of interest of brokers or agents. However, such a consultant must still work through brokers or agents in order to secure coverage for their clients.\n\nIn the United States, economists and consumer advocates generally consider insurance to be worthwhile for low-probability, catastrophic losses, but not for high-probability, small losses. Because of this, consumers are advised to select high deductibles and to not insure losses which would not cause a disruption in their life. However, consumers have shown a tendency to prefer low deductibles and to prefer to insure relatively high-probability, small losses over low-probability, perhaps due to not understanding or ignoring the low-probability risk. This is associated with reduced purchasing of insurance against low-probability losses, and may result in increased inefficiencies from moral hazard.\n\nRedlining is the practice of denying insurance coverage in specific geographic areas, supposedly because of a high likelihood of loss, while the alleged motivation is unlawful discrimination. Racial profiling or redlining has a long history in the property insurance industry in the United States. From a review of industry underwriting and marketing materials, court documents, and research by government agencies, industry and community groups, and academics, it is clear that race has long affected and continues to affect the policies and practices of the insurance industry.\n\nIn July 2007, The Federal Trade Commission (FTC) released a report presenting the results of a study concerning credit-based insurance scores in automobile insurance. The study found that these scores are effective predictors of risk. It also showed that African-Americans and Hispanics are substantially overrepresented in the lowest credit scores, and substantially underrepresented in the highest, while Caucasians and Asians are more evenly spread across the scores. The credit scores were also found to predict risk within each of the ethnic groups, leading the FTC to conclude that the scoring models are not solely proxies for redlining. The FTC indicated little data was available to evaluate benefit of insurance scores to consumers. The report was disputed by representatives of the Consumer Federation of America, the National Fair Housing Alliance, the National Consumer Law Center, and the Center for Economic Justice, for relying on data provided by the insurance industry.\n\nAll states have provisions in their rate regulation laws or in their fair trade practice acts that prohibit unfair discrimination, often called redlining, in setting rates and making insurance available.\n\nIn determining premiums and premium rate structures, insurers consider quantifiable factors, including location, credit scores, gender, occupation, marital status, and education level. However, the use of such factors is often considered to be unfair or unlawfully discriminatory, and the reaction against this practice has in some instances led to political disputes about the ways in which insurers determine premiums and regulatory intervention to limit the factors used.\n\nAn insurance underwriter's job is to evaluate a given risk as to the likelihood that a loss will occur. Any factor that causes a greater likelihood of loss should theoretically be charged a higher rate. This basic principle of insurance must be followed if insurance companies are to remain solvent. Thus, \"discrimination\" against (i.e., negative differential treatment of) potential insureds in the risk evaluation and premium-setting process is a necessary by-product of the fundamentals of insurance underwriting. For instance, insurers charge older people significantly higher premiums than they charge younger people for term life insurance. Older people are thus treated differently from younger people (i.e., a distinction is made, discrimination occurs). The rationale for the differential treatment goes to the heart of the risk a life insurer takes: Old people are likely to die sooner than young people, so the risk of loss (the insured's death) is greater in any given period of time and therefore the risk premium must be higher to cover the greater risk. However, treating insureds differently when there is no actuarially sound reason for doing so is unlawful discrimination.\n\nNew assurance products can now be protected from copying with a business method patent in the United States.\n\nA recent example of a new insurance product that is patented is Usage Based auto insurance. Early versions were independently invented and patented by a major US auto insurance company, Progressive Auto Insurance () and a Spanish independent inventor, Salvador Minguijon Perez ().\n\nMany independent inventors are in favor of patenting new insurance products since it gives them protection from big companies when they bring their new insurance products to market. Independent inventors account for 70% of the new U.S. patent applications in this area.\n\nMany insurance executives are opposed to patenting insurance products because it creates a new risk for them. The Hartford insurance company, for example, recently had to pay $80 million to an independent inventor, Bancorp Services, in order to settle a patent infringement and theft of trade secret lawsuit for a type of corporate owned life insurance product invented and patented by Bancorp.\n\nThere are currently about 150 new patent applications on insurance inventions filed per year in the United States. The rate at which patents have been issued has steadily risen from 15 in 2002 to 44 in 2006.\n\nThe first insurance patent to be granted was including another example of an application posted was US2009005522 \"risk assessment company\". It was posted on 6 March 2009. This patent application describes a method for increasing the ease of changing insurance companies.\n\nInsurance on demand (also IoD) is an insurance service that provides clients with insurance protection when they need, i.e. only episodic rather than on 24/7 basis as typically provided by traditional insurers (e.g. clients can purchase an insurance for one single flight rather than a longer-lasting travel insurance plan).\n\nCertain insurance products and practices have been described as rent-seeking by critics. That is, some insurance products or practices are useful primarily because of legal benefits, such as reducing taxes, as opposed to providing protection against risks of adverse events. Under United States tax law, for example, most owners of variable annuities and variable life insurance can invest their premium payments in the stock market and defer or eliminate paying any taxes on their investments until withdrawals are made. Sometimes this tax deferral is the only reason people use these products. Another example is the legal infrastructure which allows life insurance to be held in an irrevocable trust which is used to pay an estate tax while the proceeds themselves are immune from the estate tax.\n\nMuslim scholars have varying opinions about life insurance. Life insurance policies that earn interest (or guaranteed bonus/NAV) are generally considered to be a form of \"riba\" (usury) and some consider even policies that do not earn interest to be a form of \"gharar\" (speculation). Some argue that \"gharar\" is not present due to the actuarial science behind the underwriting.\nJewish rabbinical scholars also have expressed reservations regarding insurance as an avoidance of God's will but most find it acceptable in moderation.\n\nSome Christians believe insurance represents a lack of faith and there is a long history of resistance to commercial insurance in Anabaptist communities (Mennonites, Amish, Hutterites, Brethren in Christ) but many participate in community-based self-insurance programs that spread risk within their communities.\n\nCountry-specific articles:\n\n"}
{"id": "63121", "url": "https://en.wikipedia.org/wiki?curid=63121", "title": "Investment", "text": "Investment\n\nTo invest is to allocate money in the expectation of some benefit in the future.\n\nIn finance, the benefit from an investment is called a return. The return may consist of a gain (or loss) realised from the sale of property or an investment, unrealised capital appreciation (or depreciation), or investment income such as dividends, interest, rental income etc., or a combination of capital gain and income. The return may also include currency gains or losses due to changes in foreign currency exchange rates.\n\nInvestors generally expect higher returns from riskier investments. When a low risk investment is made, the return is also generally low.\n\nInvestors, particularly novices, are often advised to adopt a particular investment strategy and diversify their portfolio. Diversification has the statistical effect of reducing overall risk.\n\nAn investor may bear a risk of loss of some or all of their capital invested. Investment differs from arbitrage, in which profit is generated without investing capital or bearing risk.\n\nSavings bear the (normally remote) risk that the financial provider may default. \n\nForeign currency savings also bear foreign exchange risk: if the currency of a savings account differs from the account holder's home currency, then there is the risk that the exchange rate between the two currencies will move unfavorably, so that the value of the savings account decreases, measured in the account holder's home currency.\n\nIn contrast with savings, investments tend to carry more risk, in the form of both a wider variety of risk factors, and a greater level of uncertainty.\n\nThe Code of Hammurabi (around 1700 BC) provided a legal framework for investment, establishing a means for the pledge of collateral by codifying debtor and creditor rights in regard to pledged land. Punishments for breaking financial obligations were not as severe as those for crimes involving injury or death.\n\nIn the early 1900s, purchasers of stocks, bonds, and other securities were described in media, academia, and commerce as speculators. Since the Wall Street crash of 1929, and particularly by the 1950s, the term investment had come to denote the more conservative end of the securities spectrum, while speculation was applied by financial brokers and their advertising agencies to higher risk securities much in vogue at that time. Since the last half of the 20th century, the terms speculation and speculator have specifically referred to higher risk ventures.\n\nA value investor buys assets that they believe to be undervalued (and sells overvalued ones). To identify undervalued securities, a value investor uses analysis of the financial reports of the issuer to evaluate the security. Value investors employ accounting ratios, such as earnings per share and sales growth, to identify securities trading at prices below their worth.\n\nWarren Buffett and Benjamin Graham are notable examples of value investors. Graham and Dodd's seminal work, Security Analysis, was written in the wake of the Wall Street Crash of 1929.\n\nThe price to earnings ratio (P/E), or earnings multiple, is a particularly significant and recognized fundamental ratio, with a function of dividing the share price of stock, by its earnings per share. This will provide the value representing the sum investors are prepared to expend for each dollar of company earnings. This ratio is an important aspect, due to its capacity as measurement for the comparison of valuations of various companies. A stock with a lower P/E ratio will cost less per share than one with a higher P/E, taking into account the same level of financial performance; therefore, it essentially means a low P/E is the preferred option.\n\nAn instance in which the price to earnings ratio has a lesser significance is when companies in different industries are compared. For example, although it is reasonable for a telecommunications stock to show a P/E in the low teens, in the case of hi-tech stock, a P/E in the 40s range is not unusual. When making comparisons, the P/E ratio can give you a refined view of a particular stock valuation.\n\nFor investors paying for each dollar of a company's earnings, the P/E ratio is a significant indicator, but the price-to-book ratio (P/B) is also a reliable indication of how much investors are willing to spend on each dollar of company assets. In the process of the P/B ratio, the share price of a stock is divided by its net assets; any intangibles, such as goodwill, are not taken into account. It is a crucial factor of the price-to-book ratio, due to it indicating the actual payment for tangible assets and not the more difficult valuation of intangibles. Accordingly, the P/B could be considered a comparatively conservative metric.\n\nInvestments are often made indirectly through intermediary financial institutions. These intermediaries include pension funds, banks, and insurance companies. They may pool money received from a number of individual end investors into funds such as investment trusts, unit trusts, SICAVs, etc. to make large-scale investments. Each individual investor holds an indirect or direct claim on the assets purchased, subject to charges levied by the intermediary, which may be large and varied.\n\nApproaches to investment sometimes referred to in marketing of collective investments include dollar cost averaging and market timing.\n\nInvestors famous for their success include Warren Buffett. In the March 2013 edition of \"Forbes\" magazine, Warren Buffett ranked number 2 in their Forbes 400 list. Buffett has advised in numerous articles and interviews that a good investment strategy is long-term and due diligence is the key to investing in the right assets.\n\nEdward O. Thorp was a highly successful hedge fund manager in the 1970s and 1980s who spoke of a similar approach.\n\nThe investment principles of both of these investors have points in common with the Kelly criterion for money management. Numerous interactive calculators which use the Kelly criterion can be found online.\n\nFree cash flow measures the cash a company generates which is available to its debt and equity investors, after allowing for reinvestment in working capital and capital expenditure. High and rising free cash flow therefore tend to make a company more attractive to investors.\n\nThe debt-to-equity ratio is an indicator of capital structure. A high proportion of debt, reflected in a high debt-to-equity ratio, tends to make a company's earnings, free cash flow, and ultimately the returns to its investors, more risky or volatile. Investors compare a company's debt-to-equity ratio with those of other companies in the same industry, and examine trends in debt-to-equity ratios and free cash flow.\n"}
{"id": "19881", "url": "https://en.wikipedia.org/wiki?curid=19881", "title": "Management", "text": "Management\n\nManagement (or managing) is the administration of an organization, whether it is a business, a not-for-profit organization, or government body. Management includes the activities of setting the strategy of an organization and coordinating the efforts of its employees (or of volunteers) to accomplish its objectives through the application of available resources, such as financial, natural, technological, and human resources. The term \"management\" may also refer to those people who manage an organization - individually: managers.\n\nSocial scientists study management as an academic discipline, investigating areas such as social organization and organizational leadership. Some people study management at colleges or universities; major degrees in management include the Bachelor of Commerce (B.Com.) Bachelor of Business Administration (BBA.) Master of Business Administration (MBA.) Master in Management (MScM or MIM) and, for the public sector, the Master of Public Administration (MPA) degree. Individuals who aim to become management specialists or experts, management researchers, or professors may complete the Doctor of Management (DM), the Doctor of Business Administration (DBA), or the PhD in Business Administration or Management. There has recently been a movement for evidence-based management.\n\nLarger organizations generally have three levels of managers, which are typically organized in a hierarchical, pyramid structure:\n\nIn smaller organizations, an individual manager may have a much wider scope. A single manager may perform several roles or even all of the roles commonly observed in a large organization.\n\nViews on the definition and scope of management include:\n\nManagement involves identifying the mission, objective, procedures, rules and manipulation\nof the human capital of an enterprise to contribute to the success of the enterprise. This implies effective communication: an enterprise environment (as opposed to a physical or mechanical mechanism) implies human motivation and implies some sort of successful progress or system outcome. As such, management is not the manipulation of a mechanism (machine or automated program), not the herding of animals, and can occur either in a legal or in an illegal enterprise or environment. From an individual's perspective, management does not need to be seen solely from an enterprise point of view, because management is an essential function in improving one's life and relationships. Management is therefore everywhere and it has a wider range of application. Based on this, management must have humans. Communication and a positive endeavor are two main aspects of it either through enterprise or through independent pursuit. Plans, measurements, motivational psychological tools, goals, and economic measures (profit, etc.) may or may not be necessary components for there to be management. At first, one views management functionally, such as measuring quantity, adjusting plans, meeting goals. This applies even in situations where planning does not take place. From this perspective, Henri Fayol (1841–1925)\nconsiders management to consist of five functions:\n\n\nIn another way of thinking, Mary Parker Follett (1868–1933), allegedly defined management as \"the art of getting things done through people\".\nShe described management as philosophy.\n\nCritics, however, find this definition useful but far too narrow. The phrase \"management is what managers do\" occurs widely,\nsuggesting the difficulty of defining management without circularity, the shifting nature of definitions and the connection of managerial practices with the existence of a managerial cadre or of a class.\n\nOne habit of thought regards management as equivalent to \"business administration\" and thus excludes management in places outside commerce, as for example in charities and in the public sector. More broadly, every organization must \"manage\" its work, people, processes, technology, etc. to maximize effectiveness. Nonetheless, many people refer to university departments that teach management as \"business schools\". Some such institutions (such as the Harvard Business School) use that name, while others (such as the Yale School of Management) employ the broader term \"management\".\n\nEnglish-speakers may also use the term \"management\" or \"the management\" as a collective word describing the managers of an organization, for example of a corporation.\nHistorically this use of the term often contrasted with the term \"labor\" – referring to those being managed.\n\nBut in the present era the concept of management is identified in the wide areas and its frontiers have been pushed to a broader range. Apart from profitable organizations even non-profitable organizations (NGOs) apply management concepts. The concept and its uses are not constrained. Management on the whole is the process of planning, organizing, coordinating, leading\nand controlling.\n\nIn profitable organizations, management's primary function is the satisfaction of a range of stakeholders. This typically involves making a profit (for the shareholders), creating valued products at a reasonable cost (for customers), and providing great employment opportunities for employees. In nonprofit management, add the importance of keeping the faith of donors. In most models of management and governance, shareholders vote for the board of directors, and the board then hires senior management. Some organizations have experimented with other methods (such as employee-voting models) of selecting or reviewing managers, but this is rare.\n\nSome see management as a late-modern (in the sense of late modernity) conceptualization. On those terms it cannot have a pre-modern history – only harbingers (such as stewards). Others, however, detect management-like thought among ancient Sumerian traders and the builders of the pyramids of ancient Egypt. Slave-owners through the centuries faced the problems of exploiting/motivating a dependent but sometimes unenthusiastic or recalcitrant workforce, but many pre-industrial enterprises, given their small scale, did not feel compelled to face the issues of management systematically. However, innovations such as the spread of Hindu numerals (5th to 15th centuries) and the codification of double-entry book-keeping (1494) provided tools for management assessment, planning and control.\n\n\nWith the changing workplaces of industrial revolutions in the 18th and 19th centuries, military theory and practice contributed approaches to managing the newly-popular factories.\n\nGiven the scale of most commercial operations and the lack of mechanized record-keeping and recording before the industrial revolution, it made sense for most owners of enterprises in those times to carry out management functions by and for themselves. But with growing size and complexity of organizations, a distinction between owners (individuals, industrial dynasties or groups of shareholders) and day-to-day managers (independent specialists in planning and control) gradually became more common.\n\nThe English verb \"manage\" comes from the Italian \"maneggiare\" (to handle, especially tools or a horse), which derives from the two Latin words \"manus\" (hand) and \"agere\" (to act). The French word for housekeeping, \"ménagerie\", derived from \"ménager\" (\"to keep house\"; compare \"ménage\" for \"household\"), also encompasses taking care of domestic animals. \"Ménagerie\" is the French translation of Xenophon's famous book \"Oeconomicus\" () on household matters and husbandry. The French word \"mesnagement\" (or \"ménagement\") influenced the semantic development of the English word \"management\" in the 17th and 18th centuries.\n\nManagement (according to some definitions) has existed for millennia, and several writers have produced background works that have contributed to modern management theories. Some theorists have cited as providing lessons for civilian managers. For example, Chinese general Sun Tzu in his 6th-century BC work \"The Art of War\" recommends (when re-phrased in modern terminology) being aware of and acting on strengths and weaknesses of both a manager's organization and a foe's. The writings of influential Chinese Legalist philosopher Shen Buhai may be considered to embody a rare premodern example of abstract theory of administration.\n\nVarious ancient and medieval civilizations produced \"mirrors for princes\" books, which aimed to advise new monarchs on how to govern. Plato described job specialization in 350 BC, and Alfarabi listed several leadership traits in AD 900. Other examples include the Indian \"Arthashastra\" by Chanakya (written around 300 BC), and \"The Prince\" by Italian author\nNiccolò Machiavelli (c. 1515).\n\nWritten in 1776 by Adam Smith, a Scottish moral philosopher, \"The Wealth of Nations\" discussed efficient organization of work through division of labour.\nSmith described how changes in processes could boost productivity in the manufacture of pins. While individuals could produce 200 pins per day, Smith analyzed the steps involved in manufacture and, with 10 specialists, enabled production of 48,000 pins per day.\n\nClassical economists such as Adam Smith (1723–1790) and John Stuart Mill (1806–1873) provided a theoretical background to resource allocation, production (economics), and pricing issues. About the same time, innovators like Eli Whitney (1765–1825), James Watt (1736–1819), and Matthew Boulton (1728–1809) developed elements of technical production such as standardization, quality-control procedures, cost-accounting, interchangeability of parts, and work-planning. Many of these aspects of management existed in the pre-1861 slave-based sector of the US economy. That environment saw 4 million people, as the contemporary usages had it, \"managed\" in profitable quasi-mass production.\n\nSalaried managers as an identifiable group first became prominent in the late 19th century.\n\nBy about 1900 one finds managers trying to place their theories on what they regarded as a thoroughly scientific basis (see scientism for perceived limitations of this belief). Examples include Henry R. Towne's \"Science of management\" in the 1890s, Frederick Winslow Taylor's \"The Principles of Scientific Management\" (1911), Lillian Gilbreth's \"Psychology of Management\" (1914), Frank and Lillian Gilbreth's \"Applied motion study\" (1917), and Henry L. Gantt's charts (1910s). J. Duncan wrote the first college management-textbook in 1911. In 1912 Yoichi Ueno introduced Taylorism to Japan and became the first management consultant of the \"Japanese-management style\". His son Ichiro Ueno pioneered Japanese quality assurance.\n\nThe first comprehensive theories of management appeared around 1920. The Harvard Business School offered the first Master of Business Administration degree (MBA) in 1921. People like Henri Fayol (1841–1925) and Alexander Church (1866–1936) described the various branches of management and their inter-relationships. In the early-20th century, people like Ordway Tead (1891–1973), Walter Scott (1869–1955) and J. Mooney applied the principles of psychology to management. Other writers, such as Elton Mayo (1880–1949), Mary Parker Follett (1868–1933), Chester Barnard (1886–1961), Max Weber (1864–1920), who saw what he called the \"administrator\" as bureaucrat, Rensis Likert (1903–1981), and Chris Argyris (born 1923) approached the phenomenon of management from a sociological perspective.\n\nPeter Drucker (1909–2005) wrote one of the earliest books on applied management: \"Concept of the Corporation\" (published in 1946). It resulted from Alfred Sloan (chairman of General Motors until 1956) commissioning a study of the organisation. Drucker went on to write 39 books, many in the same vein.\n\nH. Dodge, Ronald Fisher (1890–1962), and Thornton C. Fry introduced statistical techniques into management-studies. In the 1940s, Patrick Blackett worked in the development of the applied-mathematics science of operations research, initially for military operations. Operations research, sometimes known as \"management science\" (but distinct from Taylor's scientific management), attempts to take a scientific approach to solving decision-problems, and can apply directly to multiple management problems, particularly in the areas of logistics and operations.\n\nSome of the more developments include the Theory of Constraints, management by objectives, reengineering, Six Sigma, the Viable system model, and various information-technology-driven theories such as agile software development, as well as group-management theories such as Cog's Ladder.\n\nAs the general recognition of managers as a class solidified during the 20th century and gave perceived practitioners of the art/science of management a certain amount of prestige, so the way opened for popularised systems of management ideas to peddle their wares. In this context many management fads may have had more to do with pop psychology than with scientific theories of management.\n\nBusiness management includes the following branches:\n\n\nIn the 21st century observers find it increasingly difficult to subdivide management into functional categories in this way. More and more processes simultaneously involve several categories. Instead, one tends to think in terms of the various processes, tasks, and objects subject to management.\n\nBranches of management theory also exist relating to nonprofits and to government: such as public administration, public management, and educational management. Further, management programs related to civil-society organizations have also spawned programs in nonprofit management and social entrepreneurship.\n\nNote that many of the assumptions made by management have come under attack from business-ethics viewpoints, critical management studies, and anti-corporate activism.\n\nAs one consequence, workplace democracy (sometimes referred to as Workers' self-management) has become both more common and more advocated, in some places distributing all management functions among workers, each of whom takes on a portion of the work. However, these models predate any current political issue, and may occur more naturally than does a command hierarchy. All management embraces to some degree a democratic principle—in that in the long term, the majority of workers must support management. Otherwise, they leave to find other work or go on strike. Despite the move toward workplace democracy, command-and-control organization structures remain commonplace as \"de facto\" organization structures. Indeed, the entrenched nature of command-and-control is evident in the way that recent layoffs have been conducted with management ranks affected far less than employees at the lower levels. In some cases, management has even rewarded itself with bonuses after laying off lower-level workers.\n\nAccording to leadership-academic Manfred F.R. Kets de Vries, a contemporary senior-management team will almost inevitably have some personality disorders.\n\nAccording to Fayol, management operates through five basic functions: planning, organizing, coordinating, commanding, and controlling.\n\nFigurehead, leader\nNerve centre, disseminator\nEntrepreneur, negotiator, allocator\n\nManagement skills include:\n\n\n\nMost organizations have three management levels: first-level, middle-level, and top-level managers. First-line managers are the lowest level of management and manage the work of nonmanagerial individuals who are directly involved with the production or creation of the organization's products. First-line managers are often called supervisors, but may also be called line managers, office managers, or even foremen. Middle managers include all levels of management between the first-line level and the top level of the organization. These managers manage the work of first-line managers and may have titles such as department head, project leader, plant manager, or division manager. Top managers are responsible for making organization-wide decisions and establishing the plans and goals that affect the entire organization. These individuals typically have titles such as executive vice president, president, managing director, chief operating officer, chief executive officer, or chairman of the board.\n\nThese managers are classified in a hierarchy of authority, and perform different tasks. In many organizations, the number of managers in every level resembles a pyramid. Each level is explained below in specifications of their different responsibilities and likely job titles.\n\nThe top or senior layer of management consists of the board of directors (including non-executive directors and executive directors), president, vice-president, CEOs and other members of the C-level executives. Different organizations have various members in their C-suite, which may include a chief financial officer, chief technology officer, and so on. They are responsible for controlling and overseeing the operations of the entire organization. They set a \"tone at the top\" and develop strategic plans, company policies, and make decisions on the overall direction of the organization. In addition, top-level managers play a significant role in the mobilization of outside resources. Senior managers are accountable to the shareholders, the general public and to public bodies that oversee corporations and similar organizations. Some members of the senior management may serve as the public face of the organization, and they may make speeches to introduce new strategies or appear in marketing.\n\nThe board of directors is typically primarily composed of non-executives who owe a fiduciary duty to shareholders and are not closely involved in the day-to-day activities of the organization, although this varies depending on the type (e.g., public versus private), size and culture of the organization. These directors are theoretically liable for breaches of that duty and typically insured under directors and officers liability insurance. Fortune 500 directors are estimated to spend 4.4 hours per week on board duties, and median compensation was $212,512 in 2010. The board sets corporate strategy, makes major decisions such as major acquisitions, and hires, evaluates, and fires the top-level manager (chief executive officer or CEO). The CEO typically hires other positions. However, board involvement in the hiring of other positions such as the chief financial officer (CFO) has increased. In 2013, a survey of over 160 CEOs and directors of public and private companies found that the top weaknesses of CEOs were \"mentoring skills\" and \"board engagement\", and 10% of companies never evaluated the CEO. The board may also have certain employees (e.g., internal auditors) report to them or directly hire independent contractors; for example, the board (through the audit committee) typically selects the auditor.\n\nHelpful skills of top management vary by the type of organization but typically include a broad understanding of competition, world economies, and politics. In addition, the CEO is responsible for implementing and determining (within the board's framework) the broad policies of the organization. Executive management accomplishes the day-to-day details, including: instructions for preparation of department budgets, procedures, schedules; appointment of middle level executives such as department managers; coordination of departments; media and governmental relations; and shareholder communication.\n\nConsist of general managers, branch managers and department managers. They are accountable to the top management for their department's function. They devote more time to organizational and directional functions. Their roles can be emphasized as executing organizational plans in conformance with the company's policies and the objectives of the top management, they define and discuss information and policies from top management to lower management, and most importantly they inspire and provide guidance to lower level managers towards better performance.\n\nMiddle management is the midway management of a categorized organization, being secondary to the senior management but above the deepest levels of operational members. An operational manager may be well-thought-out by middle management, or may be categorized as non-management operate, liable to the policy of the specific organization. Efficiency of the middle level is vital in any organization, since they bridge the gap between top level and bottom level staffs.\n\nTheir functions include:\n\nLower managers include supervisors, section leaders, forepersons and team leaders. They focus on controlling and directing regular employees. They are usually responsible for assigning employees' tasks, guiding and supervising employees on day-to-day activities, ensuring the quality and quantity of production and/or service, making recommendations and suggestions to employees on their work, and channeling employee concerns that they cannot resolve to mid-level managers or other administrators. First-level or \"front line\" managers also act as role models for their employees. In some types of work, front line managers may also do some of the same tasks that employees do, at least some of the time. For example, in some restaurants, the front line managers will also serve customers during a very busy period of the day.\n\nFront-line managers typically provide:\n\nSome front-line managers may also provide career planning for employees who aim to rise within the organization.\n\nColleges and universities around the world offer bachelor's degrees, graduate degrees, diplomas and certificates in management, generally within their colleges of business, business schools or faculty of management but also in other related departments. In the 2010s, there has been an increase in online management education and training in the form of electronic educational technology ( also called e-learning). Online education has increased the accessibility of management training to people who do not live near a college or university, or who cannot afford to travel to a city where such training is available.\n\nWhile some professions require academic credentials in order to work in the profession (e.g., law, medicine, engineering, which require, respectively the Bachelor of Law, Doctor of Medicine and Bachelor of Engineering degrees), management and administration positions do not necessarily require the completion of academic degrees. Some well-known senior executives in the US who did not complete a degree include Steve Jobs, Bill Gates and Mark Zuckerberg. However, many managers and executives have completed some type of business or management training, such as a Bachelor of Commerce or a Master of Business Administration degree. Some major organizations, including companies, not-for-profit organizations and governments, require applicants to managerial or executive positions to hold at minimum bachelor's degree in a field related to administration or management, or in the case of business jobs, a Bachelor of Commerce or a similar degree.\n\nAt the undergraduate level, the most common business program is the Bachelor of Commerce (B.Com.) However, to manage technological areas, you need an undergraduate degree in a STEM area as preferred to Defense Acquisition University guidelines. This is typically a four-year program that includes courses that give students an overview of the role of managers in planning and directing within an organization. Course topics include accounting, financial management, statistics, marketing, strategy, and other related areas. There are many other undergraduate degrees that include the study of management, such as Bachelor of Arts degrees with a major in business administration or management and Bachelor of Public Administration (B.P.A), a degree designed for individuals aiming to work as bureaucrats in the government jobs. Many colleges and universities also offer certificates and diplomas in business administration or management, which typically require one to two years of full-time study.\n\nAt the graduate level students aiming at careers as managers or executives may choose to specialize in major subareas of management or business administration such as entrepreneurship, human resources, international business, organizational behavior, organizational theory, strategic management, accounting, corporate finance, entertainment, global management, healthcare management, investment management, sustainability and real estate. A Master of Business Administration (MBA) is the most popular professional degree at the master's level and can be obtained from many universities in the United States. MBA programs provide further education in management and leadership for graduate students. Other master's degrees in business and management include Master of Management (MM) and the Master of Science (M.Sc.) in business administration or management, which is typically taken by students aiming to become researchers or professors. There are also specialized master's degrees in administration for individuals aiming at careers outside of business, such as the Master of Public Administration (MPA) degree (also offered as a Master of Arts in Public Administration in some universities), for students aiming to become managers or executives in the public service and the Master of Health Administration, for students aiming to become managers or executives in the health care and hospital sector.\n\nManagement doctorates are the most advanced terminal degrees in the field of business and management. Most individuals obtaining management doctorates take the programs to obtain the training in research methods, statistical analysis and writing academic papers that they will need to seek careers as researchers, senior consultants and/or professors in business administration or management. There are three main types of management doctorates: the Doctor of Management (D.M.), the Doctor of Business Administration (D.B.A.), and the Ph.D. in Business Administration or Management. In the 2010s, doctorates in business administration and management are available with many specializations.\n\nWhile management trends can change so fast, the long term trend in management has been defined by a market embracing diversity and a rising service industry. Managers are currently being trained to encourage greater equality for minorities and women in the workplace, by offering increased flexibility in working hours, better retraining, and innovative (and usually industry-specific) performance markers. Managers destined for the service sector are being trained to use unique measurement techniques, better worker support and more charismatic leadership styles. Human resources finds itself increasingly working with management in a training capacity to help collect management data on the success (or failure) of management actions with employees.\n\nEvidence-based management is an emerging movement to use the current, best evidence in management and decision-making. It is part of the larger movement towards evidence-based practices. Evidence-based management entails managerial decisions and organizational practices informed by the best available evidence. As with other evidence-based practice, this is based on the three principles of: 1) published peer-reviewed (often in management or social science journals) research evidence that bears on whether and why a particular management practice works; 2) judgement and experience from contextual management practice, to understand the organization and interpersonal dynamics in a situation and determine the risks and benefits of available actions; and 3) the preferences and values of those affected.\n\n\n"}
{"id": "3736784", "url": "https://en.wikipedia.org/wiki?curid=3736784", "title": "Market (economics)", "text": "Market (economics)\n\nA market is one of the many varieties of systems, institutions, procedures, social relations and infrastructures whereby parties engage in exchange. While parties may exchange goods and services by barter, most markets rely on sellers offering their goods or services (including labor power) in exchange for money from buyers. It can be said that a market is the process by which the prices of goods and services are established. Markets facilitate trade and enable the distribution and resource allocation in a society. Markets allow any trade-able item to be evaluated and priced. A market emerges more or less spontaneously or may be constructed deliberately by human interaction in order to enable the exchange of rights (cf. ownership) of services and goods. Markets generally supplant gift economies and are often held in place through rules and customs, such as a booth fee, competitive pricing, and source of goods for sale (local produce or stock registration).\n\nMarkets can differ by products (goods, services) or factors (labour and capital) sold, product differentiation, place in which exchanges are carried, buyers targeted, duration, selling process, government regulation, taxes, subsidies, minimum wages, price ceilings, legality of exchange, liquidity, intensity of speculation, size, concentration, exchange asymmetry, relative prices, volatility and geographic extension. The geographic boundaries of a market may vary considerably, for example the food market in a single building, the real estate market in a local city, the consumer market in an entire country, or the economy of an international trade bloc where the same rules apply throughout. Markets can also be worldwide, see for example the global diamond trade. National economies can also be classified as developed markets or developing markets.\n\nIn mainstream economics, the concept of a market is any structure that allows buyers and sellers to exchange any type of goods, services and information. The exchange of goods or services, with or without money, is a transaction. Market participants consist of all the buyers and sellers of a good who influence its price, which is a major topic of study of economics and has given rise to several theories and models concerning the basic market forces of supply and demand. A major topic of debate is how much a given market can be considered to be a \"free market\", that is free from government intervention. Microeconomics traditionally focuses on the study of market structure and the efficiency of market equilibrium; when the latter (if it exists) is not efficient, then economists say that a market failure has occurred. However, it is not always clear how the allocation of resources can be improved since there is always the possibility of government failure.\n\nA market is one of the many varieties of systems, institutions, procedures, social relations and infrastructures whereby parties engage in exchange. While parties may exchange goods and services by barter, most markets rely on sellers offering their goods or services (including labor) in exchange for money from buyers. It can be said that a market is the process by which the prices of goods and services are established. Markets facilitate trade and enable the distribution and allocation of resources in a society. Markets allow any trade-able item to be evaluated and priced. A market sometimes emerges more or less spontaneously or may be constructed deliberately by human interaction in order to enable the exchange of rights (cf. ownership) of services and goods.\n\nMarkets of varying types can spontaneously arise whenever a party has interest in a good or service that some other party can provide. Hence there can be a market for cigarettes in correctional facilities, another for chewing gum in a playground, and yet another for contracts for the future delivery of a commodity. There can be black markets, where a good is exchanged illegally, for example markets for goods under a command economy despite pressure to repress them and virtual markets, such as eBay, in which buyers and sellers do not physically interact during negotiation. A market can be organized as an auction, as a private electronic market, as a commodity wholesale market, as a shopping center, as a complex institution such as a stock market and as an informal discussion between two individuals.\n\nMarkets vary in form, scale (volume and geographic reach), location and types of participants as well as the types of goods and services traded. The following is a non exhaustive list:\n\n\n\n\nFinancial markets facilitate the exchange of liquid assets. Most investors prefer investing in two markets:\n\nThere are also:\n\n\nIn economics, a market that runs under laissez-faire policies is called a free market, it is \"free\" from the government, in the sense that the government makes no attempt to intervene through taxes, subsidies, minimum wages, price ceilings and so on. However, market prices may be distorted by a seller or sellers with monopoly power, or a buyer with monopsony power. Such price distortions can have an adverse effect on market participant's welfare and reduce the efficiency of market outcomes. The relative level of organization and negotiating power of buyers and sellers also markedly affects the functioning of the market.\n\nMarkets are a system and systems have structure. The structure of a well-functioning market is defined by the theory of perfect competition. Well-functioning markets of the real world are never perfect, but basic structural characteristics can be approximated for real world markets, for example:\n\nMarkets where price negotiations meet equilibrium, but the equilibrium is not efficient are said to experience market failure. Market failures are often associated with time-inconsistent preferences, information asymmetries, non-perfectly competitive markets, principal–agent problems, externalities, or public goods. Among the major negative externalities which can occur as a side effect of production and market exchange, are air pollution (side-effect of manufacturing and logistics) and environmental degradation (side-effect of farming and urbanization).\n\nThere exists a popular thought, especially among economists, that free markets would have a structure of a perfect competition. The logic behind this thought is that market failures are thought to be caused by other exogenic systems, and after removing those exogenic systems (\"freeing\" the markets) the free markets could run without market failures. For a market to be competitive, there must be more than a single buyer or seller. It has been suggested that two people may trade, but it takes at least three persons to have a market, so that there is competition in at least one of its two sides. However, competitive markets—as understood in formal economic theory—rely on much larger numbers of both buyers and sellers. A market with a single seller and multiple buyers is a monopoly. A market with a single buyer and multiple sellers is a monopsony. These are \"the polar opposites of perfect competition\". As an argument against such a logic, there is a second view that suggests that the source of market failures is inside the market system itself, therefore the removal of other interfering systems would not result in markets with a structure of perfect competition. As an analogy, such an argument may suggest that capitalists do not want to enhance the structure of markets, just like a coach of a football team would influence the referees or would break the rules if he could while he is pursuing his target of winning the game. Thus according to this view, capitalists are not enhancing the balance of their team versus the team of consumer-workers, so the market system needs a \"referee\" from outside that balances the game. In this second framework, the role of a \"referee\" of the market system is usually to be given to a democratic government.\n\nDisciplines such as sociology, economic history, economic geography and marketing developed novel understandings of markets studying actual existing markets made up of persons interacting in diverse ways in contrast to an abstract and all-encompassing concepts of \"the market\". The term \"the market\" is generally used in two ways:\n\nMicroeconomics (from Greek prefix \"mikro\"- meaning \"small\" and economics) is a branch of economics that studies the behavior of individuals and small impacting organizations in making decisions on the allocation of limited resources (see scarcity). On the other hand, macroeconomics (from the Greek prefix \"makro\"- meaning \"large\" and economics) is a branch of economics dealing with the performance, structure, behavior and decision-making of an economy as a whole, rather than individual markets.\n\nThe modern field of microeconomics arose as an effort of neoclassical economics school of thought to put economic ideas into mathematical mode. It began in the 19th century debates surrounding the works of Antoine Augustine Cournot, William Stanley Jevons, Carl Menger and Léon Walras—this period is usually denominated as the Marginal Revolution. A recurring theme of these debates was the contrast between the labor theory of value and the subjective theory of value, the former being associated with classical economists such as Adam Smith, David Ricardo and Karl Marx (Marx was a contemporary of the marginalists).\n\nIn his \"Principles of Economics\" (1890), Alfred Marshall presented a possible solution to this problem, using the supply and demand model. Marshall's idea of solving the controversy was that the demand curve could be derived by aggregating individual consumer demand curves, which were themselves based on the consumer problem of maximizing utility. The supply curve could be derived by superimposing a representative firm supply curves for the factors of production and then market equilibrium would be given by the intersection of demand and supply curves. He also introduced the notion of different market periods: mainly long run and short run. This set of ideas gave way to what economists call perfect competition—now found in the standard microeconomics texts—even though Marshall himself was highly skeptical, it could be used as general model of all markets.\n\nOpposed to the model of perfect competition, some models of imperfect competition were proposed:\n\nWilliam Baumol provided in his 1977 paper the current formal definition of a natural monopoly where “an industry in which multiform production is more costly than production by a monopoly”. Baumol defined a contestable market in his 1982 paper as a market where \"entry is absolutely free and exit absolutely costless\", freedom of entry in Stigler sense: the incumbent has no cost discrimination against entrants. He states that a contestable market will never have an economic profit greater than zero when in equilibrium and the equilibrium will also be efficient. According to Baumol, this equilibrium emerges endogenously due to the nature of contestable markets; that is, the only industry structure that survives in the long run is the one which minimizes total costs. This is in contrast to the older theory of industry structure since not only is industry structure not exogenously given, but equilibrium is reached without an ad hoc hypothesis on the behavior of firms, say using reaction functions in a duopoly. He concludes the paper commenting that regulators that seek to impede entry and/or exit of firms would do better to not interfere if the market in question resembles a contestable market.\nAround the 1970s the study of market failures came into focus with the study of information asymmetry. In particular, three authors emerged from this period: Akerlof, Spence and Stiglitz. Akerlof considered the problem of bad quality cars driving good quality cars out of the market in his classic \"The Market for Lemons\" (1970) because of the presence of asymmetrical information between buyers and sellers. Michael Spence explained that signaling was fundamental in the labour market since employers can't know beforehand which candidate is the most productive, a college degree becomes a signaling device that a firm uses to select new personnel.\n\nC.B. Macpherson identifies an underlying model of the market underlying Anglo-American liberal democratic political economy and philosophy in the seventeenth and eighteenth centuries: persons are cast as self-interested individuals, who enter into contractual relations with other such individuals, concerning the exchange of goods or personal capacities cast as commodities, with the motive of maximizing pecuniary interest. The state and its governance systems are cast as outside of this framework. This model came to dominant economic thinking in the later nineteenth century, as economists such as Ricardo, Mill, Jevons, Walras and later neo-classical economics shifted from reference to geographically located marketplaces to an abstract \"market\". This tradition is continued in contemporary neoliberalism, where the market is held up as optimal for wealth creation and human freedom and the states' role imagined as minimal, reduced to that of upholding and keeping stable property rights, contract and money supply. According to David Harvey, this allowed for boilerplate economic and institutional restructuring under structural adjustment and post-Communist reconstruction. Similar formalism occurs in a wide variety of social democratic and Marxist discourses that situate political action as antagonistic to the market. In particular, commodification theorists such as György Lukács insist that market relations necessarily lead to undue exploitation of labour and so need to be opposed \"in toto\".\nA central theme of empirical analyses is the variation and proliferation of types of markets since the rise of capitalism and global scale economies. The Regulation school stresses the ways in which developed capitalist countries have implemented varying degrees and types of environmental, economic and social regulation, taxation and public spending, fiscal policy and government provisioning of goods, all of which have transformed markets in uneven and geographical varied ways and created a variety of mixed economies.\n\nDrawing on concepts of institutional variance and path dependence, varieties of capitalism theorists (such as Peter Hall and David Soskice) identify two dominant modes of economic ordering in the developed capitalist countries, \"coordinated market economies\" such as Germany and Japan and an Anglo-American \"liberal market economies\". However, such approaches imply that the Anglo-American liberal market economies in fact operate in a matter close to the abstract notion of \"the market\". While Anglo-American countries have seen increasing introduction of neo-liberal forms of economic ordering, this has not led to simple convergence, but rather a variety of hybrid institutional orderings. Rather, a variety of new markets have emerged, such as for carbon trading or rights to pollute. In some cases, such as emerging markets for water, different forms of privatization of different aspects of previously state run infrastructure have created hybrid private-public formations and graded degrees of commodification, commercialization, and privatization.\n\nThe marketing management school, evolved in the late 1950s and early 1960s, is fundamentally linked with the marketing mix framework, a business tool used in marketing and by marketers. In his paper \"The Concept of the Marketing Mix\", Neil H. Borden reconstructed the history of the term \"marketing mix\". He started teaching the term after an associate, James Culliton, described the role of the marketing manager in 1948 as a \"mixer of ingredients\"; one who sometimes follows recipes prepared by others, sometimes prepares his own recipe as he goes along, sometimes adapts a recipe from immediately available ingredients, and at other times invents new ingredients no one else has tried. The marketer E. Jerome McCarthy proposed a four Ps classification (product, price, promotion, place) in 1960, which has since been used by marketers throughout the world. Robert F. Lauterborn proposed a four Cs classification (consumer, price, promotion, place) in 1990 which is a more consumer-oriented version of the four Ps that attempts to better fit the movement from mass marketing to niche marketing. Koichi Shimizu proposed a 7Cs Compass Model (corporation, commodity, cost, communication, channel, consumer, circumstances) to provide a more complete picture of the nature of marketing in 1981.\n\nBusinesses market their products/services to a specific segments of consumers. The defining factors of the markets are determined by demographics, interests and age/gender. A form of expansion is to enter a new market and sell/advertise to a different set of users.\n\nA prominent entry-point for challenging the market model's applicability concerns exchange transactions and the \"homo economicus\" assumption of self-interest maximization. , a number of streams of economic sociological analysis of markets focus on the role of the social in transactions and on the ways transactions involve social networks and relations of trust, cooperation and other bonds. Economic geographers in turn draw attention to the ways exchange transactions occur against the backdrop of institutional, social and geographic processes, including class relations, uneven development and historically contingent path-dependencies. Pierre Bourdieu has suggested the market model is becoming self-realizing in virtue of its wide acceptance in national and international institutions through the 1990s.\nMichel Callon's concept of framing provides a useful schema: each economic act or transaction occurs against, incorporates and also re-performs a geographically and cultural specific complex of social histories, institutional arrangements, rules and connections. These network relations are simultaneously bracketed, so that persons and transactions may be disentangled from thick social bonds. The character of calculability is imposed upon agents as they come to work in markets and are “formatted” as calculative agencies. Market exchanges contain a history of struggle and contestation that produced actors predisposed to exchange under certain sets of rules. Therefore, for Challon, market transactions can never be disembedded from social and geographic relations and there is no sense to talking of degrees of embeddedness and disembeddeness. An emerging theme is the interrelationship, inter-penetrability and variations of concepts of persons, commodities and modes of exchange under particular market formations. This is most pronounced in recent movement towards post-structuralist theorizing that draws on Michel Foucault and Actor Network Theory and stress relational aspects of person-hood, and dependence and integration into networks and practical systems. Commodity network approaches further both deconstruct and show alternatives to the market models concept of commodities.\n\nIn social systems theory (cf. Niklas Luhmann), markets are also conceptualized as inner environments of the economy. As horizon of all potential investment decisions the market represents the environment of the actually realized investment decisions. However, such inner environments can also be observed in further function systems of society like in political, scientific, religious or mass media systems.\n\nA widespread trend in economic history and sociology is skeptical of the idea that it is possible to develop a theory to capture an essence or unifying thread to markets. For economic geographers, reference to regional, local, or commodity specific markets can serve to undermine assumptions of global integration and highlight geographic variations in the structures, institutions, histories, path dependencies, forms of interaction and modes of self-understanding of agents in different spheres of market exchange. Reference to actual markets can show capitalism not as a totalizing force or completely encompassing mode of economic activity, but rather as \"a set of economic practices scattered over a landscape, rather than a systemic concentration of power\".\nProblematic for market formalism is the relationship between formal capitalist economic processes and a variety of alternative forms, ranging from semi-feudal and peasant economies widely operative in many developing economies, to informal markets, barter systems, worker cooperatives, or illegal trades that occur in most developed countries. Practices of incorporation of non-Western peoples into global markets in the nineteenth and twentieth century did not merely result in the quashing of former social economic institutions. Rather, various modes of articulation arose between transformed and hybridized local traditions and social practices and the emergent world economy. By their liberal nature, so called capitalist markets have almost always included a wide range of geographically situated economic practices that do not follow the market model. Economies are thus hybrids of market and non-market elements.\nHelpful here is J.K. Gibson-Graham's complex topology of the diversity of contemporary market economies describing different types of transactions, labour and economic agents. Transactions can occur in black markets (such as for marijuana) or be artificially protected (such as for patents). They can cover the sale of public goods under privatization schemes to co-operative exchanges and occur under varying degrees of monopoly power and state regulation. Likewise, there are a wide variety of economic agents, which engage in different types of transactions on different terms: one cannot assume the practices of a religious kindergarten, multinational corporation, state enterprise, or community-based cooperative can be subsumed under the same logic of calculability. This emphasis on proliferation can also be contrasted with continuing scholarly attempts to show underlying cohesive and structural similarities to different markets. Gibson-Graham thus read a variety of alternative markets for fair trade and organic foods or those using local exchange trading system as not only contributing to proliferation, but also forging new modes of ethical exchange and economic subjectivities.\n\nEconomic anthropology is a scholarly field that attempts to explain human economic behavior in its widest historic, geographic and cultural scope. It is practiced by anthropologists and has a complex relationship with the discipline of economics, of which it is highly critical.\n\nIts origins as a sub-field of anthropology begin with the Polish-British founder of anthropology, Bronisław Malinowski, and his French compatriot, Marcel Mauss, on the nature of gift-giving exchange (or reciprocity) as an alternative to market exchange. Studies in economic anthropology for the most part are focused on exchange. Bronisław Malinowski's path-breaking work, \"Argonauts of the Western Pacific\" (1922), addressed the question \"why would men risk life and limb to travel across huge expanses of dangerous ocean to give away what appear to be worthless trinkets?\". Malinowski carefully traced the network of exchanges of bracelets and necklaces across the Trobriand Islands and established that they were part of a system of exchange (the Kula ring). He stated that this exchange system was clearly linked to political authority. In the 1920s and later, Malinowski's study became the subject of debate with the French anthropologist, Marcel Mauss, author of \"The Gift\" (\"Essai sur le don\", 1925). Malinowski emphasized the exchange of goods between individuals and their non-altruistic motives for giving: they expected a return of equal or greater value (colloquially referred to as \"Indian giving\"). In other words, reciprocity is an implicit part of gifting as no \"free gift\" is given without expectation of reciprocity. In contrast, Mauss has emphasized that the gifts were not between individuals, but between representatives of larger collectivities. He argued these gifts were a \"total prestation\" as they were not simple, alienable commodities to be bought and sold, but like the \"Crown jewels\" embodied the reputation, history and sense of identity of a \"corporate kin group\", such as a line of kings. Given the stakes, Mauss asked \"why anyone would give them away?\" and his answer was an enigmatic concept, \"the spirit of the gift\". A good part of the confusion (and resulting debate) was due to a bad translation. Mauss appeared to be arguing that a return gift is given to keep the very relationship between givers alive; a failure to return a gift ends the relationship; and the promise of any future gifts. Based on an improved translate, Jonathan Parry has demonstrated that Mauss was arguing that the concept of a \"pure gift\" given altruistically only emerges in societies with a well-developed market ideology.\n\nRather than emphasize how particular kinds of objects are either gifts or commodities to be traded in restricted spheres of exchange, Arjun Appadurai and others began to look at how objects flowed between these spheres of exchange. They shifted attention away from the character of the human relationships formed through exchange and placed it on \"the social life of things\" instead. They examined the strategies by which an object could be \"singularized\" (made unique, special, one-of-a-kind) and so withdrawn from the market. A marriage ceremony that transforms a purchased ring into an irreplaceable family heirloom is one example whereas the heirloom in turn makes a perfect gift.\n\nAlthough arithmetic has been used since the beginning of civilization to set prices, it was not until the 19th century that more advanced mathematical tools began to be used to study markets in the form of social statistics. More recent techniques include business intelligence, data mining and marketing engineering.\n\nMarket size can be given in terms of the number of buyers and sellers in a particular market or in terms of the total exchange of money in the market, generally annually (per year). When given in terms of money, market size is often termed \"market value\", but in a sense distinct from market value of individual products. For one and the same goods, there may be different (and generally increasing) market values at the production level, the wholesale level and the retail level. For example, the value of the global illicit drug market for the year 2003 was estimated by the United Nations to be US$13 billion at the production level, $94 billion at the wholesale level (taking seizures into account) and US$322 billion at the retail level (based on retail prices and taking seizures and other losses into account).\n\n"}
{"id": "59252", "url": "https://en.wikipedia.org/wiki?curid=59252", "title": "Marketing", "text": "Marketing\n\nMarketing is the study and management of exchange relationships. It is the business process of creating relationships with and satisfying customers. Because marketing is used to attract customers, it is one of the primary components of business management and commerce. Marketers can direct product to other businesses (B2B marketing) or directly to consumers (B2C marketing). \n\nRegardless of who is being marketed to, several factors, including the perspective the marketers will use. These market orientations determine how marketers will approach the planning stage of marketing. This leads into the marketing mix, which outlines the specifics of the product and how it will be sold. This can in turn, be affected by the environment surrounding the product , the results of marketing research and market research, and the characteristics of the product's target market.\n\nOnce these factors are determined, marketers must then decide what methods will be used to market the product. This decision is based on the factors analyzed in the planning stage as well as where the product is in the product life cycle.\n\nMarketing is defined by the American Marketing Association as \"the activity, set of institutions, and processes for creating, communicating, delivering, and exchanging offerings that have value for customers, clients, partners, and society at large\". The term developed from the original meaning which referred literally to going to market with goods for sale. From a sales process engineering perspective, marketing is \"a set of processes that are interconnected and interdependent with other functions of a business aimed at achieving customer interest and satisfaction\".\"\n\nPhilip Kotler defined marketing as \"Satisfying needs and wants through an exchange process\". and a decade later defines it as “a social and managerial process by which individuals and groups obtain what they want and need through creating, offering and exchanging products of value with others.”\n\nThe Chartered Institute of Marketing defines marketing as \"the management process responsible for identifying, anticipating and satisfying customer requirements profitably\". A similar concept is the value-based marketing which states the role of marketing to contribute to increasing shareholder value. In this context, marketing can be defined as \"the management process that seeks to maximise returns to shareholders by developing relationships with valued customers and creating a competitive advantage\".\n\nIn the past, marketing practice tended to be seen as a creative industry, which included advertising, distribution and selling. However, because the academic study of marketing makes extensive use of social sciences, psychology, sociology, mathematics, economics, anthropology and neuroscience, the profession is now widely recognized as a science, allowing numerous universities to offer Master-of-Science (MSc) programs.\n\nThe process of marketing is that of bringing a product to market, which includes these steps: broad market research; market targeting and market segmentation; determining distribution, pricing and promotion strategies; developing a communications strategy; budgeting; and visioning long-term market development goals. Many parts of the marketing process (e.g. product design, art director, brand management, advertising, inbound marketing, copywriting etc.) involve use of the creative arts.\n\nThe 'marketing concept' proposes that to complete its organizational objectives, an organization should anticipate the needs and wants of potential consumers and satisfy them more effectively than its competitors. This concept originated from Adam Smith's book \"The Wealth of Nations\" but would not become widely used until nearly 200 years later. Marketing and Marketing Concepts are directly related.\n\nGiven the centrality of customer needs, and wants in marketing, a rich understanding of these concepts is essential:\n\nMarketing research, conducted for the purpose of new product development or product improvement, is often concerned with identifying the consumer's \"unmet needs.\" Customer needs are central to market segmentation which is concerned with dividing markets into distinct groups of buyers on the basis of \"distinct needs, characteristics, or behaviors who might require separate products or marketing mixes.\" Needs-based segmentation (also known as \"benefit segmentation\") \"places the customers' desires at the forefront of how a company designs and markets products or services.\" Although needs-based segmentation is difficult to do in practice, it has been proved to be one of the most effective ways to segment a market. In addition, a great deal of advertising and promotion is designed to show how a given product's benefits meet the customer's needs, wants or expectations in a unique way.\n\nThe two major segments of marketing are business-to-business (B2B) marketing and business-to-consumer (B2C) marketing. \n\nB2B marketing involves a business marketing its products to groups or individuals who will use the products for uses other than consumption.\n\nExamples of products sold through B2B marketing include:\n\n\nThe four major categories of B2B product purchasers are:\n\n\nB2C marketing involves a business marketing its products to those who will use the products for personal consumption. The marketing material the general public sees is B2C marketing material because the marketer is trying to convince customers to buy a product for their personal use. \n\nThe different goals of B2B and B2C marketing leads to differences in the B2B and B2C markets. The main differences in these markets are demand, purchasing volume, amount of customers, customer concentration, distribution, buying nature, buying influences, negotiations, reciprocity, leasing and promotional methods. \n\n\"Demand:\" B2B demand is derived because businesses buy products based on how much demand there is for the final consumer product. Businesses buy products based on customers wants and needs. B2C demand is primary because customers buy products based on their own wants and needs. \n\n\"Purchasing Volume\": Businesses buy products in large volumes to distribute to consumers. Consumers buy products in smaller volumes suitable for personal use.\n\n\"Amount of Customers:\" There are relatively fewer businesses to market to than direct consumers. \n\n\"Customer Concentration:\" Businesses that specialize in a particular market tend to be geographically concentrated while customers that buy products from these businesses are not concentrated. \n\n\"Distribution:\" B2B products pass directly from the producer of the product to the business while B2C products must additionally go through a wholesaler or retailer. \n\n\"Buying Nature:\" B2B purchasing is a formal process done by professional buyers and sellers while B2C purchasing is informal. \n\n\"Buying Influences:\" B2B purchasing is influenced by multiple people in various departments such as quality control, accounting, and logistics while B2C marketing is only influenced by the person making the purchase and possibly a few others. \n\n\"Negotiations:\" In B2B marketing, negotiating for lower prices or added benefits is commonly accepted while in B2C marketing (particularly in Western cultures) prices are fixed. \n\n\"Reciprocity:\" Businesses tend to buy from businesses they sell to. For example, a business that sells printer ink is more likely to buy office chairs from a supplier that buys the business's printer ink. In B2C marketing, this does not occur because consumers are not also selling products. \n\n\"Leasing:\" Businesses tend to lease expensive items while consumers tend to save up to buy expensive items. \n\n\"Promotional Methods:\" In B2B marketing, the most common promotional method is personal selling. B2C marketing mostly uses sales promotion, public relations, advertising, and social media. \n\nA marketing orientation has been defined as a \"philosophy of business management.\" or \"a corporate state of mind\" or as an \"organisation[al] culture\" Although scholars continue to debate the precise nature of specific orientations that inform marketing practice, the most commonly cited orientations are as follows:\n\nA firm employing a product orientation is mainly concerned with the quality of its product. A product orientation is based on the assumption that all things being equal, consumers will purchase products of superior quality. The approach is most effective when the firm has deep insights into customer needs and desires as derived from research or intuition and understands consumer's quality expectations and price consumers are willing to pay. Although the product orientation has largely been supplanted by the marketing orientation, firms practicing a product orientation can still be found in haute couture and arts marketing.\n\nA sales orientation focuses on the selling/promotion of the firm's existing products, rather than developing new products to satisfy unmet needs or wants. This orientation seeks to attain the highest possible sales through promotion and direct sales techniques. The sales orientation \"is typically practiced with unsought goods.\" One study found that industrial companies are more likely to hold a sales orientation than consumer goods companies. The approach may also suit scenarios in which a firm holds dead stock, or otherwise sells a product that is in high demand, with little likelihood of changes in consumer tastes diminishing demand.\n\nA 2011 meta analyses found that the factors with the greatest impact on sales performance are a salesperson's sales related knowledge (knowledge of market segments, sales presentation skills, conflict resolution, and products), degree of adaptiveness (changing behavior based on the aforementioned knowledge), role clarity (salesperson's role is to expressly to sell), cognitive aptitude (intelligence) and work engagement (motivation and interest in a sales role).\n\nA firm focusing on a production orientation specializes in producing as much as possible of a given product or service in order to achieve economies of scale or economies of scope. A production orientation may be deployed when a high demand for a product or service exists, coupled with certainty that consumer tastes and preferences remain relatively constant (similar to the sales orientation). The so-called production era is thought to have dominated marketing practice from the 1860s to the 1930s, but other theorists argue that evidence of the production orientation can still be found in some companies or industries. Specifically Kotler and Armstrong note that the production philosophy is \"one of the oldest philosophies that guides sellers... [and] is still useful in some situations.\" \n\nThe marketing orientation is the most common orientation used in contemporary marketing. It is a customer-centric approach that involves a firm basing its marketing program around products that suit new consumer tastes. Firms adopting a marketing orientation typically engage in extensive market research to gauge consumer desires, use R&D (Research & Development) to develop a product attuned to the revealed information, and then utilize promotion techniques to ensure consumers are aware of the product's existence and the benefits it can deliver. Scales designed to measure a firm's overall market orientation have been developed and found to be robust in a variety of contexts.\n\nThe marketing orientation has three prime facets, which are:\n\nA number of scholars and practitioners have argued that marketers have a greater social responsibility than simply satisfying customers and providing them with superior value. Marketing organisations that have embraced the societal marketing concept typically identify key stakeholder groups such as employees, customers, and local communities.Companies that adopt a societal marketing perspective typically practice triple bottom line reporting whereby they publish social impact and environmental impact reports alongside financial performance reports. Sustainable marketing or green marketing is an extension of societal marketing.\n\nThe marketing mix is a foundational tool used to guide decision making in marketing. The marketing mix represents the basic tools which marketers can use to bring their products or services to market. They are the foundation of managerial marketing and the marketing plan typically devotes a section to the marketing mix.\n\nThe traditional marketing mix refers to four broad levels of marketing decision, namely: \"product\", \"price\", \"promotion\", and \"place\".\n\n\nOne of the limitations of the 4Ps approach is its emphasis of an inside out-view. An \"inside-out\" approach is the traditional planning approach where the organisation identifies its desired goals and objectives, which are often based around what has always been done. Marketing's task then becomes one of \"selling\" the organisation's products and messages to the \"outside\" or external stakeholders. In contrast, an \"outside-in\" approach first seeks to understand the needs and wants of the consumer.\n\nFrom a model-building perspective, the 4 Ps has attracted a number of criticisms. Well-designed models should exhibit clearly defined categories that are mutually exclusive, with no overlap. Yet, the 4 Ps model has extensive overlapping problems. Several authors stress the hybrid nature of the fourth P, mentioning the presence of two important dimensions, \"communication\" (general and informative communications such as public relations and corporate communications) and \"promotion\" (persuasive communications such as advertising and direct selling). Certain marketing activities, such as personal selling, may be classified as either \"promotion\" or as part of the place (i.e., distribution) element. Some pricing tactics, such as promotional pricing, can be classified as price variables or promotional variables and, therefore, also exhibit some overlap.\n\nOther important criticisms include that the marketing mix lacks a strategic framework and is, therefore, unfit to be a planning instrument, particularly when uncontrollable, external elements are an important aspect of the marketing environment.\n\nTo overcome the deficiencies of the 4P model, some authors have suggested extensions or modifications to the original model. Extensions of the four P's are often included in cases such as services marketing where unique characteristics (i.e. intangibility, perishability, heterogeneity and the inseparability of production and consumption) warrant additional consideration factors. Other extensions have been found necessary for retail marketing, industrial marketing and internet marketing\n\ninclude \"people\", \"process\", and \"physical evidence\" and are often applied in the case of services marketing Other extensions have been found necessary in retail marketing, industrial marketing and internet marketing.\n\n\nIn response to environmental and technological changes in marketing, as well as criticisms towards the 4Ps approach, the 4Cs has emerged as a modern marketing mix model.\n\nConsumer (or Client)\n\nThe consumer refers to the person or group that will acquire the product. This aspect of the model focuses on fulfilling the wants or needs of the consumer. \n\nCost\n\nCost refers to what is exchanged in return for the product. Cost mainly consists of the monetary value of the product. Cost also refers to anything else the consumer must sacrifice to attain the product, such as time or money spent on transportation to acquire the product. \n\nConvenience\n\nLike \"Place\" in the 4Ps model, convenience refers to where the product will be sold. This, however, not only refers to physical stores, but also whether the product is available in person or online. The convenience aspect emphasizes making it as easy as possible for the consumer to attain the product, thus making them more likely to do so. \n\nCommunication\n\nLike \"Promotion\" in the 4Ps model, communication refers to how consumers find out about a product. Unlike, promotion, communication not only refers to the one-way communication of advertising, but also the two-way communication available through social media. \n\nThe term \"marketing environment\" relates to all of the factors (whether internal, external, direct or indirect) that affect a firm's marketing decision-making/planning. A firm's marketing environment consists of three main areas, which are:\n\nA firm's marketing macro-environment consists of a variety of external factors that manifest on a large (or macro) scale. These include factors that are:\n\n\nA common method of assessing a firm's macro-environment is via a PESTLE (Political, Economic, Social, Technological, Legal, Ecological) analysis. Within a PESTLE analysis, a firm would analyze national political issues, culture and climate, key macroeconomic conditions, health and indicators (such as economic growth, inflation, unemployment, etc.), social trends/attitudes, and the nature of technology's impact on its society and the business processes within the society. \n\nA firm's micro-environment comprises factors pertinent to the firm itself, or stakeholders closely connected with the firm or company.\n\nA firm's micro-environment typically spans:\n\nIn contrast to the macro-environment, an organization holds a greater (though not complete) degree of control over these factors.\n\nA firms internal environment consists of factors inside of the actual company. These are factors controlled by the firm and they affect the relationship that a firm has with its customers. These include factors such as:\n\nMarketing research is a systematic process of analyzing data which involves conducting research to support marketing activities, and the statistical interpretation of data into information. This information is then used by managers to plan marketing activities, gauge the nature of a firm's marketing environment and to attain information from suppliers. A distinction should be made between marketing research and market research. Market research involves gathering information about a particular target market. As an example, a firm may conduct research in a target market, after selecting a suitable market segment. In contrast, marketing research relates to all research conducted within marketing. Market research is a subset of marketing research.\n\nMarketing researchers use statistical methods (such as quantitative research, qualitative research, hypothesis tests, Chi-square tests, linear regression, correlation coefficients, frequency distributions, Poisson and binomial distributions, etc.) to interpret their findings and convert data into information.\n\nThe stages of research include:\n\nMarket segmentation consists of taking the total heterogeneous market for a product and dividing it into several sub-markets or segments, each of which tends to be homogeneous in all significant aspects. The process is conducted for two main purposes: better allocation of a firm's finite resources and to better serve the more diversified tastes of contemporary consumers. A firm only possesses a certain amount of resources. Thus, it must make choices (and appreciate the related costs) in servicing specific groups of consumers. Moreover, with more diversity in the tastes of modern consumers, firms are noting the benefit of servicing a multiplicity of new markets.\n\nMarket segmentation can be defined in terms of the STP acronym, meaning Segment, Target, and Position.\n\nSegmentation involves the initial splitting up of consumers into persons of like needs/wants/tastes. Commonly used criteria include:\n\nOnce a segment has been identified to target, a firm must ascertain whether the segment is beneficial for them to service. The \"DAMP\" acronym is used as criteria to gauge the viability of a target market. The elements of DAMP are:\n\nThe next step in the targeting process is the level of differentiation involved in a segment serving. Three modes of differentiation exist, which are commonly applied by firms. These are:\n\n\"Positioning\" concerns how to position a product in the minds of consumers and inform what attributes differentiate it from the competitor's products. A firm often performs this by producing a perceptual map, which denotes similar products produced in the same industry according to how consumers perceive their price and quality. From a product's placing on the map, a firm would tailor its marketing communications to meld with the product's perception among consumers and its position among competitors' offering. \n\nThe promotional mix outlines how a company will market its product. It consists of five tools: personal selling, sales promotion, public relations, advertising and social media\n\nPersonal selling involves an oral presentation given by a salesperson who approaches an individual or a group of potential customers. Personal selling allows for two-way communication and relationship building that can aid both the buyer and the seller in their goals. Personal selling is most commonly seen in business-to-business marketing (eg: selling machinery to a factory, selling paper to a print shop), but it can also be found in business-to-consumer marketing (eg: selling cars at a dealership). \n\nSales promotion involves short-term incentives to encourage the buying of products. Examples of these incentives include:\n\n\nDepending on the incentive, one or more of the other elements of the promotional mix may be used in conjunction with sales promotion to inform customers of the incentives. \n\nPublic relations is the use of media tools to promote a positive view of a company or product in the public's eye. Public relations monitors the public opinion of a company or product and generates publicity to either sustain a positive opinion or lessen or change a negative opinion.\n\nPublic relations can include interviews, speeches/presentations, corporate literature, social media, news releases and special events. \n\nAdvertising occurs when a firm directly pays a media channel to publicize its product. Common examples of advertising include:\n\n\nSocial media is used to facilitate two-way communication between companies and their customers. Social media outlets such as Facebook, Twitter, Tumblr, Pinterest, Snapchat and YouTube allow brands to start a conversation with regular and prospective customers. Additionally, social media platforms can also house advertising and public relations content. \n\nThe area of marketing planning involves forging a plan for a firm's marketing activities. A marketing plan can also pertain to a specific product, as well as to an organization's overall marketing strategy. An organization's marketing planning process is derived from its overall business strategy. Thus, when top management are devising the firm's strategic direction/mission, the intended marketing activities are incorporated into this plan.\n\nWithin the overall strategic marketing plan, the stages of the process are listed as thus:\n\nAs stated previously, the senior management of a firm would formulate a general business strategy for a firm. However, this general business strategy would be interpreted and implemented in different contexts throughout the firm.\n\nAt the corporate level, marketing objectives are typically broad-based in nature, and pertain to the general vision of the firm in the short, medium or long-term. As an example, if one pictures a group of companies (or a conglomerate), top management may state that sales for the group should increase by 25% over a ten-year period.\n\nA strategic business unit (SBU) is a subsidiary within a firm, which participates within a given market/industry. The SBU would embrace the corporate strategy, and attune it to its own particular industry. For instance, an SBU may partake in the sports goods industry. It thus would ascertain how it would attain additional sales of sports goods, in order to satisfy the overall business strategy.\n\nThe functional level relates to departments within the SBUs, such as marketing, finance, HR, production, etc. The functional level would adopt the SBU's strategy and determine how to accomplish the SBU's own objectives in its market. To use the example of the sports goods industry again, the marketing department would draw up marketing plans, strategies and communications to help the SBU achieve its marketing aims.\n\nThe product life cycle (PLC) is a tool used by marketing managers to gauge the progress of a product, especially relating to sales or revenue accrued over time. The PLC is based on a few key assumptions, including:\n\nIn the introduction stage, a product is launched onto the market. To stimulate growth of sales/revenue, use of advertising may be high, in order to heighten awareness of the product in question.\n\nDuring the growth stage, the product's sales/revenue is increasing, which may stimulate more marketing communications to sustain sales. More entrants enter into the market, to reap the apparent high profits that the industry is producing.\n\nWhen the product hits maturity, its start to level off, and an increasing number of entrants to a market produce price falls for the product. Firms may use sales promotions to raise sales.\n\nDuring decline, demand for a good begins to taper off, and the firm may opt to discontinue manufacture of the product. This is so, if revenue for the product comes from efficiency savings in production, over actual sales of a good/service. However, if a product services a niche market, or is complementary to another product, it may continue manufacture of the product, despite a low level of sales/revenue being accrued. \n\n\n"}
{"id": "8983183", "url": "https://en.wikipedia.org/wiki?curid=8983183", "title": "Money", "text": "Money\n\nMoney is any item or verifiable record that is generally accepted as payment for goods and services and repayment of debts, such as taxes, in a particular country or socio-economic context. The main functions of money are distinguished as: a medium of exchange, a unit of account, a store of value and sometimes, a standard of deferred payment. Any item or verifiable record that fulfils these functions can be considered as money.\n\nMoney is historically an emergent market phenomenon establishing a commodity money, but nearly all contemporary money systems are based on fiat money. Fiat money, like any check or note of debt, is without use value as a physical commodity. It derives its value by being declared by a government to be legal tender; that is, it must be accepted as a form of payment within the boundaries of the country, for \"all debts, public and private\". Counterfeit money can cause good money to lose its value.\n\nThe money supply of a country consists of currency (banknotes and coins) and, depending on the particular definition used, one or more types of bank money (the balances held in checking accounts, savings accounts, and other types of bank accounts). Bank money, which consists only of records (mostly computerized in modern banking), forms by far the largest part of broad money in developed countries.\n\nThe word \"money\" is believed to originate from a temple of Juno, on Capitoline, one of Rome's seven hills. In the ancient world Juno was often associated with money. The temple of Juno Moneta at Rome was the place where the mint of Ancient Rome was located. The name \"Juno\" may derive from the Etruscan goddess Uni (which means \"the one\", \"unique\", \"unit\", \"union\", \"united\") and \"Moneta\" either from the Latin word \"monere\" (remind, warn, or instruct) or the Greek word \"moneres\" (alone, unique).\n\nIn the Western world, a prevalent term for coin-money has been \"specie\", stemming from Latin \"in specie\", meaning 'in kind'.\n\nThe use of barter-like methods may date back to at least 100,000 years ago, though there is no evidence of a society or economy that relied primarily on barter. Instead, non-monetary societies operated largely along the principles of gift economy and debt. When barter did in fact occur, it was usually between either complete strangers or potential enemies.\n\nMany cultures around the world eventually developed the use of commodity money. The Mesopotamian shekel was a unit of weight, and relied on the mass of something like 160 grains of barley. The first usage of the term came from Mesopotamia circa 3000 BC. Societies in the Americas, Asia, Africa and Australia used shell money – often, the shells of the cowry (\"Cypraea moneta L.\" or \"C. annulus L.\"). According to Herodotus, the Lydians were the first people to introduce the use of gold and silver coins. It is thought by modern scholars that these first stamped coins were minted around 650–600 BC.\n\nThe system of commodity money eventually evolved into a system of representative money. This occurred because gold and silver merchants or banks would issue receipts to their depositors – redeemable for the commodity money deposited. Eventually, these receipts became generally accepted as a means of payment and were used as money. Paper money or banknotes were first used in China during the Song dynasty. These banknotes, known as \"jiaozi\", evolved from promissory notes that had been used since the 7th century. However, they did not displace commodity money, and were used alongside coins. In the 13th century, paper money became known in Europe through the accounts of travelers, such as Marco Polo and William of Rubruck. Marco Polo's account of paper money during the Yuan dynasty is the subject of a chapter of his book, \"The Travels of Marco Polo\", titled \".\" Banknotes were first issued in Europe by Stockholms Banco in 1661, and were again also used alongside coins. The gold standard, a monetary system where the medium of exchange are paper notes that are convertible into pre-set, fixed quantities of gold, replaced the use of gold coins as currency in the 17th–19th centuries in Europe. These gold standard notes were made legal tender, and redemption into gold coins was discouraged. By the beginning of the 20th century almost all countries had adopted the gold standard, backing their legal tender notes with fixed amounts of gold.\n\nAfter World War II and the Bretton Woods Conference, most countries adopted fiat currencies that were fixed to the U.S. dollar. The U.S. dollar was in turn fixed to gold. In 1971 the U.S. government suspended the convertibility of the U.S. dollar to gold. After this many countries de-pegged their currencies from the U.S. dollar, and most of the world's currencies became unbacked by anything except the governments' fiat of legal tender and the ability to convert the money into goods via payment. According to proponents of modern money theory, fiat money is also backed by taxes. By imposing taxes, states create demand for the currency they issue.\n\nIn \"Money and the Mechanism of Exchange (1875)\", William Stanley Jevons famously analyzed money in terms of four functions: a \"medium of exchange\", a \"common measure of value\" (or unit of account), a \"standard of value\" (or standard of deferred payment), and a \"store of value\". By 1919, Jevons's four functions of money were summarized in the couplet:\n\nThis couplet would later become widely popular in macroeconomics textbooks. Most modern textbooks now list only three functions, that of medium of exchange, unit of account, and store of value, not considering a standard of deferred payment as a distinguished function, but rather subsuming it in the others.\n\nThere have been many historical disputes regarding the combination of money's functions, some arguing that they need more separation and that a single unit is insufficient to deal with them all. One of these arguments is that the role of money as a medium of exchange is in conflict with its role as a store of value: its role as a store of value requires holding it without spending, whereas its role as a medium of exchange requires it to circulate. Others argue that storing of value is just deferral of the exchange, but does not diminish the fact that money is a medium of exchange that can be transported both across space and time. The term \"financial capital\" is a more general and inclusive term for all liquid instruments, whether or not they are a uniformly recognized tender.\n\nWhen money is used to intermediate the exchange of goods and services, it is performing a function as a \"medium of exchange\". It thereby avoids the inefficiencies of a barter system, such as the \"coincidence of wants\" problem. Money's most important usage is as a method for comparing the values of dissimilar objects.\n\nA \"unit of account\" (in economics) is a standard numerical monetary unit of measurement of the market value of goods, services, and other transactions. Also known as a \"measure\" or \"standard\" of relative worth and deferred payment, a unit of account is a necessary prerequisite for the formulation of commercial agreements that involve debt.\n\nMoney acts as a standard measure and common denomination of trade. It is thus a basis for quoting and bargaining of prices. It is necessary for developing efficient accounting systems.\n\nWhile \"standard of deferred payment\" is distinguished by some texts, particularly older ones, other texts subsume this under other functions. A \"standard of deferred payment\" is an accepted way to settle a debt – a unit in which debts are denominated, and the status of money as legal tender, in those jurisdictions which have this concept, states that it may function for the discharge of debts. When debts are denominated in money, the real value of debts may change due to inflation and deflation, and for sovereign and international debts via debasement and devaluation.\n\nTo act as a \"store of value\", a money must be able to be reliably saved, stored, and retrieved – and be predictably usable as a medium of exchange when it is retrieved. The value of the money must also remain stable over time. Some have argued that inflation, by reducing the value of money, diminishes the ability of the money to function as a store of value.\n\nTo fulfill its various functions, money must have certain properties:\n\nIn economics, money is any financial instrument that can fulfill the functions of money (detailed above). These financial instruments together are collectively referred to as the money supply of an economy. In other words, the money supply is the number of financial instruments within a specific economy available for purchasing goods or services. Since the money supply consists of various financial instruments (usually currency, demand deposits and various other types of deposits), the amount of money in an economy is measured by adding together these financial instruments creating a \"monetary aggregate\".\n\nModern monetary theory distinguishes among different ways to measure the stock of money or money supply, reflected in different types of monetary aggregates, using a categorization system that focuses on the liquidity of the financial instrument used as money. The most commonly used monetary aggregates (or types of money) are conventionally designated M1, M2 and M3. These are successively larger aggregate categories: M1 is currency (coins and bills) plus demand deposits (such as checking accounts); M2 is M1 plus savings accounts and time deposits under $100,000; and M3 is M2 plus larger time deposits and similar institutional accounts. M1 includes only the most liquid financial instruments, and M3 relatively illiquid instruments. The precise definition of M1, M2 etc. may be different in different countries.\n\nAnother measure of money, M0, is also used; unlike the other measures, it does not represent actual purchasing power by firms and households in the economy. M0 is base money, or the amount of money actually issued by the central bank of a country. It is measured as currency plus deposits of banks and other institutions at the central bank. M0 is also the only money that can satisfy the reserve requirements of commercial banks.\n\nIn current economic systems, money is created by two procedures:\n\nLegal tender, or narrow money (M0) is the cash money created by a Central Bank by minting coins and printing banknotes.\n\nBank money, or broad money (M1/M2) is the money created by private banks through the recording of loans as deposits of borrowing clients, with partial support indicated by the \"cash ratio\". Currently, bank money is created as electronic money.\n\nIn most countries, the majority of money is mostly created as M1/M2 by commercial banks making loans. Contrary to some popular misconceptions, banks do not act simply as intermediaries, lending out deposits that savers place with them, and do not depend on central bank money (M0) to create new loans and deposits.\n\n\"Market liquidity\" describes how easily an item can be traded for another item, or into the common currency within an economy. Money is the most liquid asset because it is universally recognised and accepted as the common currency. In this way, money gives consumers the freedom to trade goods and services easily without having to barter.\n\nLiquid financial instruments are easily tradable and have low transaction costs. There should be no (or minimal) spread between the prices to buy and sell the instrument being used as money.\n\nMany items have been used as commodity money such as naturally scarce precious metals, conch shells, barley, beads etc., as well as many other things that are thought of as having value. Commodity money value comes from the commodity out of which it is made. The commodity itself constitutes the money, and the money is the commodity. Examples of commodities that have been used as mediums of exchange include gold, silver, copper, rice, Wampum, salt, peppercorns, large stones, decorated belts, shells, alcohol, cigarettes, cannabis, candy, etc. These items were sometimes used in a metric of perceived value in conjunction to one another, in various commodity valuation or price system economies. Use of commodity money is similar to barter, but a commodity money provides a simple and automatic unit of account for the commodity which is being used as money. Although some gold coins such as the Krugerrand are considered legal tender, there is no record of their face value on either side of the coin. The rationale for this is that emphasis is laid on their direct link to the prevailing value of their fine gold content.\nAmerican Eagles are imprinted with their gold content and legal tender face value.\n\nIn 1875, the British economist William Stanley Jevons described the money used at the time as \"representative money\". Representative money is money that consists of token coins, paper money or other physical tokens such as certificates, that can be reliably exchanged for a fixed quantity of a commodity such as gold or silver. The value of representative money stands in direct and fixed relation to the commodity that backs it, while not itself being composed of that commodity.\n\nFiat money or fiat currency is money whose value is not derived from any intrinsic value or guarantee that it can be converted into a valuable commodity (such as gold). Instead, it has value only by government order (fiat). Usually, the government declares the fiat currency (typically notes and coins from a central bank, such as the Federal Reserve System in the U.S.) to be legal tender, making it unlawful not to accept the fiat currency as a means of repayment for all debts, public and private.\n\nSome bullion coins such as the Australian Gold Nugget and American Eagle are legal tender, however, they trade based on the market price of the metal content as a commodity, rather than their legal tender face value (which is usually only a small fraction of their bullion value).\n\nFiat money, if physically represented in the form of currency (paper or coins) can be accidentally damaged or destroyed. However, fiat money has an advantage over representative or commodity money, in that the same laws that created the money can also define rules for its replacement in case of damage or destruction. For example, the U.S. government will replace mutilated Federal Reserve Notes (U.S. fiat money) if at least half of the physical note can be reconstructed, or if it can be otherwise proven to have been destroyed. By contrast, commodity money which has been lost or destroyed cannot be recovered.\n\nThese factors led to the shift of the store of value being the metal itself: at first silver, then both silver and gold, and at one point there was bronze as well. Now we have copper coins and other non-precious metals as coins. Metals were mined, weighed, and stamped into coins. This was to assure the individual taking the coin that he was getting a certain known weight of precious metal. Coins could be counterfeited, but they also created a new unit of account, which helped lead to banking. Archimedes' principle provided the next link: coins could now be easily tested for their fine weight of metal, and thus the value of a coin could be determined, even if it had been shaved, debased or otherwise tampered with (see Numismatics).\n\nIn most major economies using coinage, copper, silver and gold formed three tiers of coins. Gold coins were used for large purchases, payment of the military and backing of state activities. Silver coins were used for midsized transactions, and as a unit of account for taxes, dues, contracts and fealty, while copper coins represented the coinage of common transaction. This system had been used in ancient India since the time of the Mahajanapadas. In Europe, this system worked through the medieval period because there was virtually no new gold, silver or copper introduced through mining or conquest. Thus the overall ratios of the three coinages remained roughly equivalent.\n\nIn premodern China, the need for credit and for circulating a medium that was less of a burden than exchanging thousands of copper coins led to the introduction of paper money, commonly known today as \"banknote\"s. This economic phenomenon was a slow and gradual process that took place from the late Tang dynasty (618–907) into the Song dynasty (960–1279). It began as a means for merchants to exchange heavy coinage for receipts of deposit issued as promissory notes from shops of wholesalers, notes that were valid for temporary use in a small regional territory. In the 10th century, the Song dynasty government began circulating these notes amongst the traders in their monopolized salt industry. The Song government granted several shops the sole right to issue banknotes, and in the early 12th century the government finally took over these shops to produce state-issued currency. Yet the banknotes issued were still regionally valid and temporary; it was not until the mid 13th century that a standard and uniform government issue of paper money was made into an acceptable nationwide currency. The already widespread methods of woodblock printing and then Pi Sheng's movable type printing by the 11th century was the impetus for the massive production of paper money in premodern China.\n\nAt around the same time in the medieval Islamic world, a vigorous monetary economy was created during the 7th–12th centuries on the basis of the expanding levels of circulation of a stable high-value currency (the dinar). Innovations introduced by economists, traders and merchants of the Muslim world include the earliest uses of credit, cheques, savings accounts, transactional accounts, loaning, trusts, exchange rates, the transfer of credit and debt, and banking institutions for loans and deposits.\n\nIn Europe, paper money was first introduced in Sweden in 1661. Sweden was rich in copper, thus, because of copper's low value, extraordinarily big coins (often weighing several kilograms) had to be made. The advantages of paper currency were numerous: it reduced transport of gold and silver, and thus lowered the risks; it made loaning gold or silver at interest easier, since the specie (gold or silver) never left the possession of the lender until someone else redeemed the note; and it allowed for a division of currency into credit and specie backed forms. It enabled the sale of stock in joint stock companies, and the redemption of those shares in paper.\n\nHowever, these advantages held within them disadvantages. First, since a note has no intrinsic value, there was nothing to stop issuing authorities from printing more of it than they had specie to back it with. Second, because it increased the money supply, it increased inflationary pressures, a fact observed by David Hume in the 18th century. The result is that paper money would often lead to an inflationary bubble, which could collapse if people began demanding hard money, causing the demand for paper notes to fall to zero. The printing of paper money was also associated with wars, and financing of wars, and therefore regarded as part of maintaining a standing army. For these reasons, paper currency was held in suspicion and hostility in Europe and America. It was also addictive, since the speculative profits of trade and capital creation were quite large. Major nations established mints to print money and mint coins, and branches of their treasury to collect taxes and hold gold and silver stock.\n\nAt this time both silver and gold were considered legal tender, and accepted by governments for taxes. However, the instability in the ratio between the two grew over the course of the 19th century, with the increase both in supply of these metals, particularly silver, and of trade. This is called bimetallism and the attempt to create a bimetallic standard where both gold and silver backed currency remained in circulation occupied the efforts of inflationists. Governments at this point could use currency as an instrument of policy, printing paper currency such as the United States greenback, to pay for military expenditures. They could also set the terms at which they would redeem notes for specie, by limiting the amount of purchase, or the minimum amount that could be redeemed.\nBy 1900, most of the industrializing nations were on some form of gold standard, with paper notes and silver coins constituting the circulating medium. Private banks and governments across the world followed Gresham's law: keeping gold and silver paid, but paying out in notes. This did not happen all around the world at the same time, but occurred sporadically, generally in times of war or financial crisis, beginning in the early part of the 20th century and continuing across the world until the late 20th century, when the regime of floating fiat currencies came into force. One of the last countries to break away from the gold standard was the United States in 1971.\n\nNo country anywhere in the world today has an enforceable gold standard or silver standard currency system.\n\nCommercial bank money or demand deposits are claims against financial institutions that can be used for the purchase of goods and services. A demand deposit account is an account from which funds can be withdrawn at any time by check or cash withdrawal without giving the bank or financial institution any prior notice. Banks have the legal obligation to return funds held in demand deposits immediately upon demand (or 'at call'). Demand deposit withdrawals can be performed in person, via checks or bank drafts, using automatic teller machines (ATMs), or through online banking.\n\nCommercial bank money is created through fractional-reserve banking, the banking practice where banks keep only a fraction of their deposits in reserve (as cash and other highly liquid assets) and lend out the remainder, while maintaining the simultaneous obligation to redeem all these deposits upon demand. Commercial bank money differs from commodity and fiat money in two ways: firstly it is non-physical, as its existence is only reflected in the account ledgers of banks and other financial institutions, and secondly, there is some element of risk that the claim will not be fulfilled if the financial institution becomes insolvent. The process of fractional-reserve banking has a cumulative effect of money creation by commercial banks, as it expands the money supply (cash and demand deposits) beyond what it would otherwise be. Because of the prevalence of fractional reserve banking, the broad money supply of most countries is a multiple (greater than 1) of the amount of base money created by the country's central bank. That multiple (called the money multiplier) is determined by the reserve requirement or other financial ratio requirements imposed by financial regulators.\n\nThe money supply of a country is usually held to be the total amount of currency in circulation plus the total value of checking and savings deposits in the commercial banks in the country. In modern economies, relatively little of the money supply is in physical currency. For example, in December 2010 in the U.S., of the $8853.4 billion in broad money supply (M2), only $915.7 billion (about 10%) consisted of physical coins and paper money.\n\nThe development of computer technology in the second part of the twentieth century allowed money to be represented digitally. By 1990, in the United States all money transferred between its central bank and commercial banks was in electronic form. By the 2000s most money existed as digital currency in bank databases. In 2012, by number of transaction, 20 to 58 percent of transactions were electronic (dependant on country).\n\nNon-national digital currencies were developed in the early 2000s. In particular, Flooz and Beenz had gained momentum before the Dot-com bubble. Not much innovation occurred until the conception of Bitcoin in 2008, which introduced the concept of a cryptocurrency – a decentralised trustless currency.\n\nWhen gold and silver are used as money, the money supply can grow only if the supply of these metals is increased by mining. This rate of increase will accelerate during periods of gold rushes and discoveries, such as when Columbus discovered the New World and brought back gold and silver to Spain, or when gold was discovered in California in 1848. This causes inflation, as the value of gold goes down. However, if the rate of gold mining cannot keep up with the growth of the economy, gold becomes relatively more valuable, and prices (denominated in gold) will drop, causing deflation. Deflation was the more typical situation for over a century when gold and paper money backed by gold were used as money in the 18th and 19th centuries.\n\nModern day monetary systems are based on fiat money and are no longer tied to the value of gold. The control of the amount of money in the economy is known as monetary policy. Monetary policy is the process by which a government, central bank, or monetary authority manages the money supply to achieve specific goals. Usually the goal of monetary policy is to accommodate economic growth in an environment of stable prices. For example, it is clearly stated in the Federal Reserve Act that the Board of Governors and the Federal Open Market Committee should seek \"to promote effectively the goals of maximum employment, stable prices, and moderate long-term interest rates.\"\n\nA failed monetary policy can have significant detrimental effects on an economy and the society that depends on it. These include hyperinflation, stagflation, recession, high unemployment, shortages of imported goods, inability to export goods, and even total monetary collapse and the adoption of a much less efficient barter economy. This happened in Russia, for instance, after the fall of the Soviet Union.\n\nGovernments and central banks have taken both regulatory and free market approaches to monetary policy. Some of the tools used to control the money supply include:\n\nIn the US, the Federal Reserve is responsible for controlling the money supply, while in the Euro area the respective institution is the European Central Bank. Other central banks with significant impact on global finances are the Bank of Japan, People's Bank of China and the Bank of England.\n\nFor many years much of monetary policy was influenced by an economic theory known as monetarism. Monetarism is an economic theory which argues that management of the money supply should be the primary means of regulating economic activity. The stability of the demand for money prior to the 1980s was a key finding of Milton Friedman and Anna Schwartz supported by the work of David Laidler, and many others. The nature of the demand for money changed during the 1980s owing to technical, institutional, and legal factors and the influence of monetarism has since decreased.\n\nCounterfeit money is imitation currency produced without the legal sanction of the state or government. Producing or using counterfeit money is a form of fraud or forgery. Counterfeiting is almost as old as money itself. Plated copies (known as Fourrées) have been found of Lydian coins which are thought to be among the first western coins. Before the introduction of paper money, the most prevalent method of counterfeiting involved mixing base metals with pure gold or silver. A form of counterfeiting is the production of documents by legitimate printers in response to fraudulent instructions. During World War II, the Nazis forged British pounds and American dollars. Today some of the finest counterfeit banknotes are called \"Superdollars\" because of their high quality and likeness to the real U.S. dollar. There has been significant counterfeiting of Euro banknotes and coins since the launch of the currency in 2002, but considerably less than for the U.S. dollar.\n\nMoney laundering is the process in which the proceeds of crime are transformed into ostensibly legitimate money or other assets. However, in a number of legal and regulatory systems the term money laundering has become conflated with other forms of financial crime, and sometimes used more generally to include misuse of the financial system (involving things such as securities, digital currencies, credit cards, and traditional currency), including terrorism financing, tax evasion, and evading of international sanctions.\n\n\n"}
{"id": "18878", "url": "https://en.wikipedia.org/wiki?curid=18878", "title": "Monopoly", "text": "Monopoly\n\nA monopoly (from Greek and ) exists when a specific person or enterprise is the only supplier of a particular commodity. This contrasts with a monopsony which relates to a single entity's control of a market to purchase a good or service, and with oligopoly which consists of a few sellers dominating a market. Monopolies are thus characterized by a lack of economic competition to produce the good or service, a lack of viable substitute goods, and the possibility of a high monopoly price well above the seller's marginal cost that leads to a high monopoly profit. The verb \"monopolise\" or \"monopolize\" refers to the \"process\" by which a company gains the ability to raise prices or exclude competitors. In economics, a monopoly is a single seller. In law, a monopoly is a business entity that has significant market power, that is, the power to charge overly high prices. Although monopolies may be big businesses, size is not a characteristic of a monopoly. A small business may still have the power to raise prices in a small industry (or market).\n\nA monopoly is distinguished from a monopsony, in which there is only one \"buyer\" of a product or service; a monopoly may also have monopsony control of a sector of a market. Likewise, a monopoly should be distinguished from a cartel (a form of oligopoly), in which several providers act together to coordinate services, prices or sale of goods. Monopolies, monopsonies and oligopolies are all situations in which one or a few entities have market power and therefore interact with their customers (monopoly or oligopoly), or suppliers (monopsony) in ways that distort the market.\n\nMonopolies can be established by a government, form naturally, or form by integration. In many jurisdictions, competition laws restrict monopolies due to government concerns over potential adverse effects. Holding a dominant position or a monopoly in a market is often not illegal in itself, however certain categories of behavior can be considered abusive and therefore incur legal sanctions when business is dominant. A government-granted monopoly or \"legal monopoly\", by contrast, is sanctioned by the state, often to provide an incentive to invest in a risky venture or enrich a domestic interest group. Patents, copyrights, and trademarks are sometimes used as examples of government-granted monopolies. The government may also reserve the venture for itself, thus forming a government monopoly, for example with a state-owned company.\n\nMonopolies may be naturally occurring due to limited competition because the industry is resource intensive and requires substantial costs to operate (e.g., certain railroad systems).\n\nIn economics, the idea of monopoly is important in the study of management structures, which directly concerns normative aspects of economic competition, and provides the basis for topics such as industrial organization and economics of regulation. There are four basic types of market structures in traditional economic analysis: perfect competition, monopolistic competition, oligopoly and monopoly. A monopoly is a structure in which a single supplier produces and sells a given product or service. If there is a single seller in a certain market and there are no close substitutes for the product, then the market structure is that of a \"pure monopoly\". Sometimes, there are many sellers in an industry and/or there exist many close substitutes for the goods being produced, but nevertheless companies retain some market power. This is termed monopolistic competition, whereas in oligopoly the companies interact strategically.\n\nIn general, the main results from this theory compares the price-fixing methods across market structures, analyze the effect of a certain structure on welfare, and vary technological/demand assumptions in order to assess the consequences for an abstract model of society. Most economic textbooks follow the practice of carefully explaining the \"perfect competition\" model, mainly because this helps to understand \"departures\" from it (the so-called \"imperfect competition\" models).\n\nThe boundaries of what constitutes a market and what does not are relevant distinctions to make in economic analysis. In a general equilibrium context, a good is a specific concept including geographical and time-related characteristics. Most studies of market structure relax a little their definition of a good, allowing for more flexibility in the identification of substitute goods.\n\nA monopoly has these characteristics:\n\nMonopolies derive their market power from barriers to entry – circumstances that prevent or greatly impede a potential competitor's ability to compete in a market. There are three major types of barriers to entry: economic, legal and deliberate.\nIn addition to barriers to entry and competition, barriers to exit may be a source of market power. Barriers to exit are market conditions that make it difficult or expensive for a company to end its involvement with a market. High liquidation costs are a primary barrier to exiting. Market exit and shutdown are sometimes separate events. The decision whether to shut down or operate is not affected by exit barriers. A company will shut down if price falls below minimum average variable costs.\n\nWhile monopoly and perfect competition mark the extremes of market structures there is some similarity. The cost functions are the same. Both monopolies and perfectly competitive (PC) companies minimize cost and maximize profit. The shutdown decisions are the same. Both are assumed to have perfectly competitive factors markets. There are distinctions, some of the most important distinctions are as follows:\n\nThe most significant distinction between a PC company and a monopoly is that the monopoly has a downward-sloping demand curve rather than the \"perceived\" perfectly elastic curve of the PC company. Practically all the variations mentioned above relate to this fact. If there is a downward-sloping demand curve then by necessity there is a distinct marginal revenue curve. The implications of this fact are best made manifest with a linear demand curve. Assume that the inverse demand curve is of the form x = a − by. Then the total revenue curve is TR = ay − by and the marginal revenue curve is thus MR = a − 2by. From this several things are evident. First the marginal revenue curve has the same y intercept as the inverse demand curve. Second the slope of the marginal revenue curve is twice that of the inverse demand curve. Third the x intercept of the marginal revenue curve is half that of the inverse demand curve. What is not quite so evident is that the marginal revenue curve is below the inverse demand curve at all points. Since all companies maximise profits by equating MR and MC it must be the case that at the profit-maximizing quantity MR and MC are less than price, which further implies that a monopoly produces less quantity at a higher price than if the market were perfectly competitive.\n\nThe fact that a monopoly has a downward-sloping demand curve means that the relationship between total revenue and output for a monopoly is much different than that of competitive companies. Total revenue equals price times quantity. A competitive company has a perfectly elastic demand curve meaning that total revenue is proportional to output. Thus the total revenue curve for a competitive company is a ray with a slope equal to the market price. A competitive company can sell all the output it desires at the market price. For a monopoly to increase sales it must reduce price. Thus the total revenue curve for a monopoly is a parabola that begins at the origin and reaches a maximum value then continuously decreases until total revenue is again zero. Total revenue has its maximum value when the slope of the total revenue function is zero. The slope of the total revenue function is marginal revenue. So the revenue maximizing quantity and price occur when MR = 0. For example, assume that the monopoly's demand function is P = 50 − 2Q. The total revenue function would be TR = 50Q − 2Q and marginal revenue would be 50 − 4Q. Setting marginal revenue equal to zero we have\n\nSo the revenue maximizing quantity for the monopoly is 12.5 units and the revenue maximizing price is 25.\n\nA company with a monopoly does not experience price pressure from competitors, although it may experience pricing pressure from potential competition. If a company increases prices too much, then others may enter the market if they are able to provide the same good, or a substitute, at a lesser price. The idea that monopolies in markets with easy entry need not be regulated against is known as the \"revolution in monopoly theory\".\n\nA monopolist can extract only one premium, and getting into complementary markets does not pay. That is, the total profits a monopolist could earn if it sought to leverage its monopoly in one market by monopolizing a complementary market are equal to the extra profits it could earn anyway by charging more for the monopoly product itself. However, the one monopoly profit theorem is not true if customers in the monopoly good are stranded or poorly informed, or if the tied good has high fixed costs.\n\nA pure monopoly has the same economic rationality of perfectly competitive companies, i.e. to optimise a profit function given some constraints. By the assumptions of increasing marginal costs, exogenous inputs' prices, and control concentrated on a single agent or entrepreneur, the optimal decision is to equate the marginal cost and marginal revenue of production. Nonetheless, a pure monopoly can – unlike a competitive company – alter the market price for its own convenience: a decrease of production results in a higher price. In the economics' jargon, it is said that pure monopolies have \"a downward-sloping demand\". An important consequence of such behaviour is worth noticing: typically a monopoly selects a higher price and lesser quantity of output than a price-taking company; again, less is available at a higher price.\n\nA monopoly chooses that price that maximizes the difference between total revenue and total cost. The basic markup rule (as measured by the Lerner index) can be expressed as\nformula_4,\nwhere formula_5 is the price elasticity of demand the firm faces. The markup rules indicate that the ratio between profit margin and the price is inversely proportional to the price elasticity of demand. The implication of the rule is that the more elastic the demand for the product the less pricing power the monopoly has.\n\nMarket power is the ability to increase the product's price above marginal cost without losing all customers. Perfectly competitive (PC) companies have zero market power when it comes to setting prices. All companies of a PC market are price takers. The price is set by the interaction of demand and supply at the market or aggregate level. Individual companies simply take the price determined by the market and produce that quantity of output that maximizes the company's profits. If a PC company attempted to increase prices above the market level all its customers would abandon the company and purchase at the market price from other companies. A monopoly has considerable although not unlimited market power. A monopoly has the power to set prices or quantities although not both. A monopoly is a price maker. The monopoly is the market and prices are set by the monopolist based on their circumstances and not the interaction of demand and supply. The two primary factors determining monopoly market power are the company's demand curve and its cost structure.\n\nMarket power is the ability to affect the terms and conditions of exchange so that the price of a product is set by a single company (price is not imposed by the market as in perfect competition). Although a monopoly's market power is great it is still limited by the demand side of the market. A monopoly has a negatively sloped demand curve, not a perfectly inelastic curve. Consequently, any price increase will result in the loss of some customers.\n\nPrice discrimination allows a monopolist to increase its profit by charging higher prices for identical goods to those who are willing or able to pay more. For example, most economic textbooks cost more in the United States than in developing countries like Ethiopia. In this case, the publisher is using its government-granted copyright monopoly to price discriminate between the generally wealthier American economics students and the generally poorer Ethiopian economics students. Similarly, most patented medications cost more in the U.S. than in other countries with a (presumed) poorer customer base. Typically, a high general price is listed, and various market segments get varying discounts. This is an example of framing to make the process of charging some people higher prices more socially acceptable. Perfect price discrimination would allow the monopolist to charge each customer the exact maximum amount they would be willing to pay. This would allow the monopolist to extract all the consumer surplus of the market. While such perfect price discrimination is a theoretical construct, advances in information technology and micromarketing may bring it closer to the realm of possibility.\n\nIt is very important to realize that partial price discrimination can cause some customers who are inappropriately pooled with high price customers to be excluded from the market. For example, a poor student in the U.S. might be excluded from purchasing an economics textbook at the U.S. price, which the student may have been able to purchase at the Ethiopian price'. Similarly, a wealthy student in Ethiopia may be able to or willing to buy at the U.S. price, though naturally would hide such a fact from the monopolist so as to pay the reduced third world price. These are deadweight losses and decrease a monopolist's profits. As such, monopolists have substantial economic interest in improving their market information and \"market segmenting\".\n\nThere is important information for one to remember when considering the monopoly model diagram (and its associated conclusions) displayed here. The result that monopoly prices are higher, and production output lesser, than a competitive company follow from a requirement that the monopoly not charge different prices for different customers. That is, the monopoly is restricted from engaging in price discrimination (this is termed first degree price discrimination, such that all customers are charged the same amount). If the monopoly were permitted to charge individualised prices (this is termed third degree price discrimination), the quantity produced, and the price charged to the \"marginal\" customer, would be identical to that of a competitive company, thus eliminating the deadweight loss; however, all gains from trade (social welfare) would accrue to the monopolist and none to the consumer. In essence, every consumer would be indifferent between (1) going completely without the product or service and (2) being able to purchase it from the monopolist.\n\nAs long as the price elasticity of demand for most customers is less than one in absolute value, it is advantageous for a company to increase its prices: it receives more money for fewer goods. With a price increase, price elasticity tends to increase, and in the optimum case above it will be greater than one for most customers.\n\nA company maximizes profit by selling where marginal revenue equals marginal cost. A company that does not engage in price discrimination will charge the profit maximizing price, P*, to all its customers. In such circumstances there are customers who would be willing to pay a higher price than P* and those who will not pay P* but would buy at a lower price. A price discrimination strategy is to charge less price sensitive buyers a higher price and the more price sensitive buyers a lower price. Thus additional revenue is generated from two sources. The basic problem is to identify customers by their willingness to pay.\n\nThe purpose of price discrimination is to transfer consumer surplus to the producer. Consumer surplus is the difference between the value of a good to a consumer and the price the consumer must pay in the market to purchase it. Price discrimination is not limited to monopolies.\n\nMarket power is a company's ability to increase prices without losing all its customers. Any company that has market power can engage in price discrimination. Perfect competition is the only market form in which price discrimination would be impossible (a perfectly competitive company has a perfectly elastic demand curve and has zero market power).\n\nThere are three forms of price discrimination. First degree price discrimination charges each consumer the maximum price the consumer is willing to pay. Second degree price discrimination involves quantity discounts. Third degree price discrimination involves grouping consumers according to willingness to pay as measured by their price elasticities of demand and charging each group a different price. Third degree price discrimination is the most prevalent type.\n\nThere are three conditions that must be present for a company to engage in successful price discrimination. First, the company must have market power. Second, the company must be able to sort customers according to their willingness to pay for the good. Third, the firm must be able to prevent resell.\n\nA company must have some degree of market power to practice price discrimination. Without market power a company cannot charge more than the market price. Any market structure characterized by a downward sloping demand curve has market power – monopoly, monopolistic competition and oligopoly. The only market structure that has no market power is perfect competition.\n\nA company wishing to practice price discrimination must be able to prevent middlemen or brokers from acquiring the consumer surplus for themselves. The company accomplishes this by preventing or limiting resale. Many methods are used to prevent resale. For instance, persons are required to show photographic identification and a boarding pass before boarding an airplane. Most travelers assume that this practice is strictly a matter of security. However, a primary purpose in requesting photographic identification is to confirm that the ticket purchaser is the person about to board the airplane and not someone who has repurchased the ticket from a discount buyer.\n\nThe inability to prevent resale is the largest obstacle to successful price discrimination. Companies have however developed numerous methods to prevent resale. For example, universities require that students show identification before entering sporting events. Governments may make it illegal to resale tickets or products. In Boston, Red Sox baseball tickets can only be resold legally to the team.\n\nThe three basic forms of price discrimination are first, second and third degree price discrimination. In \"first degree price discrimination\" the company charges the maximum price each customer is willing to pay. The maximum price a consumer is willing to pay for a unit of the good is the reservation price. Thus for each unit the seller tries to set the price equal to the consumer's reservation price. Direct information about a consumer's willingness to pay is rarely available. Sellers tend to rely on secondary information such as where a person lives (postal codes); for example, catalog retailers can use mail high-priced catalogs to high-income postal codes. First degree price discrimination most frequently occurs in regard to professional services or in transactions involving direct buyer/seller negotiations. For example, an accountant who has prepared a consumer's tax return has information that can be used to charge customers based on an estimate of their ability to pay.\n\nIn \"second degree price discrimination\" or quantity discrimination customers are charged different prices based on how much they buy. There is a single price schedule for all consumers but the prices vary depending on the quantity of the good bought. The theory of second degree price discrimination is a consumer is willing to buy only a certain quantity of a good at a given price. Companies know that consumer's willingness to buy decreases as more units are purchased. The task for the seller is to identify these price points and to reduce the price once one is reached in the hope that a reduced price will trigger additional purchases from the consumer. For example, sell in unit blocks rather than individual units.\n\nIn \"third degree price discrimination\" or multi-market price discrimination the seller divides the consumers into different groups according to their willingness to pay as measured by their price elasticity of demand. Each group of consumers effectively becomes a separate market with its own demand curve and marginal revenue curve. The firm then attempts to maximize profits in each segment by equating MR and MC, Generally the company charges a higher price to the group with a more price inelastic demand and a relatively lesser price to the group with a more elastic demand. Examples of third degree price discrimination abound. Airlines charge higher prices to business travelers than to vacation travelers. The reasoning is that the demand curve for a vacation traveler is relatively elastic while the demand curve for a business traveler is relatively inelastic. Any determinant of price elasticity of demand can be used to segment markets. For example, seniors have a more elastic demand for movies than do young adults because they generally have more free time. Thus theaters will offer discount tickets to seniors.\n\nAssume that by a uniform pricing system the monopolist would sell five units at a price of $10 per unit. Assume that his marginal cost is $5 per unit. Total revenue would be $50, total costs would be $25 and profits would be $25. If the monopolist practiced price discrimination he would sell the first unit for $50 the second unit for $40 and so on. Total revenue would be $150, his total cost would be $25 and his profit would be $125.00. Several things are worth noting. The monopolist acquires all the consumer surplus and eliminates practically all the deadweight loss because he is willing to sell to anyone who is willing to pay at least the marginal cost. Thus the price discrimination promotes efficiency. Secondly, by the pricing scheme price = average revenue and equals marginal revenue. That is the monopolist behaving like a perfectly competitive company. Thirdly, the discriminating monopolist produces a larger quantity than the monopolist operating by a uniform pricing scheme.\nSuccessful price discrimination requires that companies separate consumers according to their willingness to buy. Determining a customer's willingness to buy a good is difficult. Asking consumers directly is fruitless: consumers don't know, and to the extent they do they are reluctant to share that information with marketers. The two main methods for determining willingness to buy are observation of personal characteristics and consumer actions. As noted information about where a person lives (postal codes), how the person dresses, what kind of car he or she drives, occupation, and income and spending patterns can be helpful in classifying.\n\nAccording to the standard model, in which a monopolist sets a single price for all consumers, the monopolist will sell a lesser quantity of goods at a higher price than would companies by perfect competition. Because the monopolist ultimately forgoes transactions with consumers who value the product or service more than its price, monopoly pricing creates a deadweight loss referring to potential gains that went neither to the monopolist nor to consumers. Given the presence of this deadweight loss, the combined surplus (or wealth) for the monopolist and consumers is necessarily less than the total surplus obtained by consumers by perfect competition. Where efficiency is defined by the total gains from trade, the monopoly setting is less efficient than perfect competition.\n\nIt is often argued that monopolies tend to become less efficient and less innovative over time, becoming \"complacent\", because they do not have to be efficient or innovative to compete in the marketplace. Sometimes this very loss of psychological efficiency can increase a potential competitor's value enough to overcome market entry barriers, or provide incentive for research and investment into new alternatives. The theory of contestable markets argues that in some circumstances (private) monopolies are forced to behave \"as if\" there were competition because of the risk of losing their monopoly to new entrants. This is likely to happen when a market's barriers to entry are low. It might also be because of the availability in the longer term of substitutes in other markets. For example, a canal monopoly, while worth a great deal during the late 18th century United Kingdom, was worth much less during the late 19th century because of the introduction of railways as a substitute.\n\nContrary to common misconception, monopolists do not try to sell items for the highest possible price, nor do they try to maximize profit per unit, but rather they try to maximize total profit.\n\nA natural monopoly is an organization that experiences increasing returns to scale over the relevant range of output and relatively high fixed costs. A natural monopoly occurs where the average cost of production \"declines throughout the relevant range of product demand\". The relevant range of product demand is where the average cost curve is below the demand curve. When this situation occurs, it is always cheaper for one large company to supply the market than multiple smaller companies; in fact, absent government intervention in such markets, will naturally evolve into a monopoly. An early market entrant that takes advantage of the cost structure and can expand rapidly can exclude smaller companies from entering and can drive or buy out other companies. A natural monopoly suffers from the same inefficiencies as any other monopoly. Left to its own devices, a profit-seeking natural monopoly will produce where marginal revenue equals marginal costs. Regulation of natural monopolies is problematic. Fragmenting such monopolies is by definition inefficient. The most frequently used methods dealing with natural monopolies are government regulations and public ownership. Government regulation generally consists of regulatory commissions charged with the principal duty of setting prices.\n\nTo reduce prices and increase output, regulators often use average cost pricing. By average cost pricing, the price and quantity are determined by the intersection of the average cost curve and the demand curve. This pricing scheme eliminates any positive economic profits since price equals average cost. Average-cost pricing is not perfect. Regulators must estimate average costs. Companies have a reduced incentive to lower costs. Regulation of this type has not been limited to natural monopolies. Average-cost pricing does also have some disadvantages. By setting price equal to the intersection of the demand curve and the average total cost curve, the firm's output is allocatively inefficient as the price is less than the marginal cost (which is the output quantity for a perfectly competitive and allocatively efficient market).\n\nA government-granted monopoly (also called a \"\"de jure\" monopoly\") is a form of \"coercive monopoly\", in which a government grants exclusive privilege to a private individual or company to be the sole provider of a commodity. Monopoly may be granted explicitly, as when potential competitors are excluded from the market by a specific law, or implicitly, such as when the requirements of an administrative regulation can only be fulfilled by a single market player, or through some other legal or procedural mechanism, such as patents, trademarks, and copyright.\n\nA monopolist should shut down when price is less than average variable cost for every output level – in other words where the demand curve is entirely below the average variable cost curve. Under these circumstances at the profit maximum level of output (MR = MC) average revenue would be less than average variable costs and the monopolists would be better off shutting down in the short term.\n\nIn a free market, monopolies can be ended at any time by new competition, breakaway businesses, or consumers seeking alternatives. In a highly regulated market environment a government will often either regulate the monopoly, convert it into a publicly owned monopoly environment, or forcibly fragment it (see Antitrust law and trust busting). Public utilities, often being naturally efficient with only one operator and therefore less susceptible to efficient breakup, are often strongly regulated or publicly owned. American Telephone & Telegraph (AT&T) and Standard Oil are often cited as examples of the breakup of a private monopoly by government. Standard Oil never achieved monopoly status, a consequence of existing in a market open to competition for the duration of its existence. The Bell System, later AT&T, was protected from competition first by the Kingsbury Commitment, and later by a series of agreements between AT&T and the Federal Government. In 1984, decades after having been granted monopoly power by force of law, AT&T was broken up into various components, MCI, Sprint, who were able to compete effectively in the long distance phone market.\n\nThe law regulating dominance in the European Union is governed by Article 102 of the \"Treaty on the Functioning of the European Union\" which aims at enhancing the consumer's welfare and also the efficiency of allocation of resources by protecting competition on the downstream market. The existence of a very high market share does not always mean consumers are paying excessive prices since the threat of new entrants to the market can restrain a high-market-share company's price increases. Competition law does not make merely having a monopoly illegal, but rather abusing the power a monopoly may confer, for instance through exclusionary practices (i.e. pricing high just because you are the only one around.) It may also be noted that it is illegal to try to obtain a monopoly, by practices of buying out the competition, or equal practices. If one occurs naturally, such as a competitor going out of business, or lack of competition, it is not illegal until such time as the monopoly holder abuses the power.\n\nFirst it is necessary to determine whether a company is dominant, or whether it behaves \"to an appreciable extent independently of its competitors, customers and ultimately of its consumer\". Establishing dominance is a two-stage test. The first thing to consider is market definition which is one of the crucial factors of the test. It includes relevant product market and relevant geographic market.\n\nAs the definition of the market is of a matter of interchangeability, if the goods or services are regarded as interchangeable then they are within the same product market. For example, in the case of \"United Brands v Commission\", it was argued in this case that bananas and other fresh fruit were in the same product market and later on dominance was found because the special features of the banana made it could only be interchangeable with other fresh fruits in a limited extent and other and is only exposed to their competition in a way that is hardly perceptible. The demand substitutability of the goods and services will help in defining the product market and it can be access by the ‘hypothetical monopolist’ test or the ‘SSNIP’ test .\n\nIt is necessary to define it because some goods can only be supplied within a narrow area due to technical, practical or legal reasons and this may help to indicate which undertakings impose a competitive constraint on the other undertakings in question. Since some goods are too expensive to transport where it might not be economic to sell them to distant markets in relation to their value, therefore the cost of transporting is a crucial factor here. Other factors might be legal controls which restricts an undertaking in a Member States from exporting goods or services to another.\n\nMarket definition may be difficult to measure but is important because if it is defined too broadly, the undertaking may be more likely to be found dominant and if it is defined too narrowly, the less likely that it will be found dominant.\n\nAs with collusive conduct, market shares are determined with reference to the particular market in which the company and product in question is sold. It does not in itself determine whether an undertaking is dominant but work as an indicator of the states of the existing competition within the market. The Herfindahl-Hirschman Index (HHI) is sometimes used to assess how competitive an industry is. It sums up the squares of the individual market shares of all of the competitors within the market. The lower the total, the less concentrated the market and the higher the total, the more concentrated the market. In the US, the merger guidelines state that a post-merger HHI below 1000 is viewed as not concentrated while HHIs above that will provoke further review.\n\nBy European Union law, very large market shares raise a presumption that a company is dominant, which may be rebuttable. A market share of 100% may be very rare but it is still possible to be found and in fact it has been identified in some cases, for instance the \"AAMS v Commission\" case. Undertakings possessing market share that is lower than 100% but over 90% had also been found dominant, for example, Microsoft v Commission case. In the AKZO v Commission case, the undertaking is presumed to be dominant if it has a market share of 50%. There are also findings of dominance that are below a market share of 50%, for instance, United Brands v Commission, it only possessed a market share of 40% to 45% and still to be found dominant with other factors. The lowest yet market share of a company considered \"dominant\" in the EU was 39.7%.If a company has a dominant position, then there is a special responsibility not to allow its conduct to impair competition on the common market however these will all falls away if it is not dominant.\n\nWhen considering whether an undertaking is dominant, it involves a combination of factors. Each of them cannot be taken separately as if they are, they will not be as determinative as they are when they are combined together. Also, in cases where an undertaking has previously been found dominant, it is still necessary to redefine the market and make a whole new analysis of the conditions of competition based on the available evidence at the appropriate time.\n\nAccording to the Guidance, there are three more issues that must be examined. They are actual competitors that relates to the market position of the dominant undertaking and its competitors, potential competitors that concerns the expansion and entry and lastly the countervailing buyer power.\n\nMarket share may be a valuable source of information regarding the market structure and the market position when it comes to accessing it. The dynamics of the market and the extent to which the goods and services differentiated are relevant in this area.\n\nIt concerns with the competition that would come from other undertakings which are not yet operating in the market but will enter it in the future. So, market shares may not be useful in accessing the competitive pressure that is exerted on an undertaking in this area. The potential entry by new firms and expansions by an undertaking must be taken into account, therefore the barriers to entry and barriers to expansion is an important factor here.\n\nCompetitive constraints may not always come from actual or potential competitors. Sometimes, it may also come from powerful customers who have sufficient bargaining strength which come from its size or its commercial significance for a dominant firm.\n\nThere are three main types of abuses which are exploitative abuse, exclusionary abuse and single market abuse.\n\nIt arises when a monopolist has such significant market power that it can restrict its output while increasing the price above the competitive level without losing customers. This type is less concerned by the Commission than other types.\n\nThis is most concerned about by the Commissions because it is capable of causing long- term consumer damage and is more likely to prevent the development of competition. An example of it is exclusive dealing agreements.\n\nIt arises when a dominant undertaking carrying out excess pricing which would not only have an exploitative effect but also prevent parallel imports and limits intra- brand competition.\n\n\nDespite wide agreement that the above constitute abusive practices, there is some debate about whether there needs to be a causal connection between the dominant position of a company and its actual abusive conduct. Furthermore, there has been some consideration of what happens when a company merely attempts to abuse its dominant position.\n\nThe term \"monopoly\" first appears in Aristotle's \"Politics\". Aristotle describes Thales of Miletus's cornering of the market in olive presses as a monopoly (\"μονοπώλιον\"). Another early reference to the concept of “monopoly” in a commercial sense appears in tractate Demai of the Mishna (2nd century C.E.), regarding the purchasing of agricultural goods from a dealer who has a monopoly on the produce (chapter 5; 4). The meaning and understanding of the English word 'monopoly' has changed over the years.\n\nVending of common salt (sodium chloride) was historically a natural monopoly. Until recently, a combination of strong sunshine and low humidity or an extension of peat marshes was necessary for producing salt from the sea, the most plentiful source. Changing sea levels periodically caused salt \"famines\" and communities were forced to depend upon those who controlled the scarce inland mines and salt springs, which were often in hostile areas (e.g. the Sahara desert) requiring well-organised security for transport, storage, and distribution.\n\nThe Salt Commission was a legal monopoly in China. Formed in 758, the Commission controlled salt production and sales in order to raise tax revenue for the Tang Dynasty.\n\nThe \"Gabelle\" was a notoriously high tax levied upon salt in the Kingdom of France. The much-hated levy had a role in the beginning of the French Revolution, when strict legal controls specified who was allowed to sell and distribute salt. First instituted in 1286, the Gabelle was not permanently abolished until 1945.\n\nRobin Gollan argues in \"The Coalminers of New South Wales\" that anti-competitive practices developed in the coal industry of Australia's Newcastle as a result of the business cycle. The monopoly was generated by formal meetings of the local management of coal companies agreeing to fix a minimum price for sale at dock. This collusion was known as \"The Vend\". The Vend ended and was reformed repeatedly during the late 19th century, ending by recession in the business cycle. \"The Vend\" was able to maintain its monopoly due to trade union assistance, and material advantages (primarily coal geography). During the early 20th century, as a result of comparable monopolistic practices in the Australian coastal shipping business, the Vend developed as an informal and illegal collusion between the steamship owners and the coal industry, eventually resulting in the High Court case Adelaide Steamship Co. Ltd v. R. & AG.\n\nStandard Oil was an American oil producing, transporting, refining, and marketing company. Established in 1870, it became the largest oil refiner in the world. John D. Rockefeller was a founder, chairman and major shareholder. The company was an innovator in the development of the business trust. The Standard Oil trust streamlined production and logistics, lowered costs, and undercut competitors. \"Trust-busting\" critics accused Standard Oil of using aggressive pricing to destroy competitors and form a monopoly that threatened consumers. Its controversial history as one of the world's first and largest multinational corporations ended in 1911, when the United States Supreme Court ruled that Standard was an illegal monopoly. The Standard Oil trust was dissolved into 33 smaller companies; two of its surviving \"child\" companies are ExxonMobil and the Chevron Corporation.\n\nU.S. Steel has been accused of being a monopoly. J. P. Morgan and Elbert H. Gary founded U.S. Steel in 1901 by combining Andrew Carnegie's Carnegie Steel Company with Gary's Federal Steel Company and William Henry \"Judge\" Moore's National Steel Company. At one time, U.S. Steel was the largest steel producer and largest corporation in the world. In its first full year of operation, U.S. Steel made 67 percent of all the steel produced in the United States. However, U.S. Steel's share of the expanding market slipped to 50 percent by 1911, and antitrust prosecution that year failed.\n\nDe Beers settled charges of price fixing in the diamond trade in the 2000s. De Beers is well known for its monopoloid practices throughout the 20th century, whereby it used its dominant position to manipulate the international diamond market. The company used several methods to exercise this control over the market. Firstly, it convinced independent producers to join its single channel monopoly, it flooded the market with diamonds similar to those of producers who refused to join the cartel, and lastly, it purchased and stockpiled diamonds produced by other manufacturers in order to control prices through limiting supply.\n\nIn 2000, the De Beers business model changed due to factors such as the decision by producers in Russia, Canada and Australia to distribute diamonds outside the De Beers channel, as well as rising awareness of blood diamonds that forced De Beers to \"avoid the risk of bad publicity\" by limiting sales to its own mined products. De Beers' market share by value fell from as high as 90% in the 1980s to less than 40% in 2012, having resulted in a more fragmented diamond market with more transparency and greater liquidity.\n\nIn November 2011 the Oppenheimer family announced its intention to sell the entirety of its 40% stake in De Beers to Anglo American plc thereby increasing Anglo American's ownership of the company to 85%.[30] The transaction was worth £3.2 billion ($5.1 billion) in cash and ended the Oppenheimer dynasty's 80-year ownership of De Beers.\n\nA public utility (or simply \"utility\") is an organization or company that maintains the infrastructure for a public service or provides a set of services for public consumption. Common examples of utilities are electricity, natural gas, water, sewage, cable television, and telephone. In the United States, public utilities are often natural monopolies because the infrastructure required to produce and deliver a product such as electricity or water is very expensive to build and maintain.\n\nWestern Union was criticized as a \"price gouging\" monopoly in the late 19th century. American Telephone & Telegraph was a telecommunications giant. AT&T was broken up in 1984. In the case of Telecom New Zealand, local loop unbundling was enforced by central government.\n\nTelkom is a semi-privatised, part state-owned South African telecommunications company. Deutsche Telekom is a former state monopoly, still partially state owned. Deutsche Telekom currently monopolizes high-speed VDSL broadband network. The Long Island Power Authority (LIPA) provided electric service to over 1.1 million customers in Nassau and Suffolk counties of New York, and the Rockaway Peninsula in Queens.\n\nThe Comcast Corporation is the largest mass media and communications company in the world by revenue. It is the largest cable company and home Internet service provider in the United States, and the nation's third largest home telephone service provider. Comcast has a monopoly in Boston, Philadelphia, and many other small towns across the US.\n\nThe United Aircraft and Transport Corporation was an aircraft manufacturer holding company that was forced to divest itself of airlines in 1934.\n\nIarnród Éireann, the Irish Railway authority, is a current monopoly as Ireland does not have the size for more companies.\n\nThe Long Island Rail Road (LIRR) was founded in 1834, and since the mid-1800s has provided train service between Long Island and New York City. In the 1870s, LIRR became the sole railroad in that area through a series of acquisitions and consolidations. In 2013, the LIRR's commuter rail system is the busiest commuter railroad in North America, serving nearly 335,000 passengers daily.\n\nDutch East India Company was created as a legal trading monopoly in 1602. The \"Vereenigde Oost-Indische Compagnie\" enjoyed huge profits from its spice monopoly through most of the 17th century.\n\nThe British East India Company was created as a legal trading monopoly in 1600. The East India Company was formed for pursuing trade with the East Indies but ended up trading mainly with the Indian subcontinent, North-West Frontier Province, and Balochistan. The Company traded in basic commodities, which included cotton, silk, indigo dye, salt, saltpetre, tea and opium.\n\nMajor League Baseball survived U.S. antitrust litigation in 1922, though its special status is still in dispute as of 2009.\n\nThe National Football League survived antitrust lawsuit in the 1960s but was convicted of being an illegal monopoly in the 1980s.\n\n\nAccording to professor Milton Friedman, laws against monopolies cause more harm than good, but unnecessary monopolies should be countered by removing tariffs and other regulation that upholds monopolies.\n\nHowever, professor Steve H. Hanke believes that although private monopolies are more efficient than public ones, often by a factor of two, sometimes private natural monopolies, such as local water distribution, should be regulated (not prohibited) by, e.g., price auctions.\n\nThomas DiLorenzo asserts, however, that during the early days of utility companies where there was little regulation, there were no natural monopolies and there was competition. Only when companies realized that they could gain power through government did monopolies begin to form.\n\nBaten, Bianchi and Moser find historical evidence that monopolies which are protected by patent laws may have adverse effects on the creation of innovation in an economy. They argue that under certain circumstances, compulsory licensing – which allows governments to license patents without the consent of patent-owners – may be effective in promoting invention by increasing the threat of competition in fields with low pre-existing levels of competition.\n"}
{"id": "175590", "url": "https://en.wikipedia.org/wiki?curid=175590", "title": "Moral hazard", "text": "Moral hazard\n\nIn economics, moral hazard occurs when someone increases their exposure to risk when insured, especially when a person takes more risks because someone else bears the cost of those risks. A moral hazard may occur where the actions of one party may change to the detriment of another after a financial transaction has taken place.\n\nA party makes a decision about how much risk to take, while another party bears the costs if things go badly, and the party isolated from risk behaves differently from how it would if it were fully exposed to the risk.\n\nMoral hazard can occur under a type of information asymmetry where the risk-taking party to a transaction knows more about its intentions than the party paying the consequences of the risk. More broadly, moral hazard can occur when the party with more information about its actions or intentions has a tendency or incentive to behave inappropriately from the perspective of the party with less information.\n\nMoral hazard also arises in a principal-agent problem, where one party, called an agent, acts on behalf of another party, called the principal. The agent usually has more information about his or her actions or intentions than the principal does, because the principal usually cannot completely monitor the agent. The agent may have an incentive to act inappropriately (from the viewpoint of the principal) if the interests of the agent and the principal are not aligned.\n\nFor example, with respect to the originators of subprime loans, many may have suspected that the borrowers would not be able to maintain their payments in the long run and that, for this reason, the loans were not going to be worth much. Still, because there were many buyers of these loans (or of pools of these loans) willing to take on that risk, the originators did not concern themselves with the potential long-term consequences of making the loans. After selling the loans, the originators bore none of the risk so there was little to no incentive for the originators to investigate the long-term value of the loans.\n\nAccording to research by Dembe and Boden, the term dates back to the 17th century and was widely used by English insurance companies by the late 19th century. Early usage of the term carried negative connotations, implying fraud or immoral behavior (usually on the part of an insured party). Dembe and Boden point out, however, that prominent mathematicians who studied decision-making in the 18th century used \"moral\" to mean \"subjective,\" which may cloud the true ethical significance in the term.\nThe concept of moral hazard was the subject of renewed study by economists in the 1960s and then did not imply immoral behavior or fraud. Economists would use this term to describe inefficiencies that can occur when risks are displaced or cannot be fully evaluated, rather than a description of the ethics or morals of the involved parties.\n\nRowell and Connelly offer a detailed description of the genesis of the term moral hazard, by identifying salient changes in economic thought, which are identified within the medieval theological and probability literature. Their paper compares and contrasts the predominantly normative conception of moral hazard found within the insurance-industry literature with the largely positive interpretations found within the economic literature. Often what is described as \"moral hazard[s]\" in the insurance literature is upon closer reading, a description of the closely related concept, adverse selection.\n\nIn 1998, William J. McDonough, head of the New York Federal Reserve, helped the counter-parties of Long Term Capital Management avoid losses by taking over the firm. This move was criticized by former Fed Chair, Paul Volcker and others as increasing moral hazard. Tyler Cowen concludes that \"creditors came to believe that their loans to unsound financial institutions would be made good by the Fed — as long as the collapse of those institutions would threaten the global credit system.\" Fed Chair, Allan Greenspan, while conceding the risk of moral hazard, defended the policy to orderly unwind Long Term Capital by saying the world economy is at stake.\n\nEconomist Paul Krugman described moral hazard as \"any situation in which one person makes the decision about how much risk to take, while someone else bears the cost if things go badly.\" Financial bailouts of lending institutions by governments, central banks or other institutions can encourage risky lending in the future if those that take the risks come to believe that they will not have to carry the full burden of potential losses. Lending institutions need to take risks by making loans, and the riskiest loans usually have the potential for making the highest return.\n\nTaxpayers, depositors, and other creditors often have to shoulder at least part of the burden of risky financial decisions made by lending institutions.\n\nMany have argued that certain types of mortgage securitization contribute to moral hazard. Mortgage securitization enables mortgage originators to pass on the risk that the mortgages they originate might default and not hold the mortgages on their balance sheets and assume the risk. In one kind of mortgage securitization, known as \"agency securitizations,\" default risk is retained by the securitizing agency that buys the mortgages from originators. These agencies thus have an incentive to monitor originators and check loan quality. \"Agency securitizations\" refer to securitizations by either Ginnie Mae, a government agency, or by Fannie Mae and Freddie Mac, both for-profit government-sponsored enterprises. They are similar to the \"covered bonds\" that are commonly used in Western Europe in that the securitizing agency retains default risk. Under both models, investors take on only interest-rate risk, not default risk.\n\nIn another type of securitization, known as \"private label\" securitization, default risk is generally not retained by the securitizing entity. Instead, the securitizing entity passes on default risk to investors. The securitizing entity, therefore, has relatively little incentive to monitor originators and maintain loan quality. \"Private label\" securitization refers to securitizations structured by financial institutions such as investment banks, commercial banks, and non-bank mortgage lenders.\n\nDuring the years leading up to the subprime mortgage financial crisis, private label securitizations grew as a share of overall mortgage securitization by purchasing and securitizing low-quality, high-risk mortgages. Agency Securitizations appear to have somewhat lowered their standards, but Agency mortgages remained considerably safer than mortgages in private-label securitizations and performed far better in terms of default rates.\n\nEconomist Mark Zandi of Moody's Analytics described moral hazard as a root cause of the subprime mortgage crisis. He wrote that \"the risks inherent in mortgage lending became so widely dispersed that no one was forced to worry about the quality of any single loan. As shaky mortgages were combined, diluting any problems into a larger pool, the incentive for responsibility was undermined.\" He also wrote, \"Finance companies weren't subject to the same regulatory oversight as banks. Taxpayers weren't on the hook if they went belly up [pre-crisis], only their shareholders and other creditors were. Finance companies thus had little to discourage them from growing as aggressively as possible, even if that meant lowering or winking at traditional lending standards.\"\n\nMoral hazard can also occur with borrowers. Borrowers may not act prudently (in the view of the lender) when they invest or spend funds recklessly. For example, credit card companies often limit the amount borrowers can spend with their cards because without such limits, borrowers may spend borrowed funds recklessly, leading to default.\n\nSecuritization of mortgages in America started in 1983 at Salomon Brothers and where the risk of each mortgage passed to the next purchaser instead of remaining with the original mortgaging institution. These mortgages and other debt instruments were put into a large pool of debt, and then shares in the pool were sold to many creditors.\n\nThus, there is no one person responsible for verifying that any one particular loan is sound, that the assets securing that one particular loan are worth what they are supposed to be worth, that the borrower responsible for making payments on the loan can read and write the language in which the papers that he/she signed were written, or even that the paperwork exists and is in good order. It has been suggested that this may have caused subprime mortgage crisis.\n\nBrokers, who were not lending their own money, pushed risk onto the lenders. Lenders, who sold mortgages soon after underwriting them, pushed risk onto investors. Investment banks bought mortgages and chopped up mortgage-backed securities into slices, some riskier than others. Investors bought securities and hedged against the risk of default and prepayment, pushing those risks further along. In a purely capitalist scenario, the last one holding the risk (like a game of musical chairs) is the one who faces the potential losses. In the sub-prime crisis, however, national credit authorities (the Federal Reserve in the US) assumed the ultimate risk on behalf of the citizenry at large.\n\nOthers believe that financial bailouts of lending institutions do not encourage risky lending behavior since there is no guarantee to lending institutions that a bailout will occur. Decreased valuation of a corporation before any bailout would prevent risky, speculative business decisions by executives who conduct due diligence in their business transactions. The risk and the burdens of loss became apparent to Lehman Brothers, which who did not benefit from a bailout, and other financial institutions and mortgage companies such as Citibank and Countrywide Financial Corporation, whose valuation plunged during the subprime mortgage crisis.\n\nMoral hazard has been studied by insurers and academics; such as in the work of Kenneth Arrow, Tom Baker, and John Nyman.\n\nThe name comes originally from the insurance industry. Insurance companies worried that protecting their clients from risks (like fire, or car accidents) might encourage those clients to behave in riskier ways (like smoking in bed or not wearing seatbelts). This problem may inefficiently discourage those companies from protecting their clients as much as the clients would like to be protected.\n\nEconomists argue that the inefficiency results from information asymmetry. If insurance companies could perfectly observe the actions of their clients, they could deny coverage to clients choosing risky actions (like smoking in bed or not wearing seat belts), allowing them to provide thorough protection against risk (fire or accidents) without encouraging risky behavior. However, since insurance companies cannot perfectly observe their clients' actions, they are discouraged from providing the amount of protection that would be provided in a world with perfect information.\n\nEconomists distinguish moral hazard from adverse selection, another problem that arises in the insurance industry, which is caused by \"hidden information\", rather than \"hidden actions\".\n\nThe same underlying problem of non-observable actions also affects other contexts besides the insurance industry. It also arises in banking and finance: if a financial institution knows it is protected by a lender of last resort, it may make riskier investments than it would in the absence of the protection.\n\nIn insurance markets, moral hazard occurs when the behavior of the insured party changes in a way that raises costs for the insurer since the insured party no longer bears the full costs of that behavior. Because individuals no longer bear the cost of medical services, they have an added incentive to ask for pricier and more elaborate medical service, which would otherwise not be necessary. In those instances, individuals have an incentive to over consume, simply because they no longer bear the full cost of medical services.\n\nTwo types of behavior can change. One type is the risky behavior itself, resulting in a \"before the event\" moral hazard. Insured parties then behave in a more risky manner, resulting in more negative consequences that the insurer must pay for. For example, after purchasing automobile insurance, some may tend to be less careful about locking the automobile or choose to drive more, thereby increasing the risk of theft or an accident for the insurer. After purchasing fire insurance, some may tend to be less careful about preventing fires (say, by smoking in bed or neglecting to replace the batteries in fire alarms). A further example has been identified in flood risk management in which it is proposed that the possession of insurance undermines efforts to encourage people to integrate flood protection and resilience measures in properties exposed to flooding.\n\nA second type of behavior that may change is the reaction to the negative consequences of risk once they have occurred and insurance is provided to cover their costs. That may be called \"ex post\" (after the event) moral hazard. Insured parties then do not behave in a more risky manner that results in more negative consequences, but they ask an insurer to pay for more of the negative consequences from risk as insurance coverage increases. For example, without medical insurance, some may forgo medical treatment due to its costs and simply deal with substandard health. However, after medical insurance becomes available, some may ask an insurance provider to pay for the cost of medical treatment that would not have occurred otherwise.\n\nSometimes moral hazard is so severe that it makes insurance policies impossible. Coinsurance, co-payments, and deductibles reduce the risk of moral hazard by increasing the out-of-pocket spending of consumers, which decreases their incentive to consume. Thus, the insured have a financial incentive to avoid making a claim.\n\nIn economic theory, moral hazard is a situation in which the behavior of one party may change to the detriment of another after the transaction has taken place. For example, a person with insurance against automobile theft may be less cautious about locking their car because the negative consequences of vehicle theft are now (partially) the responsibility of the insurance company. A party makes a decision about how much risk to take, while another party bears the costs if things go badly, and the party insulated from risk behaves differently from how it would if it were fully exposed to the risk.\n\nAccording to contract theory, moral hazard results from a situation in which a hidden action occurs. Bengt Holmström said this:\nMoral hazard can be divided into two types when it involves asymmetric information (or lack of verifiability) of the outcome of a random event. An \"ex ante\" moral hazard is a change in behavior prior to the outcome of the random event, whereas \"ex post\" involves behavior after the outcome. For example, in the case of a health insurance company insuring an individual during a specific time period, the final health of the individual can be thought of as the outcome. The individual taking greater risks during the period would be ex-ante moral hazard whereas lying about a fictitious health problem to defraud the insurance company would be ex post moral hazard. A second example is the case of a bank making a loan to an entrepreneur for a risky business venture. The entrepreneur becoming overly risky would be ex ante moral hazard, but willful default (wrongly claiming the venture failed when it was profitable) is ex post moral hazard.\n\nAccording to Hart and Holmström (1987), moral hazard models can be subdivided in models with hidden action and models with hidden information. In the former case, after the contract has been signed the agent chooses an action (such as an effort level) that cannot be observed by the principal. In the latter case, after the contract has been signed there is a random draw by nature that determines the agent's type (such as his valuation for a good or his costs of effort). In the literature, two reasons have been discussed why moral hazard may imply that the first-best solution (the solution that would be attained under complete information) is not achieved.\n\nFirstly, the agent may be risk-averse, so there is a trade-off between providing the agent with incentives and insuring the agent. Secondly, the agent may be risk-neutral but wealth-constrained and so the agent cannot make a payment to the principal and there is a trade-off between providing incentives and minimizing the agent's limited-liability rent. Among the early contributors to the contract-theoretic literature on moral hazard were Oliver Hart and Sanford J. Grossman. In the meantime, the moral hazard model has been extended to the cases of multiple periods and multiple tasks, both with risk-averse and risk-neutral agents.\n\nThere are also models that combine hidden action and hidden information. Since there is no data on unobservable variables, the contract-theoretic moral hazard model is difficult to test directly, but there have been some successful indirect tests with field data. Direct tests of moral hazard theory are feasible in laboratory settings, using the tools of experimental economics. In such a setup, Hoppe and Schmitz (2018) have corroborated central insights of moral hazard theory.\n\n"}
{"id": "23626", "url": "https://en.wikipedia.org/wiki?curid=23626", "title": "Property", "text": "Property\n\nProperty, in the abstract, is what belongs to or with something, whether as an attribute or as a component of said thing. In the context of this article, it is one or more components (rather than attributes), whether physical or incorporeal, of a person's estate; or so belonging to, as in being owned by, a person or jointly a group of people or a legal entity like a corporation or even a society. Depending on the nature of the property, an owner of property has the right to consume, alter, share, redefine, rent, mortgage, pawn, sell, exchange, transfer, give away or destroy it, or to exclude others from doing these things, as well as to perhaps abandon it; whereas regardless of the nature of the property, the owner thereof has the right to properly use it (as a durable, mean or factor, or whatever), or at the very least exclusively keep it.\n\nIn economics and political economy, there are three broad forms of property: private property, public property, and collective property (also called cooperative property).\n\nProperty that jointly belongs to more than one party may be possessed or controlled thereby in very similar or very distinct ways, whether simply or complexly, whether equally or unequally. However, there is an expectation that each party's will (rather discretion) with regard to the property be clearly defined and unconditional, so as to distinguish ownership and easement from rent. The parties might expect their wills to be unanimous, or alternately every given one of them, when no opportunity for or possibility of dispute with any other of them exists, may expect his, her, its or their own will to be sufficient and absolute.\n\nThe Restatement (First) of Property defines property as anything, tangible or intangible whereby a legal relationship between persons and the state enforces a possessory interest or legal title in that thing. This mediating relationship between individual, property and state is called a property regime.\n\nIn sociology and anthropology, property is often defined as a relationship between two or more individuals and an object, in which at least one of these individuals holds a bundle of rights over the object. The distinction between \"collective property\" and \"private property\" is regarded as a confusion since different individuals often hold differing rights over a single object.\n\nImportant widely recognized types of property include real property (the combination of land and any improvements to or on the land), personal property (physical possessions belonging to a person), private property (property owned by legal persons, business entities or individual natural persons), public property (state owned or publicly owned and available possessions) and intellectual property (exclusive rights over artistic creations, inventions, etc.), although the last is not always as widely recognized or enforced. An article of property may have physical and incorporeal parts. A title, or a right of ownership, establishes the relation between the property and other persons, assuring the owner the right to dispose of the property as the owner sees fit.\n\nOften property is defined by the code of the local sovereignty, and protected wholly or more usually partially by such entity, the owner being responsible for any remainder of protection. The standards of proof concerning proofs of ownerships are also addressed by the code of the local sovereignty, and such entity plays a role accordingly, typically somewhat managerial. Some philosophers assert that property rights arise from social convention, while others find justifications for them in morality or in natural law.\n\nVarious scholarly disciplines (such as law, economics, anthropology or sociology) may treat the concept more systematically, but definitions vary, most particularly when involving contracts. Positive law defines such rights, and the judiciary can adjudicate and enforce property rights.\n\nAccording to Adam Smith, the expectation of profit from \"improving one's stock of capital\" rests on private property rights. Capitalism has as a central assumption that property rights encourage their holders to develop the property, generate wealth, and efficiently allocate resources based on the operation of markets. From this has evolved the modern conception of property as a right enforced by positive law, in the expectation that this will produce more wealth and better standards of living. However, Smith also expressed a very critical view on the effects of property laws on inequality:\n\nIn his text \"The Common Law\", Oliver Wendell Holmes describes property as having two fundamental aspects. The first, possession, can be defined as control over a resource based on the practical inability of another to contradict the ends of the possessor. The second, title, is the expectation that others will recognize rights to control resource, even when it is not in possession. He elaborates the differences between these two concepts, and proposes a history of how they came to be attached to persons, as opposed to families or to entities such as the church.\n\n\n\nBoth communism and some kinds of socialism have also upheld the notion that private ownership of capital is inherently illegitimate. This argument centers mainly on the idea that private ownership of capital always benefits one class over another, giving rise to domination through the use of this privately owned capital. Communists do not oppose personal property that is \"hard-won, self-acquired, self-earned\" (as the Communist Manifesto puts it) by members of the proletariat. Both socialism and communism distinguish carefully between private ownership of capital (land, factories, resources, etc.) and private property (homes, material objects and so forth).\n\nMost legal systems distinguish between different types of property, especially between land (immovable property, estate in land, real estate, real property) and all other forms of property—goods and chattels, movable property or personal property, including the value of legal tender if not the legal tender itself, as the manufacturer rather than the possessor might be the owner. They often distinguish tangible and intangible property. One categorization scheme specifies three species of property: land, improvements (immovable man-made things), and personal property (movable man-made things).\n\nIn common law, real property (immovable property) is the combination of interests in land and improvements thereto, and personal property is interest in movable property. Real property rights are rights relating to the land. These rights include ownership and usage. Owners can grant rights to persons and entities in the form of leases, licenses and easements.\n\nThroughout the last centuries of the second millennium, with the development of more complex theories of property, the concept of personal property had become divided into tangible property (such as cars and clothing) and intangible property (such as financial instruments, including stocks and bonds; intellectual property, including patents, copyrights and trademarks; digital files; communication channels; and certain forms of identifier, including Internet domain names, some forms of network address, some forms of handle and again trademarks).\n\nTreatment of intangible property is such that an article of property is, by law or otherwise by traditional conceptualization, subject to expiration even when inheritable, which is a key distinction from tangible property. Upon expiration, the property, if of the intellectual category, becomes a part of public domain, to be used by but not owned by anybody, and possibly used by more than one party simultaneously due the inapplicability of scarcity to intellectual property. Whereas things such as communications channels and pairs of electromagnetic spectrum band and signal transmission power can only be used by a single party at a time, or a single party in a divisible context, if owned or used at all. Thus far or usually those are not considered property, or at least not private property, even though the party bearing right of exclusive use may transfer that right to another.\n\nIn many societies the human body is considered property of some kind or other. The question of the ownership and rights to one's body arise in general in the discussion of human rights, including the specific issues of slavery, conscription, rights of children under the age of majority, marriage, abortion, prostitution, drugs, euthanasia and organ donation.\n\nOf the following, only sale and at-will sharing involve no encumbrance.\n\nThe two major justifications given for original property, or the homestead principle, are effort and scarcity. John Locke emphasized effort, \"mixing your labor\" with an object, or clearing and cultivating virgin land. Benjamin Tucker preferred to look at the telos of property, i.e. What is the purpose of property? His answer: to solve the scarcity problem. Only when items are relatively scarce with respect to people's desires do they become property. For example, hunter-gatherers did not consider land to be property, since there was no shortage of land. Agrarian societies later made arable land property, as it was scarce. For something to be economically scarce it must necessarily have the \"exclusivity property\"—that use by one person excludes others from using it. These two justifications lead to different conclusions on what can be property. Intellectual property—incorporeal things like ideas, plans, orderings and arrangements (musical compositions, novels, computer programs)—are generally considered valid property to those who support an effort justification, but invalid to those who support a scarcity justification, since the things don't have the exclusivity property (however, those who support a scarcity justification may still support other \"intellectual property\" laws such as Copyright, as long as these are a subject of contract instead of government arbitration). Thus even ardent propertarians may disagree about IP. By either standard, one's body is one's property.\n\nFrom some anarchist points of view, the validity of property depends on whether the \"property right\" requires enforcement by the state. Different forms of \"property\" require different amounts of enforcement: intellectual property requires a great deal of state intervention to enforce, ownership of distant physical property requires quite a lot, ownership of carried objects requires very little, while ownership of one's own body requires absolutely no state intervention. Some anarchists don't believe in property at all.\n\nMany things have existed that did not have an owner, sometimes called the commons. The term \"commons,\" however, is also often used to mean something quite different: \"general collective ownership\"—i.e. common ownership. Also, the same term is sometimes used by statists to mean government-owned property that the general public is allowed to access (public property). Law in all societies has tended to develop towards reducing the number of things not having clear owners. Supporters of property rights argue that this enables better protection of scarce resources, due to the tragedy of the commons, while critics argue that it leads to the 'exploitation' of those resources for personal gain and that it hinders taking advantage of potential network effects. These arguments have differing validity for different types of \"property\"—things that are not scarce are, for instance, not subject to the tragedy of the commons. Some apparent critics advocate general collective ownership rather than ownerlessness.\n\nThings that do not have owners include: ideas (except for intellectual property), seawater (which is, however, protected by anti-pollution laws), parts of the seafloor (see the United Nations Convention on the Law of the Sea for restrictions), gases in Earth's atmosphere, animals in the wild (although in most nations, animals are tied to the land. In the United States and Canada wildlife are generally defined in statute as property of the state. This public ownership of wildlife is referred to as the North American Model of Wildlife Conservation and is based on The Public Trust Doctrine.), celestial bodies and outer space, and land in Antarctica.\n\nThe nature of children under the age of majority is another contested issue here. In ancient societies children were generally considered the property of their parents. Children in most modern societies theoretically own their own bodies but are not considered competent to exercise their rights, and their parents or guardians are given most of the actual rights of control over them.\n\nQuestions regarding the nature of ownership of the body also come up in the issue of abortion, drugs and euthanasia.\n\nIn many ancient legal systems (e.g. early Roman law), religious sites (e.g. temples) were considered property of the God or gods they were devoted to. However, religious pluralism makes it more convenient to have religious sites owned by the religious body that runs them.\n\nIntellectual property and air (airspace, no-fly zone, pollution laws, which can include tradable emissions rights) can be property in some senses of the word.\n\nOwnership of land can be held separately from the ownership of rights over that land, including sporting rights, mineral rights, development rights, air rights, and such other rights as may be worth segregating from simple land ownership.\n\nOwnership laws may vary widely among countries depending on the nature of the property of interest (e.g. firearms, real property, personal property, animals). Persons can own property directly. In most societies legal entities, such as corporations, trusts and nations (or governments) own property.\n\nIn many countries women have limited access to property following restrictive inheritance and family laws, under which only men have actual or formal rights to own property.\n\nIn the Inca empire, the dead emperors, who were considered gods, still controlled property after death.\n\nIn 17th-century England, the legal directive that nobody may enter a home, which in the 17th-century would typically have been male owned, unless by the owners invitation or consent, was established as common law in Sir Edward Coke’s \"Institutes of the Lawes of England\". \"For a man's house is his castle, et domus sua cuique est tutissimum refugium [and each man's home is his safest refuge].\" It is the origin of the famous dictum, “an Englishman’s home is his castle”. The ruling enshrined into law what several English writers had espoused in the 16th-century. Unlike the rest of Europe the British had a proclivity towards owning their own homes. British Prime Minister William Pitt, 1st Earl of Chatham defined the meaning of castle in 1763, \"The poorest man may in his cottage bid defiance to all the forces of the crown. It may be frail – its roof may shake – the wind may blow through it – the storm may enter – the rain may enter – but the King of England cannot enter.\"\n\nA principle exported to the United States, under U.S. law the principal limitations on whether and the extent to which the State may interfere with property rights are set by the Constitution. The \"Takings\" clause requires that the government (whether state or federal—for the 14th Amendment's due process clause imposes the 5th Amendment's takings clause on state governments) may take private property only for a public purpose, after exercising due process of law, and upon making \"just compensation.\" If an interest is not deemed a \"property\" right or the conduct is merely an intentional tort, these limitations do not apply and the doctrine of sovereign immunity precludes relief. Moreover, if the interference does not almost completely make the property valueless, the interference will not be deemed a taking but instead a mere regulation of use. On the other hand, some governmental regulations of property use have been deemed so severe that they have been considered \"regulatory takings.\" Moreover, conduct sometimes deemed only a nuisance or other tort has been held a taking of property where the conduct was sufficiently persistent and severe.\n\nThere exist many theories of property. One is the relatively rare first possession theory of property, where ownership of something is seen as justified simply by someone seizing something before someone else does. Perhaps one of the most popular is the natural rights definition of property rights as advanced by John Locke. Locke advanced the theory that God granted dominion over nature to man through Adam in the book of Genesis. Therefore, he theorized that when one mixes one's labor with nature, one gains a relationship with that part of nature with which the labor is mixed, subject to the limitation that there should be \"enough, and as good, left in common for others.\" (see Lockean proviso)\n\nFrom the RERUM NOVARUM, Pope Leo XIII wrote \"It is surely undeniable that, when a man engages in remunerative labor, the impelling reason and motive of his work is to obtain property, and thereafter to hold it as his very own.\"\n\nAnthropology studies the diverse systems of ownership, rights of use and transfer, and possession under the term \"theories of property.\" Western legal theory is based, as mentioned, on the owner of property being a legal person. However, not all property systems are founded on this basis.\n\nIn every culture studied ownership and possession are the subject of custom and regulation, and \"law\" where the term can meaningfully be applied. Many tribal cultures balance individual ownership with the laws of collective groups: tribes, families, associations and nations. For example, the 1839 Cherokee Constitution frames the issue in these terms:\n\nCommunal property systems describe ownership as belonging to the entire social and political unit. Such arrangements can under certain conditions erode open access resources. This development has been critiqued by the tragedy of the commons.\n\nCorporate systems describe ownership as being attached to an identifiable group with an identifiable responsible individual. The Roman property law was based on such a corporate system. In a well-known paper that contributed to the creation of the field of law and economics in the late 1960s, the American scholar Harold Demsetz described how the concept of property rights makes social interactions easier:\n\nDifferent societies may have different theories of property for differing types of ownership. Pauline Peters argued that property systems are not isolable from the social fabric, and notions of property may not be stated as such, but instead may be framed in negative terms: for example the taboo system among Polynesian peoples.\n\nIn medieval and Renaissance Europe the term \"property\" essentially referred to land. After much rethinking, land has come to be regarded as only a special case of the property genus. This rethinking was inspired by at least three broad features of early modern Europe: the surge of commerce, the breakdown of efforts to prohibit interest (then called \"usury\"), and the development of centralized national monarchies.\n\nUrukagina, the king of the Sumerian city-state Lagash, established the first laws that forbade compelling the sale of property.\n\nThe Ten Commandments shown in Exodus 20:2–17 and Deuteronomy 5:6–21 stated that the Israelites were not to steal, but the connection between Bronze Age concepts of theft and modern concepts of property is suspect.\n\nAristotle, in \"Politics,\" advocates \"private property.\" He argues that self-interest leads to neglect of the commons. \"[T]hat which is common to the greatest number has the least care bestowed upon it. Every one thinks chiefly of his own, hardly at all of the common interest; and only when he is himself concerned as an individual.\"\n\nIn addition he says that when property is common, there are natural problems that arise due to differences in labor: \"If they do not share equally enjoyments and toils, those who labor much and get little will necessarily complain of those who labor little and receive or consume much. But indeed there is always a difficulty in men living together and having all human relations in common, but especially in their having common property.\" (\"Politics, 1261b34\")\n\nCicero held that there is no private property under natural law but only under human law. Seneca viewed property as only becoming necessary when men become avarice. St. Ambrose later adopted this view and St. Augustine even derided heretics for complaining the Emperor could not confiscate property they had labored for.\n\nThe canon law \"Decretum Gratiani\" maintained that mere human law creates property, repeating the phrases used by St. Augustine. St. Thomas Aquinas agreed with regard to the private consumption of property but modified patristic theory in finding that the private possession of property is necessary. Thomas Aquinas concludes that, given certain detailed provisions,\n\nThe principal writings of Thomas Hobbes appeared between 1640 and 1651—during and immediately following the war between forces loyal to King Charles I and those loyal to Parliament. In his own words, Hobbes' reflection began with the idea of \"giving to every man his own,\" a phrase he drew from the writings of Cicero. But he wondered: How can anybody call anything his own? He concluded: My own can only truly be mine if there is one unambiguously strongest power in the realm, and that power treats it as mine, protecting its status as such.\n\nA contemporary of Hobbes, James Harrington, reacted to the same tumult in a different way: he considered property natural but not inevitable. The author of \"Oceana\", he may have been the first political theorist to postulate that political power is a consequence, not the cause, of the distribution of property. He said that the worst possible situation is one in which the commoners have half a nation's property, with crown and nobility holding the other half—a circumstance fraught with instability and violence. A much better situation (a stable republic) will exist once the commoners own most property, he suggested.\n\nIn later years, the ranks of Harrington's admirers included American revolutionary and founder John Adams.\n\nAnother member of the Hobbes/Harrington generation, Sir Robert Filmer, reached conclusions much like Hobbes', but through Biblical exegesis. Filmer said that the institution of kingship is analogous to that of fatherhood, that subjects are but children, whether obedient or unruly, and that property rights are akin to the household goods that a father may dole out among his children—his to take back and dispose of according to his pleasure.\n\nIn the following generation, John Locke sought to answer Filmer, creating a rationale for a balanced constitution in which the monarch had a part to play, but not an overwhelming part. Since Filmer's views essentially require that the Stuart family be uniquely descended from the patriarchs of the Bible, and since even in the late 17th century that was a difficult view to uphold, Locke attacked Filmer's views in his First Treatise on Government, freeing him to set out his own views in the Second Treatise on Civil Government. Therein, Locke imagined a pre-social world, each of the unhappy residents of which are willing to create a social contract because otherwise \"the enjoyment of the property he has in this state is very unsafe, very unsecure,\" and therefore the \"great and chief end, therefore, of men's uniting into commonwealths, and putting themselves under government, is the preservation of their property.\" They would, he allowed, create a monarchy, but its task would be to execute the will of an elected legislature. \"To this end\" (to achieve the previously specified goal), he wrote, \"it is that men give up all their natural power to the society they enter into, and the community put the legislative power into such hands as they think fit, with this trust, that they shall be governed by declared laws, or else their peace, quiet, and property will still be at the same uncertainty as it was in the state of nature.\"\n\nEven when it keeps to proper legislative form, though, Locke held that there are limits to what a government established by such a contract might rightly do.\n\n\"It cannot be supposed that [the hypothetical contractors] they should intend, had they a power so to do, to give any one or more an absolute arbitrary power over their persons and estates, and put a force into the magistrate's hand to execute his unlimited will arbitrarily upon them; this were to put themselves into a worse condition than the state of nature, wherein they had a liberty to defend their right against the injuries of others, and were upon equal terms of force to maintain it, whether invaded by a single man or many in combination. Whereas by supposing they have given up themselves to the absolute arbitrary power and will of a legislator, they have disarmed themselves, and armed him to make a prey of them when he pleases...\"\n\nNote that both \"persons \"and\" estates\" are to be protected from the arbitrary power of any magistrate, inclusive of the \"power and will of a legislator.\" In Lockean terms, depredations against an estate are just as plausible a justification for resistance and revolution as are those against persons. In neither case are subjects required to allow themselves to become prey.\n\nTo explain the ownership of property Locke advanced a labor theory of property.\n\nIn contrast to the figures discussed in this section thus far David Hume lived a relatively quiet life that had settled down to a relatively stable social and political structure. He lived the life of a solitary writer until 1763 when, at 52 years of age, he went off to Paris to work at the British embassy.\n\nIn contrast, one might think, to his polemical works on religion and his empiricism-driven skeptical epistemology, Hume's views on law and property were quite conservative.\n\nHe did not believe in hypothetical contracts, or in the love of mankind in general, and sought to ground politics upon actual human beings as one knows them. \"In general,\" he wrote, \"it may be affirmed that there is no such passion in human mind, as the love of mankind, merely as such, independent of personal qualities, or services, or of relation to ourselves.\" Existing customs should not lightly be disregarded, because they have come to be what they are as a result of human nature. With this endorsement of custom comes an endorsement of existing governments, because he conceived of the two as complementary: \"A regard for liberty, though a laudable passion, ought commonly to be subordinate to a reverence for established government.\"\n\nTherefore, Hume's view was that there are property rights because of and to the extent that the existing law, supported by social customs, secure them. He offered some practical home-spun advice on the general subject, though, as when he referred to avarice as \"the spur of industry,\" and expressed concern about excessive levels of taxation, which \"destroy industry, by engendering despair.\"\n\n\"The property which every man has in his own labour, as it is the original foundation of all other property, so it is the most sacred and inviolable. The patrimony of a poor man lies in the strength and dexterity of his hands; and to hinder him from employing this strength and dexterity in what manner he thinks proper without injury to his neighbour, is a plain violation of this most sacred property. It is a manifest encroachment upon the just liberty both of the workman, and of those who might be disposed to employ him. As it hinders the one from working at what he thinks proper, so it hinders the others from employing whom they think proper. To judge whether he is fit to be employed, may surely be trusted to the discretion of the employers whose interest it so much concerns. The affected anxiety of the law-giver lest they should employ an improper person, is evidently as impertinent as it is oppressive.\"\n— (Source: Adam Smith, \"The Wealth of Nations\", 1776, Book I, Chapter X, Part II.)\n\nBy the mid 19th century, the industrial revolution had transformed England and the United States, and had begun in France. The established conception of what constitutes property expanded beyond land to encompass scarce goods in general. In France, the revolution of the 1790s had led to large-scale confiscation of land formerly owned by church and king. The restoration of the monarchy led to claims by those dispossessed to have their former lands returned.\n\nSection VIII, \"Primitive Accumulation\" of Capital involves a critique of Liberal Theories of property rights. Marx notes that under Feudal Law, peasants were legally as entitled to their land as the aristocracy was to its manors. Marx cites several historical events in which large numbers of the peasantry were removed from their lands, which were then seized by the aristocracy. This seized land was then used for commercial ventures (sheep herding). Marx sees this \"Primitive Accumulation\" as integral to the creation of English Capitalism. This event created a large un-landed class which had to work for wages in order to survive. Marx asserts that Liberal theories of property are \"idyllic\" fairy tales that hide a violent historical process.\n\nCharles Comte, in \"Traité de la propriété\" (1834), attempted to justify the legitimacy of private property in response to the Bourbon Restoration. According to David Hart, Comte had three main points: \"firstly, that interference by the state over the centuries in property ownership has had dire consequences for justice as well as for economic productivity; secondly, that property is legitimate when it emerges in such a way as not to harm anyone; and thirdly, that historically some, but by no means all, property which has evolved has done so legitimately, with the implication that the present distribution of property is a complex mixture of legitimately and illegitimately held titles.\"\n\nComte, as Proudhon later did, rejected Roman legal tradition with its toleration of slavery. He posited a communal \"national\" property consisting of non-scarce goods, such as land in ancient hunter-gatherer societies. Since agriculture was so much more efficient than hunting and gathering, private property appropriated by someone for farming left remaining hunter-gatherers with more land per person, and hence did not harm them. Thus this type of land appropriation did not violate the Lockean proviso – there was \"still enough, and as good left.\" Comte's analysis would be used by later theorists in response to the socialist critique on property.\n\nIn his 1840 treatise \"What is Property?\", Pierre Proudhon answers with \"Property is theft!\" In natural resources, he sees two types of property, \"de jure\" property (legal title) and \"de facto\" property (physical possession), and argues that the former is illegitimate. Proudhon's conclusion is that \"property, to be just and possible, must necessarily have equality for its condition.\"\n\nHis analysis of the product of labor upon natural resources as property (usufruct) is more nuanced. He asserts that land itself cannot be property, yet it should be held by individual possessors as stewards of mankind with the product of labor being the property of the producer. Proudhon reasoned that any wealth gained without labor was stolen from those who labored to create that wealth. Even a voluntary contract to surrender the product of labor to an employer was theft, according to Proudhon, since the controller of natural resources had no moral right to charge others for the use of that which he did not labor to create and therefore did not own.\n\nProudhon's theory of property greatly influenced the budding socialist movement, inspiring anarchist theorists such as Mikhail Bakunin who modified Proudhon's ideas, as well as antagonizing theorists like Karl Marx.\n\nFrédéric Bastiat's main treatise on property can be found in chapter 8 of his book \"Economic Harmonies\" (1850). In a radical departure from traditional property theory, he defines property not as a physical object, but rather as a relationship between people with respect to an object. Thus, saying one owns a glass of water is merely verbal shorthand for \"I may justly gift or trade this water to another person\". In essence, what one owns is not the object but the value of the object. By \"value,\" Bastiat apparently means \"market value\"; he emphasizes that this is quite different from utility. \"In our relations with one another, we are not owners of the utility of things, but of their value, and value is the appraisal made of reciprocal services.\"\n\nBastiat theorized that, as a result of technological progress and the division of labor, the stock of communal wealth increases over time; that the hours of work an unskilled laborer expends to buy e.g. 100 liters of wheat decreases over time, thus amounting to \"gratis\" satisfaction. Thus, private property continually destroys itself, becoming transformed into communal wealth. The increasing proportion of communal wealth to private property results in a tendency toward equality of mankind. \"Since the human race started from the point of greatest poverty, that is, from the point where there were the most obstacles to be overcome, it is clear that all that has been gained from one era to the next has been due to the spirit of property.\"\n\nThis transformation of private property into the communal domain, Bastiat points out, does not imply that private property will ever totally disappear. This is because man, as he progresses, continually invents new and more sophisticated needs and desires.\n\nAndrew J. Galambos (1924–1997) was an astrophysicist and philosopher who innovated a social structure that seeks to maximize human peace and freedom. Galambos’ concept of property was basic to his philosophy. He defined property as a man's life and all non-procreative derivatives of his life. (Because the English language is deficient in omitting the feminine form “man” when referring to humankind, it is implicit and obligatory that the feminine is included in the term “man”.)\n\nGalambos taught that property is essential to a non-coercive social structure. That is why he defined freedom as follows: “Freedom is the societal condition that exists when every individual has full (100%) control over his own property.” Galambos defines property as having the following elements:\n\nProperty includes all non-procreative derivatives of an individual's life; this means children are not the property of their parents. and \"primary property\" (a person's own ideas).\n\nGalambos emphasized repeatedly that true government exists to protect property and that the state attacks property.\nFor example, the state requires payment for its services in the form of taxes whether or not people desire such services. Since an individual's money is his property, the confiscation of money in the form of taxes is an attack on property. Military conscription is likewise an attack on a person's primordial property.\n\nContemporary political thinkers who believe that natural persons enjoy rights to own property and to enter into contracts espouse two views about John Locke. On the one hand, some admire Locke, such as William H. Hutt (1956), who praised Locke for laying down the \"quintessence of individualism\". On the other hand, those such as Richard Pipes regard Locke's arguments as weak, and think that undue reliance thereon has weakened the cause of individualism in recent times. Pipes has written that Locke's work \"marked a regression because it rested on the concept of Natural Law\" rather than upon Harrington's sociological framework.\n\nHernando de Soto has argued that an important characteristic of capitalist market economy is the functioning state protection of property rights in a formal property system which clearly records ownership and transactions. These property rights and the whole formal system of property make possible:\n\nAll of the above, according to de Soto, enhance economic growth.\n\n\nProperty-giving (legal)\n\n\nProperty-taking (legal)\n\n\nProperty-taking (illegal)\n\n\n"}
{"id": "183515", "url": "https://en.wikipedia.org/wiki?curid=183515", "title": "Retail", "text": "Retail\n\nRetail is the process of selling consumer goods or services to customers through multiple channels of distribution to earn a profit. Retailers satisfy demand identified through a supply chain. The term \"retailer\" is typically applied where a service provider fills the small orders of many individuals, who are end-users, rather than large orders of a small number of wholesale, corporate or government clientele. Shopping generally refers to the act of buying products. Sometimes this is done to obtain final goods, including necessities such as food and clothing; sometimes it takes place as a recreational activity. Recreational shopping often involves window shopping and browsing: it does not always result in a purchase.\n\nRetail markets and shops have a very ancient history, dating back to antiquity. Some of the earliest retailers were itinerant peddlers. Over the centuries, retail shops were transformed from little more than \"rude booths\" to the sophisticated shopping malls of the modern era.\n\nMost modern retailers typically make a variety of strategic level decisions including the type of store, the market to be served, the optimal product assortment, customer service, supporting services and the store's overall market positioning. Once the strategic retail plan is in place, retailers devise the retail mix which includes product, price, place, promotion, personnel, and presentation. In the digital age, an increasing number of retailers are seeking to reach broader markets by selling through multiple channels, including both bricks and mortar and online retailing. Digital technologies are also changing the way that consumers pay for goods and services. Retailing support services may also include the provision of credit, delivery services, advisory services, stylist services and a range of other supporting services.\n\nRetail shops occur in a diverse range of types and in many different contexts – from strip shopping centres in residential streets through to large, indoor shopping malls. Shopping streets may restrict traffic to pedestrians only. Sometimes a shopping street has a partial or full roof to create a more comfortable shopping environment – protecting customers from various types of weather conditions such as extreme temperatures, winds or precipitation. Forms of non-shop retailing include online retailing (a type of electronic-commerce used for business-to-consumer (B2C) transactions) and mail order.\n\nThe word \"retail\" comes from the Old French verb \"tailler\", meaning \"to cut off, clip, pare, divide in terms of tailoring\" (c. 1365). It was first recorded as a noun in 1433 with the meaning of \"a sale in small quantities\" from the Middle French verb \"retailler\" meaning \"a piece cut off, shred, scrap, paring\". At the present, the meaning of the word \"retail\" (in English, French, Dutch, and German) refers to the sale of small quantities of items to consumers (as opposed to wholesale).\n\nRetail refers to the activity of selling goods or services directly to consumers or end-users. Some retailers may sell to business customers, and such sales are termed \"non-retail activity.\" In some jurisdictions or regions, legal definitions of retail specify that at least 80 percent of sales activity must be to end-users.\n\nRetailing often occurs in retail stores or service establishments, but may also occur through direct selling such as through vending machines, door-to-door sales or electronic channels.\nAlthough the idea of retail is often associated with the purchase of goods, the term may be applied to service-providers that sell to consumers. Retail service providers include retail banking, tourism, insurance, private healthcare, private education, private security firms, legal firms, publishers, public transport and others. For example, a tourism provider might have a retail division that books travel and accommodation for consumers plus a wholesale division that purchases blocks of accommodation, hospitality, transport and sightseeing which are subsequently packaged into a holiday tour for sale to retail travel agents.\n\nSome retailers badge their stores as \"wholesale outlets\" offering \"wholesale prices.\" While this practice may encourage consumers to imagine that they have access to lower prices, while being prepared to trade-off reduced prices for cramped in-store environments, in a strictly legal sense, a store that sells the majority of its merchandise direct to consumers, is defined as a retailer rather than a wholesaler. Different jurisdictions set parameters for the ratio of consumer to business sales that define a retail business.\n\nRetail markets have existed since ancient times. Archaeological evidence for trade, probably involving barter systems, dates back more than 10,000 years. As civilizations grew, barter was replaced with retail trade involving coinage. Selling and buying are thought to have emerged in Asia Minor (modern Turkey) in around the 7th-millennium BCE. Gharipour points to evidence of primitive shops and trade centers in Sialk Hills in Kashan (6000 BCE), Catalk Huyuk in modern-day Turkey (7,500–5,700 BCE), Jericho (2600 BCE) and Susa (4000 BCE). Open air, public markets were known in ancient Babylonia, Assyria, Phoenicia, and Egypt. These markets typically occupied a place in the town's center. Surrounding the market, skilled artisans, such as metal-workers and leather workers, occupied permanent premises in alleys that led to the open market-place. These artisans may have sold wares directly from their premises, but also prepared goods for sale on market days. In ancient Greece markets operated within the agora, an open space where, on market days, goods were displayed on mats or temporary stalls. In ancient Rome, trade took place in the forum. Rome had two forums; the Forum Romanum and Trajan's Forum. The latter was a vast expanse, comprising multiple buildings with shops on four levels. The Roman forum was arguably the earliest example of a permanent retail shop-front. In antiquity, exchange involved direct selling via merchants or peddlers and bartering systems were commonplace.\n\nThe Phoenicians, noted for their seafaring skills, plied their ships across the Mediterranean, becoming a major trading power by the 9th century BCE. The Phoenicians imported and exported wood, textiles, glass and produce such as wine, oil, dried fruit, and nuts. Their trading skills necessitated a network of colonies along the Mediterranean coast, stretching from modern-day Crete through to Tangiers and onto Sardinia The Phoenicians not only traded in tangible goods, but were also instrumental in transporting culture. The Phoenician's extensive trade networks necessitated considerable book-keeping and correspondence. In around 1500 BCE, the Phoenicians developed a consonantal alphabet which was much easier to learn that the complex scripts used in ancient Egypt and Mesopotamia. Phoenician traders and merchants were largely responsible for spreading their alphabet around the region. Phoenician inscriptions have been found in archaeological sites at a number of former Phoenician cities and colonies around the Mediterranean, such as Byblos (in present-day Lebanon) and Carthage in North Africa.\n\nIn the Graeco-Roman world, the market primarily served the local peasantry. Local producers, who were generally poor, would sell small surpluses from their individual farming activities, purchase minor farm equipment and also buy a few luxuries for their homes. Major producers such as the great estates were sufficiently attractive for merchants to call directly at their farm-gates, obviating the producers' need to attend local markets. The very wealthy landowners managed their own distribution, which may have involved exporting and importing. The nature of export markets in antiquity is well documented in ancient sources and archaeological case studies. The Romans preferred to purchase goods from specific places: oysters from Londinium, cinnamon from a specific mountain in Arabia, and these place-based preferences stimulated trade throughout Europe and the Middle East. Markets were also important centers of social life.\n\nThe rise of retailing and marketing in England and Europe has been extensively studied, but less is known about developments elsewhere. Nevertheless, recent research suggests that China exhibited a rich history of early retail systems. From as early as 200 BCE, Chinese packaging and branding were used to signal family, place names and product quality, and the use of government imposed product branding was used between 600 and 900 CE. Eckhart and Bengtsson have argued that during the Song Dynasty (960–1127), Chinese society developed a consumerist culture, where a high level of consumption was attainable for a wide variety of ordinary consumers rather than just the elite. The rise of a consumer culture led to the commercial investment in carefully managed company image, retail signage, symbolic brands, trademark protection and sophisticated brand concepts.\n\nIn Medieval England and Europe, relatively few permanent shops were to be found; instead, customers walked into the tradesman's workshops where they discussed purchasing options directly with tradesmen. In 13th-century London, mercers, and haberdashers were known to exist and grocers sold \"miscellaneous small wares as well as spices and medicines\" but fish and other perishables were sold through markets, costermongers, hucksters, peddlers or other types of itinerant vendor.\n\nIn the more populous cities, a small number of shops were beginning to emerge by the 13th century. In Chester, a medieval covered shopping arcade represented a major innovation that attracted shoppers from many miles around. Known as \"The Rows\" this medieval shopping arcade is believed to be the first of its kind in Europe. Fragments of Chester's Medieval Row, which is believed to date to the mid-13th century, can still be found in Cheshire. In the 13th or 14th century, another arcade with several shops was recorded at \"Drapery Row\" in Winchester. The emergence of street names such as \"Drapery Row\", \"Mercer's Lane\" and \"Ironmonger Lane\" in the medieval period suggests that permanent shops were becoming more commonplace.\n\nMedieval shops had little in common with their modern equivalent. As late as the 16th century, London's shops were described as little more than \"rude booths\" and their owners \"bawled as loudly as the itinerants.\" Shopfronts typically had a front door with two wider openings on either side, each covered with shutters. The shutters were designed to open so that the top portion formed a canopy while the bottom was fitted with legs so that it could serve as a shopboard. Cox and Dannehl suggest that the Medieval shopper's experience was very different. The lack of glazed windows, which were rare during the medieval period, and did not become commonplace until the eighteenth century, meant that shop interiors were dark places. Outside the markets, goods were rarely out on display and the service counter was unknown. Shoppers had relatively few opportunities to inspect the merchandise prior to consumption. Many stores had openings onto the street from which they served customers.\n\nOutside the major cities, most consumable purchases were made through markets or fairs. Markets were held daily in the more populous towns and cities or weekly in the more sparsely populated rural districts. Markets sold fresh produce; fruit, vegetables, baked goods, meat, poultry, fish and some ready to eat foodstuffs; while fairs operated on a periodic cycle and were almost always associated with a religious festival. Fairs sold non-perishables such as farm tools, homewares, furniture, rugs and ceramics. Market towns dotted the medieval European landscape while itinerant vendors supplied less populated areas or hard-to-reach districts. Peddlers and other itinerant vendors operated alongside other types of retail for centuries. The political philosopher, John Stuart Mill compared the convenience of markets/fairs to that of the itinerant peddlers:\n\nBlintiff has investigated the early Medieval networks of market towns across Europe and suggests that by the 12th century there was an upsurge in the number of market towns and the emergence of merchant circuits as traders bulked up surpluses from smaller regional, different day markets and resold them at the larger centralized market towns. Market-places appear to have emerged independently outside Europe. The Grand Bazaar in Istanbul is often cited as the world's oldest continuously-operating market; its construction began in 1455. The Spanish conquistadors wrote glowingly of markets in the Americas. In the 15th century, the Mexica (Aztec) market of Tlatelolco was the largest in all the Americas.\n\nEnglish market towns were regulated from a relatively early period. The English monarchs awarded a \"charter\" to local Lords to create markets and fairs for a town or village. This charter would grant the lords the right to take tolls and also afford some protection from rival markets. For example, once a chartered market was granted for specific market days, a nearby rival market could not open on the same days. Across the boroughs of England, a network of chartered markets sprang up between the 12th and 16th centuries, giving consumers reasonable choice in the markets they preferred to patronize. A study on the purchasing habits of the monks and other individuals in medieval England, suggests that consumers of the period were relatively discerning. Purchase decisions were based on purchase criteria such as consumers' perceptions of the range, quality, and price of goods. This informed decisions about where to make their purchases and which markets were superior.\n\nBraudel and Reynold have made a systematic study of these European market towns between the thirteenth and fifteenth centuries. Their investigation shows that in regional districts markets were held once or twice a week while daily markets were common in larger cities. Gradually over time, permanent shops with regular trading days began to supplant the periodic markets, while peddlers filled in the gaps in distribution. The physical market was characterized by transactional exchange and the economy was characterized by local trading. Braudel reports that, in 1600, goods traveled relatively short distances – grain 5–10 miles; cattle 40–70 miles; wool and woollen cloth 20–40 miles. Following the European age of discovery, goods were imported from afar – calico cloth from India, porcelain, silk and tea from China, spices from India and South-East Asia and tobacco, sugar, rum and coffee from the New World.\n\nEnglish essayist, Joseph Addison, writing in 1711, described the exotic origin of produce available to English society in the following terms:\n\nLuca Clerici has made a detailed study of Vicenza’s food market during the sixteenth century. He found that there were many different types of reseller operating out of the markets. For example, in the dairy trade, cheese and butter were sold by the members of two craft guilds (i.e., cheesemongers who were shopkeepers) and that of the so-called ‘resellers’ (hucksters selling a wide range of foodstuffs), and by other sellers who were not enrolled in any guild. Cheesemongers’ shops were situated in the town hall and were very lucrative. Resellers and direct sellers increased the number of sellers, thus increasing competition, to the benefit of consumers. Direct sellers, who brought produce from the surrounding countryside, sold their wares through the central market place and priced their goods at considerably lower rates than cheesemongers.\n\nBy the 17th century, permanent shops with more regular trading hours were beginning to supplant markets and fairs as the main retail outlet. Provincial shopkeepers were active in almost every English market town. These shopkeepers sold general merchandise, much like a contemporary convenience store or a general store. For example, William Allen, a mercer in Tamworth who died in 1604, sold spices alongside furs and fabrics. William Stout of Lancaster retailed sugar, tobacco, nails and prunes at both his shop and at the central markets. His autobiography reveals that he spent most of his time preparing products for sale at the central market, which brought an influx of customers into town.\n\nAs the number of shops grew, they underwent a transformation. The trappings of a modern shop, which had been entirely absent from the sixteenth- and early seventeenth-century store, gradually made way for store interiors and shopfronts that are more familiar to modern shoppers. Prior to the eighteenth century, the typical retail store had no counter, display cases, chairs, mirrors, changing rooms, etc. However, the opportunity for the customer to browse merchandise, touch and feel products began to be available, with retail innovations from the late 17th and early 18th centuries. Glazing was widely used from the early 18th century. English commentators pointed to the speed at which glazing was installed, Daniel Defoe, writing in 1726, noted that \"Never was there such painting and guildings, such sashings and looking-glasses as the shopkeepers as there is now.\"\n\nOutside the major metropolitan cities, few stores could afford to serve one type of clientele exclusively. However, gradually retail shops introduced innovations that would allow them to separate wealthier customers from the \"riff raff.\" One technique was to have a window opening out onto the street from which customers could be served. This allowed the sale of goods to the common people, without encouraging them to come inside. Another solution, that came into vogue from the late sixteenth century was to invite favored customers into a back-room of the store, where goods were permanently on display. Yet another technique that emerged around the same time was to hold a showcase of goods in the shopkeeper's private home for the benefit of wealthier clients. Samuel Pepys, for example, writing in 1660, describes being invited to the home of a retailer to view a wooden jack. The eighteenth-century English entrepreneurs, Josiah Wedgewood and Matthew Boulton, both staged expansive showcases of their wares in their private residences or in rented halls.\n\nSavitt has argued that by the eighteenth century, American merchants, who had been operating as importers and exporters, began to specialize in either wholesale or retail roles. They tended not to specialize in particular types of merchandise, often trading as general merchants, selling a diverse range of product types. These merchants were concentrated in the larger cities. They often provided high levels of credit financing for retail transactions.\n\nBy the late eighteenth century, grand shopping arcades began to emerge across Europe and in the Antipodes. A shopping arcade refers to a multiple-vendor space, operating under a covered roof. Typically, the roof was constructed of glass to allow for natural light and to reduce the need for candles or electric lighting. Some of the earliest examples of shopping arcade appeared in Paris, due to its lack of pavement for pedestrians. Retailers, eager to attract window shoppers by providing a shopping environment away from the filthy streets, began to construct rudimentary arcades. Opening in 1771, the \"Coliseé\", situated on the Champs Elysee, consisted of three arcades, each with ten shops, all running off a central ballroom. For Parisians, the location was seen as too remote and the arcade closed within two years of opening. Inspired by the souks of Arabia, the Galerie de Bois, a series of wooden shops linked the ends of the Palais Royal, opened in 1786 and became a central part of Parisian social life.\n\nThe architect, Bertrand Lemoine, described the period, 1786 to 1935, as \"l’Ère des passages couverts\" (the Arcade Era). In the European capitals, shopping arcades spread across the continent, reaching their heyday in the early 19th century: the Palais Royal in Paris (opened in 1784); Passage de Feydeau in Paris (opened in 1791) and Passage du Claire in 1799. London's Piccadilly Arcade (opened in 1810); Paris's Passage Colbert (1826) and Milan's Galleria Vittorio Emanuele (1878). Designed to attract the genteel middle class, arcade retailers sold luxury goods at relatively high prices. However, prices were never a deterrent, as these new arcades came to be the place to shop and to be seen. Arcades offered shoppers the promise of an enclosed space away from the chaos that characterised the noisy, dirty streets; a warm, dry space away from the elements, and a safe-haven where people could socialise and spend their leisure time. As thousands of glass covered arcades spread across Europe, they became grander and more ornately decorated. By the mid-nineteenth century, they had become prominent centres of fashion and social life. Promenading in these arcades became a popular nineteenth-century pass-time for the emerging middle classes. The \"Illustrated Guide to Paris\" of 1852 summarized the appeal of arcades in the following description:\n\nThe Palais-Royal, which opened to Parisians in 1784 and became one of the most important marketplaces in Paris, is generally regarded as the earliest example in the grand shopping arcades. The Palais-Royal was a complex of gardens, shops and entertainment venues situated on the external perimeter of the grounds, under the original colonnades. The area boasted some 145 boutiques, cafés, salons, hair salons, bookshops, museums, and numerous refreshment kiosks as well as two theatres. The retail outlets specialised in luxury goods such as fine jewellery, furs, paintings and furniture designed to appeal to the wealthy elite. Retailers operating out of the Palais complex were among the first in Europe to abandon the system of bartering, and adopt fixed-prices thereby sparing their clientele the hassle of bartering. Stores were fitted with long glass exterior windows which allowed the emerging middle-classes to window shop and indulge in fantasies, even when they may not have been able to afford the high retail prices. Thus, the Palais-Royal became one of the first examples of a new style of shopping arcade, frequented by both the aristocracy and the middle classes. It developed a reputation as being a site of sophisticated conversation, revolving around the salons, cafés, and bookshops, but also became a place frequented by off-duty soldiers and was a favourite haunt of prostitutes, many of whom rented apartments in the building. London's Burlington Arcade, which opened in 1819, positioned itself as an elegant and exclusive venue from the outset. Other notable nineteenth-century grand arcades include the Galeries Royales Saint-Hubert in Brussels which was inaugurated in 1847, Istanbul's Çiçek Pasajı opened in 1870 and Milan's Galleria Vittorio Emanuele II first opened in 1877. Shopping arcades were the precursor to the modern shopping mall.\nWhile the arcades were the province of the bourgeoisie, a new type of retail venture emerged to serve the needs of the working poor. John Stuart Mill wrote about the rise of the co-operative retail store, which he witnessed first-hand in the mid-nineteenth century. Stuart Mill locates these co-operative stores within a broader co-operative movement which was prominent in the industrial city of Manchester and in the counties of Yorkshire and Lancashire. He documents one of the early co-operative retail stores in Rochdale in Manchester, England, \"In 1853, the Store purchased for £745, a warehouse (freehold) on the opposite side of the street, where they keep and retail their stores of flour, butcher's meat, potatoes, and kindred articles.\" Stuart Mill also quoted a contemporary commentator who wrote of the benefits of the co-operative store:\n\nBuyer and seller meet as friends; there is no overreaching on one side, and no suspicion on the other... These crowds of humble working men, who never knew before when they put good food in their mouths, whose every dinner was adulterated, whose shoes let in the water a month too soon, whose waistcoats shone with devil's dust, and whose wives wore calico that would not wash, now buy in the markets like millionaires, and as far as pureness of food goes, live like lords.\n\nThe modern era of retailing is defined as the period from the industrial revolution to the 21st century. In major cities, the department store emerged in the mid- to late 19th century, and permanently reshaped shopping habits, and redefined concepts of service and luxury. The term, \"department store\" originated in America. In 19th-century England, these stores were known as emporia or warehouse shops. In London, the first department stores appeared in Oxford Street and Regent Street, where they formed part of a distinctly modern shopping precinct. When London draper, William Whiteley attempted to transform his Bayswater drapery store into a department store by adding a meat and vegetable department and an Oriental Department in around 1875, he met with extreme resistance from other shop-keepers, who resented that he was encroaching on their territory and poaching their customers. Before long, however, major department stores began to open across the US, Britain and Europe from the mid-nineteenth century, including Harrod's of London in 1834; Kendall's in Manchester in 1836; Selfridges of London in 1909; Macy's of New York in 1858; Bloomingdale's in 1861; Sak's in 1867; J.C. Penney in 1902; Le Bon Marché of France in 1852 and Galeries Lafayette of France in 1905. Other twentieth-century innovations in retailing included chain stores, mail-order, multi-level marketing (pyramid selling or network marketing, 1920s), party plans ( 1930s) and B2C e-commerce.\n\nMany of the early department stores were more than just a retail emporium; rather they were venues where shoppers could spend their leisure time and be entertained. Some department stores offered reading rooms, art galleries and concerts. Most department stores had tea-rooms or dining rooms and offered treatment areas where ladies could indulge in a manicure. The fashion show, which originated in the US in around 1907, became a staple feature event for many department stores and celebrity appearances were also used to great effect. Themed events featured wares from foreign shores, exposing shoppers to the exotic cultures of the Orient and Middle-East.\nDuring this period, retailers worked to develop modern retail marketing practices. Pioneering merchants who contributed to modern retail marketing and management methods include: A. T. Stewart, Potter Palmer, John Wanamaker, Montgomery Ward, Marshall Field, Richard Warren Sears, Rowland Macy, J.C. Penney, Fred Lazarus, brothers Edward and William Filene and Sam Walton.\n\nRetail, using mail order, came of age during the mid-19th century. Although catalogue sales had been used since the 15th century, this method of retailing was confined to a few industries such as the sale of books and seeds. However, improvements in transport and postal services led several entrepreneurs on either side of the Atlantic to experiment with catalogue sales. In 1861, Welsh draper Pryce Pryce-Jones sent catalogues to clients who could place orders for flannel clothing which was then despatched by post. This enabled Pryce-Jones to extend his client base across Europe. A decade later, the US retailer, Montgomery Ward also devised a catalogue sales and mail-order system. His first catalogue which was issued in August 1872 consisted of an 8 in × 12 in (20 cm × 30 cm) single-sheet price list, listing 163 items for sale with ordering instructions for which Ward had written the copy. He also devised the catch-phrase \"satisfaction guaranteed or your money back\" which was implemented in 1875. By the 1890s, Sears and Roebuck were also using mail order with great success.\n\nEdward Filene, a proponent of the scientific approach to retail management, developed the concept of the \"automatic bargain Basement\". Although Filene's basement was not the first ‘bargain basement’ in the U.S., the principles of ‘automatic mark-downs’ generated excitement and proved very profitable. Under Filene's plan, merchandise had to be sold within 30 days or it was marked down; after a further 12 days, the merchandise was further reduced by 25% and if still unsold after another 18 days, a further markdown of 25% was applied. If the merchandise remained unsold after two months, it was given to charity. Filene was a pioneer in employee relations. He instituted a profit sharing program, a minimum wage for women, a 40-hour work week, health clinics and paid vacations. He also played an important role in encouraging the Filene Cooperative Association, \"perhaps the earliest American company union\". Through this channel he engaged constructively with his employees in collective bargaining and arbitration processes.\n\nIn the post-war period, an American architect, Victor Gruen developed a concept for a shopping mall; a planned, self-contained shopping complex complete with an indoor plaza, statues, planting schemes, piped music, and car-parking. Gruen's vision was to create a shopping atmosphere where people felt so comfortable, they would spend more time in the environment, thereby enhancing opportunities for purchasing. The first of these malls opened at Northland Mall near Detroit in 1954. He went on to design some 50 such malls. Due to the success of the mall concept, Gruen was described as \"the most influential architect of the twentieth century by a journalist in the New Yorker.\"\n\nThroughout the twentieth century, a trend towards larger store footprints became discernible. The average size of a U.S. supermarket grew from square feet in 1991 to square feet in 2000. In 1963, Carrefour opened the first hypermarket in St Genevieve-de-Bois, near Paris, France. By the end of the twentieth century, stores were using labels such as \"mega-stores\" and \"warehouse\" stores to reflect their growing size. In Australia, for example, the popular hardware chain, Bunnings has shifted from smaller \"home centres\" (retail floor space under ) to \"warehouse\" stores (retail floor space between and ) in order to accommodate a wider range of goods and in response to population growth and changing consumer preferences. The upward trend of increasing retail space was not consistent across nations and led in the early 21st century to a 2-fold difference in square footage per capita between the United States and Europe.\n\nAs the 21st century takes shape, some indications suggest that large retail stores have come under increasing pressure from online sales models and that reductions in store size are evident. Under such competition and other issues such as business debt, there has been a noted business disruption called the retail apocalypse in recent years which several retail businesses, especially in North America, are sharply reducing their number of stores, or going out of business entirely.\n\nThe distinction between \"strategic\" and \"managerial\" decision-making is commonly used to distinguish \"two phases having different goals and based on different conceptual tools. Strategic planning concerns the choice of policies aiming at improving the competitive position of the firm, taking account of challenges and opportunities proposed by the competitive environment. On the other hand, managerial decision-making is focused on the implementation of specific targets.\"\n\nIn retailing, the strategic plan is designed to set out the vision and provide guidance for retail decision-makers and provide an outline of how the product and service mix will optimize customer satisfaction. As part of the strategic planning process, it is customary for strategic planners to carry out a detailed environmental scan which seeks to identify trends and opportunities in the competitive environment, market environment, economic environment and statutory-political environment. The retail strategy is normally devised or reviewed every 3– 5 years by the chief executive officer.\n\nThe strategic retail analysis typically includes following elements:\n\nAt the conclusion of the retail analysis, retail marketers should have a clear idea of which groups of customers are to be the target of marketing activities. Not all elements are, however, equal, often with demographics, shopping motivations, and spending directing consumer activities. Retail research studies suggest that there is a strong relationship between a store's positioning and the socio-economic status of customers. In addition, the retail strategy, including service quality, has a significant and positive association with customer loyalty. A marketing strategy effectively outlines all key aspects of firms' targeted audience, demographics, preferences. In a highly competitive market, the retail strategy sets up long-term sustainability. It focuses on customer relationships, stressing the importance of added value, customer satisfaction and highlights how the store's market positioning appeals to targeted groups of customers.\n\nSee also product management; promotion mix; marketing mix; price; servicescapes and retail design\n\nOnce the strategic plan is in place, retail managers turn to the more managerial aspects of planning. A retail mix is devised for the purpose of coordinating day-to-day tactical decisions. The retail marketing mix typically consists of six broad decision layers including product decisions, place decisions, promotion, price, personnel and presentation (also known as physical evidence). The retail mix is loosely based on the marketing mix, but has been expanded and modified in line with the unique needs of the retail context. A number of scholars have argued for an expanded marketing, mix with the inclusion of two new Ps, namely, \"Personnel\" and \"Presentation\" since these contribute to the customer's unique retail experience and are the principal basis for retail differentiation. Yet other scholars argue that the \"Retail Format\" (i.e. retail formula) should be included. The modified retail marketing mix that is most commonly cited in textbooks is often called the \"6 Ps of retailing\" (see diagram at right).\n\nSee Product management\n\nThe primary product-related decisions facing the retailer are the product assortment (what product lines, how many lines and which brands to carry); the type of customer service (high contact through to self-service) and the availability of support services (e.g. credit terms, delivery services, after sales care). These decisions depend on careful analysis of the market, demand, competition as well as the retailer's skills and expertise.\n\nThe term product assortment refers to the combination of both product breadth and depth. The main characteristics of a company's product assortment are:\n\nFor a retailer, finding the right balance between breadth and depth can be a key to success. An average supermarket might carry 30,000–60,000 different product lines (product length or assortment), but might carry up to 100 different types of toothpaste (product depth). Speciality retailers typically carry fewer product lines, perhaps as few as 20 lines, but will normally stock greater depth. Costco, for example, carries 5,000 different lines while Aldi carries just 1,400 lines per store.\n\nLarge assortments offer consumers many benefits, notably increased choice and the possibility that the consumer will be able to locate the ideal product. However, for the retailer, larger assortments incur costs in terms of record-keeping, managing inventory, pricing and risks associated with wastage due to spoiled, shopworn or unsold stock. Carrying more stock also exposes the retailer to higher risks in terms of slow-moving stock and lower sales per square foot of store space. On the other hand, reducing the number of product lines can generate cost savings through increased stock turnover by eliminating slow-moving lines, fewer stockouts, increased bargaining power with suppliers, reduced costs associated with wastage and carrying inventory, and higher sales per square foot which means more efficient space utilisation.\n\nWhen determining the number of product lines to carry, the retailer must consider the store type, store's physical storage capacity, the perishability of items, expected turnover rates for each line and the customer's needs and expectations.\n\nCustomer service is the \"sum of acts and elements that allow consumers to receive what they need or desire from [the] retail establishment.\" Retailers must decide whether to provide a full service outlet or minimal service outlet, such as no-service in the case of vending machines; self-service with only basic sales assistance or a full service operation as in many boutiques and speciality stores. In addition, the retailer needs to make decisions about sales support such as customer delivery and after sales customer care.\n\nRetailing services may also include the provision of credit, delivery services, advisory services, exchange/ return services, product demonstration, special orders, customer loyalty programs, limited-scale trial, advisory services and a range of other supporting services. Retail stores often seek to differentiate along customer service lines. For example, some department stores offer the services of a \"stylist\"; a fashion advisor, to assist customers selecting a fashionable wardrobe for the forthcoming season, while smaller boutiques may allow regular customers to take goods home \"on approval\", enabling the customer to try out goods before making the final purchase. The variety of supporting services offered is known as the \"service type.\" At one end of the spectrum, self-service operators offer few basic support services. At the other end of the spectrum, full-service operators offer a broad range of highly personalised customer services to augment the retail experience.\n\nWhen making decisions about customer service, the retailer must balance the customer's desire for full-service against the customer's willingness to pay for the cost of delivering supporting services. Self-service is a very cost efficient way of delivering services since the retailer harnesses the customers labour power to carry out many of the retail tasks. However, many customers appreciate full service and are willing to pay a premium for the benefits of full-service.\n\nA sales assistant's role typically includes greeting customers, providing product and service-related information, providing advice about products available from current stock, answering customer questions, finalising customer transactions and if necessary, providing follow-up service necessary to ensure customer satisfaction. For retail store owners, it is extremely important to train personnel with the requisite skills necessary to deliver excellent customer service. Such skills may include product knowledge, inventory management, handling cash and credit transactions, handling product exchange and returns, dealing with difficult customers and of course, a detailed knowledge of store policies. The provision of excellent customer service creates more opportunities to build enduring customer relationships with the potential to turn customers into sources of referral or retail advocates. In the long term, excellent customer service provides businesses with an ongoing reputation and may lead to a competitive advantage. Customer service is essential for several reasons. Firstly, customer service contributes to the customer's overall retail experience. Secondly, evidence suggests that a retail organization which trains its employees in appropriate customer service benefits more than those who do not. Customer service training entails instructing personnel in the methods of servicing the customer that will benefit corporations and businesses. It is important to establish a bond amongst customers-employees known as Customer relationship management.\n\nThere are several ways the retailer can deliver services to consumers:\n\nPlace decisions are primarily concerned with consumer access and may involve location, space utilisation and operating hours.\n\nAlso see Site selection\n\nRetail stores are typically located where market opportunities are optimal – high traffic areas, central business districts. Selecting the right site can be a major success factor. When evaluating potential sites, retailers often carry out a \"trade area analysis\"; a detailed analysis designed to approximate the potential patronage area. Techniques used in trade area analysis include: Radial (ring) studies; Gravity models and Drive time analyses.\n\nIn addition, retailers may consider a range of both qualitative and quantitative factors to evaluate to potential sites under consideration:\n\nA major retail trend has been the shift to multi-channel retailing. To counter the disruption caused by online retail, many bricks and mortar retailers have entered the online retail space, by setting up online catalogue sales and e-commerce websites. However, many retailers have noticed that consumers behave differently when shopping online. For instance, in terms of choice of online platform, shoppers tend to choose the online site of their preferred retailer initially, but as they gain more experience in online shopping, they become less loyal and more likely to switch to other retail sites. Online stores are usually available 24 hours a day, and many consumers in Western countries have Internet access both at work and at home.\n\nSee also Pricing Strategies\n\nThe broad pricing strategy is normally established in the company's overall strategic plan. In the case of chain stores, the pricing strategy would be set by head office. Broadly, there are six approaches to pricing strategy mentioned in the marketing literature:\n\nWhen decision-makers have determined the broad approach to pricing (i.e., the pricing strategy), they turn their attention to pricing tactics. Tactical pricing decisions are shorter term prices, designed to accomplish specific short-term goals. The tactical approach to pricing may vary from time to time, depending on a range of internal considerations (e.g. the need to clear surplus inventory) or external factors (e.g. a response to competitive pricing tactics). Accordingly, a number of different pricing tactics may be employed in the course of a single planning period or across a single year. Typically store managers have the necessary latitude to vary prices on individual lines provided that they operate within the parameters of the overall strategic approach.\n\nRetailers must also plan for customer preferred payment modes – e.g. cash, credit, lay-by, Electronic Funds Transfer at Point-of-Sale (EFTPOS). All payment options require some type of handling and attract costs. If credit is to be offered, then credit terms will need to be determined. If lay-by is offered, then the retailer will need to take into account the storage and handling requirements. If cash is the dominant mode of payment, the retailer will need to consider small change requirements, the number of cash floats required, wages costs associated with handling large volumes of cash and the provision of secure storage for change floats. Large retailers, handling significant volumes of cash, may need to hire security service firms to carry the day's takings and deliver supplies of small change. A small, but increasing number of retailers are beginning to accept newer modes of payment including PayPal and Bitcoin. For example, Subway (US) recently announced that it would accept Bitcoin payments.\n\nContrary to common misconception, price is not the most important factor for consumers, when deciding to buy a product.\nPricing tactics that are commonly used in retail include:\n\nDiscount pricing is where the marketer or retailer offers a reduced price. Discounts in a variety of forms – e.g. quantity discounts, loyalty rebates, seasonal discounts, periodic or random discounts etc.\nEveryday low prices refers to the practice of maintaining a regular low price-low price – in which consumers are not forced to wait for discounting or specials. This method is extensively used by supermarkets.\n\nHigh-low pricing refers to the practice of offering goods at a high price for a period of time, followed by offering the same goods at a low price for a predetermined time. This practice is widely used by chain stores selling homewares. The main disadvantage of the high-low tactic is that consumers tend to become aware of the price cycles and time their purchases to coincide with a low-price cycle.\n\nA loss leader is a product that has a price set below the operating margin. Loss leadering is widely used in supermarkets and budget-priced retail outlets where it is intended to generate store traffic. The low price is widely promoted and the store is prepared to take a small loss on an individual item, with an expectation that it will recoup that loss when customers purchase other higher priced-higher margin items. In service industries, loss leadering may refer to the practice of charging a reduced price on the first order as an inducement and with anticipation of charging higher prices on subsequent orders.\n\n\nPrice bundling (also known as product bundling) occurs where two or more products or services are priced as a package with a single price. There are several types of bundles: \"pure bundles\" where the goods can only be purchased as package or \"mixed bundles\" where the goods can be purchased individually or as a package. The prices of the bundle is typically less than when the two items are purchased separately. Price bundling is extensively used in the personal care sector to prices cosmetics and skincare.\n\n\"Price lining\" is the use of a limited number of prices for all product offered by a business. Price lining is a tradition started in the old five and dime stores in which everything cost either 5 or 10 cents. In price lining, the price remains constant but quality or extent of product or service adjusted to reflect changes in cost. The underlying rationale of this tactic is that these amounts are seen as suitable price points for a whole range of products by prospective customers. It has the advantage of ease of administering, but the disadvantage of inflexibility, particularly in times of inflation or unstable prices. Price lining continues to be widely used in department stores where customers often note racks of garments or accessories priced at predetermined price points e.g. separate racks of men's ties, where each rack is priced at $10, $20 and $40.\n\nPromotional pricing is a temporary measure that involves setting prices at levels lower than normally charged for a good or service. Promotional pricing is sometimes a reaction to unforeseen circumstances, as when a downturn in demand leaves a company with excess stocks; or when competitive activity is making inroads into market share or profits.\n\nPsychological pricing is a range of tactics designed to have a positive psychological impact. Price tags using the terminal digit \"9\", ($9.99, $19.99 or $199.99) can be used to signal price points and bring an item in at just under the consumer's reservation price. Psychological pricing is widely used in a variety of retail settings.\n\nBecause patronage at a retail outlet varies, flexibility in scheduling is desirable. Employee scheduling software is sold, which, using known patterns of customer patronage, more or less reliably predicts the need for staffing for various functions at times of the year, day of the month or week, and time of day. Usually needs vary widely. Conforming staff utilization to staffing needs requires a flexible workforce which is available when needed but does not have to be paid when they are not, part-time workers; as of 2012 70% of retail workers in the United States were part-time. This may result in financial problems for the workers, who while they are required to be available at all times if their work hours are to be maximized, may not have sufficient income to meet their family and other obligations.\n\nAlso see Personal selling\nRetailers can employ different techniques to enhance sales volume and to improve the customer experience:\n\n\nIn the 1980s, the customary sales concept in the retail industry began to show many disadvantages. Many transactions cost too much, and the industry was unable to retain customers as it only paid attention to the process of a single transaction rather than to marketing for customer development and maintenance. The traditional marketing theory holds that transactions are one-time value exchange processes and the means of exchanging goods needed by both parties. Accordingly, when the transaction is completed, the relationship between the two parties will also end, so the theory is called \"transactional marketing\". Transactional marketing aims to find target consumers, then negotiate, trade, and finally end relationships to complete the transaction. In this one-time transaction process, both parties aim to maximize their own interests. As a result, transactional marketing raises follow-up problems such as poor after-sales service quality and a lack of feedback channels for both parties. In addition, because retail enterprises needed to redevelop client relationships for each transaction, marketing costs were high and customer retention was low. All these downsides to transactional marketing gradually pushed the retail industry towards establishing long-term cooperative relationships with customers. Through this lens, enterprises began to focus on the process from transaction to relationship.\nWhile expanding the sales market and attracting new customers is very important for the retail industry, it is also important to establish and maintain long term good relationships with previous customers, hence the name of the underlying concept, \"relational marketing\". Under this concept, retail enterprises value and attempt to improve relationships with customers, as customer relationships are conducive to maintaining stability in the current competitive retail market, and are also the future of retail enterprises.\n\nOne of the unique aspects of retail promotions is that two brands are often involved; the store brand and the brands that make up the retailer's product range. Retail promotions that focus on the store tend to be ‘image’ oriented, raising awareness of the store and creating a positive attitude towards the store and its services. Retail promotions that focus on the product range, are designed to cultivate a positive attitude to the brands stocked by the store, in order to indirectly encourage favourable attitudes towards the store itself. Some retail advertising and promotion is partially or wholly funded by brands and this is known as co-operative (or co-op) advertising.\n\nRetailers make extensive use of advertising via newspapers, television and radio to encourage store preference. In order to up-sell or cross-sell, retailers also use a variety of in-store sales promotional techniques such as product demonstrations, samples, point-of-purchase displays, free trial, events, promotional packaging and promotional pricing. In grocery retail, shelf wobblers, trolley advertisements, taste tests and recipe cards are also used. Many retailers also use loyalty programs to encourage repeat patronage.\n\nSee Merchandising; Servicescapes; Retail design\nPresentation refers to the physical evidence that signals the retail image. Physical evidence may include a diverse range of elements – the store itself including premises, offices, exterior facade and interior layout, websites, delivery vans, warehouses, staff uniforms.\n\nThe environment in which the retail service encounter occurs is sometimes known as the \"retail servicescape.\" The store environment consists of many elements such as smells, the physical environment (furnishings, layout and functionality), ambient conditions (lighting, temperature, noise) as well as signs, symbols and artifacts (e.g. sales promotions, shelf space, sample stations, visual communications). Collectively, these elements contribute to the \"perceived retail servicescape\" or the overall \"atmosphere\" and can influence both the customer's cognitions, emotions and their behaviour within the retail space.\n\nRelationship between market\nLarge retail enterprises of relationship marketing refers to a large retail enterprise with suppliers, customers, internal organization, channel distributors, market impact, and other competitors such as the interests of the enterprise marketing process related everything to establish and maintain good relations, thus maximizing the interests of the large retail enterprise in the long-term marketing activities, it was based on the relationship marketing concept as the core of innovation. Different from traditional marketing concepts, relationship marketing focuses on maintaining long-term good relations with relevant parties on marketing activities. The ultimate goal of relationship marketing is tantamount to maximize the long term interests of enterprises.\nThe marketing activities of large retail enterprises mainly have six relationship markets, which are supplier relationship market, customer relationship market, enterprise internal relationship market, intermediary relationship market at all levels, enterprise marketing activities influence relationship market and industry competitor relationship market. Among these six relational markets, supply relational market and customer relational market are the two markets that have the greatest influence on the relationship marketing of large retail enterprises. Substantial retail enterprises usually have two sources of profit. The principal source of profit is to reduce the purchase price from suppliers. The other is to develop new customers and keep old clients, so as to expand the market sales of goods. In addition, the extra four related markets have an indirect impact on the marketing activities of large retail enterprises.\nThe internal relationship market of an enterprise can be divided into several different types of relationships according to distinct objects, such as employee relationship market, department relationship market, shareholder relationship market and the mutual relations among the relationship markets. The purpose of carrying out relationship marketing is to promote the cohesion and innovation ability of enterprises and maximize the long term interests of enterprises. Another relationship of relationship marketing middlemen is the relationship between market and intermediary in the process of corporate marketing is playing the intermediary role between suppliers and customers, in the current increasingly fierce market competition, more important distribution channels for enterprises, but for retail enterprises, too much sales levels will increase the cost of sales of the enterprise. Therefore, large retail enterprises should realize the simplification of sales channel level by reasonably selecting suppliers. Large-scale retail enterprises purchasing goods to suppliers with procurement scale advantage, can directly contact with the product manufacturing, with strong bargaining power, therefore, direct contact with the manufacturer is a large retail enterprise to take the main purchasing mode, it is a terminal to the starting point of zero level channel purchasing mode, therefore, the elimination of middlemen, so as to make the large retail enterprise in the marketing activity, the dealer relationship market is not so important. Then there is the enterprise influence relationship market, which is a relational marketing influence in the enterprise supply chain. It mainly guides and standardizes the advance direction of enterprises through formulating systems at the macro level. The relationship market mainly includes the relationship between the relevant government departments at all levels where the enterprise is located, the relationship with the industry association to which the enterprise belongs, and the relationship with all kinds of public organizations, etc., and the enterprise influence itself cannot directly affect the marketing activities of the enterprise. The final relational market is the industry's competitors, potential competitors, alternative competitors and so on. How to correctly deal with the relationship between competitors and the market has become a problem that large retail enterprises need to solve.\n\nRetail designers pay close attention to the front of the store, which is known as the \"decompression zone\".This is usually an open space in the entrance of the store to allow customers to adjust to their new environment. An open-plan floor design is effective in retail as it allows customers to see everything. In terms of the store's exterior, the side of the road cars normally travel, determines the way stores direct customers. New Zealand retail stores, for instance, would direct customers to the left.\n\nIn order to maximise the number of selling opportunities, retailers generally want customers to spend more time in a retail store. However, this must be balanced against customer expectations surrounding convenience, access and realistic waiting times. The overall aim of designing a retail environment is to have customers enter the store, and explore the totality of the physical environment engaging in a variety of retail experiences – from browsing through to sampling and ultimately to purchasing. The retail service environment plays an important role in affecting the customer's perceptions of the retail experience.\n\nThe retail environment not only affects quality perceptions, but can also impact on the way that customers navigate their way through the retail space during the retail service encounter. Layout, directional signage, the placement of furniture, shelves and display space along with the store's ambient conditions all affect patron's passage through the retail service system. Layout refers to how equipment, shelves and other furnishings are placed and the relationship between them. In a retail setting, accessibility is an important aspect of layout. For example, the grid layout used by supermarkets with long aisles and gondolas at the end displaying premium merchandise or promotional items, minimises the time customers spend in the environment and makes productive use of available space. The gondola, so favoured by supermarkets, is an example of a retail design feature known as a \"merchandise outpost\" and which refers to special displays, typically at or near the end of an aisle, whose purpose is to stimulate impulse purchasing or to complement other products in the vicinity. For example, the meat cabinet at the supermarket might use a merchandise outpost to suggest a range of marinades or spice rubs to complement particular cuts of meat. As a generalisation, merchandise outposts are updated regularly so that they maintain a sense of novelty.\n\nAccording to Ziethaml et al., layout affects how easy or difficult it is to navigate through a system. Signs and symbols provide cues for directional navigation and also inform about appropriate behaviour within a store. Functionality refers to extent to which the equipment and layout meet the goals of the customer. For instance, in the case of supermarkets, the customer's goal may be to minimise the amount of time spent finding items and waiting at the check-out, while a customer in a retail mall may wish to spend more time exploring the range of stores and merchandise. With respect to functionality of layout, retail designers consider three key issues; circulation – design for traffic-flow and that encourages customers to traverse the entire store; coordination – design that combines goods and spaces in order to suggest customer needs and convenience – design that arranges items to create a degree of comfort and access for both customers and employees.\n\nThe way that brands are displayed is also part of the overall retail design. Where a product is placed on the shelves has implications for purchase likelihood as a result of visibility and access. Products placed too high or too low on the shelves may not turn over as quickly as those placed at eye level. With respect to access, store designers are increasingly giving consideration to access for disabled and elderly customers.\n\nThrough sensory stimulation retailers can engage maximum emotional impact between a brand and its consumers by relating to both profiles; the goal and experience. Purchasing behaviour can be influenced through the physical evidence detected by the senses of touch, smell, sight, taste and sound. Supermarkets offer taste testers to heighten the sensory experience of brands. Coffee shops allow the aroma of coffee to waft into streets so that passers-by can appreciate the smell and perhaps be lured inside. Clothing garments are placed at arms' reach, allowing customers to feel the different textures of clothing. Retailers understand that when customers interact with products or handle the merchandise, they are more likely to make a purchase.\n\nWithin the retail environment, different spaces may be designed for different purposes. Hard floors, such as wooden floors, used in public areas, contrast with carpeted fitting rooms, which are designed to create a sense of homeliness when trying on garments. Peter Alexander, retailer of sleep ware, is renowned for using scented candles in retail stores.\n\nAmbient conditions, such as lighting, temperature and music, are also part of the overall retail environment. It is common for a retail store to play music that relates to their target market. Studies have found that \"positively valenced music will stimulate more thoughts and feeling than negatively valenced music\", hence, positively valenced music will make the waiting time feel longer to the customer than negatively valenced music. In a retail store, for example, changing the background music to a quicker tempo may influence the consumer to move through the space at a quicker pace, thereby improving traffic flow. Evidence also suggests that playing music reduces the negative effects of waiting since it serves as a distraction. Jewellery stores like Michael Hill have dim lighting with a view to fostering a sense of intimacy.\n\nThe design of a retail store is critical when appealing to the intended market, as this is where first impressions are made. The overall servicescape can influence a consumer's perception of the quality of the store, communicating value in visual and symbolic ways. Certain techniques are used to create a consumer brand experience, which in the long run drives store loyalty.\n\nTwo different strands of research have investigated shopper behaviour. One strand is primarily concerned with shopper motivations. Another stream of research seeks to segment shoppers according to common, shared characteristics. To some extent, these streams of research are inter-related, but each stream offers different types of insights into shopper behaviour.\n\nBabin et al. carried out some of the earliest investigations into shopper motivations and identified two broad motives: \"utilitarian\" and \"hedonic.\" Utilitarian motivations are task-related and rational. For the shopper with utilitarian motives, purchasing is a work-related task that is to be accomplished in the most efficient and expedient manner. On the other hand, hedonic motives refer to pleasure. The shopper with hedonic motivations views shopping as a form of escapism where they are free to indulge fantasy and freedom. Hedonic shoppers are more involved in the shopping experience.\n\nMany different shopper profiles can be identified. Retailers develop customised segmentation analyses for each unique outlet. However, it is possible to identify a number of broad shopper profiles. One of the most well-known and widely cited shopper typologies is that developed by Sproles and Kendal in the mid-1980s. Sproles and Kendall's consumer typology has been shown to be relatively consistent across time and across cultures. Their typology is based on the consumer's approach to making purchase decisions.\n\nSome researchers have adapted Sproles and Kendall's methodology for use in specific countries or cultural groups. Consumer decision styles are important for retailers and marketers because they describe behaviours that are relatively stable over time and for this reason, they are useful for market segmentation.\n\nThe \"retail format\" (also known as the \"retail formula\") influences the consumer's store choice and addresses the consumer's expectations. At its most basic level, a retail format is a simple marketplace, that is; a location where goods and services are exchanged. In some parts of the world, the retail sector is still dominated by small family-run stores, but large retail chains are increasingly dominating the sector, because they can exert considerable buying power and pass on the savings in the form of lower prices. Many of these large retail chains also produce their own private labels which compete alongside manufacturer brands. Considerable consolidation of retail stores has changed the retail landscape, transferring power away from wholesalers and into the hands of the large retail chains.\n\nIn Britain and Europe, the retail sale of goods is designated as a \"service activity.\" The European Service Directive applies to all retail trade including periodic markets, street traders and peddlers.\n\nRetail stores may be classified by the type of product carried:\n\nRetailers carrying highly perishable foodstuffs such as meat, dairy and fresh produce typically require cold storage facilities. Consumers purchase food products on a very regular purchase cycle – e.g. daily, weekly or monthly.\nSoftline retailers sell goods that are consumed after a single-use, or have a limited life (typically under three years) in they are normally consumed. Soft goods include clothing, other fabrics, footwear, toiletries, cosmetics, medicines and stationery.\nGrocery stores, including supermarkets and hypermarkets, along with convenience stores carry a mix of food products and consumable household items such as detergents, cleansers, personal hygiene products. Consumer consumables are collectively known as fast-moving-consumer goods (FMCG) and represent the lines most often carried by supermarkets, grocers and convenience stores. For consumers, these are regular purchases and for the retailer, these products represent high turnover product lines. Grocery stores and convenience stores carry similar lines, but a convenience store (staffed or automated) is often open at times that suit its clientele and may be located for ease of access.\nRetailers selling consumer durables are sometimes known as \"hardline retailers\" – automobiles, appliances, electronics, furniture, sporting goods, lumber, etc., and parts for them. Goods that do not quickly wear out and provide utility over time. For the consumer, these items often represent major purchase decisions. Consumers purchase durables over longer purchase decision cycles. For instance, the typical consumer might replace their family car every 5 years, and their home computer every 4 years.\nSpecialist retailers operate in many industries such as the arts e.g. green grocers, contemporary art galleries, bookstores, handicrafts, musical instruments, gift shops.\n\nTypes of retail outlet by product type\nTypes of retail outlets (retail shops, retail stores) by marketing strategy include:\nA shopping arcade refers to a group of retail outlets operating under a covered walkway. Arcades are similar to shopping malls, although they typically comprise a smaller number of outlets. Shopping arcades were the evolutionary precursor to the shopping mall, and were very fashionable in the late 19th century. Stylish men and women would promenade around the arcade, stopping to window shop, making purchases and also taking light refreshments in one of the arcade's tea-rooms. Arcades offered fashionable men and women opportunities to 'be seen' and to socialise in a relatively safe environment. Arcades continue to exist as a distinct type of retail outlet. Historic 19th-century arcades have become popular tourist attractions in cities around the world. Amusement arcades, also known as penny arcades in the US, are more modern incarnation of the eighteenth and nineteenth century shopping arcade.\nAn anchor store (also known as draw tenant or anchor tenant) is a larger store with a good reputation used by shopping mall management to attract a certain volume of shoppers to a precinct.\nThe term, 'bazaar' can have multiple meanings. It may refer to a Middle-Eastern market place while a 'penny bazaar' refers to a retail outlet that specialises in inexpensive or discounted merchandise. In the United States a bazaar can mean a \"rummage sale\" which describes a charity fundraising event held by a church or other community organization and in which either donated used goods are made available for sale.\nA Boutique is a small store offering a select range of fashionable goods or accessories. The term, 'boutique', in retail and services, appears to be taking on a broader meaning with popular references to retail goods and retail services such as boutique hotels, boutique beers (i.e. craft beers), boutique investments etc.\n\nBy supplying a wide assortment in a single category for lower prices a category killer retailer can \"kill\" that category for other retailers. A category killer is a specialist store that dominates a given category. Toys \"R\" Us, established in 1957, is thought to be the first category killer, dominating the children's toys and games market. For a few categories, such as electronics, home hardware, office supplies and children's toys, the products are displayed at the centre of the store and a sales person will be available to address customer queries and give suggestions when required. Rival retail stores are forced to reduce their prices if a category killer enters the market in a given geographic area. Examples of category killers include Toys \"R\" Us and Australia's Bunnings (hardware, DIY and outdoor supplies) and Officeworks (stationery and supplies for the home office and small office). Some category killers redefine the category. For example, Australia's Bunnings began as a hardware outlet, but now supplies a broad range of goods for the home handyman or small tradesman, including kitchen cabinetry, craft supplies, gardening needs and outdoor furniture. Similarly Officeworks straddles the boundary between stationery supplies, office furniture and digital communications devices in its quest to provide for all the needs of the retail consumer and the small, home office.\nChain store is one of a series of stores owned by the same company and selling the same or similar merchandise. Chain stores aim to benefit from volume buying discounts (economies of scale) and achieve cost savings through economies of scope (e.g. centralised warehousing, marketing, promotion and administration) and pass on the cost savings in the form of lower prices.\n\nConcept stores are similar to speciality stores in that they are very small in size, and only stock a limited range of brands or a single brand. They are typically operated by the brand that controls them. Example: L'OCCITANE en Provence. The limited size and offering of L'OCCITANE's stores is too small to be considered a speciality store. However, a concept store goes beyond merely selling products, and instead offers an immersive customer experience built around the way that a brand fits with the customer's lifestyle. Examples include Apple's concept stores, Kit Kat's concept store in Japan.\nA co-operative store; also known as a co-op or coop, is a venture owned and operated by consumers to meet their social, economic and cultural needs.\nA convenience store provides limited amount of merchandise at above average prices with a speedy checkout. This store is ideal for emergency and immediate purchase consumables as it often operates with extended hours, stocking every day.\nDepartment stores are very large stores offering an extensive assortment of both \"soft\" and \"hard\" goods which often bear a resemblance to a collection of specialty stores. A retailer of such store carries a variety of categories and has a broad assortment of goods at moderate prices. They offer considerable customer service.\nA destination store is one that customers will initiate a trip specifically to visit, sometimes over a large area. These stores are often used to \"anchor\" a shopping mall or plaza, generating foot traffic, which is capitalized upon by smaller retailers.\nRetailers that aim at one particular segment (e.g. high-end/ luxury retailers focusing on wealthy individuals or niche market).\nDiscount stores tend to offer a wide array of products and services, but they compete mainly on price. They offer extensive assortments of merchandise at prices lower than other retailers and are designed to be affordable for the market served. In the past, retailers sold less fashion-oriented brands. However, in more recent years companies such as TJX Companies (Own T.J. Maxx and Marshalls) and Ross Stores are discount store operations increasingly offering fashion-oriented brands on a larger scale.\nThe customer can shop and order through the internet and the merchandise is dropped at the customer's doorstep or an e-tailer. In some cases, e-retailers use drop shipping technique. They accept the payment for the product but the customer receives the product directly from the manufacturer or a wholesaler. This format is ideal for customers who do not want to travel to retail stores and are interested in home shopping.\n\nA general merchandise retailer stocks a variety of products in considerable depth. The types of product offerings vary across this category. Department stores, convenience stores, hypermarkets and warehouse clubs are all examples of general merchandise retailers.\nA general store is a store that supplies the main needs of the local community and is often located in outback or rural areas with low population densities. In areas of very low population density, a general store may be the only retail outlet within hundreds of miles. The general store carries a very broad product assortment; from foodstuffs and pharmaceuticals through to hardware and fuel. In addition, a general store may provide essential services such as postal services, banking services, news agency services and may also act as an agent for farm equipment and stock-food suppliers.\nAs the name implies, a give-away shop provides goods for free. There are several different models of give-away shop in popular use. One is where goods are free to any shopper; an alternative is that shoppers must provide a product before they can take a product and a third variation is where consumers have the option of taking goods for free or paying any amount that they can afford. For example, Australia's restaurant group Lentil as Anything operates on a pay whatever you feel is right model.\nHawkers also known as a peddlers, costermongers or street vendors; refer to a vendor of merchandise that is readily portable. Hawkers typically operate in public places such as streets, squares, public parks or gardens or near the entrances of high traffic venues such as zoos, music and entertainment venues, but may also call on homes for door-to-door seling. Hawkers are a relatively common sight across Asia.\nA high street store is a term used widely in the United Kingdom where more than 5,000 High Streets where a variety of stores congregate along a main road. Stores situated in the High Street provide for the needs of a local community, and often give a locality a unique identity.\nA hypermarket (also known as hypermart) provides variety and huge volumes of exclusive merchandise at low margins. The operating cost is comparatively less than other retail formats; may be defined as \"a combined supermarket and discount store, at least or larger, that sells a wide variety of food and general merchandise at a low price.\"\nA mall has a range of retail shops at a single building or outlet, arranged on a single level or multiple levels. A shopping mall typically includes one or more \"anchor\" stores. The retail mix in a mall may include outlets such as food and entertainment, grocery, electronics, furniture, gifts and fashion. Malls provide 7% of retail revenue in India, 10% in Vietnam, 25% in China, 28% in Indonesia, 39% in the Philippines, and 45% in Thailand. Malls are typically managed by a central management/ marketing authority which ensures that the mall attracts the right type of retailer and an appropriate retail mix.\nA small retail outlet owned and operated by an individual or family. Focuses on a relatively limited and selective set of products.\n\nA Pop-up retail store is a temporary retail space that opens for a short period of time, possibly opening to sell a specific run of merchandise or for a special occasion or holiday period. The key to the success of a pop-up is novelty in the merchandise.\nA Marketplace is defined as venue for the retail sales of all products, packed and unpacked where the sale is to end users. In practice, retail markets are most often associated with the sale of fresh produce, including fruit, vegetables, meat, fish and poultry, but may also sell small consumable household goods such as cleaning agents. Globally, different terms may be used to refer to a retail market. For instance, in the Middle East, a market place may be known as a bazaar or souq/souk\nA market square is a city square where traders set up temporary stalls and buyers browse for purchases. In England, such markets operate on specific days of the week. This kind of market is very ancient, and countless such markets are still in operation around the world.\nA speciality (AE: specialty) store has a narrow marketing focus  – either specializing on specific merchandise, such as toys, footwear, or clothing, or on a target audience, such as children, tourists, or plus-size women. Size of store varies  – some speciality stores might be retail giants such as Toys \"R\" Us, Foot Locker, and The Body Shop, while others might be small, individual shops such as Nutters of Savile Row. Such stores, regardless of size, tend to have a greater depth of the specialist stock than general stores, and generally offer specialist product knowledge valued by the consumer. Pricing is usually not the priority when consumers are deciding upon a speciality store; factors such as branding image, selection choice, and purchasing assistance are seen as important. They differ from department stores and supermarkets which carry a wide range of merchandise.\nA supermarket is a self-service store consisting mainly of grocery and limited products on non-food items. They may adopt a Hi-Lo or an EDLP strategy for pricing. The supermarkets can be anywhere between and . Example: SPAR supermarket.\nVariety stores offer extremely low-cost goods, with a vast array of selection. The downfall to this is that the items are not very high quality.\n\nA vending machine is an automated piece of equipment wherein customers can drop the money in the machine which dispenses the customer's selection. The vending machine is a pure self-service option. Machines may carry a phone number which customers can call in the event of a fault.\n\nSome stores take a no frills approach, while others are \"mid-range\" or \"high end\", depending on what income level they target.\nWarehouse clubs are membership-based retailers that usually sell a wide variety of merchandise, in which customers may buy large, wholesale quantities of the store's products, which makes these clubs attractive to both bargain hunters and small business owners. The clubs are able to keep prices low due to the no-frills format of the stores. In addition, customers may be required to pay annual membership fees in order to shop.\nWarehouse stores are retailers housed in warehouses, and offer low-cost, often high-quantity goods with minimal services, e.g. goods are piled on pallets or steel shelves. shopping aisles are narrow and cramped, added-value services such as home delivery are non-existent.\n\nOther types of retail store include:\n\nRetailers can opt for a format as each provides different retail mix to its customers based on their customer demographics, lifestyle and purchase behaviour. An effective format will dtermine how products are display products, as well as how target customers are attracted.\n\nTo achieve and maintain a foothold in an existing market, a prospective retail establishment must overcome the following hurdles:\n\nChina is currently the largest retail market in the world.\n\nRetail stores may or may not have competitors close enough to affect their pricing, product availability, and other operations. A 2006 survey found that only 38% of retail stores in India believed they faced more than slight competition. Competition also affected less than half of retail stores in Kazakhstan, Bulgaria, and Azerbaijan. In all countries the main competition was domestic, not foreign.\nRetail trade provides 9% of all jobs in India and 14% of GDP.\n\nBetween 1985 and 2018 there have been 46,755 mergers or acquisitions conducted globally in the retail sector (either acquirer or target from the retail industry). These deals cumulate to an overall known value of around US$2,561 billion. The three major Retail M&A waves took place in 2000, 2007 and lately in 2017. However the all-time high in terms of number of deals was in 2016 with more than 2,700 deals. In terms of added value 2007 set the record with US$225 billion.\n\nHere is a list of the top ten largest deals (ranked by volume) in the Retail Industry:\n\nSTORES Magazine annually ranks the nation's top retailers according to sales.\n\nTop 100 Chart\nSince 1951, the U.S. Census Bureau has published the Retail Sales report every month. It is a measure of consumer spending, an important indicator of the US GDP. Retail firms provide data on the dollar value of their retail sales and inventories. A sample of 12,000 firms is included in the final survey and 5,000 in the advanced one. The advanced estimated data is based on a subsample from the US CB complete retail & food services sample.\n\nIn 2011, the grocery market in six countries of Central Europe was worth nearly €107bn, 2.8% more than the previous year when expressed in local currencies. The increase was generated foremost by the discount stores and supermarket segments, and was driven by the skyrocketing prices of foodstuffs. This information is based on the latest PMR report entitled Grocery retail in Central Europe 2012<ref name=\"http://www.pmrpublications.com/product/Grocery-retail-Central-Europe-2012\"> Grocery retail in Central Europe 2012 Retail in Central Europe</ref>\n\nNational accounts show a combined total of retail and wholesale trade, with hotels and restaurants. in 2012 the sector provides over a fifth of GDP in tourist-oriented island economies, as well as in other major countries such as Brazil, Pakistan, Russia, and Spain. In all four of the latter countries, this fraction is an increase over 1970, but there are other countries where the sector has declined since 1970, sometimes in absolute terms, where other sectors have replaced its role in the economy. In the United States the sector has declined from 19% of GDP to 14%, though it has risen in absolute terms from $4,500 to $7,400 per capita per year. In China the sector has grown from 7.3% to 11.5%, and in India even more, from 8.4% to 18.7%. Emarketer predicts China will have the largest retail market in the world in 2016.\n\nIn 2016, China became the largest retail market in the world.\n\nAmong retailers and retails chains a lot of consolidation has appeared over the last couple of decades. Between 1988 and 2010, worldwide 40,788 mergers & acquisitions with a total known value of US$2.255 trillion have been announced. The largest transactions with involvement of retailers in/from the United States have been: the acquisition of Albertson's Inc. for 17 bil. USD in 2006, the merger between Federated Department Stores Inc with May Department Stores valued at 16.5 bil. USD in 2005 – now Macy's, and the merger between Kmart Holding Corp and Sears Roebuck & Co with a value of 10.9 bil. USD in 2004.\n\nTypes of sales person:\nTypes of store or shop:\nInfluential thinkers in sales and retail:\n\n\n"}
{"id": "235723", "url": "https://en.wikipedia.org/wiki?curid=235723", "title": "Shopping mall", "text": "Shopping mall\n\nA shopping mall is a modern, chiefly North American, term for a form of shopping precinct or shopping center in which one or more buildings form a complex of shops with interconnecting walkways, usually indoors. In 2017, shopping malls accounted for 8% of retailing space in the United States.\n\nA shopping arcade is a type of shopping precinct that developed earlier and in which the connecting walkways are not owned by a single proprietor and may be in the open air or covered by a ground-floor loggia. Many early shopping arcades such as the Burlington Arcade in London, the Galleria Vittorio Emanuele II in Milan, and numerous arcades in Paris are famous and still trading. However, many smaller arcades have been demolished, replaced with large centers or malls, often accessible primarily by vehicle.\n\nTechnical innovations such as electric lighting and escalators were introduced from the late 19th century. From the late 20th century, entertainment venues such as movie theaters and restaurants began to be added. As a single built structure, early shopping centers were often architecturally significant constructions, enabling wealthier patrons to buy goods in spaces protected from the weather.\n\nIn places around the world, the term \"shopping centre\" is used, especially in Europe, Australia, and South America. \"Mall\" is a term used predominantly in North America. Outside of North America, \"shopping precinct\" and \"shopping arcade\" are also used. In Canada, \"shopping centre\" is often used officially (as in Square One Shopping Centre), but conversationally, \"mall\" is mostly used. In North America, Persian Gulf countries, and India, the term \"shopping mall\" is usually applied to enclosed retail structures (and is generally abbreviated to simply \"mall\"), while \"shopping centre\" usually refers to open-air retail complexes; both types of facilities usually have large parking lots, face major traffic arterials, and have few pedestrian connections to surrounding neighbourhoods.\n\nIn the United Kingdom and Ireland, \"malls\" are commonly referred to as \"shopping centres\". \"Mall\" primarily refers to either a shopping mall – a place where a collection of shops all adjoin a pedestrian area – or an exclusively pedestrianized street that allows shoppers to walk without interference from vehicle traffic. In North America, \"mall\" is generally used to refer to a large shopping area usually composed of a single building which contains multiple shops, usually \"anchored\" by one or more department stores surrounded by a parking lot, while the term \"arcade\" is more often used, especially in the United Kingdom, to refer to a narrow pedestrian-only street, often covered or between closely spaced buildings (see town centre).\n\nThe majority of British shopping centres are located in city centres, usually found in old and historic shopping districts and surrounded by subsidiary open air shopping streets. Large examples include West Quay in Southampton; Manchester Arndale; Bullring Birmingham; Liverpool One; Trinity Leeds; Buchanan Galleries in Glasgow; and Eldon Square in Newcastle upon Tyne. In addition to the inner city shopping centres, large UK conurbations will also have large out-of-town \"regional malls\" such as the Metrocentre in Gateshead; Meadowhall Centre, Sheffield serving South Yorkshire; the Trafford Centre in Greater Manchester; White Rose Centre in Leeds; the Merry Hill Centre near Dudley; and Bluewater in Kent. These centres were built in the 1980s and 1990s, but planning regulations prohibit the construction of any more. Out-of-town shopping developments in the UK are now focused on retail parks, which consist of groups of warehouse style shops with individual entrances from outdoors. Planning policy prioritizes the development of existing town centres, although with patchy success. Westfield Stratford City, in Stratford (London), is the largest shopping centre in Europe with over 330 shops, 50 restaurants and an 11 screen cinema and Westfield London is the largest inner-city shopping center in Europe. Bullring, Birmingham is the busiest shopping centre in the UK welcoming over 36.5 million shoppers in its opening year. There are a reported 222 malls in Europe. In 2014, these malls had combined sales of $12.47 billion. This represented a 10% bump in revenues from the prior year.\n\nOne of the earliest examples of public shopping areas comes from ancient Rome, in forums where shopping markets were located. One of the earliest public shopping centers is Trajan's Market in Rome located in Trajan's Forum. Trajan's Market was probably built around 100–110 AD by Apollodorus of Damascus, and it is thought to be the world's oldest shopping center – a forerunner of today's shopping mall. The Grand Bazaar of Istanbul was built in the 15th century and is still one of the largest covered shopping centers in the world, with more than 58 streets and 4,000 shops. Numerous other covered shopping arcades, such as the 19th-century Al-Hamidiyah Souq in Damascus, Syria, might also be considered as precursors to the present-day shopping mall. Isfahan's Grand Bazaar, which is largely covered, dates from the 10th century. The 10-kilometer-long, covered Tehran's Grand Bazaar also has a lengthy history. The oldest continuously occupied shopping mall in the world is likely to be the Chester Rows. Dating back at least to the 13th century, these covered walkways housed shops, with storage and accommodation for traders on various levels. Different rows specialized in different goods, such as 'Bakers Row' or 'Fleshmongers Row'.\n\nGostiny Dvor in St. Petersburg, which opened in 1785, may be regarded as one of the first purposely-built mall-type shopping complexes, as it consisted of more than 100 shops covering an area of over .\n\nThe Marché des Enfants Rouges in Paris opened in 1628 and still runs today. The Oxford Covered Market in Oxford, England opened in 1774 and still runs today.\n\nThe Passage du Caire was opened in Paris in 1798. The Burlington Arcade in London was opened in 1819.\nThe Arcade in Providence, Rhode Island introduced the retail arcade concept to the United States in 1828 and is arguably the oldest \"shopping mall\" in the country. The Galleria Vittorio Emanuele II in Milan, Italy followed in the 1870s and is closer to large modern malls in spaciousness. Other large cities created arcades and shopping centers in the late 19th century and early 20th century, including the Cleveland Arcade, and Moscow's GUM, which opened in 1890. When the Cleveland Arcade opened in 1890, it was among the first indoor shopping arcades in the US, and like its European counterparts, was an architectural triumph. Two sides of the arcade had 1,600 panes of glass set in iron framing and is a prime example of Victorian architecture. Sydney's Queen Victoria Markets Building, opened in 1898, was also an ambitious architectural project.\n\nIn the mid-20th century, with the rise of the suburb and automobile culture in the United States, a new style of shopping center was created away from downtown. Early shopping centers designed for the automobile include Market Square, Lake Forest, Illinois (1916), and Country Club Plaza, Kansas City, Missouri (1924). From early on, the design tended to be inward-facing, with malls following theories of how customers could best be enticed in a controlled environment. Similar, the concept of a mall having one or more \"anchor stores\" or \"big box stores\" was pioneered early, with individual stores or smaller-scale chain stores intended to benefit from the shoppers attracted by the big stores. Mall construction in America was encouraged by the accelerated depreciation laws of 1954, which incentivized greenfield development on the urban fringe. A second stimulus came from legislation passed in 1960, which allowed investors to band together in REITs (Real Estate Investment Trusts) to avoid corporate income taxes. The laws helped to shape the familiar exurban landscape of malls, motels, and fast food chains.\n\nIn the 1970s in Canada, the Ontario government created the Ontario Downtown Renewal Programme, which helped finance the building of several downtown malls across Ontario such as Eaton Centre. The program was created to reverse the tide of small business leaving downtowns for larger sites surrounding the city. In the first quarter of 2012 shopping mall private investment hit an all-time low under 0.1 percent.\n\nDayton Arcade in the United States, was built between 1902 and 1904 and Lake View Store at Morgan Park, Duluth, Minnesota, built in 1915, held its grand opening on July 20, 1916. The architect was Dean and Dean from Chicago and the building contractor was George H. Lounsberry from Duluth. The early shopping center in the United States took shape at the Grandview Avenue Shopping Center (the \"Bank Block\") in Grandview Heights, Ohio in 1928, the first regional shopping center in America that integrated parking into the design. This general plan by Don Monroe Casto Sr. became the prototype of shopping centers for several decades. Other important shopping centers built in the 1920s and early 1930s include Country Club Plaza in Kansas City, Missouri, the Highland Park Village in Dallas, Texas; River Oaks in Houston, Texas; and the Park and Shop in Washington, D.C..\n\nThe suburban shopping center concept evolved further in the United States after World War II. Bellevue Shopping Square (now known as Bellevue Square) opened in 1946 in Bellevue, Washington, a suburb of Seattle. Town & Country Village also opened in 1946 in Sacramento, California. Then came the Broadway-Crenshaw Center (known today as the Baldwin Hills Crenshaw Plaza), which was dedicated, in the Crenshaw district of Los Angeles on November 10, 1947 as the first major shopping mall on the West Coast. Three more suburban shopping centers were completed in 1949. Town and Country Drive-In Shopping Center (Town and Country Shopping Center), in Whitehall, Ohio was a strip-type complex erected in the environs of Columbus, Ohio. Park Forest, Illinois' Park Forest Plaza (Park Forest Downtown) was built along the lines of a cluster-type complex. It was situated in the southern suburbs of Chicago, Illinois. Cameron Village contained a shopping center as part of a planned community in what was then the outskirts of Raleigh, NC.\n\nIn April 1950, the suburban shopping mall came into being with the opening of Seattle's Northgate Center (now known as Northgate Mall). This was followed by Lakewood Center (1951), in Lakewood, California; Shoppers' World (1951), in Framingham, Massachusetts; Stonestown Center (now Stonestown Galleria) (1952) in San Francisco, California; and Northland Center (1954), in Southfield, Michigan. Open-air-type malls were also built in Canada and Australia. Don Mills Convenience Centre (now Shops at Don Mills) opened in 1955, in Toronto, Ontario. Chermside Drive-In Shopping Centre started trading to the public in 1957, in Brisbane, Australia.\n\nThe fully enclosed shopping mall did not appear until the mid-1950s. One of the earliest examples was the Valley Fair Shopping Center in Appleton, Wisconsin, which opened in March 1955. Valley Fair featured a number of modern features including a large parking area, anchor stores, and restaurants. The idea of a regionally-sized, fully enclosed shopping complex was pioneered in 1956 by the Austrian-born architect and American immigrant Victor Gruen. This new generation of regional-size shopping centers began with the Gruen-designed Southdale Center, which opened in the Twin Cities suburb of Edina, Minnesota, United States in October 1956. For pioneering the soon-to-be enormously popular mall concept in this form, Gruen has been called the \"most influential architect of the twentieth century\" by Malcolm Gladwell.\n\nThe first retail complex to be promoted as a \"mall\" was Paramus, New Jersey's Bergen Mall. The center, which opened with an open-air format in 1957, was enclosed in 1973. Aside from Southdale Center, significant early enclosed shopping malls were Harundale Mall (1958), in Glen Burnie, Maryland, Big Town Mall (1959), in Mesquite, Texas, Chris-Town Mall (1961), in Phoenix, Arizona, and Randhurst Center (1962), in Mount Prospect, Illinois.\n\nThe world's first enclosed shopping mall was opened in Luleå, in northern Sweden in 1955 (architect: Ralph Erskine) and was named Shopping; the region now claims the highest shopping center density in Europe.\n\nThe first fully enclosed shopping mall in Canada was Wellington Square. It was designed for Eaton's by John Graham, Jr. as an enclosed mall with a department store anchor and subterranean parking which opened in downtown London, Ontario, on August 11, 1960. After several renovations, it remains open today as Citi Plaza. Other early malls moved retailing away from the dense, commercial downtowns into the largely residential suburbs. This formula (enclosed space with stores attached, away from downtown, and accessible only by automobile) became a popular way to build retail across the world. Gruen himself came to abhor this effect of his new design; he decried the creation of enormous \"land wasting seas of parking\" and the spread of suburban sprawl.\n\nIn the UK, Chrisp Street Market was the first pedestrian shopping area built with a road at the shop fronts. The first mall-type shopping precinct in Great Britain was built in the downtown area of Birmingham. Known as Bull Ring Centre (now Bull Ring, Birmingham), it was officially dedicated in May 1964. A notable example is the Halton Lea Shopping Centre (originally known as Shopping City) in Runcorn, which opened in 1972 and was conceived as the center point for the new town's development. Another early example is the Brent Cross Centre, Britain's first out-of-town shopping mall and located on the northern outskirts of London, which was opened in March 1976.\n\nIn the United States, developers such as A. Alfred Taubman of Taubman Centers extended the concept further in 1980, with terrazzo tiles at the Mall at Short Hills in New Jersey, indoor fountains, and two levels allowing a shopper to make a circuit of all the stores. Taubman believed carpeting increased friction, slowing down customers, so it was removed. Fading daylight through glass panels was supplemented by gradually increased electric lighting, making it seem like the afternoon was lasting longer, which encouraged shoppers to linger.\n\nThe size of shopping centers and malls continued to increase throughout the twentieth and into the twenty-first centuries. With approximately , the Ala Moana Center in Honolulu, Hawaii was one of the largest malls in the United States when it opened for business in August 1959. The Outlets at Bergen Town Center, the oldest enclosed mall in New Jersey, opened in Paramus on November 14, 1957, with Dave Garroway, host of \"The Today Show\", serving as master of ceremonies. The mall, located just outside New York City, was planned in 1955 by Allied Stores to have 100 stores and 8,600 parking spaces in a mall that would include a Stern's store and two other department stores as part of the design. Allied's chairman B. Earl Puckett confidently announced The Outlets at Bergen Town Center as the largest of ten proposed centers, stating that there were 25 cities that could support such centers and that no more than 50 malls of this type would ever be built nationwide.\n\nThe largest enclosed shopping mall from 1986 to 2004 was the West Edmonton Mall in Edmonton, Alberta, Canada. Currently, the largest mall in the world is the New South China Mall in Dongguan, China with a gross floor area of . The world's second-largest shopping mall is the Golden Resources Mall in Beijing, China with a gross floor area of . SM Megamall in the Philippines, is the world's third-largest at of gross floor area. The fourth largest shopping mall in the world is SM City North EDSA in Quezon City, Philippines with a gross floor area of and the fifth largest shopping mall is 1 Utama in Malaysia at of gross floor area.\n\nThe most visited shopping mall in the world and third-largest mall in the United States is the Mall of America, located near the Twin Cities in Bloomington, Minnesota. However, several Asian malls are advertised as having more visitors, including Mal Taman Anggrek, Kelapa Gading Mall and Pluit Village, all in Jakarta, Indonesia; Berjaya Times Square in Malaysia; SM City North EDSA, SM Mall of Asia and SM Megamall, all in Metro Manila, Philippines. The largest mall in South Asia is Lucky One Mall in Karachi, Pakistan.\n\nThe Philippines has the most number of shopping malls in the top 100 largest shopping malls in the world with 22.\n\nThe International Council of Shopping Centers classifies shopping malls into eight basic types: neighborhood center, community center, regional center, superregional center, fashion/specialty center, power center, theme/festival center, and outlet center. These definitions, published in 1999, were not restricted to shopping centers in any particular country, but later editions were made specific to the US with a separate set for Europe.\n\nNeighborhood centers are small-scale malls serving the local neighborhood. They typically have a supermarket or a drugstore as an anchor, and are commonly arranged in a strip mall format. Neighborhood centers usually have a retail area of , and serve a primary area in a radius. They are sometimes known as convenience centers.\n\nCommunity malls are larger than neighborhood centers, and offer a wider range of goods. They usually feature two anchor stores which are larger than that of a neighborhood center's, e.g. a discount department store. They may also follow a strip configuration, or may be L- or U-shaped. Community centers usually feature a retail area of and serve a primary area of .\n\nA regional mall is, per the International Council of Shopping Centers, in the United States, a shopping mall which is designed to service a larger area than a conventional shopping mall. As such, it is typically larger with to gross leasable area with at least two anchor stores and offers a wider selection of stores. Given their wider service area, these malls tend to have higher-end stores that need a larger area in order for their services to be profitable but may have discount department stores. Regional malls are also found as tourist attractions in vacation areas.\n\nA super regional mall is, per the International Council of Shopping Centers, in the US a shopping mall with over of gross leasable area, three or more anchors, mass merchant, more variety, fashion apparel, and serves as the dominant shopping venue for the region () in which it is located.\n\nFashion or specialty centers feature apparel shops and boutiques and cater to customers with higher incomes. They usually have a retail area ranging from and serve an area of .\n\nPower centers are small shopping centers that almost exclusively feature several big-box retailers as their anchors. They usually have a retail area of and a primary trade area of .\n\nTheme or festival centers have distinct unifying themes that are followed by their individual shops as well as their architecture. They are usually located in urban areas and cater to tourists. They typically feature a retail area of .\n\nAn outlet mall (or outlet center) is a type of shopping mall in which manufacturers sell their products directly to the public through their own stores. Other stores in outlet malls are operated by retailers selling returned goods and discontinued products, often at heavily reduced prices. Outlet stores were found as early as 1936, but the first multi-store outlet mall, Vanity Fair, located in Reading, PA, did not open until 1974. Belz Enterprises opened the first enclosed factory outlet mall in 1979, in Lakeland, TN, a suburb of Memphis.\n\nA common feature of shopping malls is a food court: this typically consists of a number of fast food vendors of various types, surrounding a shared seating area.\n\nWhen the shopping mall format was developed by Victor Gruen in the mid-1950s, signing larger department stores was necessary for the financial stability of the projects, and to draw retail traffic that would result in visits to the smaller stores in the mall as well. These larger stores are termed anchor store or draw tenant. In physical configuration, anchor stores are normally located as far from each other as possible to maximize the amount of traffic from one anchor to another.\n\nFrequently, a shopping mall or shopping center will have satellite buildings located either on the same tract of land or on one abutting it, on which will be located stand-alone stores, which may or may not be legally connected to the central facility through contract or ownership. These stores may have their own parking lots, or their lots may interconnect with those of the mall or center. The existence of the stand-alone store may have been planned by the mall's developer, or may have come about through opportunistic actions by others, but visually the central facility – the mall or shopping center – and the satellite buildings will often be perceived as being a single \"unit\", even in circumstances where the outlying buildings are not officially or legally connected to the mall in any way.\n\nIn the United States, in the mid-1990s, malls were still being constructed at a rate of 140 a year. But in 2001, a PricewaterhouseCoopers study found that underperforming and vacant malls, known as \"greyfield\" and \"dead mall\" estates, were an emerging problem. In 2007, a year before the Great Recession, no new malls were built in America, for the first time in 50 years. City Creek Center Mall in Salt Lake City, which opened in March 2012, was the first to be built since the recession.\n\nIn recent years, the number of dead malls increased significantly in the early twenty first century because the economic health of malls across the United States has been in decline, with high vacancy rates in these malls. From 2006 to 2010, the percentage of malls that are considered to be \"dying\" by real estate experts (have a vacancy rate of at least 40%), unhealthy (20–40%), or in trouble (10–20%) all increased greatly, and these high vacancy rates only partially decreased from 2010 to 2014. In 2014, nearly 3% of all malls in the United States were considered to be \"dying\" (40% or higher vacancy rates) and nearly one-fifth of all malls had vacancy rates considered \"troubling\" (10% or higher). Some real estate experts say the \"fundamental problem\" is a glut of malls in many parts of the country creating a market that is \"extremely over-retailed\".\n\nIn parts of Canada, it is now rare for new shopping malls to be built. The Vaughan Mills Shopping Centre, opened in 2004, Crossiron Mills, opened in 2009, and Tsawwassen Mills Mall in 2016, are the only malls built in Canada since 1992. Outdoor outlet malls or big box shopping areas known as power centers are now favored, although the traditional enclosed shopping mall is still in demand by those seeking weather-protected, all-under-one-roof shopping. In addition, the enclosed interconnections between downtown multi story shopping malls continue to grow in the Underground city of Montreal (32 kilometres of passageway), the PATH system of Toronto ( of passageway) and the Plus15 system of Calgary ( of overhead passageway). This trend is also evident in Australia, where city renewal and gentrification projects have focused on expanding pedestrian-only shopping districts of city centres rather than building more shopping centres.\n\nIn Russia, on the other hand, a large number of new malls had been built near major cities, notably the MEGA malls such as Mega Belaya Dacha mall near Moscow. In large part they were financed by international investors and were popular with shoppers from the emerging middle class.\n\nIn the United States, owners are making drastic moves to convert struggling malls. This includes converting malls into apartments, offices and industrial space. Other owners have taken the approach to turning large chunks of malls into parks and playgrounds. In Austin, Texas, the 600,000 square foot Highland Mall will be a campus for Austin Community College.\n\nHigh land prices in populous cities have led to the concept of the \"vertical mall,\" in which space allocated to retail is configured over a number of stories accessible by elevators and/or escalators (usually both) linking the different levels of the mall. The challenge of this type of mall is to overcome the natural tendency of shoppers to move horizontally and encourage shoppers to move upwards and downwards. The concept of a vertical mall was originally conceived in the late 1960s by the Mafco Company, former shopping center development division of Marshall Field & Co. The Water Tower Place skyscraper, Chicago, Illinois, was built in 1975 by Urban Retail Properties. It contains a hotel, luxury condominiums, and office space and sits atop a block-long base containing an eight-level atrium-style retail mall that fronts on the Magnificent Mile.\n\nVertical malls are common in densely populated conurbations such as Hong Kong, Jakarta, and Bangkok. Times Square in Hong Kong is a principal example.\n\nA vertical mall may also be built where the geography prevents building outward or there are other restrictions on construction, such as historical buildings or significant archeology. The Darwin Shopping Centre and associated malls in Shrewsbury, UK, are built on the side of a steep hill, around the former town walls; consequently the shopping center is split over seven floors vertically – two locations horizontally – connected by elevators, escalators and bridge walkways. Some establishments incorporate such designs into their layout, such as Shrewsbury's former McDonald's, split into four stories with multiple mezzanines which featured medieval castle vaults – complete with arrowslits – in the basement dining rooms.\nFaced with the exploding popularity of buying online, shopping malls are emptying and are seeking new solutions to generate traffic. In the US, for example, roughly 200 out of 1,300 malls across the country are going out of business. To combat this trend, developers are trying to turn malls into leisure centers that include attractions such as parks, movie theaters, gyms, and even fishing lakes. Others, such as the European commercial real-estate giant Unibail-Rodamco, are modernizing their approach by promoting brand interaction and enhanced architectural appeal. A recent example that integrates both approaches is the So Ouest mall outside of Paris that was designed to resemble elegant, Louis XV-style apartments and includes of green space. The Australian mall company Westfield launched an online mall (and later a mobile app) with 150 stores, 3,000 brands and over 1 million products. Online shopping has increased its share of total retail sales since 2008. In Q3 2008, it comprised 3.6% of retail purchases and this increased to 7.4% by Q3 2015.\n\nA shopping property management firm is a company that specializes in owning and managing shopping malls. Most shopping property management firms own at least 20 malls. Some firms use a similar naming scheme for most of their malls; for example, Mills Corporation puts \"Mills\" in most of its mall names and SM Prime Holdings of the Philippines puts \"SM\" in all of its malls, as well as anchor stores such as The SM Store, SM Appliance Center, SM Hypermarket, SM Cinema, and SM Supermarket. In the UK, The Mall Fund changes the name of any center it buys to \"The Mall (location)\", using its pink-M logo; when it sells a mall the center reverts to its own name and branding, such as the Ashley Centre in Epsom. Similarly, following its rebranding from Capital Shopping Centres, intu Properties renamed many of its centres to \"intu (name/location)\" (such as intu Lakeside; again, malls removed from the network revert to their own brand (see for instance The Glades in Bromley).\n\nShopping center management and advisory firms are bringing about professional management practices to the largely fragmented shopping center development industry in India. Historically, land ownership in India, has been fragmented and as a byproduct shopping center development, which rendered the single mall developers vulnerable to dubious advice and practices, since standard benchmarks, knowledge resources, and skilled people were scarce. This is changing as new firms promoted by former shopping center managers are stepping in to bridge the gap between ownership and professional management.\n\nBeyond Squarefeet from India is another mall management company, which is foraying into various other countries such as India, Iran, Nepal, Nigeria, Qatar, etc. Mall management is slowly becoming a trend and is much sought after services in Asia and other markets.\n\nOne controversial aspect of malls has been their effective displacement of traditional main streets or high streets. Some consumers prefer malls, with their parking garages, controlled environments, and private security guards, over CBDs or downtowns, which frequently have limited parking, poor maintenance, outdoor weather, and limited police coverage.\n\nIn response, a few jurisdictions, notably California, have expanded the right of freedom of speech to ensure that speakers will be able to reach consumers who prefer to shop, eat, and socialize within the boundaries of privately owned malls. See \"Pruneyard Shopping Center v. Robins\".\n\n\n"}
{"id": "51862", "url": "https://en.wikipedia.org/wiki?curid=51862", "title": "Supermarket", "text": "Supermarket\n\nA supermarket is self-service shop offering a wide variety of food, beverages and household products, organized into sections. It is larger and has a wider selection than earlier grocery stores, but is smaller and more limited in the range of merchandise than a hypermarket or big-box market.\n\nThe supermarket typically has aisles for meat, fresh produce, dairy, and baked goods. \nShelf space is also reserved for canned and packaged goods and for various non-food items such as kitchenware, household cleaners, pharmacy products and pet supplies. Some supermarkets also sell other household products that are consumed regularly, such as alcohol (where permitted), medicine, and clothes, and some sell a much wider range of non-food products: DVDs, sporting equipment, board games, and seasonal items (e.g., Christmas wrapping paper in December).\n\nA larger full-service supermarket combined with a department store is sometimes known as a hypermarket. Other services may include those of banks, cafés, childcare centres/creches, insurance (and other financial services), Mobile Phone services, photo processing, video rentals, pharmacies or petrol stations. If the eatery in a supermarket is substantial enough, the facility may be called a \"grocerant\", a blend of \"grocery\" and \"restaurant\".\n\nThe traditional supermarket occupies a large amount of floor space, usually on a single level. It is usually situated near a residential area in order to be convenient to consumers. The basic appeal is the availability of a broad selection of goods under a single roof, at relatively low prices. Other advantages include ease of parking and frequently the convenience of shopping hours that extend into the evening or even 24 hours of the day. Supermarkets usually allocate large budgets to advertising, typically through newspapers. They also present elaborate in-shop displays of products.\n\nSupermarkets typically are chain stores, supplied by the distribution centers of their parent companies thus increasing opportunities for economies of scale. Supermarkets usually offer products at relatively low prices by using their buying power to buy goods from manufacturers at lower prices than smaller stores can. They also minimise financing costs by paying for goods at least 30 days after receipt and some extract credit terms of 90 days or more from vendors. Certain products (typically staple foods such as bread, milk and sugar) are very occasionally sold as loss leaders so as to attract shoppers to their store. Supermarkets make up for their low margins by a high volume of sales, and with of higher-margin items bought by the attracted shoppers. Self-service with shopping carts (trolleys) or baskets reduces labor cost, and many supermarket chains are attempting further reduction by shifting to self-service check-out.\n\nIn the early days of retailing, products generally were fetched by an assistant from shelves behind the merchant's counter while customers waited in front of the counter and indicated the items they wanted. Most foods and merchandise did not come in individually wrapped consumer-sized packages, so an assistant had to measure out and wrap the precise amount desired by the consumer. This offered opportunities for social interaction: many regarded this style of shopping as \"a social occasion\" and would often \"pause for conversations with the staff or other customers\". These practices were by nature slow and labor-intensive and therefore also quite expensive. The number of customers who could be attended to at one time was limited by the number of staff employed in the store. Shopping for groceries also often involved trips to multiple specialty shops, such as a greengrocer, butcher, bakery, fishmonger and dry goods store; in addition to a general store. Milk and other items of short shelf life were delivered by a milkman. \n\nThe concept of an inexpensive food market relying on large economies of scale was developed by Vincent Astor. He founded the Astor Market in 1915, investing $750,000 ($18 million in 2015 currency) of his fortune into a 165' by 125' (50x38 metre) corner of 95th and Broadway, Manhattan, creating, in effect, an open-air mini-mall that sold meat, fruit, produce and flowers. The expectation was that customers would come from great distances (\"miles around\"), but in the end, even attracting people from ten blocks away was difficult, and the market folded in 1917.\n\nThe concept of a self-service grocery store was developed by entrepreneur Clarence Saunders and his Piggly Wiggly stores. His first store opened in 1916. Saunders was awarded a number of patents for the ideas he incorporated into his stores. The stores were a financial success and Saunders began to offer franchises. The Great Atlantic & Pacific Tea Company, which was established in 1859, was another successful early grocery store chain in Canada and the United States, and became common in North American cities in the 1920s. Early self-service grocery stores did not sell fresh meats or produce. Combination stores that sold perishable items were developed in the 1920s.\n\nHistorically, there has been debate about the origin of the supermarket, with King Kullen and Ralphs of California having strong claims. Other contenders included Weingarten's Big Food Markets and Henke & Pillot. To end the debate, the Food Marketing Institute in conjunction with the Smithsonian Institution and with funding from H.J. Heinz, researched the issue. They defined the attributes of a supermarket as \"self-service, separate product departments, discount pricing, marketing and volume selling\".\n\nThey determined that the first true supermarket in the United States was opened by a former Kroger employee, Michael J. Cullen, on 4 August 1930, inside a former garage in Jamaica, Queens in New York City. The store, King Kullen, operated under the slogan \"Pile it high. Sell it low.\" At the time of Cullen's death in 1936, there were seventeen King Kullen stores in operation. Although Saunders had brought the world self-service, uniform stores, and nationwide marketing, Cullen built on this idea by adding separate food departments, selling large volumes of food at discount prices and adding a parking lot.\nOther established American grocery chains in the 1930s, such as Kroger and Safeway at first resisted Cullen's idea, but eventually were forced to build their own supermarkets as the economy sank into the Great Depression, while consumers were becoming price-sensitive at a level never experienced before. Kroger took the idea one step further and pioneered the first supermarket surrounded on all four sides by a parking lot.\n\nAs larger chain supermarkets began to dominate the market in the USA, able to supply consumers with the desired lower prices as opposed to the smaller \"mom and pop\" stands with considerably more overhead costs, the backlash of this infrastructure alteration was seen through numerous anti-chain campaigns. The idea of \"monopsony\", proposed by Cambridge economist Joan Robinson in 1933, that a single buyer could out-power the market of multiple sellers, became a strong anti-chain rhetorical device. With public backlash came political pressure to even the playing field for smaller vendors without the luxuries of economies of scale. In 1936, the Robinson-Patman Act was implemented as a way of preventing such larger chains from using this buying power to reap advantages over smaller stores, although the act was not well enforced and did not have much impact on the prevention of larger chains overtaking power in the markets.\n\nSupermarkets proliferated across Canada and the United States with the growth of automobile ownership and suburban development after World War II. Most North American supermarkets are located in suburban strip shopping centers as an anchor store along. They are generally regional rather than national in their company branding. Kroger is perhaps the most nationally oriented supermarket chain in the United States but it has preserved most of its regional brands, including Ralphs, City Market, King Soopers, Fry's, Smith's, and QFC.\n\nIn Canada, the largest such company is Loblaw, which operates stores under a variety of banners targeted to different segments and regions, including Fortinos, Zehrs, No Frills, the Real Canadian Superstore, and Loblaws, the foundation of the company. Sobeys is Canada's second largest supermarket with locations across the country, operating under many banners (Sobeys IGA in Quebec). Québec's first supermarket opened in 1934 in Montréal, under the banner Steinberg's.\n\nIn the United Kingdom, self-service shopping took longer to become established. Even in 1947, there were just ten self-service shops in the country. In 1951, ex-US Navy sailor Patrick Galvani, son-in-law of Express Dairies chairman, made a pitch to the board to open a chain of supermarkets across the country. The UK's first supermarket under the new Premier Supermarkets brand opened in Streatham, South London, taking ten times as much per week as the average British general store of the time. Other chains caught on, and after Galvani lost out to Tesco's Jack Cohen in 1960 to buy the 212 Irwin's chain, the sector underwent a large amount of consolidation, resulting in 'the big four' dominant UK of today: Tesco, Asda (owned by Wal-Mart), Sainsbury's and Morrisons.\n\nIn the 1950s, supermarkets frequently issued trading stamps as incentives to customers. Today, most chains issue store-specific \"membership cards\", \"club cards\", or \"loyalty cards\". These typically enable the cardholder to receive special members-only discounts on certain items when the credit card-like device is scanned at check-out. Sales of selected data generated by club cards is becoming a significant revenue stream for some supermarkets.\n\nTraditional supermarkets in many countries face intense competition from discounters such as Wal-Mart, and Tesco in the UK, which typically is non-union and operates with better buying power. Other competition exists from warehouse clubs such as Costco that offer savings to customers buying in bulk quantities. Superstores, such as those operated by Wal-Mart and Asda, often offer a wide range of goods and services in addition to foods. In Australia, ALDI, Woolworths and Coles are the major players running the industry with fierce competition among all the three. The rising market share of ALDI has forced the other two to slash prices and increase their private label product ranges. The proliferation of such warehouse and superstores has contributed to the continuing disappearance of smaller, local grocery stores; increased dependence on the automobile; suburban sprawl because of the necessity for large floor space and increased vehicular traffic. For example, in 2009 51% of Wal-Mart's $251 billion domestic sales were recorded from grocery goods. Some critics consider the chains' common practice of selling loss leaders to be anti-competitive. They are also wary of the negotiating power that large, often multinationals have with suppliers around the world.\n\nDuring the dot-com boom, an online-only supermarket startup called Webvan was formed, but it went bankrupt after 3 years and was acquired by Amazon. The British online supermarket Ocado, which uses a high degree of automation in its warehouses, was the first successful online-only supermarket. Ocado has now expanded into providing services to multiple other supermarket firms such as Waitrose and Morrisons. \nRegular grocery stores such as Walmart have started to employ food delivery services offered by third parties (i.e. DoorDash). Sainsbury’s Streatham Common store for instance has started to deliver food by means of an e-bike food delivery service. \nAlso, robotic delivery of food is being offered by various companies partnering with supermarkets.\n\nThere has been a rapid transformation of the food sector in developing countries, beginning in the 1990s. This applies particularly to Latin America, South-East Asia, India, China and South Africa. However, growth is being witnessed in nearly all countries. With growth, has come considerable competition and some amount of consolidation. The growth has been driven by increasing affluence and the rise of a middle class; the entry of women into the workforce; with a consequent incentive to seek out easy-to-prepare foods; the growth in the use of refrigerators, making it possible to shop weekly instead of daily; and the growth in car ownership, facilitating journeys to distant stores and purchases of large quantities of goods. The opportunities presented by this potential have encouraged several European companies to invest in these markets (mainly in Asia) and American companies to invest in Latin America and China. Local companies also entered the market. Initial development of supermarkets has now been followed by hypermarket growth. In addition there were investments by companies such as Makro and Metro in large-scale Cash-and-Carry operations.\n\nWhile the growth in sales of processed foods in these countries has been much more rapid than the growth in fresh food sales, the imperative nature of supermarkets to achieve economies of scale in purchasing means that the expansion of supermarkets in these countries has important repercussions for small farmers, particularly those growing perishable crops. New supply chains have developed involving cluster formation; development of specialized wholesalers; leading farmers organizing supply, and farmer associations or cooperatives. In some cases supermarkets have organized their own procurement from small farmers; in others wholesale markets have adapted to meet supermarket needs.\n\nLarger supermarkets in North America and in Europe typically sell a great number of items among many brands, sizes and varieties, including:\n\nMost merchandise is already packaged when it arrives at the supermarket. Packages are placed on shelves, arranged in aisles and sections according to type of item. Some items, such as fresh produce, are stored in bins. Those requiring an intact cold chain are in temperature-controlled display cases.\n\nWhile branding and store advertising will differ from company to company, the layout of a supermarket remains virtually unchanged. Although big companies spend time giving consumers a pleasant shopping experience, the design of a supermarket is directly connected to the in-store marketing that supermarkets must conduct in order to get shoppers to spend more money while there.\n\nEvery aspect of the store is mapped out and attention is paid to color, wording and even surface texture. The overall layout of a supermarket is a visual merchandising project that plays a major role. Stores can creatively use a layout to alter customers’ perceptions of the atmosphere. Alternatively, they can enhance the store’s atmospherics through visual communications (signs and graphics), lighting, colors, and even scents. For example, to give a sense of the supermarket being healthy, fresh produce is deliberately located at the front of the store. In terms of bakery items, supermarkets usually dedicate 30 to 40 feet of store space to the bread aisle.\n\nSupermarkets are designed to \"give each product section a sense of individual difference and this is evident in the design of what is called the anchor departments; fresh produce, dairy, delicatessen, meat and the bakery\". Each section has different floor coverings, style, lighting and sometimes even individual services counters to allow shoppers to feel as if there are a number of markets within this one supermarket.\nMarketers use well-researched techniques to try to control purchasing behavior. The layout of a supermarket is considered by some to consist of a few rules of thumb and three layout principles. The high-draw products are placed in separate areas of the store to keep drawing the consumer through the store. High impulse and high margin products are placed in the most predominant areas to grab attention. Power products are placed on both sides of the aisle to create increased product awareness, and end caps are used to receive a high exposure of a certain product whether on special, promotion or in a campaign, or a new line.\n\nThe first principle of the layout is circulation. Circulation is created by arranging product so the supermarket can control the traffic flow of the consumer. Along with this path, there will be high-draw, high-impulse items that will influence the consumer to purchase which he or she did not intend. Service areas such as restrooms are placed in a location which draws the consumer past certain products to create extra buys. Necessity items such as bread and milk are found at the rear of the store to increase the start of circulation. Cashiers' desks are placed in a position to promote circulation. The entrance will be on the right-hand side because research has shown that consumers who travel in a counter-clockwise direction spend more.\n\nThe second principle of the layout is coordination. Coordination is the organized arrangement of product that promotes sales. Products such as fast-selling and slow-selling lines are placed in strategic positions in aid of the overall sales plan. Managers sometimes place different items in fast-selling places to increase turnover or to promote a new line.\n\nThe third principle is consumer convenience. The layout of a supermarket is designed to create a high degree of convenience to the consumer to make the shopping experience pleasant and increase customer spending. This is done through the character of merchandising and product placement. There are many different ideas and theories in relation to layout and how product layout can influence the purchases made. One theory suggests that certain products are placed together or near one another that are of a similar or complementary nature to increase the average customer spend. This strategy is used to create cross-category sales similarity. In other words, the toothpaste is next to or adjacent the toothbrushes and the tea and coffee are down the same aisle as the sweet biscuits. These products complement one another and placing them near is one-way marketers try to increase purchases. \n\nFor vertical placement, cheap generic brands tend to be on the lowest shelves, products appealing to children are placed at the mid-thigh level, and the most profitable brands are placed at eye level.\n\nThe fourth principle is the use of color psychology, and the locations of the food, similar to its use in fast food branding.\n\nConsumer psychologists suggest that most buyers tend to enter the store and shop to their right first. Some supermarkets, therefore, choose to place the entrance to the left-hand side as the consumer will likely turn right upon entry, and this allows the consumer to do a full anticlockwise circle around the store before returning to the checkouts. This suggests that supermarket marketers should use this theory to their advantage by placing their temporary displays of products on the right-hand side to entice you to make an unplanned purchase. Furthermore, aisle ends are extremely popular with product manufacturers, who pay top dollar to have their products located there. These aisle ends are used to lure customers into making a snap purchase and to also entice them to shop down the aisle. The most obvious place supermarket layout influences consumers are at the checkout. Small displays of chocolates, magazines, and drinks are located at each checkout to tempt shoppers while they wait to be served.\n\nSome supermarkets are focusing on selling more (or even exclusively) organically certified produce. Others are trying to differentiate itself through selling less (or no) products containing palm oil. This as the demand of palm oil is a main driver for the destruction of rainforests.\nAs a response to the growing concern on the heavy use of petroleum-based plastics for food packaging, so-called \"zero waste\" and \"plastic-free\" supermarkets and groceries are on the rise.\n\n\n\n"}
{"id": "28168", "url": "https://en.wikipedia.org/wiki?curid=28168", "title": "Stock exchange", "text": "Stock exchange\n\nA stock exchange, securities exchange or bourse is a facility where stockbrokers and traders can buy and sell securities, such as shares of stock and bonds and other financial instruments. Stock exchanges may also provide facilities for the issue and redemption of such securities and instruments and capital events including the payment of income and dividends. Securities traded on a stock exchange include stock issued by listed companies, unit trusts, derivatives, pooled investment products and bonds. Stock exchanges often function as \"continuous auction\" markets with buyers and sellers consummating transactions via open outcry at a central location such as the floor of the exchange or by using an electronic trading platform.\n\nTo be able to trade a security on a certain stock exchange, the security must be listed there. Usually, there is a central location at least for record keeping, but trade is increasingly less linked to a physical place, as modern markets use electronic communication networks, which give them advantages of increased speed and reduced cost of transactions. Trade on an exchange is restricted to brokers who are members of the exchange. In recent years, various other trading venues, such as electronic communication networks, alternative trading systems and \"dark pools\" have taken much of the trading activity away from traditional stock exchanges.\n\nInitial public offerings of stocks and bonds to investors is done in the primary market and subsequent trading is done in the secondary market. A stock exchange is often the most important component of a stock market. Supply and demand in stock markets are driven by various factors that, as in all free markets, affect the price of stocks (see stock valuation).\n\nThere is usually no obligation for stock to be issued through the stock exchange itself, nor must stock be subsequently traded on an exchange. Such trading may be \"off exchange\" or over-the-counter. This is the usual way that derivatives and bonds are traded. Increasingly, stock exchanges are part of a global securities market. Stock exchanges also serve an economic function in providing liquidity to shareholders in providing an efficient means of disposing of shares.\n\nThere is little consensus among scholars as to when corporate stock was first traded. Some see the key event as the Dutch East India Company's founding in 1602, while others point to earlier developments (Bruges, Antwerp in 1531 and in Lyon in 1548).The first book in history of securities exchange, the Confusion of Confusions, was written by the Dutch-Jewish trader Joseph de la Vega. One of Europe's oldest stock exchanges is the Frankfurt Stock Exchange () established in 1585 in Frankfurt am Main. Economist Ulrike Malmendier of the University of California at Berkeley argues that a share market existed as far back as ancient Rome, that derives from Etruscan \"Argentari\". In the Roman Republic, which existed for centuries before the Empire was founded, there were \"societates publicanorum\", organizations of contractors or leaseholders who performed temple-building and other services for the government. One such service was the feeding of geese on the Capitoline Hill as a reward to the birds after their honking warned of a Gallic invasion in 390 B.C. Participants in such organizations had \"partes\" or shares, a concept mentioned various times by the statesman and orator Cicero. In one speech, Cicero mentions \"shares that had a very high price at the time\". Such evidence, in Malmendier's view, suggests the instruments were tradable, with fluctuating values based on an organization's success. The \"societas\" declined into obscurity in the time of the emperors, as most of their services were taken over by direct agents of the state.\n\nTradable bonds as a commonly used type of security were a more recent innovation, spearheaded by the Italian city-states of the late medieval and early Renaissance periods.\n\nWhile the Italian city-states produced the first transferable government bonds, they did not develop the other ingredient necessary to produce a fully-fledged capital market: the stock market in its modern sense. In the early 1600s the Dutch East India Company (VOC) became the first company in history to issue bonds and shares of stock to the general public. As Edward Stringham (2015) notes, \"companies with transferable shares date back to classical Rome, but these were usually not enduring endeavors and no considerable secondary market existed (Neal, 1997, p. 61).\" The VOC, formed to build up the spice trade, operated as a colonial ruler in what is now Indonesia and beyond, a purview that included conducting military operations against the wishes of the exploited natives and of competing colonial powers. Control of the company was held tightly by its directors, with ordinary shareholders not having much influence on management or even access to the company's accounting statements.\n\nHowever, shareholders were rewarded well for their investment. The company paid an average dividend of over 16% per year from 1602 to 1650. Financial innovation in Amsterdam took many forms. In 1609, investors led by Isaac Le Maire formed history's first bear market syndicate, but their coordinated trading had only a modest impact in driving down share prices, which tended to remain robust throughout the 17th century. By the 1620s, the company was expanding its securities issuance with the first use of corporate bonds.\n\nJoseph de la Vega, also known as Joseph Penso de la Vega and by other variations of his name, was an Amsterdam trader from a Spanish Jewish family and a prolific writer as well as a successful businessman in 17th-century Amsterdam. His 1688 book \"Confusion of Confusions\" explained the workings of the city's stock market. It was the earliest book about stock trading and inner workings of a stock market, taking the form of a dialogue between a merchant, a shareholder and a philosopher, the book described a market that was sophisticated but also prone to excesses, and de la Vega offered advice to his readers on such topics as the unpredictability of market shifts and the importance of patience in investment.\nIn England, King William III sought to modernize the kingdom's finances to pay for its wars, and thus the first government bonds were issued in 1693 and the Bank of England was set up the following year. Soon thereafter, English joint-stock companies began going public. \n\nLondon's first stockbrokers, however, were barred from the old commercial center known as the Royal Exchange, reportedly because of their rude manners. Instead, the new trade was conducted from coffee houses along Exchange Alley. By 1698, a broker named John Castaing, operating out of Jonathan's Coffee House, was posting regular lists of stock and commodity prices. Those lists mark the beginning of the London Stock Exchange.\n\nOne of history's greatest financial bubbles occurred around 1720. At the center of it were the South Sea Company, set up in 1711 to conduct English trade with South America, and the Mississippi Company, focused on commerce with France's Louisiana colony and touted by transplanted Scottish financier John Law, who was acting in effect as France's central banker. Investors snapped up shares in both, and whatever else was available. In 1720, at the height of the mania, there was even an offering of \"a company for carrying out an undertaking of great advantage, but nobody to know what it is\".\n\nBy the end of that same year, share prices had started collapsing, as it became clear that expectations of imminent wealth from the Americas were overblown. In London, Parliament passed the Bubble Act, which stated that only royally chartered companies could issue public shares. In Paris, Law was stripped of office and fled the country. Stock trading was more limited and subdued in subsequent decades. Yet the market survived, and by the 1790s shares were being traded in the young United States. On May 17, 1792, the New York Stock Exchange opened under a platanus occidentalis (buttonwood tree) in New York City, as 24 stockbrokers signed the Buttonwood Agreement, agreeing to trade five securities under that buttonwood tree.\n\nStock exchanges have multiple roles in the economy. This may include the following:\n\nBesides the borrowing capacity provided to an individual or firm by the banking system, in the form of credit or a loan, a stock exchange provides companies with the facility to raise capital for expansion through selling shares to the investing public.\n\nCapital intensive companies, particularly high tech companies, always need to raise high volumes of capital in their early stages. For this reason, the public market provided by the stock exchanges has been one of the most important funding sources for many capital intensive startups. , it has been much more demanding for the high-tech entrepreneur to take his/her company public, unless either the company is already generating sales and earnings, or the company has demonstrated credibility and potential from successful outcomes: clinical trials, market research, patent registrations, etc. This is quite different from the situation of the 1990s to early-2000s period, when a number of companies (particularly Internet boom and biotechnology companies) went public in the most prominent stock exchanges around the world in the total absence of sales, earnings, or any type of well-documented promising outcome. Though it's not as common, it still happens that highly speculative and financially unpredictable hi-tech startups are listed for the first time in a major stock exchange. Additionally, there are smaller, specialized entry markets for these kind of companies with stock indexes tracking their performance (examples include the Alternext, CAC Small, SDAX, TecDAX).\n\nCompanies have also raised significant amounts of capital through R&D limited partnerships. Tax law changes that were enacted in 1987 in the United States changed the tax deductibility of investments in R&D limited partnerships. In order for a partnership to be of interest to investors today, the cash on cash return must be high enough to entice investors.\n\nA general source of capital for startup companies has been venture capital. This source remains largely available today, but the maximum statistical amount that the venture company firms in aggregate will invest in any one company is not limitless (it was approximately $15 million in 2001 for a biotechnology company).\n\nAnother alternative source of cash for a private company is a corporate partner, usually an established multinational company, which provides capital for the smaller company in return for marketing rights, patent rights, or equity. Corporate partnerships have been used successfully in a large number of cases.\n\nWhen people draw their savings and invest in shares (through an initial public offering or the seasoned equity offering of an already listed company), it usually leads to rational allocation of resources because funds, which could have been consumed, or kept in idle deposits with banks, are mobilized and redirected to help companies' management boards finance their organizations. This may promote business activity with benefits for several economic sectors such as agriculture, commerce and industry, resulting in stronger economic growth and higher productivity levels of firms.\n\nCompanies view acquisitions as an opportunity to expand product lines, increase distribution channels, hedge against volatility, increase their market share, or acquire other necessary business assets. A takeover bid or mergers and acquisitions through the stock market is one of the simplest and most common ways for a company to grow by acquisition or fusion.\n\nBoth casual and professional stock investors, as large as institutional investors or as small as an ordinary middle-class family, through dividends and stock price increases that may result in capital gains, share in the wealth of profitable businesses. Unprofitable and troubled businesses may result in capital losses for shareholders.\n\nBy having a wide and varied scope of owners, companies generally tend to improve management standards and efficiency to satisfy the demands of these shareholders and the more stringent rules for public corporations imposed by public stock exchanges and the government. This improvement can be attributed in some cases to the price mechanism exerted through shares of stock, wherein the price of the stock falls when management is considered poor (making the firm vulnerable to a takeover by new management) or rises when management is doing well (making the firm less vulnerable to a takeover). In addition, publicly listed shares are subject to greater transparency so that investors can make informed decisions about a purchase. Consequently, it is alleged that public companies (companies that are owned by shareholders who are members of the general public and trade shares on public exchanges) tend to have better management records than privately held companies (those companies where shares are not publicly traded, often owned by the company founders, their families and heirs, or otherwise by a small group of investors).\n\nDespite this claim, some well-documented cases are known where it is alleged that there has been considerable slippage in corporate governance on the part of some public companies, particularly in the cases of accounting scandals. The policies that led to the dot-com bubble in the late 1990s and the subprime mortgage crisis in 2007–08 are also examples of corporate mismanagement. The mismanagement of companies such as Pets.com (2000), Enron (2001), One.Tel (2001), Sunbeam Products (2001), Webvan (2001), Adelphia Communications Corporation (2002), MCI WorldCom (2002), Parmalat (2003), American International Group (2008), Bear Stearns (2008), Lehman Brothers (2008), General Motors (2009) and Satyam Computer Services (2009) all received plenty of media attention.\n\nMany banks and companies worldwide utilize securities identification numbers (ISIN) to identify, uniquely, their stocks, bonds and other securities. Adding an ISIN code helps to distinctly identify securities and the ISIN system is used worldwide by funds, companies, and governments.\n\nHowever, when poor financial, ethical or managerial records become public, stock investors tend to lose money as the stock and the company tend to lose value. In the stock exchanges, shareholders of underperforming firms are often penalized by significant share price decline, and they tend as well to dismiss incompetent management teams.\n\nAs opposed to other businesses that require huge capital outlay, investing in shares is open to both the large and small stock investors as minimum investment amounts are minimal. Therefore, the stock exchange provides the opportunity for small investors to own shares of the same companies as large investors.\n\nGovernments at various levels may decide to borrow money to finance infrastructure projects such as sewage and water treatment works or housing estates by selling another category of securities known as bonds. These bonds can be raised through the stock exchange whereby members of the public buy them, thus loaning money to the government. The issuance of such bonds can obviate, in the short term, direct taxation of citizens to finance development—though by securing such bonds with the full faith and credit of the government instead of with collateral, the government must eventually tax citizens or otherwise raise additional funds to make any regular coupon payments and refund the principal when the bonds mature.\n\nAt the stock exchange, share prices rise and fall depending, largely, on economic forces. Share prices tend to rise or remain stable when companies and the economy in general show signs of stability and growth. A recession, depression, or financial crisis could eventually lead to a stock market crash. Therefore, the movement of share prices and in general of the stock indexes can be an indicator of the general trend in the economy.\n\nEach stock exchange imposes its own listing requirements upon companies that want to be listed on that exchange. Such conditions may include minimum number of shares outstanding, minimum market capitalization, and minimum annual income.\n\nThe listing requirements imposed by some stock exchanges include:\n\nStock exchanges originated as mutual organizations, owned by its member stockbrokers. However, the major stock exchanges have \"demutualized\", where the members sell their shares in an initial public offering. In this way the mutual organization becomes a corporation, with shares that are listed on a stock exchange. Examples are Australian Securities Exchange (1998), Euronext (merged with New York Stock Exchange), NASDAQ (2002), Bursa Malaysia (2004), the New York Stock Exchange (2005), Bolsas y Mercados Españoles, and the São Paulo Stock Exchange (2007).\n\nThe Shenzhen Stock Exchange and Shanghai Stock Exchange can be characterized as quasi-state institutions insofar as they were created by government bodies in China and their leading personnel are directly appointed by the China Securities Regulatory Commission.\n\nAnother example is Tashkent Stock Exchange established in 1994, three years after the collapse of the Soviet Union, mainly state-owned but has a form of a public corporation (joint-stock company). Korea Exchange (KRX) owns 25% less one share of the Tashkent Stock Exchange.\n\nIn 2018, there were 15 licensed stock exchanges in the United States, of which 13 actively traded securities. All of these exchanges were owned by three publicly traded multinational companies, Intercontinental Exchange, Nasdaq, Inc., and Cboe Global Markets, except one, IEX. In 2019, a group of financial corporations announced plans to open a members owned exchange, MEMX, an ownership structure similar to the mutual organizations of earlier exchanges.\n\nIn the 19th century, exchanges were opened to trade forward contracts on commodities. Exchange traded forward contracts are called futures contracts. These \"commodity markets\" later started offering future contracts on other products, such as interest rates and shares, as well as options contracts. They are now generally known as futures exchanges.\n\n\nLists:\n\n"}
{"id": "21560", "url": "https://en.wikipedia.org/wiki?curid=21560", "title": "New York Stock Exchange", "text": "New York Stock Exchange\n\nThe New York Stock Exchange (NYSE, nicknamed \"The Big Board\") is an American stock exchange located at 11 Wall Street, Lower Manhattan, New York City, New York. It is by far the world's largest stock exchange by market capitalization of its listed companies at US$30.1 trillion as of February 2018. The average daily trading value was approximately 169 billion in 2013. The NYSE trading floor is located at 11 Wall Street and is composed of 21 rooms used for the facilitation of trading. A fifth trading room, located at 30 Broad Street, was closed in February 2007. The main building and the 11 Wall Street building were designated National Historic Landmarks in 1978.\n\nThe NYSE is owned by Intercontinental Exchange, an American holding company that it also lists (). Previously, it was part of NYSE Euronext (NYX), which was formed by the NYSE's 2007 merger with Euronext.\n\nThe earliest recorded organization of securities trading in New York among brokers directly dealing with each other can be traced to the Buttonwood Agreement. Previously, securities exchange had been intermediated by the auctioneers, who also conducted more mundane auctions of commodities such as wheat and tobacco. On May 17, 1792, twenty four brokers signed the Buttonwood Agreement, which set a floor commission rate charged to clients and bound the signers to give preference to the other signers in securities sales. The earliest securities traded were mostly governmental securities such as War Bonds from the Revolutionary War and First Bank of the United States stock, although Bank of New York stock was a non-governmental security traded in the early days. The Bank of North America, along with the First Bank of the United States and the Bank of New York, were the first shares traded on the New York Stock Exchange.\n\nIn 1817, the stockbrokers of New York, operating under the Buttonwood Agreement, instituted new reforms and reorganized. After sending a delegation to Philadelphia to observe the organization of their board of brokers, restrictions on manipulative trading were adopted, as well as formal organs of governance. After re-forming as the New York Stock and Exchange Board, the broker organization began renting out space exclusively for securities trading, which previously had been taking place at the Tontine Coffee House. Several locations were used between 1817 and 1865, when the present location was adopted.\n\nThe invention of the electrical telegraph consolidated markets and New York's market rose to dominance over Philadelphia after weathering some market panics better than other alternatives. The Open Board of Stock Brokers was established in 1864 as a competitor to the NYSE. With 354 members, the Open Board of Stock Brokers rivaled the NYSE in membership (which had 533) \"because it used a more modern, continuous trading system superior to the NYSE’s twice-daily call sessions\". The Open Board of Stock Brokers merged with the NYSE in 1869. Robert Wright of \"Bloomberg\" writes that the merger increased the NYSE's members as well as trading volume, as \"several dozen regional exchanges were also competing with the NYSE for customers. Buyers, sellers and dealers all wanted to complete transactions as quickly and cheaply as technologically possible and that meant finding the markets with the most trading, or the greatest liquidity in today’s parlance. Minimizing competition was essential to keep a large number of orders flowing, and the merger helped the NYSE maintain its reputation for providing superior liquidity.\" The Civil War greatly stimulated speculative securities trading in New York. By 1869, membership had to be capped, and has been sporadically increased since. The latter half of the nineteenth century saw rapid growth in securities trading.\n\nSecurities trade in the latter nineteenth and early twentieth centuries was prone to panics and crashes. Government regulation of securities trading was eventually seen as necessary, with arguably the most dramatic changes occurring in the 1930s after a major stock market crash precipitated the Great Depression.\n\nThe Stock Exchange Luncheon Club was situated on the seventh floor from 1898 until its closure in 2006.\n\nThe main building, located at 18 Broad Street, between the corners of Wall Street and Exchange Place, was designated a National Historic Landmark in 1978, as was the 11 Wall Street building.\nOn April 21, 2005, the NYSE announced its plans to merge with Archipelago in a deal intended to reorganize the NYSE as a publicly traded company. NYSE's governing board voted to merge with rival Archipelago on December 6, 2005, and became a for-profit, public company. It began trading under the name NYSE Group on March 8, 2006. On April 4, 2007, the NYSE Group completed its merger with Euronext, the European combined stock market, thus forming NYSE Euronext, the first transatlantic stock exchange.\n\nWall Street is the leading US money center for international financial activities and the foremost US location for the conduct of wholesale financial services. \"It comprises a matrix of wholesale financial sectors, financial markets, financial institutions, and financial industry firms\" (Robert, 2002). The principal sectors are securities industry, commercial banking, asset management, and insurance.\n\nPrior to the acquisition of NYSE Euronext by the ICE in 2013, Marsh Carter was the Chairman of the NYSE and the CEO was Duncan Niederauer. Currently, the chairman is Jeffrey Sprecher. In 2016, NYSE owner Intercontinental Exchange Inc. earned $419 million in listings-related revenues.\n\nThe exchange was closed shortly after the beginning of World War I (July 31, 1914), but it partially re-opened on November 28 of that year in order to help the war effort by trading bonds, and completely reopened for stock trading in mid-December.\n\nOn September 16, 1920, a bomb exploded on Wall Street outside the NYSE building, killing 33 people and injuring more than 400. The perpetrators were never found. The NYSE building and some buildings nearby, such as the JP Morgan building, still have marks on their façades caused by the bombing.\n\nThe Black Thursday crash of the Exchange on October 24, 1929, and the sell-off panic which started on Black Tuesday, October 29, are often blamed for precipitating the Great Depression. In an effort to restore investor confidence, the Exchange unveiled a fifteen-point program aimed to upgrade protection for the investing public on October 31, 1938.\n\nOn October 1, 1934, the exchange was registered as a national securities exchange with the U.S. Securities and Exchange Commission, with a president and a thirty-three-member board. On February 18, 1971, the non-profit corporation was formed, and the number of board members was reduced to twenty-five.\n\nOne of Abbie Hoffman's well-known publicity stunts took place in 1967, when he led members of the Yippie movement to the Exchange's gallery. The provocateurs hurled fistfuls of dollars toward the trading floor below. Some traders booed, and some laughed and waved. Three months later the stock exchange enclosed the gallery with bulletproof glass. Hoffman wrote a decade later, \"We didn't call the press; at that time we really had no notion of anything called a media event.\"\nOn October 19, 1987, the Dow Jones Industrial Average (DJIA) dropped 508 points, a 22.6% loss in a single day, the second-biggest one-day drop the exchange had experienced. Black Monday was followed by Terrible Tuesday, a day in which the Exchange's systems did not perform well and some people had difficulty completing their trades.\n\nSubsequently, there was another major drop for the Dow on October 13, 1989—the Mini-Crash of 1989. The crash was apparently caused by a reaction to a news story of a $6.75 billion leveraged buyout deal for UAL Corporation, the parent company of United Airlines, which broke down. When the UAL deal fell through, it helped trigger the collapse of the junk bond market causing the Dow to fall 190.58 points, or 6.91 percent.\n\nSimilarly, there was a panic in the financial world during the year of 1997; the Asian Financial Crisis. Like the fall of many foreign markets, the Dow suffered a 7.18% drop in value (554.26 points) on October 27, 1997, in what later became known as the 1997 Mini-Crash but from which the DJIA recovered quickly. This was the first time that the \"circuit breaker\" rule had operated.\n\nOn January 26, 2000, an altercation during filming of the music video for Rage Against the Machine's \"Sleep Now in the Fire\", directed by Michael Moore, caused the doors of the exchange to be closed and the band to be escorted from the site by security after the members attempted to gain entry into the exchange.\n\nIn the aftermath of the September 11 attacks, the NYSE was closed for four trading sessions, resuming on Monday, September 17, one of the rare times the NYSE was closed for more than one session and only the third time since March 1933. On the first day, the NYSE suffered a 7.1% drop in value (684 points); after a week, it dropped by 14% (1370 points). An estimated of $1.4 trillion was lost within five days of trading. The NYSE was only 5 blocks from Ground Zero.\n\nOn May 6, 2010, the Dow Jones Industrial Average posted its largest intraday percentage drop since the crash on October 19, 1987, with a 998-point loss later being called the 2010 Flash Crash (as the drop occurred in minutes before rebounding). The SEC and CFTC published a report on the event, although it did not come to a conclusion as to the cause. The regulators found no evidence that the fall was caused by erroneous (\"fat finger\") orders.\n\nOn October 29, 2012, the stock exchange was shut down for two days due to Hurricane Sandy. The last time the stock exchange was closed due to weather for a full two days was on March 12 and 13, 1888.\n\nOn May 1, 2014, the stock exchange was fined $4.5 million by the Securities and Exchange Commission to settle charges that it had violated market rules.\n\nOn August 14, 2014, Berkshire Hathaway's A Class shares, the highest priced shares on the NYSE, hit $200,000 a share for the first time.\n\nOn July 8, 2015, technical issues affected the stock exchange, halting trading at 11:32 am ET. The NYSE reassured stock traders that the outage was \"not a result of a cyber breach\", and the Department of Homeland Security confirmed that there was \"no sign of malicious activity\". Trading eventually resumed at 3:10 pm ET the same day.\n\nOn May 25, 2018, Stacey Cunningham, the NYSE's chief operating officer, became the Big Board's 67th president, succeeding Thomas Farley. She is the first female leader in the exchange's 226-year history.\n\nThe New York Stock Exchange is closed on New Year's Day, Martin Luther King, Jr. Day, Washington's Birthday, Good Friday, Memorial Day, Fourth of July, Labor Day, Thanksgiving, and Christmas. When those holidays occur on a weekend, the holiday is observed on the closest weekday. In addition, the Stock Exchange closes early on the day before Independence Day, the day after Thanksgiving, and the day before Christmas. The NYSE averages about 253 trading days per year.\n\nThe New York Stock Exchange (sometimes referred to as \"the Big Board\") provides a means for buyers and sellers to trade shares of stock in companies registered for public trading. The NYSE is open for trading Monday through Friday from 9:30 am – 4:00 pm ET, with the exception of holidays declared by the Exchange in advance.\n\nThe NYSE trades in a continuous auction format, where traders can execute stock transactions on behalf of investors. They will gather around the appropriate post where a specialist broker, who is employed by a NYSE member firm (that is, he/she is not an employee of the New York Stock Exchange), acts as an auctioneer in an open outcry auction market environment to bring buyers and sellers together and to manage the actual auction. They do on occasion (approximately 10% of the time) facilitate the trades by committing their own capital and as a matter of course disseminate information to the crowd that helps to bring buyers and sellers together. The auction process moved toward automation in 1995 through the use of wireless hand held computers (HHC). The system enabled traders to receive and execute orders electronically via wireless transmission. On September 25, 1995, NYSE member Michael Einersen, who designed and developed this system, executed 1000 shares of IBM through this HHC ending a 203-year process of paper transactions and ushering in an era of automated trading.\n\nAs of January 24, 2007, all NYSE stocks can be traded via its electronic hybrid market (except for a small group of very high-priced stocks). Customers can now send orders for immediate electronic execution, or route orders to the floor for trade in the auction market. In the first three months of 2007, in excess of 82% of all order volume was delivered to the floor electronically. NYSE works with US regulators such as the SEC and CFTC to coordinate risk management measures in the electronic trading environment through the implementation of mechanisms like circuit breakers and liquidity replenishment points.\n\nUntil 2005, the right to directly trade shares on the exchange was conferred upon owners of the 1,366 \"seats\". The term comes from the fact that up until the 1870s NYSE members sat in chairs to trade. In 1868, the number of seats was fixed at 533, and this number was increased several times over the years. In 1953, the number of seats was set at 1,366. These seats were a sought-after commodity as they conferred the ability to directly trade stock on the NYSE, and seat holders were commonly referred to as members of the NYSE. The Barnes family is the only known lineage to have five generations of NYSE members: Winthrop H. Barnes (admitted 1894), Richard W.P. Barnes (admitted 1926), Richard S. Barnes (admitted 1951), Robert H. Barnes (admitted 1972), Derek J. Barnes (admitted 2003). Seat prices varied widely over the years, generally falling during recessions and rising during economic expansions. The most expensive inflation-adjusted seat was sold in 1929 for $625,000, which, today, would be over six million dollars. In recent times, seats have sold for as high as $4 million in the late 1990s and as low as $1 million in 2001. In 2005, seat prices shot up to $3.25 million as the exchange entered into an agreement to merge with Archipelago and became a for-profit, publicly traded company. Seat owners received $500,000 in cash per seat and 77,000 shares of the newly formed corporation. The NYSE now sells one-year licenses to trade directly on the exchange. Licenses for floor trading are available for $40,000 and a license for bond trading is available for as little as $1,000 as of 2010. Neither are resell-able, but may be transferable during a change of ownership of a corporation holding a trading license.\n\nFollowing the Black Monday market crash in 1987, NYSE imposed trading curbs to reduce market volatility and massive panic sell-offs. Following the 2011 rule change, at the start of each trading day, the NYSE sets three circuit breaker levels at levels of 7% (Level 1), 13% (Level 2), and 20% (Level 3) of the average closing price of the S&P 500 for the preceding trading day. Level 1 and Level 2 declines result in a 15-minute trading halt unless they occur after 3:25 pm, when no trading halts apply. A Level 3 decline results in trading being suspended for the remainder of the day. (The biggest one-day decline in the S&P 500 since 1987 was the 9.0% drop on October 15, 2008.)\n\nIn the mid-1960s, the NYSE Composite Index (NYSE: NYA) was created, with a base value of 50 points equal to the 1965 yearly close. This was done to reflect the value of all stocks trading at the exchange instead of just the 30 stocks included in the Dow Jones Industrial Average. To raise the profile of the composite index, in 2003, the NYSE set its new base value of 5,000 points equal to the 2002 yearly close. Its close at the end of 2013 was 10,400.32.\n\n\nIn October 2008, NYSE Euronext completed acquisition of the American Stock Exchange (AMEX) for $260 million in stock.\n\nOn February 15, 2011, NYSE and Deutsche Börse announced their merger to form a new company, as yet unnamed, wherein Deutsche Börse shareholders would have 60% ownership of the new entity, and NYSE Euronext shareholders would have 40%.\n\nOn February 1, 2012, the European Commission blocked the merger of NYSE with Deutsche Börse, after commissioner Joaquín Almunia stated that the merger \"would have led to a near-monopoly in European financial derivatives worldwide\". Instead, Deutsche Börse and NYSE would have to sell either their Eurex derivatives or LIFFE shares in order to not create a monopoly. On February 2, 2012, NYSE Euronext and Deutsche Börse agreed to scrap the merger.\n\nIn April 2011, Intercontinental Exchange (ICE), an American futures exchange, and NASDAQ OMX Group had together made an unsolicited proposal to buy NYSE Euronext for approximately , a deal in which NASDAQ would have taken control of the stock exchanges. NYSE Euronext rejected this offer twice, but it was finally terminated after the United States Department of Justice indicated their intention to block the deal due to antitrust concerns.\n\nIn December 2012, ICE had proposed to buy NYSE Euronext in a stock swap with a valuation of $8 billion. NYSE Euronext shareholders would receive either $33.12 in cash, or $11.27 in cash and approximately a sixth of a share of ICE. Jeffrey Sprecher, the chairman and CEO of ICE, will retain those positions, but four members of the NYSE board of directors will be added to the ICE board.\n\nThe NYSE's opening and closing bells mark the beginning and the end of each trading day. The 'opening bell' is rung at 9:30 am ET to mark the start of the day's trading session. At 4 pm ET the 'closing bell' is rung and trading for the day stops. There are bells located in each of the four main sections of the NYSE that all ring at the same time once a button is pressed. There are three buttons that control the bells, located on the control panel behind the podium which overlooks the trading floor. The main bell, which is rung at the beginning and end of the trading day, is controlled by a green button. The second button, colored orange, activates a single-stroke bell that is used to signal a moment of silence. A third, red button controls a backup bell which is used in case the main bell fails to ring.\n\nThe signal to start and stop trading was not always a bell. The original signal was a gavel (which is still in use today along with the bell), but during the late 1800s, the NYSE decided to switch the gavel for a gong to signal the day's beginning and end. After the NYSE changed to its present location at 18 Broad Street in 1903, the gong was switched to the bell format that is currently being used.\n\nA common sight today is the highly publicized events in which a celebrity or executive from a corporation stands behind the NYSE podium and pushes the button that signals the bells to ring. Due to the amount of coverage that the opening/closing bells receive, many companies coordinate new product launches and other marketing-related events to start on the same day as when the company's representatives ring the bell. It was only in 1995 that the NYSE began having special guests ring the bells on a regular basis; prior to that, ringing the bells was usually the responsibility of the exchange's floor managers.\n\nMany of the people who ring the bell are business executives whose companies trade on the exchange. However, there have also been many famous people from outside the world of business that have rung the bell. Athletes such as Joe DiMaggio of the New York Yankees and Olympic swimming champion Michael Phelps, entertainers such as rapper Snoop Dogg, members of ESPN’s College GameDay crew, singer and actress Liza Minnelli and members of the band Kiss, and politicians such as Mayor of New York City Rudy Giuliani and President of South Africa Nelson Mandela have all had the honor of ringing the bell. Two United Nations Secretaries General have also rung the bell. On April 27, 2006, Secretary-General Kofi Annan rang the opening bell to launch the United Nations Principles for Responsible Investment. On July 24, 2013, Secretary-General Ban Ki-moon rang the closing bell to celebrate the NYSE joining the United Nations Sustainable Stock Exchanges Initiative.\n\nIn addition, there have been many bell-ringers who are famous for heroic deeds, such as members of the New York police and fire departments following the events of 9/11, members of the United States Armed Forces serving overseas, and participants in various charitable organizations.\n\nThere have also been several fictional characters that have rung the bell, including Mickey Mouse, the Pink Panther, Mr. Potato Head, the Aflac Duck, and Darth Vader.\n\n\nNotes\nBibliography\n"}
{"id": "21559", "url": "https://en.wikipedia.org/wiki?curid=21559", "title": "Nasdaq", "text": "Nasdaq\n\nThe NASDAQ Stock Market, also known as NASDAQ, is an American stock exchange located at One Liberty Plaza in New York City. It is ranked second on the list of stock exchanges by market capitalization of shares traded, behind only the New York Stock Exchange. The exchange platform is owned by Nasdaq, Inc., which also owns the Nasdaq Nordic stock market network and several U.S. stock and options exchanges.\n\n\"Nasdaq\" was initially an acronym for the National Association of Securities Dealers Automated Quotations.\n\nIt was founded in 1971 by the National Association of Securities Dealers (NASD), now known as the Financial Industry Regulatory Authority (FINRA).\n\nOn February 8, 1971, the Nasdaq stock market began operations as the world's first electronic stock market. At first, it was merely a \"quotation system\" and did not provide a way to perform electronic trades. The Nasdaq Stock Market helped lower the bid–ask spread (the difference between the bid price and the ask price of the stock), but was unpopular among brokers as it reduced their profits.\n\nThe NASDAQ Stock Market eventually assumed the majority of major trades that had been executed by the over-the-counter (OTC) system of trading, but there are still many securities traded in this fashion. As late as 1987, the Nasdaq exchange was still commonly referred to as \"OTC\" in media reports and also in the monthly Stock Guides (stock guides and procedures) issued by Standard & Poor's Corporation.\n\nOver the years, the Nasdaq Stock Market became more of a stock market by adding trade and volume reporting and automated trading systems.\n\nIn 1981, Nasdaq traded 37% of the U.S. securities markets' total of 21 billion shares. By 1991, Nasdaq's share had grown to 46%.\n\nIn 1998, it was the first stock market in the United States to trade online, using the slogan \"the stock market for the next hundred years\". The Nasdaq Stock Market attracted many companies during the dot-com bubble.\n\nIts main index is the NASDAQ Composite, which has been published since its inception. The QQQ exchange-traded fund tracks the large-cap NASDAQ-100 index, which was introduced in 1985 alongside the NASDAQ Financial-100 Index, which tracks the largest 100 companies in terms of market capitalization.\n\nIn 1992, the Nasdaq Stock Market joined with the London Stock Exchange to form the first intercontinental linkage of capital markets.\n\nIn 2000, the National Association of Securities Dealers spun off the Nasdaq Stock Market to form a public company.\n\nOn March 10, 2000, the NASDAQ Composite stock market index peaked at 5,132.52, but fell to 3,227 by April 17, and, in the following 30 months, fell 78% from its peak.\n\nIn a series of sales in 2000 and 2001, FINRA sold its stake in the Nasdaq.\n\nOn July 2, 2002, Nasdaq Inc. became a public company via an initial public offering.\n\nIn 2006, the status of the Nasdaq Stock Market was changed from a stock market to a licensed national securities exchange.\n\nIn 2010, Nasdaq merged with OMX, a leading exchange operator in the Nordic countries, expanded its global footprint, and changed its name to the NASDAQ OMX Group.\n\nTo qualify for listing on the exchange, a company must be registered with the United States Securities and Exchange Commission (SEC), must have at least three market makers (financial firms that act as brokers or dealers for specific securities) and must meet minimum requirements for assets, capital, public shares, and shareholders.\n\nIn February 2011, in the wake of an announced merger of NYSE Euronext with Deutsche Börse, speculation developed that NASDAQ OMX and Intercontinental Exchange (ICE) could mount a counter-bid of their own for NYSE. NASDAQ OMX could be looking to acquire the American exchange's cash equities business, ICE the derivatives business. At the time, \"NYSE Euronext's market value was $9.75 billion. Nasdaq was valued at $5.78 billion, while ICE was valued at $9.45 billion.\" Late in the month, Nasdaq was reported to be considering asking either ICE or the Chicago Mercantile Exchange to join in what would probably have to be, if it proceeded, an $11–12 billion counterbid.\n\nIn December 2005, NASDAQ acquired Instinet for $1.9 billion, retaining the Inet ECN and subsequently selling the agency brokerage business to Silver Lake Partners and Instinet management.\n\nThe European Association of Securities Dealers Automatic Quotation System (EASDAQ) was founded as a European equivalent to the Nasdaq Stock Market. It was purchased by NASDAQ in 2001 and became NASDAQ Europe. In 2003, operations were shut down as a result of the burst of the dot-com bubble. In 2007, NASDAQ Europe was revived first as Equiduct, and later that year, it was acquired by Börse Berlin.\n\nOn June 18, 2012, Nasdaq OMX became a founding member of the United Nations Sustainable Stock Exchanges Initiative on the eve of the United Nations Conference on Sustainable Development (Rio+20). \n\nIn November 2016, chief operating officer Adena Friedman was promoted to chief executive officer, becoming the first woman to run a major exchange in the U.S.\n\nIn 2016, Nasdaq earned $272 million in listings-related revenues.\n\nIn October 2018, the SEC ruled that the New York Stock Exchange and Nasdaq did not justify the continued price increases when selling market data.\n\nNasdaq quotes are available at three levels:\n\n\nThe Nasdaq Stock Market sessions, with times in the Eastern Time Zone are:\n\n4:00 a.m. to 9:30 a.m. Extended hours trading session (premarket)\n\n9:30 a.m. to 4:00 p.m. normal trading session\n\n4:00 p.m. to 8:00 p.m. Extended hours trading session (postmarket)\n\nThe Nasdaq Stock Market averages about 253 trading days per year.\n\nThe Nasdaq Stock Market has three different market tiers:\n\n"}
{"id": "197867", "url": "https://en.wikipedia.org/wiki?curid=197867", "title": "London Stock Exchange", "text": "London Stock Exchange\n\nLondon Stock Exchange is a stock exchange located in the City of London, England. , London Stock Exchange had a market capitalization of US$4.59 trillion. It was founded in 1571, making it one of the oldest exchanges in the world. Its current premises are situated in Paternoster Square close to St Paul's Cathedral in the City of London. It is part of London Stock Exchange Group (LSEG).\n\nLondon Stock Exchange is one of the world's oldest stock exchanges and can trace its history back to 1571. London Stock Exchange Group was created in October 2007 when London Stock Exchange merged with Milan Stock Exchange, Borsa Italiana.\n\nThe Royal Exchange had been founded by English financier Thomas Gresham and Sir Richard Clough on the model of the Antwerp Bourse. It was opened by Elizabeth I of England in 1571.\n\nDuring the 17th century, stockbrokers were not allowed in the Royal Exchange due to their rude manners. They had to operate from other establishments in the vicinity, notably Jonathan's Coffee-House. At that coffee house, a broker named John Castaing started listing the prices of a few commodities, such as salt, coal, and paper, and exchange rates in 1698. Originally, this was not a daily list and was only published a few days of the week.\n\nThis list and activity was later moved to Garraway's coffee house. Public auctions during this period were conducted for the duration that a length of tallow candle could burn; these were known as \"by inch of candle\" auctions. As stocks grew, with new companies joining to raise capital, the royal court also raised some monies. These are the earliest evidence of organised trading in marketable securities in London.\n\nAfter Gresham's Royal Exchange building was destroyed in the Great Fire of London, it was rebuilt and re-established in 1669. This was a move away from coffee houses and a step towards the modern model of stock exchange.\n\nThe Royal Exchange housed not only brokers but also merchants and merchandise. This was the birth of a regulated stock market, which had teething problems in the shape of unlicensed brokers. In order to regulate these, Parliament passed an Act in 1697 that levied heavy penalties, both financial and physical, on those brokering without a licence. It also set a fixed number of brokers (at 100), but this was later increased as the size of the trade grew. This limit led to several problems, one of which was that traders began leaving the Royal Exchange, either by their own decision or through expulsion, and started dealing in the streets of London. The street in which they were now dealing was known as 'Exchange Alley', or 'Change Alley'; it was suitably placed close to the Bank of England. Parliament tried to regulate this and ban the unofficial traders from the Change streets.\n\nTraders became weary of \"bubbles\" when companies rose quickly and fell, so they persuaded Parliament to pass a clause preventing \"unchartered\" companies from forming.\n\nAfter the Seven Years' War (1756–1763), trade at Jonathan's Coffee House boomed again. In 1773, Jonathan, together with 150 other brokers, formed a club and opened a new and more formal \"Stock Exchange\" in Sweeting's Alley. This now had a set entrance fee, by which traders could enter the stock room and trade securities. It was, however, not an exclusive location for trading, as trading also occurred in the Rotunda of the Bank of England. Fraud was also rife during these times and in order to deter such dealings, it was suggested that users of the stock room pay an increased fee. This was not met well and ultimately, the solution came in the form of annual fees and turning the Exchange into a Subscription room.\n\nThe Subscription room created in 1801 was the first regulated exchange in London, but the transformation was not welcomed by all parties. On the first day of trading, non-members had to be expelled by a constable. In spite of the disorder, a new and bigger building was planned, at Capel Court.\n\nWilliam Hammond laid the first foundation stone for the new building on 18 May. It was finished on 30 December when \"The Stock Exchange\" was incised on the entrance.\n\nIn the Exchange's first operating years, on several occasions there was no clear set of regulations or fundamental laws for the Capel Court trading. In February 1812, the General Purpose Committee confirmed a set of recommendations, which later became the foundation of the first codified rule book of the Exchange. Even though the document was not a complex one, topics such as settlement and default were, in fact, quite comprehensive.\n\nWith its new governmental commandments and increasing trading volume, the Exchange was progressively becoming an accepted part of the financial life in the City. In spite of continuous criticism from newspapers and the public, the government used the Exchange's organised market (and would most likely not have managed without it) to raise the enormous amount of money required for the wars against Napoleon.\n\nAfter the war and facing a booming world economy, foreign lending to countries such as Brazil, Peru and Chile was a growing market. Notably, the Foreign Market at the Exchange allowed for merchants and traders to participate, and the Royal Exchange hosted all transactions where foreign parties were involved. The constant increase in overseas business eventually meant that dealing in foreign securities had to be allowed within all of the Exchange's premises.\n\nJust as London enjoyed growth through international trade, the rest of Great Britain also benefited from the economic boom. Two other cities, in particular, showed great business development: Liverpool and Manchester. Consequently, in 1836 both the Manchester and Liverpool stock exchanges were opened. Some stock prices sometimes rose by 10%, 20% or even 30% in a week. These were times when stockbroking was considered a real business profession, and such attracted many entrepreneurs. Nevertheless, with booms came busts, and in 1835 the \"Spanish panic\" hit the markets, followed by a second one two years later.\n\nBy June 1853, both participating members and brokers were taking up so much space that the Exchange was now uncomfortably crowded, and continual expansion plans were taking place. Having already been extended west, east and northwards, it was then decided the Exchange needed an entire new establishment. Thomas Allason was appointed as the main architect, and in March 1854 the new brick building inspired from the Great Exhibition stood ready. This was a huge improvement in both surroundings and space, with twice the floor space available.\n\nBy the late 1800s, the telephone, ticker tape and the telegraph had been invented. Those new technologies led to a revolution in the work of the Exchange.\n\nAs the financial centre of the world, both the City and the Stock Exchange were hit hard by the outbreak of World War I in 1914. Due to fears that borrowed money was to be called in and that foreign banks would demand their loans or raise interest, prices surged at first. The decision to close the Exchange for improved breathing space and to extend the August Bank Holiday to prohibit a run on banks, was hurried through by the committee and Parliament, respectively. The Stock Exchange ended up being closed from the end of July until the New Year, causing street business to be introduced again as well as the \"challenge system\".\n\nThe Exchange was set to open again on 4 January 1915 under tedious restrictions: transactions were to be in cash only. Due to the limitations and challenges on trading brought by the war, almost a thousand members quit the Exchange between 1914 and 1918. When peace returned in November 1918, the mood on the trading floor was generally cowed. In 1923 the Exchange received its own coat of arms, with the motto \"Dictum Meum Pactum\", My Word is My Bond.\n\nIn 1937 officials at the Exchange used their experiences from World War I to draw up plans for how to handle a new war. The main concerns included air raids and the subsequent bombing of the Exchange's perimeters, and one suggestion was a move to Denham, Buckinghamshire. This however never took place. On the first day of September 1939, the Exchange closed its doors \"until further notice\" and two days later World War II was declared. Unlike in the prior war, the Exchange opened its doors again six days later, on 7 September.\n\nAs the war escalated into its second year, the concerns for air raids were greater than ever. Eventually, on the night of 29 December 1940 one of the greatest fires in London's history took place. The Exchange's floor was hit by a clutch of incendiary bombs, which were extinguished quickly. Trading on the floor was now drastically low and most was done over the phone to reduce the possibility of injuries.\n\nThe Exchange was only closed for one more day during wartime, in 1945 due to damage from a V-2 rocket. Nonetheless trading continued in the house's basement.\n\nAfter decades of uncertain if not turbulent times, stock market business boomed in the late 1950s. This spurred officials to find new, more suitable accommodation. The work on the new Stock Exchange Tower began in 1967. The Exchange's new 321 feet (96 metre) high building had 26 storeys with council and administration at the top, and middle floors let out to affiliate companies. Queen Elizabeth II opened the building on 8 November 1972; it was a new City landmark, with its trading floor.\n1973 marked a year of changes for the Stock Exchange. First, two trading prohibitions were abolished. A report from the Monopolies and Mergers Commission recommended the admittance of both women and foreign-born members on the floor. Second, in March the London Stock Exchange formally merged with the eleven British and Irish regional exchanges, including the Scottish Stock Exchange. This expansion led to the creation of a new position of Chief Executive Officer; after an extensive search this post was given to Robert Fell. There were more governance changes in 1991, when the governing Council of the Exchange was replaced by a Board of Directors drawn from the Exchange's executive, customer and user base; and the trading name became \"The London Stock Exchange\".\n\nFTSE 100 Index (pronounced \"Footsie 100\") was launched by a partership of the \"Financial Times\" and the Stock Exchange on 3 January 1984. This turned out to be one of the most useful indices of all, and tracked the movements of the 100 leading companies listed on the Exchange.\n\nOn 20 July 1990 a bomb planted by the Provisional Irish Republican Army exploded in the men's toilets behind the visitors' gallery. The area had already been evacuated and nobody was injured. About 30 minutes before the blast at 8:49 a.m., a man who said he was a member of the IRA told Reuters that a bomb had been placed at the exchange and was about to explode. Police officials said that if there had been no warning, the human toll would have been very high. The explosion ripped a hole in the 23-storey building in Threadneedle Street and sent a shower of glass and concrete onto the street. The long-term trend towards electronic trading platforms reduced the Exchange's attraction to visitors, and although the gallery reopened, it was closed permanently in 1992.\n\nThe biggest event of the 1980s was the sudden de-regulation of the financial markets in the UK in 1986. The phrase \"Big Bang\" was coined to describe measures, including abolition of fixed commission charges and of the distinction between stockjobbers and stockbrokers on the London Stock Exchange, as well as the change from an open outcry to electronic, screen-based trading.\n\nIn 1995, the Exchange launched the Alternative Investment Market, the AIM, to allow growing companies to expand into international markets. Two years later the Electronic Trading Service (SETS) was launched, bringing greater speed and efficiency to the market. Next, the CREST settlement service was launched. In 2000, the Exchange's shareholders voted to become a public limited company, London Stock Exchange plc. London Stock Exchange also transferred its role as UK Listing Authority to the Financial Services Authority (FSA-UKLA).\n\nEDX London, an international equity derivatives business, was created in 2003 in partnership with OM Group. The Exchange also acquired Proquote Limited, a new generation supplier of real-time market data and trading systems.\n\nThe old Stock Exchange Tower became largely redundant with Big Bang, which deregulated many of the Stock Exchange's activities: computerised systems and dealing rooms replaced face-to-face trading. In 2004 LondonStock Exchange moved to a brand-new headquarters in Paternoster Square, close to St Paul's Cathedral.\n\nIn 2007, the London Stock Exchange merged with Borsa Italiana, creating London Stock Exchange Group (LSEG). The Group's headquarters are in Paternoster Square.\n\nThe Stock Exchange in Paternoster Square was the initial target for the protesters of Occupy London on 15 October 2011. Attempts to occupy the square were thwarted by police. Police sealed off the entrance to the square as it is private property, a High Court injunction having previously been granted against public access to the square.\n\nThe protesters moved nearby to occupy the space in front of St Paul's Cathedral. The protests were part of the global Occupy movement.\n\nOn 25 April 2019, the final day of the Extinction Rebellion disruption in London, 13 activists glued themselves together in a chain, blocking the entrances of the Stock Exchange. The protesters were all later arrested on suspicion of aggravated trespass.\n\nExtinction Rebellion had said its protesters would target the financial industry \"and the corrosive impacts of the ... sector on the world we live in\" and activists also blocked entrances to HM Treasury and the Goldman Sachs office on Fleet Street.\n\nIssuer services help companies from around the world to join the London equity market in order to gain access to capital. London Stock Exchange allows companies to raise money, increase their profile and obtain a market valuation through a variety of routes, thus following the firms throughout the whole IPO process.\n\nLondon Stock Exchange runs several markets for listing, giving an opportunity for different sized companies to list. International companies can list a number of products in London including shares, depositary receipts and debt, offering different and cost-effective ways to raise capital. In 2004 the Exchange opened a Hong Kong office and has attracted more than 200 companies from the Asia-Pacific region.\n\nFor the biggest companies exists the Premium Listed Main Market. This operates a Super Equivalence method where conditions of both the UK Listing Authority as well as London Stock Exchange's own criteria have to be met. The largest IPO on the Exchange was completed in May 2011 by Glencore International plc. The company raised $10 billion at admission, making it one of the largest IPOs ever since foundation.\n\nIn terms of smaller SME's London Stock Exchange operates the Alternative Investment Market (AIM). For international companies that fall outside of the EU, it operates the Depository Receipt (DR) scheme as a way of listing and raising capital.\n\nThere are also two specialised markets:\n\nProfessional Securities Market\nThis market facilitates the raising of capital through the issue of specialist debt securities or depositary receipts (DRs) to professional investors. The market operates under the status as a Recognised Investment Exchange, and by July 2011 it had 32 DRs, 108 Eurobonds and over 350 Medium Term Notes.\n\nSpecialist Fund Market\nIs London Stock Exchange's dedicated market, designed to accept more sophisticated fund vehicles, governance models and security. It is suitable only for institutional, professional and highly knowledgeable investors. The Specialist Fund Market is an EU Regulated Market and thus securities admitted to the market are eligible for most investor mandates providing a pool of liquidity for issuers admitted to the market\n\nThe securities available for trading on London Stock Exchange:\n\n\nThere are two main markets on which companies trade on the LSE:\n\nThe main market is home to Over 1,300 large companies from 60 different countries. Over the past 10 years over £366 billion has been raised through new and further issues by Main Market companies. The FTSE 100 Index (\"footsie\") is the main share index of the 100 most highly capitalised UK companies listed on the Main Market.\n\nThe Alternative Investment Market is LSE's international market for smaller companies. A wide range of businesses including early-stage, venture capital-backed as well as more-established companies join AIM seeking access to growth capital. The AIM is classified as a Multilateral Trading Facility (MTF) under the 2004 MiFID directive, and as such it is a flexible market with a simpler admission process for companies wanting to be publicly listed.\n\nThere are also several electronic platforms on which the different products trade:\nTrading of derivative products is available on the \"Turquoise\" platform (ex EDX London). Products are Norwegian Futures and options on Norwegian single stocks and indices, Russian futures and options on the most liquid IOB Depositary Receipts, Futures, options on the FTSE RIOB index and futures on the FTSE 100. Futures and options on the most liquid European stock underlyings and on European benchmark indices were expected to be launched in Q4 2011 and Q1 2012 subject to Financial Services Authority approval.\n\n\nThe largest products offered are:\n\n\nThe \"Order book for Retail Bonds\" (ORB), launched in February 2010, offers continuous two-way pricing for trading in UK gilts and retail-size corporate bonds on-exchange. ORB acts as an electronic secondary market for retail investors. 2009 saw highest-ever inflow into bond funds, a net total of £10.7bn, driven almost entirely by retail investors (90% of total), with corporate bonds being the bestselling sector.\n\nORB offers an open and transparent market model for trading in retail-size. Currently there are five dedicated market makers committed to quoting two-way prices in a range of retail bonds throughout the trading day. New market models means private investors will be able to see prices on-screen and trade in bonds in a similar way as they currently do for shares. This creates a greater efficiency of electronic on-book execution and option to use straight-through-processing to settlement system.\n\nRetail Bonds are driven by cost-effectiveness, simplicity of transaction charging and standardisation of market structure. The key aim of ORB is to increase distribution for bonds by opening up these markets to private investors who may have previously felt excluded from this market. This is by increasing the availability of publication on offer, detailing the risks and benefits involved in Retail Bonds, such as taxation.\n\nNew entrants into ORB have been able to raise sufficient funds, such as Places for People who were able to raise capital of £140 million. This portrays the advantage using ORB can have, even for non-bank smaller firms seeking to raise capital.\n\nThere are currently 2,600 companies from over 60 countries listed on London Stock Exchange, of which 1151 are on AIM, 44 on the Professional Securities Market and 10 on the Specialist Funds Market. Pence sterling (GBX) is a subdivision of Pounds sterling (GBP). Pounds sterling are the UK's major currency unit, but pence are often used when quoting prices; e.g. a quoted price of GBX 2,360 is equivalent to £23.60.\n\n, the AIM had 56 companies as per country of operations from Africa, 41 from China, 26 from Latin America, 23 from Central & Eastern Europe and 29 from India & Bangladesh, making it one of the world's leading growth markets. Since its launch in 1995, more than £67 billion has been raised on AIM. The total market value of these companies was £3.9 trillion. The daily turnover in July 2011 was £4.4 billion (€5.0 billion) and the daily number of trades 611,941. The LSE's share of trading in the UK lit order book trading was 62.2%. London Stock Exchange offered trading in more emerging market exchange traded funds (ETFs) than any other exchange in the world. There were a total of 158 emerging market ETFs listed on the Exchange in May 2011, compared with 126 on the New York Stock Exchange (NYSE Arca) and 93 on Deutsche Börse.\n\nLondon Stock Exchange supplies its participants with real time prices and trading data creating the transparency and liquidity through several services. Feeds are also available through providers such as Bloomberg and Thomson Reuters. Some of the products and references provided by London Stock Exchange Group are:\n\nLCH & CC&G\n\nThrough the Exchange's Italian arm, Borsa Italiana, the London Stock Exchange Group as a whole offers clearing and settlement services for trades through \"CC&G\" (Cassa di Compensazione e Garanzia) and Monte Titoli. is the Groups Central Counterparty (CCP) and covers multiple asset classes throughout the Italian equity, derivatives and bond markets. CC&G also clears Turquoise derivatives. \"Monte Titoli\" (MT) is the pre-settlement, settlement, custody and asset services provider of the Group. MT operates both on-exchange and OTC trades with over 400 banks and brokers.\n\nLondon Stock Exchange's current trading platform is its own Linux-based edition named Millennium Exchange.\n\nTheir old trading platform TradElect was based on Microsoft's .NET Framework, and was developed by Microsoft and Accenture. Microsoft used the LSE software as an example of the supposed superiority of Windows over Linux in the \"Get the Facts\" campaign, claiming that the LSE system provided \"five nines\" reliability, and a processing speed of 3–4 milliseconds. For Microsoft, LSE was a good combination of a highly visible exchange and yet a relatively modest IT problem.\n\nDespite TradElect only being in use for about two years, after suffering multiple periods of extended downtime and unreliability the LSE announced in 2009 that it was planning to switch to Linux in 2010. LSE main market migration to MillenniumIT technology was successfully completed in February 2011.\n\nLSEG now provides high performance technology solutions, including trading, market surveillance and post trade systems for over 40 organisations and exchanges, including the Group's own markets. Additional services include network connectivity, hosting and quality assurance testing. MillenniumIT, GATElab and Exactpro are among the Group's technology companies.\n\nOn 3 May 2000, it was announced that the LSE would merge with the Deutsche Börse; however this fell through.\n\nOn 23 June 2007, the London Stock Exchange announced that it had agreed on the terms of a recommended offer to the shareholders of the Borsa Italiana S.p.A. The merger of the two companies created a leading diversified exchange group in Europe. The combined group was named the London Stock Exchange Group, but still remained two separate legal and regulatory entities. One of the long-term strategies of the joint company is to expand Borsa Italiana's efficient clearing services to other European markets.\n\nIn 2007, after Borsa Italiana announced that it was exercising its call option to acquire full control of MBE Holdings; thus the combined Group would now control Mercato dei Titoli di Stato, or MTS. This merger of Borsa Italiana and MTS with LSE's existing bond-listing business enhanced the range of covered European fixed income markets.\n\nLondon Stock Exchange Group acquired Turquoise (TQ), a Pan-European MTF, in 2009 and since coupling with MillenniumIT's software, it currently offers the fastest latency of any in Europe. Currently the speed of latency on Turquoise (as measured at the end of August 2011) is 97 microseconds on average for 99.9% of trades. Initially founded by a consortium of nine banks, it is now majority-owned by the London Stock Exchange Group. Currently shareholders include twelve of the leading investment banks.\n\nTurquoise operates a maker-taker fee scheme: 0.30 basis points for aggressive traders and 0.20 rebates for passive traders, providing liquidity. The market share of Turquoise as an MTF has doubled over the past twelve months, from 3% to 6%. There are currently 2,000 securities, across 19 countries that are on Turquoise. Unlike Broker-Dealer Crossing Networks, TQ does not discriminate as to who can trade on their platform.\n\nIn December 2005, London Stock Exchange rejected a £1.6 billion takeover offer from Macquarie Bank. London Stock Exchange described the offer as \"derisory\", a sentiment echoed by shareholders in the Exchange. Shortly after Macquarie withdrew its offer, the LSE received an unsolicited approach from NASDAQ valuing the company at £2.4 billion. This too it rejected. NASDAQ later pulled its bid, and less than two weeks later on 11 April 2006, struck a deal with LSE's largest shareholder, Ameriprise Financial's Threadneedle Asset Management unit, to acquire all of that firm's stake, consisting of 35.4 million shares, at £11.75 per share. NASDAQ also purchased 2.69 million additional shares, resulting in a total stake of 15%. While the seller of those shares was undisclosed, it occurred simultaneously with a sale by Scottish Widows of 2.69 million shares. The move was seen as an effort to force LSE to the negotiating table, as well as to limit the Exchange's strategic flexibility.\n\nSubsequent purchases increased NASDAQ's stake to 25.1%, holding off competing bids for several months. United Kingdom financial rules required that NASDAQ wait for a period of time before renewing its effort. On 20 November 2006, within a month or two of the expiration of this period, NASDAQ increased its stake to 28.75% and launched a hostile offer at the minimum permitted bid of £12.43 per share, which was the highest NASDAQ had paid on the open market for its existing shares. The LSE immediately rejected this bid, stating that it \"substantially undervalues\" the company.\n\nNASDAQ revised its offer (characterized as an \"unsolicited\" bid, rather than a \"hostile takeover attempt\") on 12 December 2006, indicating that it would be able to complete the deal with 50% (plus one share) of LSE's stock, rather than the 90% it had been seeking. The U.S. exchange did not, however, raise its bid. Many hedge funds had accumulated large positions within the LSE, and many managers of those funds, as well as Furse, indicated that the bid was still not satisfactory. NASDAQ's bid was made more difficult because it had described its offer as \"final\", which, under British bidding rules, restricted their ability to raise its offer except under certain circumstances.\n\nIn the end, NASDAQ's offer was roundly rejected by LSE shareholders. Having received acceptances of only 0.41% of rest of the register by the deadline on 10 February 2007, Nasdaq's offer duly lapsed. Responding to the news, Chris Gibson-Smith, the LSE's chairman, said: \"The Exchange’s strategy has produced outstanding results for shareholders by facilitating a structural shift in volume growth in an increasingly international market at the centre of the world’s equity flows. The Exchange intends to build on its exceptionally valuable brand by progressing various competitive, collaborative and strategic opportunities, thereby reinforcing its uniquely powerful position in a fast evolving global sector.\"\n\nOn 20 August 2007, NASDAQ announced that it was abandoning its plan to take over the LSE and subsequently look for options to divest its 31% (61.3 million shares) shareholding in the company in light of its failed takeover attempt. In September 2007, NASDAQ agreed to sell the majority of its shares to Borse Dubai, leaving the United Arab Emirates-based exchange with 28% of the LSE.\n\nOn 9 February 2011, London Stock Exchange Group announced it had agreed to merge with the Toronto-based TMX Group, the owners of the Toronto Stock Exchange, creating a combined entity with a market capitalization of listed companies equal to £3.7 trillion. Xavier Rolet, CEO of the LSE Group at the time, would have headed the new enlarged company, while TMX Chief Executive Thomas Kloet would have become the new firm president. London Stock Exchange Group however announced it was terminating the merger with TMX on 29 June 2011 citing that \"LSEG and TMX Group believe that the merger is highly unlikely to achieve the required two-thirds majority approval at the TMX Group shareholder meeting\". Even though LSEG obtained the necessary support from its shareholders, it failed to obtain the required support from TMX's shareholders.\n\nNormal trading sessions on the main orderbook (SETS) are from 08:00 to 16:30 local time every day of the week except Saturdays, Sundays and holidays declared by the exchange in advance. The detailed schedule is as follows:\n\nAuction Periods (SETQx)\n\nSETSqx (Stock Exchange Electronic Trading Service – quotes and crosses) is a trading service for securities less liquid than those traded on SETS.\n\nThe auction uncrossings are scheduled to take place at 8am, 9am, 11am, 2pm and 4:35pm.\n\nHolidays are currently: New Year's Day, Good Friday, Easter Monday, May Bank Holiday, Spring Bank Holiday, Summer Bank Holiday, Christmas Day, and Boxing Day. If New Year's Day, Christmas Day, and/or Boxing Day is on a weekend, the following working day is a holiday.\n\n\n"}
{"id": "191354", "url": "https://en.wikipedia.org/wiki?curid=191354", "title": "Tokyo Stock Exchange", "text": "Tokyo Stock Exchange\n\nThe , which is called or TSE/TYO for short, is a stock exchange located in Tokyo, Japan. It is the third largest stock exchange in the world by aggregate market capitalization of its listed companies, and largest in Asia. It had 2,292 listed companies with a combined market capitalization of US$5.67 trillion as of February 2019.\n\nIn July 2012, a planned merger with the Osaka Securities Exchange was approved by the Japan Fair Trade Commission. The resulting entity, the , was launched on January 1, 2013.\n\nThe TSE is incorporated as a kabushiki gaisha with nine directors, four auditors and eight executive officers. Its headquarters are located at 2-1 Nihonbashi-Kabutochō, Chūō, Tokyo which is the largest financial district in Japan. Its operating hours are from 8:00 to 11:30 a.m., and from 12:30 to 5:00 p.m. From April 24, 2006, the afternoon trading session started at its usual time of 12:30 p.m..\n\nStocks listed on the TSE are separated into the First Section for large companies, the Second Section for mid-sized companies, and the section for high-growth startup companies. As of October 31, 2010, there are 1,675 First Section companies, 437 Second Section companies and 182 Mothers companies.\n\nThe main indices tracking the TSE are the Nikkei 225 index of companies selected by the \"Nihon Keizai Shimbun\" (Japan's largest business newspaper), the TOPIX index based on the share prices of First Section companies, and the J30 index of large industrial companies maintained by Japan's major broadsheet newspapers.\n\nNinety-four domestic and 10 foreign securities companies participate in TSE trading. \"See: Members of the Tokyo Stock Exchange\"\n\nOther TSE-related institutions include:\n\nOn 15 June 2007, the TSE paid $303 million to acquire a 4.99% stake in Singapore Exchange Ltd.\n\nThe Tokyo Stock Exchange was established on May 15, 1878, as the under the direction of then-Finance Minister Ōkuma Shigenobu and capitalist advocate Shibusawa Eiichi. Trading began on June 1, 1878.\n\nIn 1943, the exchange was combined with ten other stock exchanges in major Japanese cities to form a single . The combined exchange was shut down and reorganized shortly after the bombing of Nagasaki.\n\nThe Tokyo Stock Exchange reopened under its current Japanese name on May 16, 1949, pursuant to the new Securities Exchange Act.\n\nThe TSE runup from 1983 to 1990 was unprecedented, in 1990 it accounted for over 60% of the world's stock market capitalization (by far the world's largest) before falling precipitously in value and rank one of the 4th largest exchange in the world by market capitalization of listed shares.\n\nThe current TSE building was opened on May 23, 1988, replacing the original TSE building from 1931, and the trading floor of the TSE was closed on April 30, 1999, so that the exchange could switch to electronic trading for all transactions. A new facility, called , opened on May 9, 2000. In 2010, the TSE launched its Arrowhead trading facility.\n\nIn 2001, the TSE restructured itself as a kabushiki gaisha (\"stock company\"): before this time, it was structured as an with its members as shareholders.\n\nThe exchange was only able to operate for 90 minutes on November 1, 2005, due to bugs with a newly installed transactions system, developed by Fujitsu, which was supposed to help cope with higher trading volumes. The interruption in trading was the worst in the history of the exchange. Trading was suspended for four-and-a-half hours.\n\nDuring the initial public offering of advertising giant Dentsu, in December 2001, a trader at UBS Warburg, the Swiss investment bank, sent an order to sell 610,000 shares in this company at ¥1 each, while he intended to sell 1 share at ¥610,000. The bank lost £71 million.\n\nDuring yet another initial public offering, that of J-Com, on December 8, 2005, an employee at Mizuho Securities Co., Ltd. mistakenly typed an order to sell 600,000 shares at ¥1, instead of an order to sell 1 share at ¥600,000. Mizuho failed to catch the error; the Tokyo Stock Exchange initially blocked attempts to cancel the order, resulting in a net loss of US$347 million to be shared between the exchange and Mizuho. Both companies are now trying to deal with their troubles: lack of error checking, lack of safeguards, lack of reliability, lack of transparency, lack of testing, loss of confidence, and loss of profits. On 11 December, the TSE acknowledged that its system was at fault in the Mizuho trade. On 21 December, Takuo Tsurushima, chief executive of the TSE, and two other senior executives resigned over the Mizuho affair.\n\nOn January 17, 2006, the Nikkei 225 fell 2.8%, its fastest drop in nine months, as investors sold stocks across the board in the wake of a raid by prosecutors on internet company livedoor. The Tokyo Stock Exchange closed early on January 18 due to the trade volume threatening to exceed the exchange's computer system's capacity of 4.5 million trades per day. This was called the \"livedoor shock\". The exchange quickly increased its order capacity to five million trades a day.\n\nThe exchange's normal trading sessions are from 9:00 a.m. to 11:30 a.m. and from 12:30 p.m. to 3:00 p.m. on all days of the week except Saturdays, Sundays and holidays declared by the Exchange in advance. The exchange is closed for the following holidays: New Year's Day, Coming of Age Day, National Foundation Day, Vernal Equinox Day, Shōwa Day, Constitution Memorial Day, Greenery Day, Children's Day, Marine Day, Respect for the Aged Day, Autumnal Equinox, Health and Sports Day, Culture Day, Labour Thanksgiving Day, and The Emperor's Birthday.\n\nCorporate shares are listed and traded at Tokyo Stock Exchange in several sections: the First Section which started when Tokyo Stock Exchange was re-established in 1949 and includes mainly large companies; the Second Section which started in 1961 and includes mainly mid-sized companies; JASDAQ (established in 1991, acquired by Osaka Stock Exchange in 2010, and absorbed into TSE in 2013) and Mothers (Market of the high-growth and emerging stocks, \nin Japanese: , established at TSE in 1999) which are both for emerging companies; and TOKYO PRO Market (in Japanese: ) which was established in 2009 jointly with London Stock Exchange as an AIM.\n\nThere were a total of 3,607 companies listed in Tokyo Stock Exchange, as of March 31, 2018.\n\nThere are also active bond market and futures market.\n\nThe London Stock Exchange (LSE) and the TSE are developing jointly traded products and share technology, marking the latest cross-border deal among bourses as international competition heats up.\n\nIn July 2008, the LSE and the TSE announced a new joint venture Tokyo-based market, which will be based on the LSE's Alternative Investment Market (AIM).\n\n\n"}
