{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "import spacy\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "#import our_metrics\n",
    "\n",
    "TRAIN_FILE = Path(\"data/train/english_combine_train.txt\")\n",
    "TEST_FILE = Path(\"data/test/english_combine_test.txt\")\n",
    "#TEST_FILE = Path(\"data/test.tsv\")\n",
    "\n",
    "LABELS = [0,1, 2, 3, 4, 5, 6, 7, 8, 9,10,11,12,13,14,15,16,17,18,19]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_file(data_file):\n",
    "    print(\"Loading from {} ...\".format(data_file.name), end=\"\")\n",
    "    \n",
    "    data = {}\n",
    "    data[\"sentence\"] = []\n",
    "    data[\"label\"] = []\n",
    "    \n",
    "    with open(data_file,\"r\",encoding=\"utf8\") as f:\n",
    "        lines=f.read().split('\\n')\n",
    "        for id in range(len(lines) -1):\n",
    "            sent = lines[id].split('\\t')[0]\n",
    "            lab = lines[id].split('\\t')[1]\n",
    "            data[\"sentence\"].append(sent)\n",
    "            data[\"label\"].append(lab)\n",
    "    return data[\"sentence\"], data[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from english_combine_train.txt ...Loading from english_combine_test.txt ...10000\n"
     ]
    }
   ],
   "source": [
    "train_X,train_y = load_data_file(TRAIN_FILE)\n",
    "test_X,test_y = load_data_file(TEST_FILE)\n",
    "print(len(test_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_pipeline = Pipeline(\n",
    "        steps = [(\"ngram\",CountVectorizer()) , (\"bayes\", ComplementNB()),],\n",
    "    )\n",
    "\n",
    "logistic_pipeline = Pipeline(\n",
    "        steps = [(\"ngram\",CountVectorizer()) , (\"logistic\", LogisticRegression()),],\n",
    "    )\n",
    "\n",
    "SVM_pipeline = Pipeline(\n",
    "        steps = [(\"ngram\",CountVectorizer()) , (\"SVM\", SVC()),],\n",
    "    )\n",
    "\n",
    "Forest_pipeline = Pipeline(\n",
    "        steps = [(\"ngram\",CountVectorizer()) , (\"Forest\", RandomForestClassifier(n_estimators=200)),],\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB \n",
      " ==\n",
      "For train data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.82      0.72     19378\n",
      "           1       0.77      0.66      0.71      9108\n",
      "          10       0.90      0.76      0.82      2659\n",
      "          11       0.66      0.85      0.74      3106\n",
      "          12       0.58      0.79      0.67      2466\n",
      "          13       0.91      0.53      0.67      2238\n",
      "          14       0.93      0.58      0.72      2390\n",
      "          15       0.89      0.59      0.71      2238\n",
      "          16       0.93      0.58      0.72      2224\n",
      "          17       0.64      0.91      0.75      2538\n",
      "          18       0.83      0.77      0.80      3251\n",
      "          19       0.93      0.57      0.71      2023\n",
      "           2       0.61      0.86      0.71      8887\n",
      "           3       0.83      0.50      0.63      4978\n",
      "           4       0.71      0.84      0.77      5504\n",
      "           5       0.89      0.53      0.66      3621\n",
      "           6       0.85      0.64      0.73      3653\n",
      "           7       0.73      0.64      0.68      4064\n",
      "           8       0.84      0.53      0.65      3062\n",
      "           9       0.92      0.54      0.68      2612\n",
      "\n",
      "    accuracy                           0.72     90000\n",
      "   macro avg       0.80      0.67      0.71     90000\n",
      "weighted avg       0.75      0.72      0.71     90000\n",
      "\n",
      "\n",
      "For test data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.52      0.44      2180\n",
      "           1       0.24      0.18      0.21      1001\n",
      "          10       0.21      0.12      0.15       317\n",
      "          11       0.43      0.64      0.51       371\n",
      "          12       0.24      0.38      0.29       261\n",
      "          13       0.18      0.06      0.09       222\n",
      "          14       0.08      0.03      0.04       293\n",
      "          15       0.18      0.08      0.11       255\n",
      "          16       0.05      0.02      0.03       235\n",
      "          17       0.48      0.77      0.59       286\n",
      "          18       0.26      0.19      0.22       452\n",
      "          19       0.06      0.02      0.03       201\n",
      "           2       0.29      0.51      0.37       888\n",
      "           3       0.14      0.06      0.08       512\n",
      "           4       0.38      0.50      0.43       729\n",
      "           5       0.01      0.01      0.01       309\n",
      "           6       0.22      0.14      0.17       392\n",
      "           7       0.29      0.21      0.25       579\n",
      "           8       0.14      0.08      0.10       283\n",
      "           9       0.06      0.03      0.04       234\n",
      "\n",
      "    accuracy                           0.31     10000\n",
      "   macro avg       0.22      0.23      0.21     10000\n",
      "weighted avg       0.27      0.31      0.28     10000\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for name, pipeline in (\n",
    "    [\"NB\",nb_pipeline,],\n",
    "    [\"LR\",logistic_pipeline,],\n",
    "    #[\"SVM\",SVM_pipeline,],\n",
    "    [\"RandomForest\",Forest_pipeline,],\n",
    "    ):\n",
    "    pipeline.fit(train_X,train_y)\n",
    "    train_pred = pipeline.predict(train_X)\n",
    "    test_pred = pipeline.predict(test_X)\n",
    "    print(name,\"\\n\",\"=\" * len(name))\n",
    "    \n",
    "    for split, y, pred in [\n",
    "        (\"train\", train_y, train_pred),\n",
    "        (\"test\", test_y, test_pred),\n",
    "    ]:\n",
    "        print(\"For {} data\".format(split))\n",
    "        print(classification_report(y,pred))\n",
    "        print()\n",
    "    \n",
    "    with open('data/test/english_result_'+str(name)+'.prediction',mode='wt',encoding='utf-8') as myfile:\n",
    "        myfile.write('\\n'.join([str(x) for x in test_pred]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro F-Score (official): 20.753\r\n",
      "-----\r\n",
      "Micro F-Score: 31.15\r\n",
      "Precision: 31.15\r\n",
      "Recall: 31.15\r\n"
     ]
    }
   ],
   "source": [
    "!python scorer_semeval18.py data/test/english_test.labels data/test/english_result_NB.prediction\n",
    "!python scorer_semeval18.py data/test/english_test.labels data/test/english_result_LR.prediction\n",
    "!python scorer_semeval18.py data/test/english_test.labels data/test/english_result_RandomForest.prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
