{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "import spacy\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "#import our_metrics\n",
    "\n",
    "TRAIN_FILE = Path(\"data/train/spanish_with_extra_english.txt\")\n",
    "TEST_FILE = Path(\"data/test/spanish_combine_test.txt\")\n",
    "#TEST_FILE = Path(\"data/test.tsv\")\n",
    "\n",
    "LABELS = [0,1, 2, 3, 4, 5, 6, 7, 8, 9,10,11,12,13,14,15,16,17,18,19]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_file(data_file):\n",
    "    print(\"Loading from {} ...\".format(data_file.name), end=\"\")\n",
    "    \n",
    "    data = {}\n",
    "    data[\"sentence\"] = []\n",
    "    data[\"label\"] = []\n",
    "    \n",
    "    with open(data_file,\"r\",encoding=\"utf8\") as f:\n",
    "        lines=f.read().split('\\n')\n",
    "        for id in range(len(lines) -1):\n",
    "            sent = lines[id].split('\\t')[0]\n",
    "            lab = lines[id].split('\\t')[1]\n",
    "            data[\"sentence\"].append(sent)\n",
    "            data[\"label\"].append(lab)\n",
    "    return data[\"sentence\"], data[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from spanish_with_extra_english.txt ...Loading from spanish_combine_test.txt ...1000\n"
     ]
    }
   ],
   "source": [
    "train_X,train_y = load_data_file(TRAIN_FILE)\n",
    "test_X,test_y = load_data_file(TEST_FILE)\n",
    "print(len(test_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_pipeline = Pipeline(\n",
    "        steps = [(\"ngram\",CountVectorizer()) , (\"bayes\", ComplementNB()),],\n",
    "    )\n",
    "\n",
    "logistic_pipeline = Pipeline(\n",
    "        steps = [(\"ngram\",CountVectorizer()) , (\"logistic\", LogisticRegression()),],\n",
    "    )\n",
    "\n",
    "\n",
    "# Forest_pipeline = Pipeline(\n",
    "#         steps = [(\"ngram\",CountVectorizer()) , (\"Forest\", RandomForestClassifier(n_estimators=200)),],\n",
    "#     )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB \n",
      " ==\n",
      "For train data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.84      0.73     25523\n",
      "           1       0.79      0.68      0.73     12744\n",
      "          10       0.81      0.68      0.74      4617\n",
      "          11       0.85      0.55      0.67      3972\n",
      "          12       0.91      0.54      0.68      2978\n",
      "          13       0.94      0.60      0.73      2738\n",
      "          14       0.71      0.75      0.73       370\n",
      "          15       0.72      0.69      0.70      5252\n",
      "          16       0.55      0.90      0.68       455\n",
      "          17       0.74      0.77      0.75       385\n",
      "          18       0.92      0.61      0.74      2901\n",
      "           2       0.66      0.88      0.76     12087\n",
      "           3       0.85      0.52      0.65      6513\n",
      "           4       0.88      0.58      0.70      5048\n",
      "           5       0.89      0.57      0.69      3618\n",
      "           6       0.53      0.94      0.67       652\n",
      "           7       0.93      0.62      0.74      3476\n",
      "           8       0.68      0.80      0.74       482\n",
      "           9       0.35      0.96      0.52       756\n",
      "\n",
      "    accuracy                           0.72     94567\n",
      "   macro avg       0.76      0.71      0.70     94567\n",
      "weighted avg       0.76      0.72      0.72     94567\n",
      "\n",
      "\n",
      "For test data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.18      0.25       204\n",
      "           1       0.26      0.30      0.28       136\n",
      "          10       0.08      0.03      0.04        34\n",
      "          11       0.16      0.05      0.08        57\n",
      "          12       0.11      0.03      0.05        30\n",
      "          13       0.05      0.02      0.03        41\n",
      "          14       0.00      0.00      0.00         5\n",
      "          15       0.21      0.06      0.09        51\n",
      "          16       0.09      0.26      0.13        19\n",
      "          17       0.07      0.11      0.08         9\n",
      "          18       0.12      0.05      0.07        19\n",
      "           2       0.45      0.59      0.51       157\n",
      "           3       0.00      0.00      0.00        34\n",
      "           4       0.00      0.00      0.00        41\n",
      "           5       0.13      0.12      0.13        40\n",
      "           6       0.09      0.41      0.15        22\n",
      "           7       0.11      0.07      0.08        46\n",
      "           8       0.03      0.06      0.04        18\n",
      "           9       0.19      0.65      0.29        37\n",
      "\n",
      "    accuracy                           0.23      1000\n",
      "   macro avg       0.14      0.16      0.12      1000\n",
      "weighted avg       0.24      0.23      0.21      1000\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for name, pipeline in (\n",
    "    [\"NB\",nb_pipeline,],\n",
    "   \n",
    "    ):\n",
    "    pipeline.fit(train_X,train_y)\n",
    "    train_pred = pipeline.predict(train_X)\n",
    "    test_pred = pipeline.predict(test_X)\n",
    "    print(name,\"\\n\",\"=\" * len(name))\n",
    "    \n",
    "    for split, y, pred in [\n",
    "        (\"train\", train_y, train_pred),\n",
    "        (\"test\", test_y, test_pred),\n",
    "    ]:\n",
    "        print(\"For {} data\".format(split))\n",
    "        print(classification_report(y,pred))\n",
    "        print()\n",
    "    \n",
    "    with open('data/test/spanish_combined_result_'+str(name)+'.prediction',mode='wt',encoding='utf-8') as myfile:\n",
    "        myfile.write('\\n'.join([str(x) for x in test_pred]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro F-Score (official): 12.242\r\n",
      "-----\r\n",
      "Micro F-Score: 22.8\r\n",
      "Precision: 22.8\r\n",
      "Recall: 22.8\r\n"
     ]
    }
   ],
   "source": [
    "!python scorer_semeval18.py data/test/spanish_test.labels data/test/spanish_combined_result_NB.prediction\n",
    "#!python scorer_semeval18.py data/test/spanish_test.labels data/test/spanish_result_LR.prediction\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
