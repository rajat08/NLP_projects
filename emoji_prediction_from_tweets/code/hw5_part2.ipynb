{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "import spacy\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "#import our_metrics\n",
    "\n",
    "TRAIN_FILE = Path(\"data/train/spanish_combine_train.txt\")\n",
    "TEST_FILE = Path(\"data/test/spanish_combine_test.txt\")\n",
    "#TEST_FILE = Path(\"data/test.tsv\")\n",
    "\n",
    "LABELS = [0,1, 2, 3, 4, 5, 6, 7, 8, 9,10,11,12,13,14,15,16,17,18,19]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_file(data_file):\n",
    "    print(\"Loading from {} ...\".format(data_file.name), end=\"\")\n",
    "    \n",
    "    data = {}\n",
    "    data[\"sentence\"] = []\n",
    "    data[\"label\"] = []\n",
    "    \n",
    "    with open(data_file,\"r\",encoding=\"utf8\") as f:\n",
    "        lines=f.read().split('\\n')\n",
    "        for id in range(len(lines) -1):\n",
    "            sent = lines[id].split('\\t')[0]\n",
    "            lab = lines[id].split('\\t')[1]\n",
    "            data[\"sentence\"].append(sent)\n",
    "            data[\"label\"].append(lab)\n",
    "    return data[\"sentence\"], data[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from spanish_combine_train.txt ...Loading from spanish_combine_test.txt ...1000\n"
     ]
    }
   ],
   "source": [
    "train_X,train_y = load_data_file(TRAIN_FILE)\n",
    "test_X,test_y = load_data_file(TEST_FILE)\n",
    "print(len(test_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_pipeline = Pipeline(\n",
    "        steps = [(\"ngram\",CountVectorizer()) , (\"bayes\", ComplementNB()),],\n",
    "    )\n",
    "\n",
    "logistic_pipeline = Pipeline(\n",
    "        steps = [(\"ngram\",CountVectorizer()) , (\"logistic\", LogisticRegression()),],\n",
    "    )\n",
    "\n",
    "\n",
    "# Forest_pipeline = Pipeline(\n",
    "#         steps = [(\"ngram\",CountVectorizer()) , (\"Forest\", RandomForestClassifier(n_estimators=200)),],\n",
    "#     )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB \n",
      " ==\n",
      "For train data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.90      0.80      3965\n",
      "           1       0.87      0.81      0.84      2635\n",
      "          10       0.93      0.80      0.86       572\n",
      "          11       0.94      0.68      0.79       627\n",
      "          12       0.94      0.66      0.78       518\n",
      "          13       0.95      0.79      0.86       514\n",
      "          14       0.95      0.65      0.77       370\n",
      "          15       0.90      0.76      0.83       609\n",
      "          16       0.91      0.87      0.89       455\n",
      "          17       0.92      0.64      0.76       385\n",
      "          18       0.95      0.77      0.85       442\n",
      "           2       0.80      0.94      0.87      2312\n",
      "           3       0.90      0.69      0.78      1023\n",
      "           4       0.90      0.78      0.83      1118\n",
      "           5       0.91      0.72      0.81       772\n",
      "           6       0.88      0.89      0.89       652\n",
      "           7       0.94      0.82      0.88       793\n",
      "           8       0.93      0.75      0.83       482\n",
      "           9       0.61      0.93      0.74       756\n",
      "\n",
      "    accuracy                           0.82     19000\n",
      "   macro avg       0.89      0.78      0.82     19000\n",
      "weighted avg       0.84      0.82      0.82     19000\n",
      "\n",
      "\n",
      "For test data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.32      0.45      0.37       204\n",
      "           1       0.24      0.21      0.23       136\n",
      "          10       0.06      0.03      0.04        34\n",
      "          11       0.12      0.04      0.05        57\n",
      "          12       0.09      0.03      0.05        30\n",
      "          13       0.07      0.02      0.04        41\n",
      "          14       0.00      0.00      0.00         5\n",
      "          15       0.24      0.08      0.12        51\n",
      "          16       0.16      0.16      0.16        19\n",
      "          17       0.00      0.00      0.00         9\n",
      "          18       0.10      0.05      0.07        19\n",
      "           2       0.41      0.66      0.51       157\n",
      "           3       0.00      0.00      0.00        34\n",
      "           4       0.04      0.05      0.05        41\n",
      "           5       0.15      0.12      0.14        40\n",
      "           6       0.15      0.23      0.18        22\n",
      "           7       0.18      0.09      0.12        46\n",
      "           8       0.00      0.00      0.00        18\n",
      "           9       0.27      0.38      0.31        37\n",
      "\n",
      "    accuracy                           0.27      1000\n",
      "   macro avg       0.14      0.14      0.13      1000\n",
      "weighted avg       0.22      0.27      0.23      1000\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:938: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR \n",
      " ==\n",
      "For train data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.96      0.78      3965\n",
      "           1       0.83      0.87      0.85      2635\n",
      "          10       0.96      0.76      0.85       572\n",
      "          11       0.97      0.63      0.76       627\n",
      "          12       0.98      0.61      0.75       518\n",
      "          13       0.98      0.74      0.84       514\n",
      "          14       0.98      0.59      0.73       370\n",
      "          15       0.94      0.76      0.84       609\n",
      "          16       0.96      0.84      0.90       455\n",
      "          17       0.98      0.52      0.68       385\n",
      "          18       0.99      0.76      0.86       442\n",
      "           2       0.86      0.95      0.90      2312\n",
      "           3       0.92      0.69      0.79      1023\n",
      "           4       0.91      0.79      0.85      1118\n",
      "           5       0.91      0.71      0.80       772\n",
      "           6       0.95      0.87      0.91       652\n",
      "           7       0.96      0.82      0.89       793\n",
      "           8       0.93      0.71      0.80       482\n",
      "           9       0.84      0.87      0.85       756\n",
      "\n",
      "    accuracy                           0.83     19000\n",
      "   macro avg       0.92      0.76      0.82     19000\n",
      "weighted avg       0.86      0.83      0.83     19000\n",
      "\n",
      "\n",
      "For test data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.32      0.64      0.43       204\n",
      "           1       0.27      0.33      0.30       136\n",
      "          10       0.10      0.03      0.05        34\n",
      "          11       0.20      0.04      0.06        57\n",
      "          12       0.00      0.00      0.00        30\n",
      "          13       0.00      0.00      0.00        41\n",
      "          14       0.00      0.00      0.00         5\n",
      "          15       0.18      0.06      0.09        51\n",
      "          16       0.38      0.16      0.22        19\n",
      "          17       0.00      0.00      0.00         9\n",
      "          18       0.00      0.00      0.00        19\n",
      "           2       0.42      0.62      0.51       157\n",
      "           3       0.00      0.00      0.00        34\n",
      "           4       0.03      0.02      0.03        41\n",
      "           5       0.24      0.15      0.18        40\n",
      "           6       0.17      0.14      0.15        22\n",
      "           7       0.00      0.00      0.00        46\n",
      "           8       0.00      0.00      0.00        18\n",
      "           9       0.44      0.32      0.38        37\n",
      "\n",
      "    accuracy                           0.30      1000\n",
      "   macro avg       0.14      0.13      0.13      1000\n",
      "weighted avg       0.23      0.30      0.25      1000\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for name, pipeline in (\n",
    "    [\"NB\",nb_pipeline,],\n",
    "    [\"LR\",logistic_pipeline]\n",
    "    ):\n",
    "    pipeline.fit(train_X,train_y)\n",
    "    train_pred = pipeline.predict(train_X)\n",
    "    test_pred = pipeline.predict(test_X)\n",
    "    print(name,\"\\n\",\"=\" * len(name))\n",
    "    \n",
    "    for split, y, pred in [\n",
    "        (\"train\", train_y, train_pred),\n",
    "        (\"test\", test_y, test_pred),\n",
    "    ]:\n",
    "        print(\"For {} data\".format(split))\n",
    "        print(classification_report(y,pred))\n",
    "        print()\n",
    "    \n",
    "    with open('data/test/spanish_result_'+str(name)+'.prediction',mode='wt',encoding='utf-8') as myfile:\n",
    "        myfile.write('\\n'.join([str(x) for x in test_pred]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro F-Score (official): 12.763\n",
      "-----\n",
      "Micro F-Score: 26.6\n",
      "Precision: 26.6\n",
      "Recall: 26.6\n",
      "Macro F-Score (official): 12.548\n",
      "-----\n",
      "Micro F-Score: 30.5\n",
      "Precision: 30.5\n",
      "Recall: 30.5\n"
     ]
    }
   ],
   "source": [
    "!python scorer_semeval18.py data/test/spanish_test.labels data/test/spanish_result_NB.prediction\n",
    "!python scorer_semeval18.py data/test/spanish_test.labels data/test/spanish_result_LR.prediction\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
